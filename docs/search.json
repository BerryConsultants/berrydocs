[
  {
    "objectID": "releaseNotes/v7/facts711.html",
    "href": "releaseNotes/v7/facts711.html",
    "title": "FACTS 7.1.1 Release Notes",
    "section": "",
    "text": "1 Introduction\n\n\n2 FACTS Core and Staged Improvements\n\nIn Staged design, conditional power of current stage 2 when no control arm is carried to stage 2 is handled correctly."
  },
  {
    "objectID": "releaseNotes/v7/facts700.html",
    "href": "releaseNotes/v7/facts700.html",
    "title": "FACTS 7.0.0 Release Notes",
    "section": "",
    "text": "1 Introduction\nFACTS 7.0.0 is now available for download via App Center. This release marks the addition of two new FACTS design types: Platform Trial Design – Continuous and Platform Trial Design – Dichotomous.\nPlease contact us regarding any questions.\n\n\n2 FACTS Platform Trial Features\nWithin these new Platform Trial design types, FACTS users can now:\n\nSimulate a platform trial, for a continuous/dichotomous endpoint, with various trial level participant and arm constraints. In particular, users can specify a maximum enrollment time, number of participants, successful treatments, participants per arm and concurrent treatments.\nSimulate a platform trial with treatments arriving at different times during the trial.\nSpecify simulated mean arm responses/effects to be a fixed value or sampled from a distribution.\nSimulate participant accrual, responses, and dropout rates as per FACTS Core.\nSpecify a constant proportion of participants allocated to the control arm, or an allocation dependent on the number of treatments currently in the trial, with the option of performing response adaptive randomization.\nAnalyze participant data and estimate mean treatment responses using a Bayesian independent arm model, or frequentist p-values, comparing treatment arms to a common control arm.\nSpecify “Trial Update” information and frequency, at which analyses are performed and allocation ratios may get updated.\nSpecify when to evaluate “Treatment Milestones”, at which decisions are made about treatment outcomes.\nSpecify success/futility criteria that apply to all treatments, or to specific treatments.\nClassify treatments as Good, Mediocre or Unacceptable to get summary statistics such as the proportion of ‘Good’ treatments that are successful/inconclusive/unsuccessful and similarly for the other classifications.\nView granular simulation and summary results of various Platform Trial operating characteristics.\nGenerate a Platform Trial design report outlining the characteristics of the simulated design in a Word document.\n\n\n\n3 FACTS Core and Staged Improvements\n\nIn FACTS Core and Staged designs (except Time-to-Event designs), users can now simulate single arm trials, with options for both Bayesian and Frequentist p-values to be calculated comparing the data on the experimental arm to an objective reference response/response rate specified on the QOI tab.\nFACTS Core and Staged designs (except Time-to-Event designs) will now correctly handle frequentist calculations when a control arm is not present and comparison is performed against an objective reference response/response rate.\np-value calculations have been updated to better accommodate their use at interims, with dropouts and incomplete subjects now handled differently. No incomplete subjects have a final endpoint imputed, but subjects that are known dropouts and have had the opportunity to complete are imputed/ignored according to the “Handle missingness” option for the p-value.\nLOCF behavior has been made consistent. LOCF will impute a participant’s baseline value as their final outcome if a baseline value is observed and no non-baseline visit data is observed.\nFACTS Staged designs will now correctly handle the mirroring of Stage 1 data in Stage 2 for the Dose Response and Longitudinal models.\n\n\n\n4 FACTS Enrichment Design Improvements\n\nIn FACTS Enrichment Time-to-Event designs, FACTS will now correctly apply the user specified alpha levels per group when calculating frequentist output summaries.\nIn FACTS Enrichment Time-to-Event designs, FACTS will now correctly calculate frequentist output when the underlying design has only specified one group.\nIn FACTS Enrichment designs, FACTS will now enforce group caps to be strictly greater than zero.\n\n\n\n5 FACTS Dose Escalation Improvements\n\nOn the Analysis tab, FACTS will now enforce the specification of the cohort number when uploading a subject data file to run an analysis.\nIn 2D-CRM, FACTS will now correctly handle a rare situation in the row-by-row run-in scheme.\nIn 2D-CRM, the engines when run in a Linux environment will have a correctly formatted simulation results output header.\n\n\n\n6 General Improvements\n\nBREAKING CHANGE: FACTS will now consistently handle the “Date” column in a patients file to be in weeks rather than days, making it consistent with the rest of FACTS. “Patients” files generated from FACTS simulations will report the “Date” column as “DateInWeeks” to avoid any ambiguity.\nBREAKING CHANGE: The “Date” column in Deterministic Accrual external data files will need to be manually updated to specify the date in weeks rather than days.\nBREAKING CHANGE: The “Date” column in subject data file provided when running a FACTS Analysis will need to be updated to specify the date in weeks rather than days. If performing FACTS Analysis via the GUI, the FACTS Analysis tab provides a “Convert Date from Days to Weeks” utility that does the conversion.\nThe precision of results output in FACTS will now consistently be up to 6 decimal places for all design types, except for Time-to-Event designs which will display output up to 8 decimal places.\nFACTS will now correctly handle interactions with the latest version of RStudio to date (2023.03.0). This includes the generation of design reports and the importing of FACTS results output to RStudio via the “Open in R” button on the Simulation tab. Note that FACTS will continue to support older version of RStudio.",
    "crumbs": [
      "Release Notes",
      "FACTS 7 Release Notes",
      "FACTS 7.0.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts641.html",
    "href": "releaseNotes/v6/facts641.html",
    "title": "FACTS 6.4.1 Release Notes",
    "section": "",
    "text": "1 Introduction\nBerry Consultants would like to announce a new maintenance release, FACTS 6.4.1. FACTS 6.4.1 contains the following improvements to the FACTS 6.4.0 version. Please contact us regarding any questions.\n\n\n2 FACTS (Staged) Core Improvements\n\nIn Time-to-Event designs, the sigmoidal, 3-parameter logistic and hierarchical logistic dose response models have been improved to better handle their respective likelihood evaluation. Namely, when the dose response is non-monotone, or the doses are widely separated.\nIn Time-to-Event designs, the prior for the sigmoidal model’s a2 parameter is now properly applied. As a result, estimates for the sigmoidal model’s a1 and a2 parameter have now been corrected.\nIn Time-to-Event designs, the option to model control separately in TTE predictor models is now applied correctly.\nIn Dichotomous designs, selecting the “Log-odds” parametrization of Posterior Probability QOIs will no longer be rejected as invalid if the Delta values for comparison are outside of [-1, 1].\nIn Multiple Endpoint designs with a dichotomous endpoint, Posterior Probability QOIs with the “Log-odds” parametrization will now be computed correctly.\nA very rare bug has been fixed that occurred when an adaptive design was converted back to a fixed design. The simulator would check the now irrelevant details of the interims and crash.\n\n\n\n3 FACTS Dose Escalation Improvements\n\nIn CRM(Efficacy) designs, FACTS files created with FACTS 6.1.0 or older versions will have their “Model control separately” setting correctly migrated over in FACTS 6.4.1 and later versions.\nIn N-CRM designs, the number of beta distribution samples in the specific quantiles prior derivation algorithm has been increased from 1,000 to 10,000.\nIn Dose Escalation designs, Windows and Linux simulation result differences have been resolved.\nIn 2D-CRM dose values of 0 are now allowed with some restrictions:\n\nany combination where the transformed dose strengths of both drugs are very low (or 0) must be excluded from the study and not have any prior toxicities specified as to have occurred on that combination. The model cannot fit toxicity on such combinations.\nif there is a combination where the transformed dose strength of both drugs are 0, the response model must be re-scaled (using the “Asymptotes” option) so the lower bound is not asymptotically 0, but some value slightly above that (such as 0.0001).\n\nIn 2D-CRM the prior graph on the Response Model tab can now show the sampled priors for the individual drugs without the lowest dose being plotted (when a dose 0 or very low dose is included this can compress the plot for all the other doses). The x-axis has also been re-labelled to make it clear the doses are being plotted at the log of their transformed dose values.\nIn N-CRM if using Open Enrolment and Backfill, the “Max Study Allocation for Escalation” was not being respected, this is fixed in FACTS 6.4.1.\n\n\n\n4 FACTS Enrichment Design Improvements\n\nFACTS will no longer error when running multiple scenarios when using external data files.\n\n\n\n5 Framework Improvements\n\nSimulation of FACTS files stored on a shared drive will be handled more robustly in the case of intermittent connectivity to the shared drive.\nRenaming of FACTS analyses on the Analysis tab will now correctly handle the situation when the analysis name has been unchanged.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.4.1 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts630.html",
    "href": "releaseNotes/v6/facts630.html",
    "title": "FACTS 6.3.0 Release Notes",
    "section": "",
    "text": "FACTS 6.3.0 is now available for official release. This version contains significant changes to FACTS N-CRM Open Enrollment to make it more efficient, and adds to FACTS Core and FACTS Staged Designs (Continuous, Dichotomous and Multiple Endpoint) options to model arms that differ in strength along 2 dimensions (for example, but not limited to: dose strength and dosing frequency). Please contact us regarding any questions.\nIn detail the new features in FACTS 6.3.0 are:\n\nIn FACTS Dose Escalation N-CRM the open enrollment option has been improved:\n\nThe limit of the “maximum number of subjects without final results” is now applied per dose not overall. This means that after escalating to a higher dose, allocation is not held up waiting for later subjects on the lower dose to complete. Accrual is faster, fewer subjects are lost. If you are thinking of doing an open enrollment N-CRM design, we strongly recommend you update to FACTS 6.3.0.\nThe user supplies two limits, one used while allocating to an “uncleared” dose, the other used when allocating to a “cleared” dose (and hence allocating to the MTD).\nIf recruiting 2 groups, different maximums can be specified for the second group.\nThere is now an option so that the simulation of Open enrollment only “pauses” when the early stopping criteria are met, allowing enrollment to be re-started if the final follow up data move MTD to a dose where the stopping criteria are not met.\n\nIn FACTS Dose Escalation N-CRM the open enrollment option has a new feature, the option to use “backfill”. Enabling “backfill” allows a subject who would otherwise be lost (because the “maximum number of subjects without final results” is currently met) to be allocated to a lower dose. There are parameters to control the backfill:\n\nseparate trial maximums can be specified for the subjects allocated in escalation or to the MTD, or in backfill.\nlimits on how many subjects can be on a dose for it to be open for backfill.\nlimits on how high the dose must be before it is open for backfill.\nlimits on how close a dose must be to the current dose for it to be open for backfill.\n\nIn FACTS Dose Escalation N-CRM there are now more “run-in” options:\n\nsimple run-in (as in FACTS 6.2.0)\ncustom run-in – where the user precisely specifies the sequence of doses to be tested and the number of subjects to test at each dose.\nsmall cohort pre-escalation – this follows the full escalation rules, including overdose control but with a smaller cohort size – and the same number of cohorts required to clear doses. Like all run-ins, it ends when a toxicity is observed.\n\nIn FACTS Dose Escalation N-CRM the calculation of the likelihood when analyzing an Ordinal Toxicity endpoint has been improved. This means however that a design using Ordinal Toxicity created under FACTS 6.2.0 is likely to behave noticeably differently under FACTS 6.3.0. If the design is well advanced, or in use, you are advised to stay with using FACTS 6.2.0 for that design. If you are just starting out designing an Ordinal Toxicity endpoint N-CRM we recommend upgrading to FACTS 6.3.0.\nFACTS Core and FACTS Staged Designs features a new 2D treatment arm option and associated 2D response models. The 2D options are available for the Continuous, Dichotomous and Multiple Endpoints. The 2D treatment arm option allows:\n\nArms to be defined as a combination of 2 “factors” e.g. dose strength and dosing frequency, or dose strengths of two different agents.\nThe combinations can be analyzed independently, mapped onto a 1D ordering and analyzed with any of the standard 1D dose models, or with one of the three new 2D response models: a 2D NDLM, a 2D continuous factorial model, or a 2D discrete factorial model.\nTarget Quantities of Interest can be defined to be confined to those combinations in a particular row or column (e.g. the calculate the Pr(max) of the once a day doses).\n\nIn FACTS Enrichment Designs the implementation of fitting of the Hierarchical model (options for treatment arms across groups and control arms across group) have been improved. They should converge somewhat faster and at the FACTS default MCMC sample length (2500), will typically be more accurate than before.\n\nThis release addresses some situations in FACTS 6.2.0 that could cause errors. If any of your designs replicate these circumstances, you are recommended to upgrade to FACTS 6.3.0:\n\nIn FACTS 6.2.0 Dose Escalation 3+3, the simulations don’t properly implement the re-escalation rules after de-escalation. This was introduced when we made the significant extensions to N-CRM in FACTS 6.2.0.\nIn FACTS 6.2.0 Dose Escalation N-CRM many “pseudo-patients” parameters are not interpreted correctly.\nIn FACTS 6.2.0 Enrichment Designs with a Continuous endpoint, when using the Linear Regression Longitudinal Model, it fitted incorrectly when informative priors were used.\nIn FACTS 6 Core with a Continuous endpoint and simulating baseline, calculating a p-value QOI, with BOCF for missing data, the BOCF value for missing subjects was being set incorrectly (only a problem if baseline values are very difference from 0).\n\nThe following minor issues in the FACTS GUI were also fixed:\n\nIn FACTS Dose Escalation with N-CRM when specifying an open enrollment design, maximum subjects on MTD for “clearing” a dose and for stopping are meant to be entered in “subjects” but the GUI interpreted the input as “cohorts’ using whatever was the last cohort size in that “.facts” file.\nWhen using the “Ppn Correct Arm” in FACTS Core by marking arms as “should succeed” in the VSR profiles, if variants were not enabled, the variant target QOI arm selection criteria would incorrectly re-set to “Pr(Max)” when re-opening the file.\nWhen using a large external data file, running simulations with lots of packets could cause “out-of-memory” issues. Finally, some enhancements and fixes in the Design Report in FACTS Core have been implemented.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.3.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts624.html",
    "href": "releaseNotes/v6/facts624.html",
    "title": "FACTS 6.2.4 Release Notes",
    "section": "",
    "text": "Berry Consultants would like to announce a new maintenance release, FACTS 6.2.4. FACTS 6.2.4 contains the following fixes to the FACTS 6.2.3 version:\nUpdating to 6.2.4 is recommended for those of you wishing to use predictive probabilities in FACTS Core TTE, in combination with a TTE predictor endpoint:\n\nIn FACTS Core with a Time-to-Event end point and a Time-to-Event predictor, the imputations of final event times for subjects with a predictor event but no final event during the estimation of “predictive probability of success at full enrolment” could produce an error in the prior version. There are two rare situations in FACTS 6.2.3 that uncover a bug in the dose escalation simulator and causes it to produce an error:\nIn FACTS Dose Escalation, in the N-CRM with only 3 doses the simulator could produce an error during some dose escalation decisions.\nIn FACTS Dose Escalation CRM (Toxicity) could produce an error when simulating 2 samples. The remaining, minor fixes in FACTS 6.2.4 are:\nIn FACTS N-CRM, the GUI was improved to handle the “Variant” options making is easier to change them once they were set.\nA fix to FACTS Dose Escalation 3+3 (!) – improved to handle the circumstance when the starting dose is not the lowest dose, and the dose assignment de-escalates to below the starting dose and validates the next lower dose.\n\nPlus we improved the labeling of a class of prior parameters:\n\nIn the FACTS GUI labels of parameters for prior with an Inverse-Gamma distribution the wording has been changed from “mean value” (which is technically incorrect) to “central value”.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.2.4 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts616.html",
    "href": "releaseNotes/v6/facts616.html",
    "title": "FACTS 6.1.6 Release Notes",
    "section": "",
    "text": "FACTS 6.1.6 is a maintenance release for FACTS 6.1.0. The first product release of FACTS 6.1.0 was FACTS 6.1.3. Subsequent releases have introduced the following changes:\n\nFACTS 6.1.4: This was FACTS 6.1.3 with some additional logging when using the grid interface.\nFACTS 6.1.5: This was FACTS 6.1.4 with the Dose Escalation N-CRM re-compiled to allow a higher number (40) of dose strengths to be defined when using “Explicit Doses” rather than finely spaced doses.\nFACTS 6.1.6: This was FACTS 6.1.5 with 2 problems fixed in FACTS Core with a TTE endpoint & FACTS Staged Design with a TTE endpoint. In either engine the calculation of a “Current Trial Predictive Probability of Success at Current Enrollment” had 2 problems:\n\nThere was an error in the way timings of future events were simulated in the calculation of the predictive probability. The result was approximately correct, and erred on the conservative side, the error is more manifest if the trial has long follow-up times.\nThere was an error if the design also includes a predictor endpoint. This effects a much smaller set of designs, but the effect was much more marked and its impact was difficult to characterize in general. Our current advice is to not use predictive probability QOIs in combination with a “Predictor” endpoint using FACTS prior to FACTS 6.1.6.\n\n\nUpgrading FACTS 6.1.6 should introduce no changes to the simulation or analysis results relative to FACTS 6.1.3 except in designs using a time-to-event endpoint and a “Predictive Probability of Success in the Current Trial at Current Enrollment” Quantity of Interest.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.1.6 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts600.html",
    "href": "releaseNotes/v6/facts600.html",
    "title": "FACTS 6.0.0 Release Notes",
    "section": "",
    "text": "1 Introducing FACTS 6.0.0\nBerry Consultants is delighted to announce that FACTS 6.0.0 is ready for release!\nBuilding on FACTS 5, FACTS 6.0.0 adds a new simulation type: “FACTS Staged Design”.\n\nFACTS “Staged Design” is a simulator that runs a “FACTS Core” simulation followed by a second “FACTS Core” simulation that can take decisions based on the result of the first simulation and include data from the first simulation. This allows, for example, the simulation of a Phase II trial followed by a Phase III trial, whether as separate trials or as a seamless Phase II/III.\nFACTS Enrichment Designs includes the flexibility over the timing of interims and the ability to set different decision thresholds at different interims.\n\nFACTS 6.0.0 is fully backwards compatible with FACTS 5 – it can load and run all your FACTS 5 designs – and then add new FACTS 6.0.0 features to them. In particular you can load a FACTS Core design into FACTS Staged Design as the starting point for the design of the first stage. You can have FACTS 5 and FACTS 6.0.0 installed on the same machine, so it’s easy to have a transition period as you move to the new version.\n\n\n2 Key New Features\n\nFACTS Staged Design:\n\nThe simulation of one treatment selection stage followed by another.\nThe stages can be connected on a scale from completely seamless to completely independent.\nFACTS Staged Design can be used to simulate:\n\na Phase II and the consequential Phase III trials, or a seamless Phase II/III trial\na Phase IIA and the consequential Phase IIB trials, or a seamless Phase IIA/B trial\na Phase II trial with a treatment arm selection and expansion stage\n\nThe simulations include:\n\nDifferent options for specifying the interval between the stages\nDifferent options for which data from the first stage can be included in the second stage: all of it, none of it, all the data on the arms retained in the second stage, all the data on the study drug arms in the first stage pooled on the one study drug arm retained in the second stage and just subjects from the first stage who did not complete in that stage.\nRules for selecting which treatment arms are kept in the second stage or are dropped after the first stage, including rules on specific arms (such as “retain the top dose if …”), rules on specific target arms (such as “retain the Minimum Efficacious Dose which has a Hazard Ratio of X or less compared to the Control Arm”) rules across all arms (such as “retain the 2 treatment arms with the highest probability of having a response greater than control, as long as their probability of toxicity is less than …”) and rules applied to groups of treatment arms (such as “retain the two arms that are once a day treatments rather than the two that are twice a day treatments if …”).\nDifferent analysis models, allocation rules, interims and decision criteria for each stage.\n\nThe ability to take decision in Stage 1 based on the predictive probability of the outcome of stage 2.\nThe full simulation output of both stages.\nGraphs of the Stage 1, Stage 2, Dose Selection and Overall results.\n\nFACTS Enrichment Designs:\n\nAs in FACTS Core, the scheduling of interims can now be specified by the number of subjects who have completed or have completed up to a particular visit.\nThe decision criteria thresholds can be specified separately for different interims.\n\nFACTS Core:\n\nThe option to specify a deterministic accrual and/or deterministic allocation sequence, for example allowing custom dose escalation trials with cohort accrual, while allowing the full functionality of the Core engine\n\nFACTS Dose Escalation:\n\nIs unchanged.\n\n\n\n\n3 Downloading FACTS 6.0.0\nThe FACTS 6.0.0 release is available for download from the Berry Consultants FACTS 6 ftp repository at http://berry1.berryconsultants.com/facts_6/.\nLogin using:\n\nUsername: facts_6\nPassword: DynIrgyur4\n\nThere are, as usual, 4 files to download: Documents.zip, Examples.zip, Setup.msi, setup.exe. Obfuscated versions of setup.exe and Setup.msi have been included for those of you accessing through firewalls that prevent the download of .exe and .msi files. Having downloaded setup.e_e and Setup.m_i simply rename the file suffix before using.\n\n\n4 Installing FACTS 6.0.0\nAs with previous version of FACTS, FACTS 6.0.0 installs on a PC. Simply place the downloaded files on the PC / laptop it is to be installed on and run the file “setup.exe”. You will need a new FACTS license key for this new version. It will be sent to you separately.\nFor any support questions or issues, please contact us.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.0.0 Release Notes"
    ]
  },
  {
    "objectID": "notes/posts/2024-10-14.html",
    "href": "notes/posts/2024-10-14.html",
    "title": "Post1",
    "section": "",
    "text": "TEXT TEXT\nTEXT"
  },
  {
    "objectID": "notes/posts/2024-10-12.html",
    "href": "notes/posts/2024-10-12.html",
    "title": "Post3",
    "section": "",
    "text": "TEXT TEXT\nTEXT"
  },
  {
    "objectID": "introduction/webinars.html",
    "href": "introduction/webinars.html",
    "title": "Webinars",
    "section": "",
    "text": "List of Webinars",
    "crumbs": [
      "Introduction",
      "Webinars"
    ]
  },
  {
    "objectID": "introduction/tutorials/tutorial1.html",
    "href": "introduction/tutorials/tutorial1.html",
    "title": "Tutorial 1",
    "section": "",
    "text": "First tutorial",
    "crumbs": [
      "Introduction",
      "Tutorials",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Knowledge Hub",
    "section": "",
    "text": "Welcome to the Fixed and Adaptive Clinical Trial Simulator (FACTS) Knowledge Hub!\nFACTS is a powerful software tool that is trusted by half of the top 20 pharma companies to help them design efficient and successful clinical trials.\nWe are proud that also numerous academic, government and regulatory institutions trust FACTS."
  },
  {
    "objectID": "documentation/v71/userguides/installation.html",
    "href": "documentation/v71/userguides/installation.html",
    "title": "FACTS Installation Guide",
    "section": "",
    "text": "This document describes how to install and verify the installation of the FACTSTM (Fixed and Adaptive Clinical Trial Simulator) software. It is intended for anyone concerned with the installation of the system.\n\n\n\nThis document covers the installation and installation verification FACTS. It is only intended to demonstrate the usage of the software to the extent that it verifies the software will execute properly in the installed environment.\nFor parameter meanings or detail into the internal workings of the design engines or algorithm check the appropriate System Requirements Document. For appropriate guidance on usage check the User Guides.\n\n\n\nThis document is a guide to the FACTS installation, including both the desktop application and the grid components.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#purpose-of-this-document",
    "href": "documentation/v71/userguides/installation.html#purpose-of-this-document",
    "title": "FACTS Installation Guide",
    "section": "",
    "text": "This document describes how to install and verify the installation of the FACTSTM (Fixed and Adaptive Clinical Trial Simulator) software. It is intended for anyone concerned with the installation of the system.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#scope-of-this-document",
    "href": "documentation/v71/userguides/installation.html#scope-of-this-document",
    "title": "FACTS Installation Guide",
    "section": "",
    "text": "This document covers the installation and installation verification FACTS. It is only intended to demonstrate the usage of the software to the extent that it verifies the software will execute properly in the installed environment.\nFor parameter meanings or detail into the internal workings of the design engines or algorithm check the appropriate System Requirements Document. For appropriate guidance on usage check the User Guides.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#context-of-this-issue",
    "href": "documentation/v71/userguides/installation.html#context-of-this-issue",
    "title": "FACTS Installation Guide",
    "section": "",
    "text": "This document is a guide to the FACTS installation, including both the desktop application and the grid components.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#desktop-requirements",
    "href": "documentation/v71/userguides/installation.html#desktop-requirements",
    "title": "FACTS Installation Guide",
    "section": "3.1 Desktop Requirements",
    "text": "3.1 Desktop Requirements\nFACTS can be run on a standard system laptop or desktop running Windows 10 or 11 with the Windows .NET framework v4 or higher installed and at least 1 GB per core or more memory.\nIn addition:\n\nFACTS is expected to run on a display with a resolution of at least 1024x768 pixels and preferably greater.\n\nUser choice of non-default Windows styles/themes may result in unexpected and impractical foreground and background color combinations.\nFACTS 7.0 targets .NET Framework 4.8. Future versions of FACTS will target the latest available .NET Framework version.\nFACTS is now a 64-bit application and will be installed on the target machine’s Program Files area. Previous to FACTS 6.4 versions of FACTS were 32-bit applications installed on the target machine’s Program Files (x86) area.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#computation-requirements",
    "href": "documentation/v71/userguides/installation.html#computation-requirements",
    "title": "FACTS Installation Guide",
    "section": "3.2 Computation Requirements",
    "text": "3.2 Computation Requirements\nFACTS relies on running simulations and these simulations can be very computationally intensive. When running simulations, each simulation can be run separately (they do not depend on the results of other simulations) though to do so can be somewhat inefficient – repeatedly starting new processes and generating separate output files for every simulation that will need to be gathered together in a single “simulations.csv” file and then summarized. Thus FACTS allows the user to specify a “packet size” and the total number of simulations for each scenario to be simulated is divided by this packet size to create a set of independent jobs.\nIf the simulations are run on the users laptop or PC, FACTS will spawn a simulation thread for every core on the local machine up to the maximum number of simulation ‘packets’ that have been requested. The simulations are run at reduced priority so it is possible to continue to use the machine e.g. for email or Word whilst they run. Thus usually 2 or 4 sets of simulations are run in parallel depending on the processor in the laptop or PC.\nThere are a number of options for speeding up the running of FACTS simulations:\n\nThe simplest technically (and the approach we used to take at Berry Consultants) is to have a large multi-core server (say 32 core) remotely accessible to FACTS users and FACTs installed on it. To use, the user copies the “.facts” files to be simulated to a network shared directory which can be accessed from the server. Then after remotely logging into to the server, the user copies these files to a drive on the server, runs the simulations, zips up the results (within the FACTS GUI there is the FACTS File &gt; Export Project menu command to do this) and copies them back to the network shared drive and thence to their local machine.\nUse the FACTS network share folder “grid” interface, implemented using file transfers to and from a shared network drive. On a machine that can act as a client to a grid of compute nodes managed by one of the standard grid management packages (they used to be called “SunGrid” and “Condor” but have metamorphosed over the years) a “sweeper script” runs that transfers jobs to the grid. The jobs automatically transfer their results back to this shared drive. FACTS copies the job to a unique subfolder on the shared network location and then watches for a change in the lock file name - “submitted”, “running”, “complete” that are managed by the sweeper script. Once the simulations are complete FACTS copies the results back to the local machine. The fact that the simulations have been submitted to the grid are stored in the “.facts” file. Whenever that “.facts” file is open in FACTS, FACTS will poll the remote network drive to check if the simulations are complete.\nA more sophisticated FACTS grid interface that uses a web services to communicate between the FACTS client and a Linux server running a web-server (Apache Tomcat) and database (MySQL). The web service is used to submit jobs and they are stored in the database. A database process then submits them to the grid, once again managed by one of the standard grid management packages. The simulation results are then stored in the database for FACTS to download once complete. This provides a more robust and manageable interface, but it more work to set up. We can provide documentation and scripts and we can assist in setting this up. This is the form of grid that we now use in-house at Berry Consultants.\nTechnically as 3. (but for a fee) Berry Consultants can set and manage the grid for you in the cloud. Please contact us to discuss your requirements and for pricing. Therefore FACTS is able to offload the simulations from the desktop to be run by an external system. The interface describing the interactions with the external system is described in the FACTS Grid Interface document. With a FACTS Enterprise License, the command line executable files to run simulations externally under either Windows or Linux environments are available upon request.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#installation-instructions",
    "href": "documentation/v71/userguides/installation.html#installation-instructions",
    "title": "FACTS Installation Guide",
    "section": "4.1 Installation Instructions",
    "text": "4.1 Installation Instructions\nThe FACTS Desktop installation package consists of:\nsetup.exe a Windows installation program, Setup.msi the FACTS Microsoft Installer file Examples.zip a Zip file containing example FACTS projects, Documents.zip a Zip file containing the FACTS documentation. Config.xml an XML file containing the local configuration settings. These files are usually made available for download from Berry Consultants Microsoft App Center site. Download instructions are in a separate document. Versions of these files with the standard file extensions (.msi and .zip) modified are available it may have been these versions that were downloaded to circumvent firewall restrictions and these files will need to be renamed prior to use. Installation will take only a few moments. - Ensure that all the files have the correct file extension and are located on a local drive on the machine on which FACTS is to be installed. Windows can treat installs from networked drives as less trustworthy than installs from local drives and this can result in an incomplete installation. - Right click the setup.exe Windows installation program and select “Run as Administrator”. - Follow the instructions on the screen to complete the installation. - During FACTS installation you will have to option to enable FACTS to report Analytics back to the App Center. This allows to see how much FACTS is used and which features in FACTS are being used. It does NOT include any user or license information, we can’t see WHO is doing what, only WHAT is being done. Obviously we’d be grateful if you’d enable them. Analytics are off by default they will only be enabled of you enable them. Once installed analytics can be turned on or off from the FACTS “Settings” menu command.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#config.xml",
    "href": "documentation/v71/userguides/installation.html#config.xml",
    "title": "FACTS Installation Guide",
    "section": "4.2 Config.xml",
    "text": "4.2 Config.xml\nIncluded with the FACTS installation files is a configuration file that can be edited to local settings before the install files are distributed to users. It is also possible to provide an updated copy of the configuration file to users and ask them to update their default configuration, it is also possible for users to locally modify their configuration and revert to the installed configuration details.\nPrior to installation, a configuration file, ‘config.xml’, is available as one of the installation files. This file can be edited to set up a number of default settings for FACTS.\nThe settings are listed between the tags: &lt;configuration&gt; &lt;userSettings&gt; and &lt;/userSettings&gt; &lt;/configurations&gt;, for example:\n&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;configuration&gt;\n  &lt;userSettings&gt;\n    &lt;GridLocation&gt;C:\\\\work\\\\grid&lt;/GridLocation&gt;\n    &lt;GridOpSys&gt;1&lt;/GridOpSys&gt;\n    &lt;GridListenerDelay&gt;10000&lt;/GridListenerDelay&gt;\n    &lt;LocalRVersions&gt;\n      &lt;value&gt;version=\"3.3.2\" path=\"C:\\\\Program Files\\\\R\\\\R-3.3.2\\\\bin\\\\R.exe\" active=\"1\"&lt;/value&gt;\n      &lt;value&gt;version=\"RStudio\" path=\"C:\\\\Program Files\\\\RStudio\\\\bin\\\\RStudio.exe\"&lt;/value&gt;\n    &lt;/LocalRVersions&gt;\n    &lt;FactsSimulationServicePortURL&gt;http://nowhere.com:8080/axis2/services/FactsSimulationServicePort&lt;/FactsSimulationServicePortURL&gt;\n    &lt;GridSimMethod&gt;0&lt;/GridSimMethod&gt;\n  &lt;/userSettings&gt;\n&lt;/configuration&gt;\nSpecifically, the following values may be adjusted, as desired:\n\nLocalRVersions – a list of available R (or RStudio) versions, each one bracketed by the tags  and  and composed of two parameters “version” which can contain any string to be used to identify that version of R and “path” which should contain location of “.exe” that should be run when the user requests R to be run or a Design Report to be generated.\nGridSimMethod – 0 or 1, Determines how FACTS tries to connect to the grid, 0 means the network file share & sweeper script method (option 2 above) is to be used, 1 means that the Web Service method (option 3 or 4 above) is to be used\nIf the network file share method is to be used to connect to the grid then:\n\nGridLocation – the network location of the network file share.\nGridOpSys – 0 or 1, the type of the operating system that is running on the nodes of the grid: 0 – Linux, 1 – Windows (the simulation engine executables have different names in the two environments).\nGridListenerDelay – the delay (in milliseconds) between each poll of the network file share for changes in the state of the simulation results.\n\nIf the Web Service grid access method is to be used to connect to the grid then:\n\nFactsSimulationServicePortURL – specifies the URL to the FACTS web-service endpoint.\n\n\nNote, this configuration file is only used on the initial load of FACTS – subsequently, a local user configuration file is created in a location under the AppData folder – e.g.:\nC:\\Users\\&lt;user_id&gt;\\AppData\\Local\\Berry_Consultants_Inc\\FACTS_File_Loader_Url_&lt;Windows unique file id &gt;\\6.1.6.17435\\user.config\nAny changes made to the configuration from the UI (under the ‘Settings’ menu) are saved to this local file. – and the original config file is only used if the options are reset.\nNB, these local configuration are FACTS version and build specific (note the version and build number in the directory) – which means that if a new install is run, local configuration modifications will be lost.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#notes-on-access-permissions",
    "href": "documentation/v71/userguides/installation.html#notes-on-access-permissions",
    "title": "FACTS Installation Guide",
    "section": "4.3 Notes on access permissions",
    "text": "4.3 Notes on access permissions\nFACTS uses the locations C:\\Program Data\\BerryConsultants and &lt;user&gt;\\AppData\\Local\\BerryConsultants, we have seen some IT departments set the default access permissions to deny access to these locations contrary to Microsoft’s intention and the access will need to be granted for FACTS to run. When FACTS runs simulations it spawns one or more simulations processes, and we have encountered environments where these processes do not get permission to write to network drives. If these permissions cannot be changed, it will be necessary for users to save their “.facts” file run in a directory on the local drive before running simulations, so the results can be written there and then copied/moved to the network drive once complete.\n\n4.3.1 License Installation\nWhen FACTS is first run, it may require the license to be entered. The user can choose the file when prompted, or cut and paste the information into the dialog box. Alternatively, the file can be dropped in the application folder and it will be picked up when needed. Note, depending on access permissions, it may be necessary to initially load FACTS with admin rights in order to load the license key from file.\nSubsequent runs, and subsequent installations of mod level updates, will not require the license to be re-entered.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/installation.html#installation-verification",
    "href": "documentation/v71/userguides/installation.html#installation-verification",
    "title": "FACTS Installation Guide",
    "section": "4.4 Installation Verification",
    "text": "4.4 Installation Verification",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Installation Guide"
    ]
  },
  {
    "objectID": "documentation/v71/examples/Staged/example2.html",
    "href": "documentation/v71/examples/Staged/example2.html",
    "title": "Example 2",
    "section": "",
    "text": "Second example",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "Examples",
      "Staged",
      "Example 2"
    ]
  },
  {
    "objectID": "documentation/v71/examples/CRM/example2.html",
    "href": "documentation/v71/examples/CRM/example2.html",
    "title": "Example 2",
    "section": "",
    "text": "Second example",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "Examples",
      "CRM",
      "Example 2"
    ]
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "Documentation",
    "section": "",
    "text": "Home page for Documentation.\nTable 1 gives an overview of the acronyms and abbreviations used in the documentation.\n\n\n\nTable 1: List of terms used in the user guides\n\n\n\n\n\n\n\n\n\nName\nDefinition\n\n\n\n\nCap\nA limit on the number of subjects recruited. In FACTS N-CRM users can specify a cap on the overall number of subjects to be recruited in the trial (the ‘Overall Cap’) and specify stopping rules to define when the trial should stop before it reaches cap.\n\n\nControl\nIs the treatment arm with which the novel treatment(s) are principally being compared. Control may be placebo, or some existing standard of care, or therapy, against which the novel treatment has to be benchmarked in order to determine its likely usefulness.\n\n\nCore\nFACTS Core: A mode of FACTS for designing trials where multiple treatments, (possibly different doses of a novel treatment) are tested against a control and optionally an active comparator.\n\n\nCRM\nContinual Reassessment Method – a dose escalation design where the dose-toxicity is estimated using a simple Bayesian model, and the resulting estimates used to control the dose escalation and estimate the Maximum Tolerated Dose (MTD).\n\n\nDE\nDose Escalation: a mode of FACTS where subjects are treated in cohorts and dose escalation is determined by the number of toxicities observed.\n\n\nED\nEnrichment Designs: a mode of FACTS for designing trials where the same treatment is testing in different settings for example different sub-populations or different but related indications.\n\n\nFACTS\nFixed and Adaptive Clinical Trial Simulator.\n\n\nFinal Endpoint\nThe final value, or state, of a subject’s endpoint.\n\n\nGUI\nGraphical User Interface, the part of the FACTS application that the user interacts with.\n\n\nMethod\nIn the FACTS documentation we try to reserve the term ‘method’ for the algorithms used in the simulation (as opposed to the analysis) part of the program. In the analysis part we use the term ‘Model’, see below.\n\n\nModel\nIn the FACTS documentation we try to reserve the term ‘model’ for the statistical models used in the analysis of the trial data (in the ‘design’ section of the FACTS user interface). Where mathematical algorithms are used for other purposes in FACTS (for instance in the generation of the simulated data) we try to use the term ‘method’. We have found that initially it is very easy for users to be confused between these two parts of FACTS and we feel that using distinct terminology may help to reduce this.\n\n\nMTD\nThe dose most likely to be the Maximum Tolerated Dose (MTD) – the dose with the highest Pr(MTD).\n\n\nMTD+\nThe dose most likely to be the MTD+ – the dose with the highest Pr(MTD+).\n\n\nPr(MTD)\nA dose’s probability of being MTD is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable toxicity band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. This estimate of MTD is constrained to select one of the available doses.\n\n\nPr(MTD+)\nA dose’s probability of being the MTD+ is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. Unlike Pr(MTD), Pr(MTD+) includes estimating whether a dose below or a dose above the range of those being tested is more likely to have a toxicity in the acceptable band than any of the doses in the range.\n\n\nProfile\nA profile is a specification of one aspect of a scenario. A scenario is made up of one profile of each of the required types for the type of trial being simulated. FACTS allows the user to specify multiple profiles of each type and then presents all the possible combinations of profiles as scenarios that can be used to drive simulations.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nScenario\nA scenario is the complete specification of the unknown external factors that determine the data observed on the trial and its timing. The exact factors depend on the type of trial being simulated but typically include:  -) the distribution of the final change from base line, or probability of response or rate of events in the different treatment groups  -) the properties of subjects’ early responses and the correlation with their final outcome  -) the rate at which subjects are recruited into the trial  -) the rate at which subjects drop out of the trial.\n\n\nSPEC\nThe Design Engine Specification, describes the system algorithms, and meaning of parameters.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nSubject\nSomeone recruited onto a clinical trial for the purposes of learning about the properties of a treatment. Depending on the type of trial they might be patients or they might be healthy volunteers.\n\n\nTreatment Arm\nSubjects on entering the study are randomized to different ‘treatment arms’. Subjects randomized to the same arm receive the same treatment and the responses of the subjects in the arm analyzed to determine the expected response to that treatment, allowing the expected responses to the different treatments to be compared.\n\n\nUG\nThe User Guide; describes how to use the system.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "concepts/index.html",
    "href": "concepts/index.html",
    "title": "Concepts",
    "section": "",
    "text": "Landing page for encyclopedia.",
    "crumbs": [
      "Concepts"
    ]
  },
  {
    "objectID": "concepts/facts/InverseGammaDistribution.html",
    "href": "concepts/facts/InverseGammaDistribution.html",
    "title": "Inverse Gamma Distributions in FACTS",
    "section": "",
    "text": "The Inverse Gamma distribution is used as a prior for most variances in FACTS. The standard parameterization of the Inverse Gamma distribution using \\(\\alpha\\) and \\(\\beta\\) as the shape and scale parameter is not always intuitive for specifying a prior. In order to assist with prior specification, FACTS reparameterizes the Inverse Gamma distribution to be a function of the expected center of the standard deviation and a prior weight.\nThe application below is intended to help users of FACTS understand what the distribution they are specifying for the prior of a variance actually looks like.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 1000\n\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\n\nqinvgamma = function (p, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, \n          log.p = FALSE) \n{\n  if (missing(rate) && !missing(scale)) \n    rate &lt;- 1/scale\n  qgamma(1 - p, shape, rate, lower.tail = lower.tail, log.p = log.p)^(-1)\n}\npinvgamma = function (q, shape, rate = 1, scale = 1/rate, lower.tail = TRUE, \n          log.p = FALSE) \n{\n  if (missing(rate) && !missing(scale)) \n    rate &lt;- 1/scale\n  pgamma(1/q, shape, rate, lower.tail = !lower.tail, log.p = log.p)\n}\ndinvgamma = function (x, shape, rate = 1, scale = 1/rate, log = FALSE) \n{\n  if (missing(rate) && !missing(scale)) \n    rate &lt;- 1/scale\n  log_f &lt;- dgamma(1/x, shape, rate, log = TRUE) - 2 * log(x)\n  if (log) \n    return(log_f)\n  exp(log_f)\n}\nrinvgamma = function (n, shape, rate = 1, scale = 1/rate) \n{\n  if (missing(rate) && !missing(scale)) \n    rate &lt;- 1/scale\n  1/rgamma(n, shape, rate)\n}\n\n# Define UI for application that draws a histogram\nui &lt;- fluidPage(\n  tags$head(\n    tags$style(HTML(\"\n      #radioButtonDiv {\n      display: flex;\n      justify-content: center;\n      }\"\n    ))\n  ),\n  withMathJax(),\n  titlePanel(h1(\"Inverse Gamma Distribution in FACTS\", align = \"center\")),\n  h5('$$\\\\sigma^2 \\\\sim \\\\text{IG}\\\\left(\\\\alpha=\\\\frac{\\\\text{weight}}{2}, \\\\beta=\\\\frac{\\\\text{center}^2\\\\;*\\\\;\\\\text{weight}}{2}\\\\right)$$'),\n  sidebarLayout(\n    sidebarPanel(width = 3,\n                      style = \"border: 1px solid #000000\",\n                      titlePanel(h4(\"Center/Weight Parameterization\")),\n                      fluidRow(\n                        column(width = 10, offset = 1, numericInput(inputId = \"center\", label = \"Center of SD:\", value = 5, min = 0, max = Inf, step = 1)),\n                        column(width = 10, offset = 1, numericInput(inputId = \"weight\", label = \"Weight:\", value = 2, min = 0.001, max = Inf, step = 1)),\n                      ),\n                      titlePanel(h4(\"Alpha/Beta Parameterization\")),\n                      fluidRow(\n                        column(width = 10, offset = 1, numericInput(inputId = \"alpha\", label = \"Alpha:\", value = 1, min = 0.0005, max = Inf, step = 1)),\n                        column(width = 10, offset = 1, numericInput(inputId = \"beta\", label = \"Beta:\", value = 25, min = 0, max = Inf, step = 1))\n                      )\n                    ),\n    mainPanel(width = 9,\n      wellPanel(style = \"background: white; border: 1px solid #000000\",\n        fluidRow(\n          column(12,\n            div(\n              radioButtons(\"whichParam\", \n                           \"Which parameter should be summarized?\", \n                           choiceNames = c(\"Variance \\\\((\\\\sigma^2)\\\\)\", \"Std. Dev. \\\\((\\\\sigma)\\\\)\"), \n                           choiceValues = c(\"sigma2\", \"sigma\"), \n                           selected = \"sigma2\", \n                           inline = TRUE),\n            id = \"radioButtonDiv\")\n          )\n        ),\n        uiOutput(\"sectionTitle\"),\n        fluidRow(\n          column(width = 4, value_box(\"Mean\", value= uiOutput(\"mean\"), theme = value_box_theme(bg = \"#06402b\"))),\n          column(width = 4, value_box(\"Median\", value= uiOutput(\"median\"), theme = value_box_theme(bg = \"#ba5a31\"))),\n          column(width = 4, value_box(\"Mode\", value= uiOutput(\"mode\"), theme = value_box_theme(bg = \"#0b2545\")))    \n        ),\n        br(),\n        plotOutput(\"igDistributionPlot\")\n      )\n    )\n  )\n)\n\n# Define server logic required to draw a histogram\nserver &lt;- function(input, output, session) {\n\n  update &lt;- reactiveVal(TRUE)\n  \n  observeEvent(input$center | input$weight, {\n    cat(\"CenterWeightChanged\\n\")\n    ctr = input$center\n    wgt = input$weight\n\n    if(update() & !is.null(ctr) & !is.null(wgt) & !is.na(ctr) & !is.na(wgt) & ctr &gt; 0 & wgt &gt; 0 & (a != wgt/2 | b != ctr^2*wgt/2)) {\n      a = wgt/2\n      b = ctr^2*wgt/2\n\n      updateNumericInput(session, \"alpha\", value = a)\n      updateNumericInput(session, \"beta\", value = b)\n      \n      update(FALSE)\n    } else {\n      update(TRUE)\n    }\n  })\n  observeEvent(input$alpha | input$beta, {\n    cat(\"AlphaBetaChanged\\n\")\n    a = input$alpha\n    b = input$beta\n\n    if(update() & !is.null(a) & !is.null(b) & !is.na(a) & !is.na(b) & a &gt; 0 & b &gt; 0) {\n      wgt = 2*a\n      ctr = sqrt(b/a)\n\n      updateNumericInput(session, \"center\", value = ctr)\n      updateNumericInput(session, \"weight\", value = wgt)\n      \n      update(FALSE)\n    } else {\n      update(TRUE)\n    }\n  })\n  \n  meanHolder = reactiveVal(NA)\n  \n  output$mean = renderText({\n    cat(\"CalcMean\\n\")\n    a = input$alpha\n    b = input$beta\n\n    if(a &gt; 1) {\n      if(input$whichParam == \"sigma2\") {\n        meanHolder(b/(a-1))\n        return(round(b/(a-1), 2))\n      } else {\n        tmp = mean(sqrt(rinvgamma(10000, a, b)))\n        meanHolder(tmp)\n        return(round(tmp, 2))\n      }\n    } else {\n      meanHolder(NA)\n      return(\"-\")\n    }\n  })\n  output$median = renderText({\n    cat(\"CalcMedian\\n\")\n    a = input$alpha\n    b = input$beta\n    \n    if(input$whichParam == \"sigma2\") {\n      return(round(qinvgamma(0.5, shape = a, rate = b), 2))\n    } else {\n      return(round(sqrt(qinvgamma(0.5, shape = a, rate = b)),2))\n    }\n  })\n  \n  output$mode = renderText({\n    cat(\"CalcMode\\n\")\n    a = input$alpha\n    b = input$beta\n    \n    if(input$whichParam == \"sigma2\") {\n      return(round(b/(a+1),2))\n    } else {\n      lmode = 0\n      hmode = max(b/(a+1), 2)\n      smode = seq(lmode, hmode, length.out = 100001)\n      dmode = dinvgamma(smode, a, b)*(1/(2*sqrt(smode)))\n      calcMode = sqrt(smode[which.max(dmode)])\n\n      return(round(calcMode, 2))\n    }\n  })\n  \n  output$sectionTitle = renderUI({\n    cat(\"ChangeHeader\\n\")\n    if(input$whichParam == \"sigma2\") {\n      return(h4(\"Characteristics of the Variance\"))\n    } else {\n      return(h4(\"Characteristics of the Standard Deviation\"))\n    }\n  })\n  \n  output$igDistributionPlot = renderPlot({\n    cat(\"MakePlot\\n\")\n    a = input$alpha\n    b = input$beta\n    wchParam = input$whichParam\n    isolate({\n      if(!is.null(a) & !is.null(b) & !is.null(input$center) & !is.null(input$weight) &\n         a &gt; 0 & b &gt; 0 & input$center &gt; 0 & input$weight &gt; 0) {\n        if(wchParam == \"sigma2\") {\n          lowerbound = 0\n          upperbound = qinvgamma(.995, a, b)\n          upperbound = min(1e15, upperbound)\n          \n          sq0to1 = seq(1e-10, 1-(1e-10), length.out = 1000)\n          sq = qinvgamma(sq0to1, a, b)\n        #  sq = seq(1e-10,upperbound, length.out = 1001)\n          \n          df = data.frame(sq = sq,\n                          density = dinvgamma(sq, a, b))\n          \n          modeDensity = dinvgamma(b/(a+1), a, b)\n          \n          if(df$density[sum(is.finite(df$density))] &gt; modeDensity*.01) {\n            maxPlot = sq[length(sq)]\n          } else {\n            maxPlot = sq[min(which(df$density &lt; modeDensity*.01 & sq &gt; sq[which.max(df$density)]))]\n          }\n          maxPlot = max(maxPlot, 2*(b/(a+1)))\n\n          sq0to1 = seq(1e-10, pinvgamma(maxPlot*1.1, a, b), length.out = 1001)\n          sq = qinvgamma(sq0to1, a, b)\n          \n          df = data.frame(sq = sq,\n                          density = dinvgamma(sq, a, b))\n          \n          p1 = ggplot(data = df) + geom_line(aes(x = sq, y = density)) + geom_area(aes(x = sq, y = density), fill = \"gray80\") +\n            theme_bw() +\n            xlab(\"Variance\") + ylab(\"Density\") +\n            scale_y_continuous(expand = c(0, 0)) +\n            ggtitle(\"Probability Distribution of the Variance\") +\n            coord_cartesian(xlim = c(0, maxPlot), ylim = c(0, modeDensity*1.3)) +\n            theme(text = element_text(size = 18))\n          \n          if(a &gt; 1) {\n            meantmp = meanHolder()\n            p1 = p1 + geom_vline(xintercept = meantmp, color = \"#06402b\") + annotate(geom=\"label\", color = \"white\", fill = \"#06402b\", x = meantmp, y = modeDensity*1.15, label = \"mean\", angle=90, size = 4.5)\n          }\n          p1 = p1 + geom_vline(xintercept = b/(a+1), color = \"#0b2545\") + annotate(geom=\"label\", color = \"white\", fill = \"#0b2545\", x = b/(a+1), y = modeDensity*1.15, label = \"mode\", angle=90, size = 4.5)\n          \n          if(is.finite(qinvgamma(.5, a, b))) {\n            p1 = p1 + geom_vline(xintercept = qinvgamma(.5, a, b), color = \"#ba5a31\") + annotate(geom=\"label\", color = \"white\", fill = \"#ba5a31\", x = qinvgamma(.5, a, b), y = modeDensity*1.15, label = \"median\", angle=90, size = 4.5)\n          }\n          \n          p1 = p1 + geom_vline(xintercept = b/a) + annotate(geom=\"label\", x = b/a, y = modeDensity*1.15, label = \"center\", angle=90, size = 4.5)\n          \n          p1\n        }\n        else {\n          #df = data.frame(sq = sq,\n          #density = dinvgamma(sq, a, b)*(1/(2*sqrt(sq))))\n          \n          lowerbound = 0\n          upperbound = qinvgamma(.995, a, b)\n          upperbound = min(1e15, upperbound)\n          \n          sq0to1 = seq(1e-10, 1-(1e-10), length.out = 1000)\n          sq = qinvgamma(sq0to1, a, b)\n          df = data.frame(sq = sq,\n                          density = dinvgamma(sq, a, b)*(1/(2*sqrt(sq))))\n          \n          lmode = 0\n          hmode = max(b/(a+1), 2)\n          smode = seq(lmode, hmode, length.out = 1001)\n          dmode = dinvgamma(smode, a, b)*(1/(2*sqrt(smode)))\n          wchMax = which.max(dmode)\n          if(wchMax &gt; 1) {\n            smode2 = seq(smode[wchMax-1], smode[wchMax + 1], length.out = 1001)\n            dmode2 = dinvgamma(smode2, a, b)*(1/(2*sqrt(smode2)))\n            wchMax = which.max(dmode2)\n          } else {\n            smode2 = seq(0, smode[2], length.out = 1000)\n            dmode2 = dinvgamma(smode2, a, b)*(1/(2*sqrt(smode2)))\n            wchMax = which.max(dmode2)\n          }\n          calcMode = sqrt(smode2[wchMax])\n          \n          modeDensity = dinvgamma(calcMode^2, a, b)*(1/(2*calcMode))\n          \n          if(df$density[sum(is.finite(df$density))] &gt; modeDensity*.01) {\n            maxPlot = sq[length(sq)]\n          } else {\n            maxPlot = sq[min(which(df$density &lt; modeDensity*.01 & sq &gt; sq[which.max(df$density)]))]\n          }\n          maxPlot = max(maxPlot, 2*smode2[wchMax])\n          \n          sq = seq(1e-10,maxPlot*1.1, length.out = 1001)\n          \n          df = data.frame(sq = sq,\n                          density = dinvgamma(sq, a, b)*(1/(2*sqrt(sq))))\n          \n          p1 = ggplot(data = df) + geom_line(aes(x = sqrt(sq), y = density)) + geom_area(aes(x = sqrt(sq), y = density), fill = \"gray80\") +\n            theme_bw() +\n            xlab(\"Standard Deviation\") + ylab(\"Density\") +\n            scale_y_continuous(expand = c(0, 0)) +\n            ggtitle(\"Probability Distribution of the Variance\") +\n            coord_cartesian(xlim = c(0, sqrt(maxPlot)), ylim = c(0, modeDensity*1.3)) +\n            theme(text = element_text(size = 18))\n          \n          if(a &gt; 1) {\n            meantmp = meanHolder()\n            p1 = p1 + geom_vline(xintercept = meantmp, color = \"#06402b\") + annotate(geom=\"label\", color = \"white\", fill = \"#06402b\", x = meantmp, y = modeDensity*1.15, label = \"mean\", angle=90, size = 4.5)\n          }\n\n          p1 = p1 + geom_vline(xintercept = calcMode, color = \"#0b2545\") + annotate(geom=\"label\", color = \"white\", fill = \"#0b2545\", x = calcMode, y = modeDensity*1.15, label = \"mode\", angle=90, size = 4.5)\n          if(is.finite(sqrt(qinvgamma(.5, a, b)))) {\n            p1 = p1 + geom_vline(xintercept = sqrt(qinvgamma(.5, a, b)), color = \"#ba5a31\") + annotate(geom=\"label\", color = \"white\", fill = \"#ba5a31\", x = sqrt(qinvgamma(.5, a, b)), y = modeDensity*1.15, label = \"median\", angle=90, size = 4.5)\n          }\n          p1 = p1 + geom_vline(xintercept = sqrt(b/a)) + annotate(geom=\"label\", x = sqrt(b/a), y = modeDensity*1.15, label = \"center\", angle=90, size = 4.5)\n          \n          p1\n        }\n      }\n    })\n  })\n}\n\n# Run the application \nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Inverse Gamma Distributions in FACTS"
    ]
  },
  {
    "objectID": "concepts/bayes/bayes2.html",
    "href": "concepts/bayes/bayes2.html",
    "title": "Bayes 2",
    "section": "",
    "text": "Second Article on Bayesian Concepts",
    "crumbs": [
      "Concepts",
      "Bayesian Statistics",
      "Bayes 2"
    ]
  },
  {
    "objectID": "concepts/adaptiveDesigns/adaptiveDesigns3.html",
    "href": "concepts/adaptiveDesigns/adaptiveDesigns3.html",
    "title": "Adaptive Designs 3",
    "section": "",
    "text": "Third Article on Adaptive Designs",
    "crumbs": [
      "Concepts",
      "Adaptive Designs",
      "Adaptive Designs 3"
    ]
  },
  {
    "objectID": "concepts/adaptiveDesigns/adaptiveDesigns1.html",
    "href": "concepts/adaptiveDesigns/adaptiveDesigns1.html",
    "title": "Adaptive Designs 1",
    "section": "",
    "text": "First Article on Adaptive Designs",
    "crumbs": [
      "Concepts",
      "Adaptive Designs",
      "Adaptive Designs 1"
    ]
  },
  {
    "objectID": "concepts/adaptiveDesigns/adaptiveDesigns2.html",
    "href": "concepts/adaptiveDesigns/adaptiveDesigns2.html",
    "title": "Adaptive Designs 2",
    "section": "",
    "text": "Second Article on Adaptive Designs",
    "crumbs": [
      "Concepts",
      "Adaptive Designs",
      "Adaptive Designs 2"
    ]
  },
  {
    "objectID": "concepts/bayes/bayes1.html",
    "href": "concepts/bayes/bayes1.html",
    "title": "Bayes 1",
    "section": "",
    "text": "First Article on Bayesian Concepts",
    "crumbs": [
      "Concepts",
      "Bayesian Statistics",
      "Bayes 1"
    ]
  },
  {
    "objectID": "concepts/facts/DropoutsDeepdive.html",
    "href": "concepts/facts/DropoutsDeepdive.html",
    "title": "Dropout Rate Explanation",
    "section": "",
    "text": "For the continuous and dichotomous engines, and the multiple endpoint engine, the default dropout scenario is that no subjects drop out of the study before observing their final endpoint data. If dropouts are expected, the user can specify either the “Dropouts per Dose,” or “Dropouts per Dose per Visit.”\n\n\nIf “Dropouts per Dose” is selected, then each subject has a probability of not having an observable final endpoint value equal to the dropout rate of the dose that subject is randomized to. If each subject has multiple visits and “Dropouts per Dose” is selected, then the conditional probability of dropping out before each visit given that the subject had not dropped out up to the visit before rates are all equal. In other words, if the total dropout rate is π_D, the probability of dropping out between visits i and i+1 given that the subject had not dropped out at visit \\(i\\) is \\[\n1-\\left(1-\\pi_D\\right)^{(\\frac{1}{V})}\\text{ where } V \\text{ is the total number of visits.}\n\\] The following interactive widget takes in the desired dropout rate for a single dose and the number of visits a subject will have during their follow-up, and returns information about the dropout rate that FACTS will simulate by visit for that dose.\nThe columns in the dynamic output table are:\n\nVisit number\n\nThe index of the visit that a subject would observe.\n\nConditional Visit Dropout Rate\n\nThe probability that a subject drops out before row specified visit given that they have not dropped out after the previous visit.\n\nMarginal Visit Dropout Rate\n\nThe probability that a subject that has not yet been enrolled in the study will dropout before row specified visit and after the previous row’s visit.\n\nCumulative Dropout Prob.\n\nThe probability that a subject will drop out at the row specified visit or before. At the last visit row this value will equal the Desired Dropout Rate.\n\n\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 450\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  \n  titlePanel(\"Dropout Per Dose\"),\n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"dropoutRate\", \"Desired Dropout Rate:\", value = 0.1, min = 0.0, max = 1.0, step = 0.05),\n      sliderInput(\"numVisits\", \"Number of visits:\", \n                  min = 1, max = 20, value = 5)\n    ),\n    mainPanel(\n      tableOutput(\"visitsGuide\")\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  output$visitsGuide &lt;- renderTable({\n    \n    if(is.na(input$dropoutRate)) {stop(safeError(\"Please enter a dropout rate.\"))}\n    else if(input$dropoutRate &lt; 0 | input$dropoutRate &gt; 1) {stop(safeError(\"Dropout rate must be between 0 and 1.\"))}\n    else {\n      df = data.frame(Visits = 1:input$numVisits,\n                                                     ConditionalDropoutRate = 1-(1-input$dropoutRate)^(1/input$numVisits))\n      df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n      df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n  \n      df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n      colnames(df) = c(\"Visit number\",\n                \"Conditional Visit Dropout Rate\",\n                \"Marginal Visit Dropout Rate\",\n                \"Cumulative Dropout Prob.\")\n    df}\n  }, digits = 4)\n}\n\nshinyApp(ui = ui, server = server)\n\n\n\n\nIf “Dropouts per Dose per Visit” is selected, then each subject has a user specified probability of dropping out before a visit v that is specified as the conditional probability of dropping out before visit v given that that they had not dropped out by visit v-1. This leads to a total dropout rate π_D for a participant that is equal to:\n\\[\n\\pi_D = 1-\\Pi_{v=0}^V(1-\\pi_v)\n\\] When specifying Dropouts Per Dose Per Visit in FACTS, the user inputs the conditional visit dropout rate for each visit. This can make it not completely intuitive to get the exact desired cumulative dropout rate. The below application allows the user to enter either the conditional visit dropout rates or the marginal visit dropout rates for a single dose, and provides the implied dropout profile from those inputs. Again, the columns of the table represent:\n\nVisit number\n\nThe index of the visit that a subject would observe.\n\nConditional Visit Dropout Rate\n\nThe probability that a subject drops out before row specified visit given that they have not dropped out after the previous visit.\n\nMarginal Visit Dropout Rate\n\nThe probability that a subject that has not yet been enrolled in the study will dropout before row specified visit and after the previous row’s visit.\n\nCumulative Dropout Prob.\n\nThe probability that a subject will drop out at the row specified visit or before. At the last visit row this value will equal the Desired Dropout Rate.\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\nlibrary(DT)\nlibrary(htmltools)\n\nalignCenter &lt;- function(el) {\n  htmltools::tagAppendAttributes(el,\n                                 style=\"margin-left:auto;margin-right:auto;\"\n  )\n}\n\nui &lt;- fluidPage(\n  tags$head(\n    # Note the wrapping of the string in HTML()\n    tags$style(HTML(\"\n      .my_col_class {\n         align-content: center;\n      }\")\n    )\n  ),\n  \n  fluidRow(\n    titlePanel(h1(\"Dropout Per Dose Per Visit\", align = \"center\")),\n    alignCenter(sliderInput(\"numVisits\", \"Number of visits:\", \n            min = 1, max = 20, value = 5)),\n    DTOutput(\"dataInputTable\")\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  df = data.frame(Visits = 1:5,\n                       ConditionalDropoutRate = 0.05)\n  df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n  df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n  df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n  colnames(df) = c(\"Visit number\",\n                   \"Conditional Visit Dropout Rate\",\n                   \"Marginal Visit Dropout Rate\",\n                   \"Cumulative Dropout Prob.\")\n  \n  ## Render DF to actually change\n  output$dataInputTable = renderDT(datatable(df, options = list(\n    pageLength = 20,\n    dom = \"t\",\n    autoWidth = TRUE,\n    columnDefs = list(list(width = '150px', targets = 1:4, orderable = FALSE))), selection = 'none', editable = \"cell\") |&gt; formatRound(2:4, digits = 4))\n  \n  ## Update from Conditional\n  \n  proxy = dataTableProxy('dataInputTable')\n  \n  observeEvent(input$dataInputTable_cell_edit, {\n    info = input$dataInputTable_cell_edit\n    str(info)\n    i = info$row\n    j = info$col\n    v = info$value\n    df &lt;&lt;- editData(df, info)\n    if(j == 2) {\n      ## Update other columns from Conditional\n      df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n      df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n    } else if(j == 3) {\n      ## Update other columns from Marginal\n      df[,4] &lt;&lt;- cumsum(df[,3])\n      df[,2] &lt;&lt;- c(df[1,3],\n                   df[-1,3]/(1-df[-nrow(df),4]))\n    } else if(j == 4) {\n      ## Update other columns from Cumulative\n      \n      df[info$row, 3] &lt;&lt;- df[info$row, 4] - ifelse(info$row == 1, 0, df[info$row-1, 4])\n      df[info$row, 2] &lt;&lt;- ifelse(info$row == 1, df[info$row,3], df[info$row,3]/(1-df[info$row-1,4]))\n      df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n      df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n    }\n    replaceData(proxy, df) \n  })\n  \n  observe({\n    input$numVisits\n    nv = input$numVisits\n    if(nv &gt; nrow(df)) {\n      if(nrow(df) == 0) {\n        df &lt;&lt;- data.frame(Visits = 1,\n                   ConditionalDropoutRate = 1-(1-.1)^(1))\n        df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n        df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n        df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n        colnames(df) = c(\"Visit number\",\n                         \"Conditional Visit Dropout Rate\",\n                         \"Marginal Visit Dropout Rate\",\n                         \"Cumulative Dropout Prob.\")\n      } else {\n        for(i in 1:(nv-nrow(df))) {\n          df &lt;&lt;- rbind(df, setNames(data.frame(matrix(c(1+nrow(df), 0.05, 0, 0), nrow = 1)), names(df)))\n        }\n        df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n        df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n      }\n    } else if(nv &lt; nrow(df)) {\n      df &lt;&lt;- df[1:nv,]\n    }\n    replaceData(proxy, df) \n  })\n}\n\nshinyApp(ui = ui, server = server)\nIn order to simulate dropouts from the below profile in FACTS, enter the Conditional Visit Dropout Rate into the FACTS Dropout Rate tab.",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Dropout Rate Explanation"
    ]
  },
  {
    "objectID": "concepts/facts/DropoutsDeepdive.html#dropouts-per-dose",
    "href": "concepts/facts/DropoutsDeepdive.html#dropouts-per-dose",
    "title": "Dropout Rate Explanation",
    "section": "",
    "text": "If “Dropouts per Dose” is selected, then each subject has a probability of not having an observable final endpoint value equal to the dropout rate of the dose that subject is randomized to. If each subject has multiple visits and “Dropouts per Dose” is selected, then the conditional probability of dropping out before each visit given that the subject had not dropped out up to the visit before rates are all equal. In other words, if the total dropout rate is π_D, the probability of dropping out between visits i and i+1 given that the subject had not dropped out at visit \\(i\\) is \\[\n1-\\left(1-\\pi_D\\right)^{(\\frac{1}{V})}\\text{ where } V \\text{ is the total number of visits.}\n\\] The following interactive widget takes in the desired dropout rate for a single dose and the number of visits a subject will have during their follow-up, and returns information about the dropout rate that FACTS will simulate by visit for that dose.\nThe columns in the dynamic output table are:\n\nVisit number\n\nThe index of the visit that a subject would observe.\n\nConditional Visit Dropout Rate\n\nThe probability that a subject drops out before row specified visit given that they have not dropped out after the previous visit.\n\nMarginal Visit Dropout Rate\n\nThe probability that a subject that has not yet been enrolled in the study will dropout before row specified visit and after the previous row’s visit.\n\nCumulative Dropout Prob.\n\nThe probability that a subject will drop out at the row specified visit or before. At the last visit row this value will equal the Desired Dropout Rate.\n\n\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 450\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  \n  titlePanel(\"Dropout Per Dose\"),\n  sidebarLayout(\n    sidebarPanel(\n      numericInput(\"dropoutRate\", \"Desired Dropout Rate:\", value = 0.1, min = 0.0, max = 1.0, step = 0.05),\n      sliderInput(\"numVisits\", \"Number of visits:\", \n                  min = 1, max = 20, value = 5)\n    ),\n    mainPanel(\n      tableOutput(\"visitsGuide\")\n    )\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  output$visitsGuide &lt;- renderTable({\n    \n    if(is.na(input$dropoutRate)) {stop(safeError(\"Please enter a dropout rate.\"))}\n    else if(input$dropoutRate &lt; 0 | input$dropoutRate &gt; 1) {stop(safeError(\"Dropout rate must be between 0 and 1.\"))}\n    else {\n      df = data.frame(Visits = 1:input$numVisits,\n                                                     ConditionalDropoutRate = 1-(1-input$dropoutRate)^(1/input$numVisits))\n      df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n      df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n  \n      df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n      colnames(df) = c(\"Visit number\",\n                \"Conditional Visit Dropout Rate\",\n                \"Marginal Visit Dropout Rate\",\n                \"Cumulative Dropout Prob.\")\n    df}\n  }, digits = 4)\n}\n\nshinyApp(ui = ui, server = server)",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Dropout Rate Explanation"
    ]
  },
  {
    "objectID": "concepts/facts/DropoutsDeepdive.html#dropouts-per-dose-per-visit",
    "href": "concepts/facts/DropoutsDeepdive.html#dropouts-per-dose-per-visit",
    "title": "Dropout Rate Explanation",
    "section": "",
    "text": "If “Dropouts per Dose per Visit” is selected, then each subject has a user specified probability of dropping out before a visit v that is specified as the conditional probability of dropping out before visit v given that that they had not dropped out by visit v-1. This leads to a total dropout rate π_D for a participant that is equal to:\n\\[\n\\pi_D = 1-\\Pi_{v=0}^V(1-\\pi_v)\n\\] When specifying Dropouts Per Dose Per Visit in FACTS, the user inputs the conditional visit dropout rate for each visit. This can make it not completely intuitive to get the exact desired cumulative dropout rate. The below application allows the user to enter either the conditional visit dropout rates or the marginal visit dropout rates for a single dose, and provides the implied dropout profile from those inputs. Again, the columns of the table represent:\n\nVisit number\n\nThe index of the visit that a subject would observe.\n\nConditional Visit Dropout Rate\n\nThe probability that a subject drops out before row specified visit given that they have not dropped out after the previous visit.\n\nMarginal Visit Dropout Rate\n\nThe probability that a subject that has not yet been enrolled in the study will dropout before row specified visit and after the previous row’s visit.\n\nCumulative Dropout Prob.\n\nThe probability that a subject will drop out at the row specified visit or before. At the last visit row this value will equal the Desired Dropout Rate.\n\n\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\nlibrary(DT)\nlibrary(htmltools)\n\nalignCenter &lt;- function(el) {\n  htmltools::tagAppendAttributes(el,\n                                 style=\"margin-left:auto;margin-right:auto;\"\n  )\n}\n\nui &lt;- fluidPage(\n  tags$head(\n    # Note the wrapping of the string in HTML()\n    tags$style(HTML(\"\n      .my_col_class {\n         align-content: center;\n      }\")\n    )\n  ),\n  \n  fluidRow(\n    titlePanel(h1(\"Dropout Per Dose Per Visit\", align = \"center\")),\n    alignCenter(sliderInput(\"numVisits\", \"Number of visits:\", \n            min = 1, max = 20, value = 5)),\n    DTOutput(\"dataInputTable\")\n  )\n)\n\nserver &lt;- function(input, output) {\n  \n  df = data.frame(Visits = 1:5,\n                       ConditionalDropoutRate = 0.05)\n  df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n  df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n  df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n  colnames(df) = c(\"Visit number\",\n                   \"Conditional Visit Dropout Rate\",\n                   \"Marginal Visit Dropout Rate\",\n                   \"Cumulative Dropout Prob.\")\n  \n  ## Render DF to actually change\n  output$dataInputTable = renderDT(datatable(df, options = list(\n    pageLength = 20,\n    dom = \"t\",\n    autoWidth = TRUE,\n    columnDefs = list(list(width = '150px', targets = 1:4, orderable = FALSE))), selection = 'none', editable = \"cell\") |&gt; formatRound(2:4, digits = 4))\n  \n  ## Update from Conditional\n  \n  proxy = dataTableProxy('dataInputTable')\n  \n  observeEvent(input$dataInputTable_cell_edit, {\n    info = input$dataInputTable_cell_edit\n    str(info)\n    i = info$row\n    j = info$col\n    v = info$value\n    df &lt;&lt;- editData(df, info)\n    if(j == 2) {\n      ## Update other columns from Conditional\n      df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n      df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n    } else if(j == 3) {\n      ## Update other columns from Marginal\n      df[,4] &lt;&lt;- cumsum(df[,3])\n      df[,2] &lt;&lt;- c(df[1,3],\n                   df[-1,3]/(1-df[-nrow(df),4]))\n    } else if(j == 4) {\n      ## Update other columns from Cumulative\n      \n      df[info$row, 3] &lt;&lt;- df[info$row, 4] - ifelse(info$row == 1, 0, df[info$row-1, 4])\n      df[info$row, 2] &lt;&lt;- ifelse(info$row == 1, df[info$row,3], df[info$row,3]/(1-df[info$row-1,4]))\n      df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n      df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n    }\n    replaceData(proxy, df) \n  })\n  \n  observe({\n    input$numVisits\n    nv = input$numVisits\n    if(nv &gt; nrow(df)) {\n      if(nrow(df) == 0) {\n        df &lt;&lt;- data.frame(Visits = 1,\n                   ConditionalDropoutRate = 1-(1-.1)^(1))\n        df$TotalDropoutRate = 1-cumprod(1-df$ConditionalDropoutRate)\n        df$MarginalDropoutRate = c(df$TotalDropoutRate[1], df$TotalDropoutRate[-1] - df$TotalDropoutRate[-nrow(df)])\n        df = df[,c(\"Visits\", \"ConditionalDropoutRate\", \"MarginalDropoutRate\", \"TotalDropoutRate\")]\n        colnames(df) = c(\"Visit number\",\n                         \"Conditional Visit Dropout Rate\",\n                         \"Marginal Visit Dropout Rate\",\n                         \"Cumulative Dropout Prob.\")\n      } else {\n        for(i in 1:(nv-nrow(df))) {\n          df &lt;&lt;- rbind(df, setNames(data.frame(matrix(c(1+nrow(df), 0.05, 0, 0), nrow = 1)), names(df)))\n        }\n        df[,4] &lt;&lt;- 1-cumprod(1-df[,2])\n        df[,3] &lt;&lt;- c(df[1,4], df[-1,4] - df[-nrow(df),4])\n      }\n    } else if(nv &lt; nrow(df)) {\n      df &lt;&lt;- df[1:nv,]\n    }\n    replaceData(proxy, df) \n  })\n}\n\nshinyApp(ui = ui, server = server)\nIn order to simulate dropouts from the below profile in FACTS, enter the Conditional Visit Dropout Rate into the FACTS Dropout Rate tab.",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Dropout Rate Explanation"
    ]
  },
  {
    "objectID": "concepts/facts/LinearRegressionLMPriors.html",
    "href": "concepts/facts/LinearRegressionLMPriors.html",
    "title": "Linear Regression Multiple Imputation Model",
    "section": "",
    "text": "Jump to widget\n\n\n\nClick to jump straight to prior specification application.",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Linear Regression Multiple Imputation Model"
    ]
  },
  {
    "objectID": "concepts/facts/LinearRegressionLMPriors.html#prior-specification-for-the-linear-regression-multiple-imputation-model",
    "href": "concepts/facts/LinearRegressionLMPriors.html#prior-specification-for-the-linear-regression-multiple-imputation-model",
    "title": "Linear Regression Multiple Imputation Model",
    "section": "Prior Specification for the Linear Regression Multiple Imputation Model",
    "text": "Prior Specification for the Linear Regression Multiple Imputation Model\nThe default setting of “Same priors across all model instances and visits,” implies that each parameter \\(\\alpha\\), \\(\\beta\\), and \\(\\lambda\\) have the same prior for all visits \\(t\\). Estimation of the posterior distribution for these parameters is still done independently for each model instance.\n\nSame prior for all visits and model instances\nThe one prior across all model instance are formulated as: \\[\\alpha_t \\sim \\text{N}\\left(\\alpha_\\mu, \\alpha_{\\sigma}^2\\right)\\] \\[\\beta_t \\sim \\text{N}\\left(\\beta_\\mu, \\beta_{\\sigma}^2\\right)\\] \\[\\lambda_t^2 \\sim \\text{IG}\\left(\\frac{\\lambda_n}{2}, \\frac{\\lambda_\\mu^2 \\lambda_n}{2}\\right)\\]\n\n\nSame prior for all model instances, different prior per visit\nSince each visit will likely have a different estimated intercept and slope needed to accurately impute the final endpoint, the above prior formulation may not be desirable if specifying priors that are not extremely diffuse – especially on the \\(\\beta\\) parameters. Instead, selecting “Specify priors per visit across all model instances,” will share the prior specification across all instances of the model, but allows for different priors to be put on the parameters associated with each visit. The user inputted prior parameters are now subscripted with \\(t\\) to denote the visit they correspond to. These priors apply to all model instances:\n\\[\\alpha_t \\sim \\text{N}\\left(\\alpha_{\\mu_t}, \\alpha_{\\sigma_t}^2\\right)\\] \\[\\beta_t \\sim \\text{N}\\left(\\beta_{\\mu_t}, \\beta_{\\sigma_t}^2\\right)\\] \\[\\lambda_t^2 \\sim \\text{IG}\\left(\\frac{\\lambda_{n_t}}{2}, \\frac{\\lambda_{\\mu_t}^2 \\lambda_{n_t}}{2}\\right)\\]\n\n\nDifferent prior for all model instances and visits\nIt is also possible to specify priors “Per model instance and visit,” in which every visit has separate priors, and those differing priors vary across model instances. This is the most flexible prior specification method. The user inputted prior parameters are now subscripted by both t for visit and i for model instance. \\[\\alpha_{ti} \\sim \\text{N}\\left(\\alpha_{\\mu_{ti}}, \\alpha_{\\sigma_{ti}}^2\\right)\\] \\[\\beta_{ti} \\sim \\text{N}\\left(\\beta_{\\mu_{ti}}, \\beta_{\\sigma_{ti}}^2\\right)\\] \\[\\lambda_{ti}^2 \\sim \\text{IG}\\left(\\frac{\\lambda_{n_{ti}}}{2}, \\frac{\\lambda_{\\mu_{ti}}^2 \\lambda_{n_{ti}}}{2}\\right)\\]",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Linear Regression Multiple Imputation Model"
    ]
  },
  {
    "objectID": "concepts/facts/LinearRegressionLMPriors.html#sec-priorSpecWidget",
    "href": "concepts/facts/LinearRegressionLMPriors.html#sec-priorSpecWidget",
    "title": "Linear Regression Multiple Imputation Model",
    "section": "Prior Specification Widget",
    "text": "Prior Specification Widget\n\nInterpretation of parameters\n\n\\(\\alpha_{t}\\)\n\nThe expected response on the final endpoint when the early visit \\(t\\) has a response of 0\n\n\\(\\beta_{t}\\)\n\nIf \\(\\alpha=0\\), then \\(\\beta\\) is how many times larger the final endpoint response is than the early endpoint at visit \\(t\\). If \\(\\beta=0\\), then no matter what the early visit response is, the expectation for the final visit is \\(\\alpha\\). If \\(\\beta=1\\), then for any early response the expectation of the final response is the \\(\\text{early response} + \\alpha\\). A \\(\\beta \\lt 1\\) generally implies that the final endpoint is expected to regress towards 0 (when \\(\\alpha=0\\)), and a \\(\\beta \\gt 1\\) implies that the final response is expected to keep growing relative to the early visit response.\n\n\\(\\lambda_{t}\\)\n\nThe standard deviation around the expectation of the final visit response. This dictates how close the imputed final endpoint responses are to the mean response for a subject given \\(\\alpha\\) and \\(\\beta\\). Lower \\(\\lambda_t\\) implies higher correlation between the early visit response and final visit response.\n\n\n```xentzestcdgtw #| standalone: true #| viewerHeight: 1000\nlibrary(shiny) library(DT) library(ggplot2) library(htmltools)\nalignCenter &lt;- function(el) { htmltools::tagAppendAttributes(el, style=“margin-left:auto;margin-right:auto;” ) }\nsketch = htmltools::withTags(table( class = ‘display’, thead( tr( th(rowspan = 2, ’‘), th(rowspan = 2, style = “border-right: solid 1px;”,’Observed Visit Data’), th(colspan = 2, class=” dt-center”, style = “border-right: solid 1px;”,‘B1 priors’), th(colspan = 2, class=” dt-center”, style = “border-right: solid 1px;”,‘B2 priors’), th(colspan = 2, class=” dt-center”, style = “border-right: solid 1px;”,‘BB priors’) ), tr( th(“mean”), th(style = “border-right: solid 1px;”, “SD”), th(“mean”), th(style = “border-right: solid 1px;”, “SD”), th(“center”), th(style = “border-right: solid 1px;”, “weight”), ) ) ))\nui &lt;- fluidPage( tags\\(head(\n    # Note the wrapping of the string in HTML()\n    tags\\)style(HTML(” .my_col_class { align-content: center; }“) ) ),\ntitlePanel(h1(“Linear Regression LM Priors”, align = “center”)), alignCenter(sliderInput(“numVisits”, “Number of visits:”, min = 2, max = 20, value = 5, step = 1)), DTOutput(“dataInputTable”), h5(“Double click on a cell to edit.”, align = “center”), br(), titlePanel(h2(“Plot a subject’s prior predictive”, align = “center”)), fluidRow( #column(5, offset = 1, uiOutput(“slider”)), column(5, offset = 1, uiOutput(“slider”)), column(6, fluidRow( column(6, offset = 2, checkboxInput(“fixAlpha”, “Fix alpha at its mean?”, value = FALSE, width = “100%”)), column(6, offset = 2, checkboxInput(“fixBeta”, “Fix beta at its mean?”, value = FALSE, width = “100%”)), column(6, offset = 2, checkboxInput(“removePredictive”, “Remove endpoint prior predictive?”, value = FALSE, width = “100%”)) )) ), fluidRow( column(6, plotOutput(“visitToFinalPlot”)), column(6, plotOutput(“priorPredictive”)) )\n)\ngetLowerMedianUpper = function(earlyVisitVal, alpha = c(0,1), beta = c(0,1), lambda = c(1,1)) { distMeanFinal = c(alpha[1] + beta[1]earlyVisitVal, sqrt(alpha[2]^2 + beta[2]^2earlyVisitVal^2))\ndeviates = rnorm(10000) deviates = (deviates - mean(deviates))/(sd(deviates))\nif(any(is.na(lambda))) { samps = (deviatesdistMeanFinal[2] + distMeanFinal[1]) } else { samps = (deviatesdistMeanFinal[2] + distMeanFinal[1]) + rnorm(10000, 0, sd = sqrt(1/rgamma(10000, lambda[2]/2, lambda[1]^2*lambda[2]/2))) }\ndistValueFinal = c(mean(samps), sd(samps))\nreturn(list(“meanFinal” = data.frame(lower = distMeanFinal[1] + qnorm(.025)distMeanFinal[2], median = distMeanFinal[1], upper = distMeanFinal[1] + qnorm(0.975)distMeanFinal[2]), “predictionFinal” = data.frame(lower = quantile(samps,.025), median = median(samps), upper = quantile(samps,.975)))) }\nserver &lt;- function(input, output, session) {\ndf = data.frame(VisitResponse = c(2,5,3,7,11), alphaPriorMean = 0, alphaPriorSD = 2, betaPriorMean = 1, betaPriorSD = 2, lambdaPriorCenter = 5, lambdaPriorWeight = 3) df[5,] = c(5, NA, NA, NA, NA, NA, NA) row.names(df) = paste(“Visit”, 1:5)\n## Render DF to actually change output\\(dataInputTable = renderDT(datatable(df,\n                                             options = list(\n                                               pageLength = 20,\n                                               dom = \"t\",\n                                               autoWidth = TRUE,\n                                               columnDefs = list(list(className = 'dt-center', orderable = FALSE, width = '75px', targets = 0:7),\n                                                                 list(width = \"150px\", targets = 0:1))\n                                             ),\n                                             container = sketch,\n                                             rownames = TRUE,\n                                             # escape = FALSE,\n                                             selection = 'none',\n                                             editable = list(target = \"cell\")\n  ) |&gt; formatStyle(c(1,3,5,7), `border-right` = \"solid 1px\") |&gt;\n    formatRound(1, digits = 4) |&gt; formatRound(2:7, digits = 2) |&gt;\n    formatStyle(0,\n                target = \"row\",\n                backgroundColor = styleEqual(paste(\"Visit\",input\\)lastVisitWithData), “lightblue”, ‘white’)) )\n## Update from Conditional proxy = dataTableProxy(‘dataInputTable’)\nobserveEvent(input\\(dataInputTable_cell_edit, {\n    info = input\\)dataInputTable_cell_edit i = info\\(row\n    j = info\\)col v = info$value\nif(i &lt; nrow(df) | j == 1) {\n  df &lt;&lt;- editData(df, info)\n} else {\n  df[i,j] &lt;&lt;- NA\n}\nreplaceData(proxy, df) \n})\nobserve({ nv = input$numVisits if(nv &gt; nrow(df)) { tempd = df for(i in 1:(nv-nrow(df))) { tempd = rbind(tempd, setNames(data.frame(c(tempd[nrow(tempd),])), names(tempd))) rownames(tempd)[nrow(tempd)] = paste(“Visit”, nrow(tempd)) tempd[nrow(tempd)-1,-1] = tempd[nrow(tempd)-2,-1] } df &lt;&lt;- tempd } else if(nv &lt; nrow(df)) { df &lt;&lt;- df[1:nv,] df[nv,-1] &lt;&lt;- NA } replaceData(proxy, df) })\nsliderParams &lt;- reactiveValues(max = 5, value = 3) output\\(slider &lt;- renderUI({\n    sliderInput(\"lastVisitWithData\", \"Last complete visit:\", min = 1, max = sliderParams\\)max, value = sliderParams\\(value, step = 1)\n  })\n  observeEvent(input\\)numVisits, { sliderParams\\(max = input\\)numVisits if(!is.null(input\\(lastVisitWithData)) {\n      sliderParams\\)value &lt;- min(input\\(lastVisitWithData, input\\)numVisits) } else { sliderParams$value = 3 } })\noutput\\(priorPredictive = renderPlot({\n    req(input\\)lastVisitWithData) input$dataInputTable_cell_edit\nlvIndex = input$lastVisitWithData\nfinalVisitIndex = input$numVisits\ntempDF = df\ndataToPlot = getLowerMedianUpper(tempDF[lvIndex,1],\n                                 alpha = c(tempDF[lvIndex,2], ifelse(input$fixAlpha, 0, tempDF[lvIndex,3])),\n                                 beta = c(tempDF[lvIndex,4], ifelse(input$fixBeta, 0, tempDF[lvIndex,5])),\n                                 lambda = c(tempDF[lvIndex,6], tempDF[lvIndex,7]))\n\ntempDF$RowVisitIndex = 1:nrow(tempDF)\ntempDF$visitKnown = \"included\"\ntempDF$visitKnown[tempDF$RowVisitIndex &gt; lvIndex] = \"excluded\"\n\n# tempDF = rbind(setNames(data.frame(c(tempDF[1,])), names(tempDF)), tempDF)\n# tempDF[1,1] = 0\n# tempDF$RowVisitIndex[1] = 0\n# rownames(tempDF)[1] = \"Baseline\"\n\np1 = ggplot() + \n  geom_point(dat = tempDF, aes(x = RowVisitIndex, y = VisitResponse, color = visitKnown), size = 3) + \n  scale_color_manual(breaks = c(\"included\", \"excluded\"), values = c(\"black\", \"gray70\"), guide = \"none\") +\n  coord_cartesian(xlim = c(0, finalVisitIndex)) + \n  scale_x_continuous(breaks = 0:finalVisitIndex, labels = c(\"Baseline\", 1:finalVisitIndex)) +\n  xlab(\"Visit\") + ylab(\"Response\") + ggtitle(\"Predicting Final Endpoint of a Subject\") +\n  theme_bw() + \n  theme(plot.title = element_text(size = 20), text = element_text(size = 16), legend.justification = \"left\", legend.position = \"bottom\", legend.direction = \"vertical\")\n\nif(lvIndex &lt; finalVisitIndex) {\n  if(!input$removePredictive) {\n    p1 = p1 + \n      geom_segment(data = dataToPlot[[2]], aes(x = finalVisitIndex, y = lower, yend = upper), color = \"darkgreen\", linewidth = 2.5) +\n      annotate(geom = \"point\", x = finalVisitIndex, y = dataToPlot[[2]]$median, color = \"darkgreen\", size = 3, shape = 18) +\n      geom_ribbon(data = NULL, aes(x = c(lvIndex, finalVisitIndex),\n                                   ymin = c(tempDF$VisitResponse[lvIndex], dataToPlot[[2]]$lower),\n                                   ymax = c(tempDF$VisitResponse[lvIndex], dataToPlot[[2]]$upper),\n                                   fill = \"preds\"),  color = NA, alpha = .2)\n  }\n  p1 = p1 +\n    geom_segment(data = dataToPlot[[1]], aes(x = finalVisitIndex, y = lower, yend = upper), color = \"darkblue\", linewidth = 1.5) +\n    annotate(geom = \"point\", x = finalVisitIndex, y = dataToPlot[[1]]$median, color = \"darkblue\", size = 3, shape = 18) +\n    annotate(geom = \"segment\", x = lvIndex, xend = finalVisitIndex, y = tempDF$VisitResponse[lvIndex], yend = dataToPlot[[1]]$median, linetype = \"dashed\", color = \"darkblue\")+\n    geom_ribbon(data = NULL, aes(x = c(lvIndex, finalVisitIndex),\n                                 ymin = c(tempDF$VisitResponse[lvIndex], dataToPlot[[1]]$lower),\n                                 ymax = c(tempDF$VisitResponse[lvIndex], dataToPlot[[1]]$upper)),\n                fill = \"darkblue\",  color = NA, alpha = .4)\n} else {\n  p1 = p1 + annotate(geom=\"text\", label = \"Final Visit Value Known\",\n                     alpha = .5, size = 10, x = (finalVisitIndex)/2, y = Inf, vjust = 1.3)\n}\n\np1 = p1 + scale_fill_manual(NULL, breaks = c(\"preds\"), limits = c(\"preds\"), values = c(\"darkgreen\"), labels = c(\"Prior predictive distribution for final endpoint of subject.\"))\n#  guides(fill = guide_legend(override.aes = list(limits = c(\"darkgreen\", \"darkblue\"), labels = c(\"Prior distribution for mean of imputed value.\", \"Prior predictive distribution for final endpoint of subject.\")))) \n\np1\n})\noutput\\(visitToFinalPlot = renderPlot({\n    input\\)dataInputTable_cell_edit req(input$lastVisitWithData)\nlvIndex = input$lastVisitWithData\nfinalVisitIndex = input$numVisits\n\ntempDF = df\n\nmin_s = ifelse(min(tempDF$VisitResponse, na.rm = TRUE) &lt; 0, (min(tempDF$VisitResponse, na.rm = TRUE)+1)*1.1, 0)\nmax_s = ifelse(max(tempDF$VisitResponse, na.rm = TRUE) &gt; 0, (max(tempDF$VisitResponse, na.rm = TRUE)+1)*1.1, 0)\n\ns = seq(min_s-5, max_s+5, length.out = 101)\n\nmeanDist_mean = tempDF$alphaPriorMean[lvIndex] + tempDF$betaPriorMean[lvIndex]*s\nif(!input$fixAlpha & !input$fixBeta) {\n  meanDist_sd = sqrt(tempDF$alphaPriorSD[lvIndex]^2 + tempDF$betaPriorSD[lvIndex]^2*s^2)\n} else if(input$fixAlpha & !input$fixBeta) {\n  meanDist_sd = sqrt(tempDF$betaPriorSD[lvIndex]^2*s^2)\n} else if(!input$fixAlpha & input$fixBeta) {\n  meanDist_sd = rep(sqrt(tempDF$alphaPriorSD[lvIndex]^2), length(s))\n} else {\n  meanDist_sd = rep(0, length(meanDist_mean))\n}\n\nplotDF = data.frame(earlyVis = s,\n                    lower = meanDist_mean + qnorm(0.025)*meanDist_sd,\n                    median= meanDist_mean,\n                    upper = meanDist_mean + qnorm(0.975)*meanDist_sd)\n\nif(lvIndex &lt; finalVisitIndex) {\n  if(!input$removePredictive) {\n    numSamps = 2500\n    \n    deviates = rnorm(numSamps)\n    deviates = (deviates - mean(deviates))/(sd(deviates))\n    normigsamps = rnorm(numSamps, 0, sd = sqrt(1/rgamma(numSamps, tempDF$lambdaPriorWeight[lvIndex]/2, tempDF$lambdaPriorCenter[lvIndex]^2*tempDF$lambdaPriorWeight[lvIndex]/2)))\n    \n    distVals = matrix(NA, ncol = 2, nrow = length(s))\n    for(i in 1:length(s)) {\n      distVals[i,] = quantile((deviates*meanDist_sd[i] + meanDist_mean[i] + normigsamps), c(0.025, 0.975))\n    }\n    \n    plotDF$lowerPred = distVals[,1]\n    plotDF$upperPred = distVals[,2]\n  }\n  \n  p2 = ggplot(data = plotDF) + geom_abline(aes(slope = tempDF$betaPriorMean[lvIndex], intercept = tempDF$alphaPriorMean[lvIndex]), color = \"darkblue\", linewidth = 1.5) + \n    geom_ribbon(aes(x = s, ymin = lower, ymax = upper, fill = \"means\"), color = NA, alpha = 0.4)\n  \n  if(!input$removePredictive) {\n    p2 = p2 + geom_ribbon(aes(x = s, ymin = lowerPred, ymax = upperPred), fill = \"darkgreen\", color = NA, alpha = 0.2) \n  }\n  p2 = p2 +\n    coord_cartesian(xlim = c(min_s, max_s)) +\n    xlab(\"Early Visit Known Value\") + ylab(\"Expectation of Final Visit Response\") + ggtitle(\"Expectation of Final Visit Given Early Visit\") +\n    theme_bw() + \n    theme(plot.title = element_text(size = 20), text = element_text(size = 16), legend.justification = \"right\", legend.position = \"bottom\", legend.direction = \"vertical\")\n} else {\n  p2 = ggplot(data = NULL) + geom_abline(aes(fill = \"means\"), slope = 1, intercept = 0, color = \"darkblue\", linewidth = 1.5) + \n    coord_cartesian(xlim = c(min_s, max_s), ylim = c(min_s, max_s)) +\n    annotate(geom=\"text\", label = \"Final Visit Value Known\",\n             alpha = .5, size = 10, x = (max_s + min_s)/2, y = Inf, vjust = 1.3) +\n    xlab(\"Early Visit Known Value\") + ylab(\"Expectation of Final Visit Response\") + ggtitle(\"Expectation of Final Visit Given Early Visit\") +\n    theme_bw() + \n    theme(plot.title = element_text(size = 20), text = element_text(size = 16), legend.justification = \"right\", legend.position = \"bottom\", legend.direction = \"vertical\")\n}\np2 = p2 + scale_fill_manual(NULL, breaks = c(\"means\"), limits = c(\"means\"), values = c(\"darkblue\"), labels = c(\"Prior distribution for mean of imputed value.\"))  \np2\n}) }\nshinyApp(ui = ui, server = server)```",
    "crumbs": [
      "Concepts",
      "FACTS Tips and Tricks",
      "Linear Regression Multiple Imputation Model"
    ]
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "We pride ourselves in delivering fast support and will go above and beyond for you.\n\n\nGeneral Inquiries and Help using FACTS\nPlease contact us directly via e-mail at facts@berryconsultants.com.\n\n\nGet FACTS\nTo directly apply for a free 3-months FACTS Evaluation license, please use the following online form.\nTo directly enquire about a free demo or a regular license, please use the following online form.\nIf you are unsure, feel free to contact us directly via email at facts@berryconsultants.com.\n\n\nGeneral Inquiries about Berry Consultants\nPlease use the following online form."
  },
  {
    "objectID": "documentation/v71/examples/CRM/example1.html",
    "href": "documentation/v71/examples/CRM/example1.html",
    "title": "Example 1",
    "section": "",
    "text": "First example",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "Examples",
      "CRM",
      "Example 1"
    ]
  },
  {
    "objectID": "documentation/v71/examples/Staged/example1.html",
    "href": "documentation/v71/examples/Staged/example1.html",
    "title": "Example 1",
    "section": "",
    "text": "First example",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "Examples",
      "Staged",
      "Example 1"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html",
    "href": "documentation/v71/userguides/crm.html",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "This document describes how use the FACTS Dose Escalation (DE) CRM design engine. It is intended for all end users of the system.\n\n\n\nThis document covers the FACTS Dose Escalation N-CRM design engine user interface.\nThis document does not address the internal workings of the design engines or algorithms, which are addressed in the associated Design Engine Specification. It also does not address the use of FACTS Core Designs or Enrichment Designs, which are covered in other User Guides.\nThe screenshots provided are specific to a particular installation and may not reflect the exact layout of the information seen by any particular user. They were taken from FACTS 6.3 and later installed on Windows 10. Different versions of Windows or the use of different Windows themes will introduce some differences in appearance. The contents of each tab, however, will be consistent with the software.\n\n\n\nThis document has been updated for the version 7.1 release of Dose Escalation FACTS.\n\n\n\nIf writing in LaTex and using Bibtex, if you wish to cite FACTS (thank you!), can we suggest the following:\n@techreport{FACTS71,\n  author = {{FACTS Development Team}},\n  title = {{FACTS}: Fixed and Adaptive Clinical Trial Simulator},\n  year  = {2024},\n  month = {12},\n  number = {Version 7.1},\n  type         = {Computer Software},\n  institution = {Berry Consultants LLC},\n  address = {Austin, TX},\n  note   = {https://www.berryconsultants.com/software/facts/}\n}\nThis will result in a reference that, for example in the APA style, will look like the following:\nFACTS Development Team (2024). FACTS: Fixed and adaptive clinical trial simulator. Computer Software Version 7.1, Berry Consultants LLC, Austin, TX. https://www.berryconsultants.com/software/facts/.\n\n\n\nTable 1 gives an overview of the acronyms and abbreviations used in this document.\n\n\n\nTable 1: List of terms used in the CRM user guide\n\n\n\n\n\n\n\n\n\nName\nDefinition\n\n\n\n\nCap\nA limit on the number of subjects recruited. In FACTS N-CRM users can specify a cap on the overall number of subjects to be recruited in the trial (the ‘Overall Cap’) and specify stopping rules to define when the trial should stop before it reaches cap.\n\n\nControl\nIs the treatment arm with which the novel treatment(s) are principally being compared. Control may be placebo, or some existing standard of care, or therapy, against which the novel treatment has to be benchmarked in order to determine its likely usefulness.\n\n\nCore\nFACTS Core: A mode of FACTS for designing trials where multiple treatments, (possibly different doses of a novel treatment) are tested against a control and optionally an active comparator.\n\n\nCRM\nContinual Reassessment Method – a dose escalation design where the dose-toxicity is estimated using a simple Bayesian model, and the resulting estimates used to control the dose escalation and estimate the Maximum Tolerated Dose (MTD).\n\n\nDE\nDose Escalation: a mode of FACTS where subjects are treated in cohorts and dose escalation is determined by the number of toxicities observed.\n\n\nED\nEnrichment Designs: a mode of FACTS for designing trials where the same treatment is testing in different settings for example different sub-populations or different but related indications.\n\n\nFACTS\nFixed and Adaptive Clinical Trial Simulator.\n\n\nFinal Endpoint\nThe final value, or state, of a subject’s endpoint.\n\n\nGUI\nGraphical User Interface, the part of the FACTS application that the user interacts with.\n\n\nMethod\nIn the FACTS documentation we try to reserve the term ‘method’ for the algorithms used in the simulation (as opposed to the analysis) part of the program. In the analysis part we use the term ‘Model’, see below.\n\n\nModel\nIn the FACTS documentation we try to reserve the term ‘model’ for the statistical models used in the analysis of the trial data (in the ‘design’ section of the FACTS user interface). Where mathematical algorithms are used for other purposes in FACTS (for instance in the generation of the simulated data) we try to use the term ‘method’. We have found that initially it is very easy for users to be confused between these two parts of FACTS and we feel that using distinct terminology may help to reduce this.\n\n\nMTD\nThe dose most likely to be the Maximum Tolerated Dose (MTD) – the dose with the highest Pr(MTD).\n\n\nMTD+\nThe dose most likely to be the MTD+ – the dose with the highest Pr(MTD+).\n\n\nPr(MTD)\nA dose’s probability of being MTD is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable toxicity band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. This estimate of MTD is constrained to select one of the available doses.\n\n\nPr(MTD+)\nA dose’s probability of being the MTD+ is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. Unlike Pr(MTD), Pr(MTD+) includes estimating whether a dose below or a dose above the range of those being tested is more likely to have a toxicity in the acceptable band than any of the doses in the range.\n\n\nProfile\nA profile is a specification of one aspect of a scenario. A scenario is made up of one profile of each of the required types for the type of trial being simulated. FACTS allows the user to specify multiple profiles of each type and then presents all the possible combinations of profiles as scenarios that can be used to drive simulations.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nScenario\nA scenario is the complete specification of the unknown external factors that determine the data observed on the trial and its timing. The exact factors depend on the type of trial being simulated but typically include:  -) the distribution of the final change from base line, or probability of response or rate of events in the different treatment groups  -) the properties of subjects’ early responses and the correlation with their final outcome  -) the rate at which subjects are recruited into the trial  -) the rate at which subjects drop out of the trial.\n\n\nSPEC\nThe Design Engine Specification, describes the system algorithms, and meaning of parameters.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nSubject\nSomeone recruited onto a clinical trial for the purposes of learning about the properties of a treatment. Depending on the type of trial they might be patients or they might be healthy volunteers.\n\n\nTreatment Arm\nSubjects on entering the study are randomized to different ‘treatment arms’. Subjects randomized to the same arm receive the same treatment and the responses of the subjects in the arm analyzed to determine the expected response to that treatment, allowing the expected responses to the different treatments to be compared.\n\n\nUG\nThe User Guide; describes how to use the system.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-purpose",
    "href": "documentation/v71/userguides/crm.html#sec-purpose",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "This document describes how use the FACTS Dose Escalation (DE) CRM design engine. It is intended for all end users of the system.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-scope",
    "href": "documentation/v71/userguides/crm.html#sec-scope",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "This document covers the FACTS Dose Escalation N-CRM design engine user interface.\nThis document does not address the internal workings of the design engines or algorithms, which are addressed in the associated Design Engine Specification. It also does not address the use of FACTS Core Designs or Enrichment Designs, which are covered in other User Guides.\nThe screenshots provided are specific to a particular installation and may not reflect the exact layout of the information seen by any particular user. They were taken from FACTS 6.3 and later installed on Windows 10. Different versions of Windows or the use of different Windows themes will introduce some differences in appearance. The contents of each tab, however, will be consistent with the software.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-context",
    "href": "documentation/v71/userguides/crm.html#sec-context",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "This document has been updated for the version 7.1 release of Dose Escalation FACTS.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-citing",
    "href": "documentation/v71/userguides/crm.html#sec-citing",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "If writing in LaTex and using Bibtex, if you wish to cite FACTS (thank you!), can we suggest the following:\n@techreport{FACTS71,\n  author = {{FACTS Development Team}},\n  title = {{FACTS}: Fixed and Adaptive Clinical Trial Simulator},\n  year  = {2024},\n  month = {12},\n  number = {Version 7.1},\n  type         = {Computer Software},\n  institution = {Berry Consultants LLC},\n  address = {Austin, TX},\n  note   = {https://www.berryconsultants.com/software/facts/}\n}\nThis will result in a reference that, for example in the APA style, will look like the following:\nFACTS Development Team (2024). FACTS: Fixed and adaptive clinical trial simulator. Computer Software Version 7.1, Berry Consultants LLC, Austin, TX. https://www.berryconsultants.com/software/facts/.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-definitions",
    "href": "documentation/v71/userguides/crm.html#sec-definitions",
    "title": "FACTS Dose Escalation CRM",
    "section": "",
    "text": "Table 1 gives an overview of the acronyms and abbreviations used in this document.\n\n\n\nTable 1: List of terms used in the CRM user guide\n\n\n\n\n\n\n\n\n\nName\nDefinition\n\n\n\n\nCap\nA limit on the number of subjects recruited. In FACTS N-CRM users can specify a cap on the overall number of subjects to be recruited in the trial (the ‘Overall Cap’) and specify stopping rules to define when the trial should stop before it reaches cap.\n\n\nControl\nIs the treatment arm with which the novel treatment(s) are principally being compared. Control may be placebo, or some existing standard of care, or therapy, against which the novel treatment has to be benchmarked in order to determine its likely usefulness.\n\n\nCore\nFACTS Core: A mode of FACTS for designing trials where multiple treatments, (possibly different doses of a novel treatment) are tested against a control and optionally an active comparator.\n\n\nCRM\nContinual Reassessment Method – a dose escalation design where the dose-toxicity is estimated using a simple Bayesian model, and the resulting estimates used to control the dose escalation and estimate the Maximum Tolerated Dose (MTD).\n\n\nDE\nDose Escalation: a mode of FACTS where subjects are treated in cohorts and dose escalation is determined by the number of toxicities observed.\n\n\nED\nEnrichment Designs: a mode of FACTS for designing trials where the same treatment is testing in different settings for example different sub-populations or different but related indications.\n\n\nFACTS\nFixed and Adaptive Clinical Trial Simulator.\n\n\nFinal Endpoint\nThe final value, or state, of a subject’s endpoint.\n\n\nGUI\nGraphical User Interface, the part of the FACTS application that the user interacts with.\n\n\nMethod\nIn the FACTS documentation we try to reserve the term ‘method’ for the algorithms used in the simulation (as opposed to the analysis) part of the program. In the analysis part we use the term ‘Model’, see below.\n\n\nModel\nIn the FACTS documentation we try to reserve the term ‘model’ for the statistical models used in the analysis of the trial data (in the ‘design’ section of the FACTS user interface). Where mathematical algorithms are used for other purposes in FACTS (for instance in the generation of the simulated data) we try to use the term ‘method’. We have found that initially it is very easy for users to be confused between these two parts of FACTS and we feel that using distinct terminology may help to reduce this.\n\n\nMTD\nThe dose most likely to be the Maximum Tolerated Dose (MTD) – the dose with the highest Pr(MTD).\n\n\nMTD+\nThe dose most likely to be the MTD+ – the dose with the highest Pr(MTD+).\n\n\nPr(MTD)\nA dose’s probability of being MTD is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable toxicity band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. This estimate of MTD is constrained to select one of the available doses.\n\n\nPr(MTD+)\nA dose’s probability of being the MTD+ is the probability that it is the dose with the highest probability of having a toxicity rate in the acceptable band, and (if a threshold has been specified) does not have a probability of excess or unacceptable toxicity above the threshold. Unlike Pr(MTD), Pr(MTD+) includes estimating whether a dose below or a dose above the range of those being tested is more likely to have a toxicity in the acceptable band than any of the doses in the range.\n\n\nProfile\nA profile is a specification of one aspect of a scenario. A scenario is made up of one profile of each of the required types for the type of trial being simulated. FACTS allows the user to specify multiple profiles of each type and then presents all the possible combinations of profiles as scenarios that can be used to drive simulations.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nScenario\nA scenario is the complete specification of the unknown external factors that determine the data observed on the trial and its timing. The exact factors depend on the type of trial being simulated but typically include:  -) the distribution of the final change from base line, or probability of response or rate of events in the different treatment groups  -) the properties of subjects’ early responses and the correlation with their final outcome  -) the rate at which subjects are recruited into the trial  -) the rate at which subjects drop out of the trial.\n\n\nSPEC\nThe Design Engine Specification, describes the system algorithms, and meaning of parameters.\n\n\nResponse\nThe change in a subject’s endpoint compared to their baseline state.\n\n\nSubject\nSomeone recruited onto a clinical trial for the purposes of learning about the properties of a treatment. Depending on the type of trial they might be patients or they might be healthy volunteers.\n\n\nTreatment Arm\nSubjects on entering the study are randomized to different ‘treatment arms’. Subjects randomized to the same arm receive the same treatment and the responses of the subjects in the arm analyzed to determine the expected response to that treatment, allowing the expected responses to the different treatments to be compared.\n\n\nUG\nThe User Guide; describes how to use the system.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-7.1-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-7.1-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.1 FACTS 7.1 Changes to N-CRM",
    "text": "2.1 FACTS 7.1 Changes to N-CRM\nIn FACTS 7.1 there were new features added to N-CRM:\n\nIt is now possible to backfill to the current escalation dose (also known as “frontfilling”).\nIt is now possible to specify a third queue concept – maximum number of patients in their DLT period on the current MTD estimate.\nIt is now possible to define the concept of “near” target/MTD as part of stopping rules, for both fine-grained and regular dosing.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-7.0-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-7.0-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.2 FACTS 7.0 Changes to N-CRM",
    "text": "2.2 FACTS 7.0 Changes to N-CRM\nIn FACTS 7.0 the only change was on the Analysis tab, when entering subject data manually, the FACTS GUI now ensures that a cohort number is entered for every subject.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-6.5-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-6.5-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.3 FACTS 6.5 Changes to N-CRM",
    "text": "2.3 FACTS 6.5 Changes to N-CRM\nIn FACTS 6.5 there was a new feature added to N-CRM:\n\nIt is now possible to generate a design report – a Word document describing design - once the design has been simulated. In FACTS 6.5 there was two small changes to the functionality:\nWhen deriving toxicity/efficacy priors from quantiles at the lowest and highest doses, the “middle” probability option now refers to the median dose rather than the reference dose and is now optional. When pre-6.5 FACTS files are loaded in FACTS 6.5, the “middle” probability option will be ignored and replaced by 0.5.\nWhen deriving toxicity/efficacy priors from specific quantiles the specification of at least two dose levels is now required whereas previously the specification of at least three dose levels was required.\n\nIn FACTS 6.5 there were some improvements in the simulated behavior:\n\nDesigns which include efficacy, the “Maximum cohorts used to determine MTD” parameter on the Allocation Rule tab is now observed, in FACTS 6.4 and earlier it was ignored.\nIn N-CRM designs using open enrollment without accrual pausing, FACTS will now output entries in the cohort file for subjects that have been lost following stopping rules being met.\nIn N-CRM designs using open enrollment, FACTS will no longer prematurely apply stopping conditions when there are still subjects whose outcomes have been observed, but not yet processed.\nIn N-CRM designs using open enrollment, FACTS will now report the selected MTD/MED/OSD and associated state to be the dose where the stopping conditions were first met, unless the MTD has subsequently decreased post stopping rules being met. This is to prevent a dose above the one selected when the stopping conditions were met being reported as the MTD when it is very likely that there is insufficient data on this higher dose to justify its selection. If rather than reporting the MTD at the point when the stopping rules where met, you would like the trial to resume if the dose selected as MTD has changed (and this the stopping rules possibly no longer met), ensure that the ”Pause accrual and wait for completers” option is selected on the “Stopping Criteria” tab. This allows the trial to resume if the recruitment cap has not been met.\nFACTS Command Line mode and FLFLL (FACTS Linux File Loader Lite) now correctly handle the processing of N-CRM designs whose prior was derived using the “Legacy Prior” option.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-6.4-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-6.4-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.4 FACTS 6.4 Changes to N-CRM",
    "text": "2.4 FACTS 6.4 Changes to N-CRM\nIn FACTS 6.4 there were no changes to the Dose Escalation simulators.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-6.3-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-6.3-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.5 FACTS 6.3 Changes to N-CRM",
    "text": "2.5 FACTS 6.3 Changes to N-CRM\nIn FACTS 6.3 a number of changes were made to improve facilities in N-CRM, or improve the way existing facilities were implemented. These were:\n\nNew run-in options: the existing run-in scheme is available as “simple run-in”, “custom run-in” allows a specific sequence of doses and number of subjects to test at each dose to be specified, “small cohort pre-escalation” allows a run that uses a smaller cohort size but follows the dose escalation rules and over dose control.\nNew “backfill” options in open enrolment. Backfill allows subjects that become available at a time when they can’t be allocated to the current dose (because the maximum number of subjects without final results have already been allocated to the current dose).\nImproved handling of “maximum subjects without final results” in open enrolment. In earlier versions of FACTS this was a “global” maximum, which led to a suboptimal allocation pattern and overly cautious rejection of subjects that became available. The new model applies a maximum “per dose” so that once the trial has escalated to a new dose strength, any subjects without final results on lower doses do not block allocation to the new dose, in addition it is possible to specify two different maximums – one for when a dose has just been escalated to but has not been “cleared” (typically smaller and more cautious), and one when a dose has been cleared but we continue to allocate to it because it is the target dose (typically larger and more confident). This method is such an improvement that we recommend moving any design using open enrolment to this new version of FACTS.\nImproved Ordinal Toxicity model – the way the likelihood is calculated has been improved – reducing the uncertainty in the model fit. Any design using an ordinal model will need to re-calibrate the prior if you move the design to FACTS 6.3. If you have a design already complete, or in execution we recommend you remain using the earlier version of FACTS for that trial.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-6.2-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-6.2-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.6 FACTS 6.2 Changes to N-CRM",
    "text": "2.6 FACTS 6.2 Changes to N-CRM\nIn FACTS 6.2 features available separately in the other FACTS CRM engines (CRM (Toxicity), bCRM & CRM Ordinal) were all incorporated into N-CRM. This allowed these features to be used in conjunction with N-CRM’s target toxicity band methodology, overdose control and open enrollment features, as well as in conjunction with each other for the first time.\nThe new features are:\n\nFrom CRM (Toxicity) the option to specify that the data is coming from ‘two groups’ and for the toxicity experienced in the two groups to be modelled with a joint model [CRM 2 Sample]. This allows a trial where there are two patient populations (such as adults and children) or where there are two versions of the treatment to be simulated.\nFrom bCRM the option to model a second binary efficacy endpoint [bCRM] and the for dose allocation to proceed in two stages – the first to establish an MTD and the second to establish an MED.\nFrom CRM Ordinal the option for the toxicity endpoint to be modelled not as binary endpoint, but one with different categories of toxicity, and with a joint model applied to the different categories [CRM Ordinal]. The endpoint can be to model either 3 or 4 categories of toxicity:\n\ncategory 1 is “no toxicity”,\ncategory 2 is “mild toxicity”,\ncategory 3 is “toxicity”\ncategory 4 (if included) is “severe toxicity”\n\n\nAll decision making is made in terms of the probability of observing a category 3 (or worse) toxicity.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-6.1-changes-to-n-crm",
    "href": "documentation/v71/userguides/crm.html#facts-6.1-changes-to-n-crm",
    "title": "FACTS Dose Escalation CRM",
    "section": "2.7 FACTS 6.1 Changes to N-CRM",
    "text": "2.7 FACTS 6.1 Changes to N-CRM\nIn FACTS 6.1 N-CRM has the new feature of ‘design variants’ that allow the user to easily simulate and evaluate an N-CRM design at different sample sizes. This change includes 4 elements:\n\nUnder the ‘Study’ tab the user can now specify the number of design variants, and for each variant the maximum study size in Cohorts.\nOn the simulation tab FACTS will display a copy of each simulation scenario for each variant.\nThe simulation results now include the Ppn of trials that stopped for each stopping reason: stopping because all doses are too toxic (the toxicity estimates exceed the overdose criteria), because a stopping rule was met or because the study cap was reached.\nThere are now a set of cross variant graphs that show trellis plots of the key summary graphs by design variant and scenario.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#overdose-control",
    "href": "documentation/v71/userguides/crm.html#overdose-control",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.1 Overdose Control",
    "text": "3.1 Overdose Control\nOverdose control can be specified on the Study &gt; Toxicity tab. Overdose control specifies a limit on the probability that a dose has a toxicity rate above a certain level. After fitting the Bayesian logistic regression model, all doses for which the posterior probability that their toxicity rate lies above the specified level exceeds the specified limit are ineligible for allocation. Because the Bayesian Logistic regression is monotonic, this means that after every analysis either all doses are permitted for allocation or there will be a dose level above which no dose is permitted for allocation.\n\n\n\n\n\n\nFigure 1: Setting the overdose control limit\n\n\n\nThe overdose control is specified in terms of the “toxicity bands” (concept of allowing ranges for the target toxicity, excess toxicity, unacceptable toxicity and under-dosing explained in more detail in this section) and can either be in terms of the “excess and unacceptable toxicity bands” or just the “unacceptable toxicity band”. The “excess and unacceptable toxicity band” is every toxicity rate above the upper bound of the target band. Care should be taken when setting the permitted threshold for this joint band. If set below 0.5, it will likely exclude doses whose mean expected toxicity rate is within the target band with the risk that this makes the escalation decision in the design too cautious. Initially it might be recommended to just use the “unacceptable band” for specifying the overdose control. This allows an overdose control that is more strict – for example: “exclude any dose where the probability that the toxicity rate is above 0.6, is greater than 20%“. The lower bound for the unacceptable band can be set wherever desired, its only role is in defining this band for overdose control. It is also possible to specify that the limit changes over the course of the trial, allowing the overdose control to become stricter as more information becomes available. For example, one could reduce the permitted probability of a dose having a toxicity rate in the unacceptable band from 50% to 25% in steps of 2.5% after every cohort.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#dose-escalation-rules",
    "href": "documentation/v71/userguides/crm.html#dose-escalation-rules",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.2 Dose Escalation Rules",
    "text": "3.2 Dose Escalation Rules\nThe dose escalation could be solely controlled by the overdose control (as originally proposed in (Neuenschwander, Branson, and Gsponer 2008)), however this means that the escalation behavior is very dependent on the interplay between the prior and the observed data. Usually, teams prefer to have a fixed set of rules in place ensuring the escalation behavior is sufficiently cautious. FACTS has an option to just use overdose control or to use a combination of overdose control and a set of fixed escalation rules. In the latter case, the following rules can be set in the Design &gt; Allocation Rule &gt; Allocation tab:\n\n\n\n\n\n\nFigure 2: Dose escalation rules\n\n\n\nWe introduce the notion of whether a dose has been “cleared”. A dose is cleared once we have sufficient data on it (usually, but not necessarily, the results of one cohort, but if the cohort size is small, for example 2 subjects, perhaps more than one cohort will be required). This can be supplemented by a rule that if the observed raw toxicity rate at the dose exceeds a certain limit, then the dose is not counted as cleared (this rule is usually unnecessary if overdose control limits have been set). Once a dose has been cleared, it stays cleared, meaning there is “maximum cleared dose”. The number of dose increments or the factor of dose strength above the current cleared dose that can be allocated to is then specified. For example, with doses of 12.5, 25, 50, 100, 150, 200, 250, we might allow escalation at two dose increments a time. In the figure below, you see the combination of settings used to achieve this behaviour alongside the “Fastest Possible Dose Escalation” plot on the right:\n\n\n\n\n\n\nFigure 3: Escalation by number of dose increments\n\n\n\nAlternatively, we can specify the permitted escalation as a ratio, for example we might allow the dose strength to be at most tripled at each escalation, which, with the example dose strengths, makes the initial escalation more cautious:\n\n\n\n\n\n\nFigure 4: Escalation by dose strength factor\n\n\n\nThe escalation rules can be adjusted so that instead of a single increment rule, there are different increments depending on the dose, or depending on the number of observed toxicities. To modify our earlier example, we can allow escalation by 2 dose levels while no toxicities have been observed, but limit it to only one dose level once one or more toxicities have been observed:\n\n\n\n\n\n\nFigure 5: Escalation increment varying by number of toxicities\n\n\n\nLastly escalation can be relative to the highest cleared dose, or relative to the last dose allocated.\nTo summarize the allocation procedure:\n\nThe current maximum cleared dose is identified.\nThe current data is analyzed using the Bayesian Logistic Regression model.\nThe overdose rules are evaluated and all doses exceeding the overdose control limit are excluded from this escalation selection.\nFrom the remaining doses, the dose best meeting the target MTD or target toxicity interval objective based on the model is selected as the “target dose” (TD).\nIf the TD is at or below the current maximum cleared dose, the next cohort is allocated to the TD.\nIf the TD is within the escalation rules of the current maximum cleared dose, the next cohort is allocated to the TD.\nOtherwise, the next cohort is allocated to the highest dose above the current maximum cleared dose as allowed by the escalation rules.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#initial-run-in",
    "href": "documentation/v71/userguides/crm.html#initial-run-in",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.3 Initial Run-in",
    "text": "3.3 Initial Run-in\nThe purpose of defining a run-in is to define a fixed allocation behavior to be followed up to the first toxicity being observed. The specified number of subjects to allocate to each dose in the run-in and which doses to test are specified. This scheme is followed until a toxicity is observed or we reach the end of this fixed scheme.\nThree forms of run-in specification are available:\n\nSimple: allocates a small cohort to every defined dose in ascending order (unless fine grain doses - see this section – have been specified, in which case the escalation rules are followed).\nCustom: allocates a defined number of subjects (possibly varying by dose) to selected doses in ascending order.\nSmall cohort pre-escalation: allocates a small cohort, but follows the escalation rules assuming just a single small cohort is required to clear a dose.\n\nAll run-in schemes can be modified in a number of ways:\n\nSpecifying a maximum dose at which the run-in stops if no toxicities are observed until that dose.\nIf ordinal toxicities are being simulated, the run-in may should at the first observed category 2 toxicity (rather than a category 3 toxicity)\nWhether the subjects used in the run-in should be counted towards the trial sample size or not.\nWhen a toxicity is observed the standard behavior is to allocate to the minimum of: the last dose tested in the run-in, the current TD or the highest dose that can be allocated to by the overdose rules. This can be replaced by expanding the allocation on the current dose to make it a full cohort as specified in Study &gt; Study Info tab (this option is particularly useful in conjunction with stopping for a category 2 toxicity).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#two-groups",
    "href": "documentation/v71/userguides/crm.html#two-groups",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.4 Two Groups",
    "text": "3.4 Two Groups\nFACTS has the option to model the subjects in the trial as belonging to two different groups, these can be either:\n\nTwo groups distinguished by a baseline property of the subjects, for example adults and paediatrics.\nTwo groups separated by a difference in treatment (and selected randomly), for example the study drug alone or in combination with an additional drug.\n\nThere are options for when group 2 starts enrolling:\n\nThey can be recruited sequentially – group 1 then group 2.\nThey can be recruited in parallel\nThe second group can be started when the allocation to the first group reaches a particular dose\nThe second group can be started when the number of subjects allocated to group 1 reaches a particular threshold.\n\nA joint model is fitted to the two groups.\nThe first group is modeled:\n\\[\nlogit(p_{1j}) = \\alpha + \\beta \\hat{x}_j\n\\]\nThe second group is modeled:\n\\[\nlogit(p_{2j}) = (\\alpha + a) + (\\beta + b) \\hat{x}_j\n\\] With separate priors and some optional constraints on \\(a\\) and \\(b\\). Dose escalation and stopping are judged independently for the two groups.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-concepts-efficacy",
    "href": "documentation/v71/userguides/crm.html#sec-concepts-efficacy",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.5 Efficacy",
    "text": "3.5 Efficacy\nFACTS has the option to additionally model an efficacy endpoint. There are currently two limitations in simulation:\n\nOnly a binary efficacy endpoint can be simulated\nThe efficacy endpoint is assumed to be available at the same time as the toxicity endpoint.\n\nThe efficacy and toxicity endpoints are modelled separately. There are options to specify early stopping rules for finding the MTD, and to specify a cap on the sample size that can be spent finding the MTD. Once these rules are met, then allocation is towards the Minimum Efficacious Dose (MED) – if this is below the MTD. If the estimated MED lies at or above the estimated MTD, the allocation is at the estimated MTD.\nIf while allocating to the estimated MED further toxicity results change the estimate of the MTD, and if there is now insufficient information on the MTD as specified by the early stopping rules for finding the MTD, allocation switches back to allocating to the estimated MTD, if the sample size cap for finding the MTD allows.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-concepts-fgd",
    "href": "documentation/v71/userguides/crm.html#sec-concepts-fgd",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.6 Fine Grain Dosing",
    "text": "3.6 Fine Grain Dosing\nIn some settings, e.g. when the drug is delivered in solution by IV or when manufacturing allows any dose in a range from say 100mg to 400mg in steps of 10mg, dose strengths need not be restricted to just a small number of pre-defined levels. FACTS has a feature that allows this to be simulated, not with a continuous range of doses, but with “fine grain” dosing.\nFACTS supports the specification of a range of doses from a minimum to a maximum with doses either equally spaced or spaced with equal ratio. Using dose ratio makes most sense it you want to use the dose strength whilst believing the effect will be roughly log-dose. Using dose ratios, it’s necessary to accept FACTS reporting dose strengths only close to those desired. As an example, if the main doses followed a dose doubling scheme: 12.5, 25, 50, etc., one might use fine grain dosing with dose space ratios of approximately the 4th root of 2 (1.1892). The resulting doses are 12.5, 14.865, 17.677, 21.022, 24.999, 29.729, 35.354, 42.043, 49.998, etc., which means there are three dose levels between each of the original doses.\nThere are two alternatives:\n\nUse nominal dose strengths 1, 2, 3, 4, … (i.e. assuming the dose spacing is linear in expected effect) and label the doses according to their actual strength.\nUse a fixed dose interval (e.g. 12.5 resulting in doses of 12.5, 25, 37.5, 50, 62.5, etc.) so the lower doses (of the original scheme) have fewer (or no) intermediate doses and the higher doses have many more. The dose escalation rules can be specified in terms of dose strength ratio to achieve the required escalation, for example allowing dose escalation with a dose strength ratio of 2 will result in the initial escalation using doses 12.5, 25, 50, 100, etc.\n\nAs well as possibly adjusting the dose escalation step size to accommodate the new dose levels on the Design &gt; Allocation Rule tab, there are two other rules that may need modification:\n\nTo count a dose as “cleared”, we might now count cohorts on nearby doses to count towards the required clearing total. This is specified as the “Max ratio of dose strengths considered as near” (if dose allocation rules apply to ratio of dose strength) or “Delta in dose strength considered as near” (if dose allocation rules apply to dose strength) on the Design &gt; Allocation Rule tab.\n\nFor example, if we have doses at roughly 4th root of 2 intervals, we might count any dose within a ratio of 1.2 as “near” so that any cohorts allocated to immediate neighbor doses count towards clearing a dose.\nAlternatively, if we have doses every 12.5mg from 12.5 to 400, counting any dose within a ratio of 1.1 will mean that from dose 125 and above, immediate neighbor doses (within 12.5) count towards clearing a dose, and from dose 250 and above, doses within 25mg (two immediate neighbor doses) count towards clearing a dose.\n\nThe concept of “near doses” in fine grained dosing allows us to skip certain doses in the escalation phase, which might make sense if there is reason to believe that doses of similar dose strengths behave similarly and don’t provide enough additional information to justify assigning more cohorts to.\n\n\n\n\n\n\nFigure 6: Doses from 12.5 to 400mg, with fixed spacing of 12.5. Showing dose escalation by dose doubling.\n\n\n\nWhen requiring a certain number of cohorts to have been allocated to the estimated MTD before the trial can stop / to allow the trial to stop, we might now count cohorts on doses near the estimated MTD as counting towards that total. This is set on the Design &gt; Stopping Criteria tab. In considering which doses are near, the same logic as on the Design &gt; Allocation Rule tab regarding Dose Strength or Ratio of Dose Strength will be used.\n\nIf Dose Strength is used, then on the Design &gt; Stopping Criteria tab, we can include cohorts on nearby doses to count towards the required number of cohorts on the estimated MTD by specifying “nearby” in terms of dose strength. For example, by +/- 12.5 mg:\n\n\n\n\n\n\nFigure 7\n\n\n\nIf ratio of Dose Strength is used then on the Design &gt; Stopping Criteria tab, we can include cohorts on nearby doses to count towards the required number of cohorts on the estimated MTD by specifying “nearby” in terms of dose strength ratio. For example, by +/- 10%:\n\n\n\n\n\n\nFigure 8\n\n\n\n\n\nNote that with Fine Grain dosing, if a band is specified for a dose to count as cleared, then the maximum cleared dose will be the maximum dose within that band, and if incrementing relative to the Maximum cleared dose, then the maximum permitted increment will be relative to the maximum dose within the cleared band.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-concepts-oe",
    "href": "documentation/v71/userguides/crm.html#sec-concepts-oe",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.7 Open Enrollment",
    "text": "3.7 Open Enrollment\nOpen enrollment (Broglio et al. 2015) can be used instead of cohort enrollment. Cohort enrolment enrolls a fixed number of subjects to a given dose, then waits until their treatment and follow up is complete (so their final status – whether they suffered a DLT (Dose Limiting Toxicity) or not – is known) before deciding on the next dose to allocate to and then recruiting the next cohort. This likely means that subjects become available for inclusion in the trial, but have to be turned away as the trial waits for the current cohort to complete. Open enrollment attempts to address this by allowing subjects to be enrolled whilst the current “cohort” is completing. However, this may come with some risk – more than a cohort’s worth of subjects may now be exposed to a new dose before we have any estimate of its DLT rate. To allow this risk to be managed, open enrollment introduces two new concepts:\n\nWhen allocating to an uncleared dose, a cap can be set on the number of subjects that can be allocated to that dose who have not yet got their final results (“OE cap 1”). For example, if this number is set to 3 (to be the same as a common cohort size), after 3 subjects have been recruited and allocated to the current dose, no more subjects will be allocated to this dose until at least one of these subjects has completed. Until then, potential subjects that become available will be turned away unless backfilling is enabled (see next point below). But unlike cohort enrolment, as soon as the first of the subjects on the dose completes, a subject that comes available could now be allocated to the dose, depending on further rules explained below (frontfilling) – unless of course that subject’s result has changed the estimated MTD. Note that the trial won’t escalate beyond the current dose until the required number of subjects to clear the dose have completed. By default, the trial won’t allocate more than the number of subjects required to clear the dose until the dose is cleared, meaning if 3 subjects are required to clear a dose and 3 subjects have been allocated to this dose, even when 1 or 2 of these subjects have their final results and a new subjects is enrolled, they won’t be allocated to this dose. If this is regarded as over cautious, it can be modified by enabling frontfilling, allowing 3 subjects without final results simultaneously. In the above example, this would mean we could place a fourth subject on the dose when the result of the first subject has come in and a fifth subject as soon as the result of the second subject has come in.\nWhen the cap on the number of subjects without final results on an uncleared dose has been reached (“OE cap 1”) new potential subjects will be turned away, unless backfilling is enabled. Enabling backfilling allows these subjects to instead be included, allocating them to a lower dose that has already been cleared. Whilst such an allocation may not contribute as much to identifying the MTD as allocating to the current dose would, it can still contribute by:\n\nIncreasing the information on the next lower dose can inform the estimate of toxicity on the current dose through the Bayesian logistic model.\nProviding additional information on a dose that it may be necessary to de-escalate too if the current dose turns out to be too toxic.\n\nIt can also contribute information on other endpoints (such as efficacy). Once backfilling has been enabled, it is also possible to enable frontfilling. For more information on backfilling and frontfilling, see this section.\n\nAssume at a given point in time we want to allocate a subject to a specific dose, denoted by “candidate dose”. FACTS allows 3 different caps to be specified on how many subjects who have not yet got their final results (i.e. are not yet complete) can be allocated to this candidate dose:\n\n\n\n\n\n\nFigure 9\n\n\n\n\nMaximum subjects without final results if dose is uncleared: As described early in this section, we encounter this cap during escalation when the candidate dose is not yet cleared. This cap takes into account subjects not yet complete on the candidate dose and any higher dose (“OE cap 1”).\nMax subjects without final results if dose is cleared and below MTD: We encounter this cap when the candidate dose is cleared and below the estimated MTD (which can happen if the estimated MTD is beyond the range of available doses, when backfilling, or when allocating during the efficacy phase of a toxicity plus efficacy trial). This cap takes into account subject not yet complete on the candidate dose and any lower doses (“OE cap 2”).\nMax subjects without final results if dose is cleared and at MTD: We encounter this cap when the candidate dose is cleared and the current model estimated MTD (which can happen when after clearing a dose we decide not to escalate, or after de-escalating) (“OE cap 3”).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-concepts-bf",
    "href": "documentation/v71/userguides/crm.html#sec-concepts-bf",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.8 Backfilling and Frontfilling",
    "text": "3.8 Backfilling and Frontfilling\nAs described in the preceding section, Backfilling is the allocation of subjects to a lower dose when, due to restrictions, it is not possible to allocate a subject who comes available to the current dose (Dehbi, O’Quigley, and Iasonos 2021). FACTS provides a number of options to configure how backfilling behaves. Backfilling can be enabled in the Study &gt; Study Info tab. The total sample size can be divided between the subjects allocated as part of conventional dose escalation and those allocated using backfill. When backfill is enabled, it is important to increase the total sample size and then limit the number that can be allocated using backfill, as subjects allocated using backfilling will not contribute to the escalation and the confirmation of the MTD and it’s usually important to retain sufficient sample size to achieve this aim.\n\n\n\n\n\n\nFigure 10\n\n\n\nWhen enabling backfilling, several options can be specified in the Design &gt; Backfill Allocation tab.\n\n\n\n\n\n\nFigure 11\n\n\n\n\nTwo maximum caps can be specified on the number of subjects that are assigned in the process of backfilling to a given dose:\n\nan overall cap on subjects per dose that cannot be exceeded by backfill, counting also subjects that were assigned to that dose through regular allocation\na cap on the number of subjects per dose that were allocated by backfill, counting only subjects that were assigned to that dose using backfilling.\n\nHow many dose levels below the current dose can be allocated to when backfilling. Backfilling will always be to the highest dose possible (which might be the current dose if frontfilling is enabled, otherwise it will be below the current dose). Allocation to the next highest dose might be limited either by an open enrolment cap if there are already subjects allocated to that dose who have not yet completed, or it might be limited by the backfill caps described above. If allocation to the dose below the current dose is not possible, backfilling will by default look at the dose below that (two levels below the current dose) and so on. Using this option can ensure no backfilling happens to doses that are too far below the current dose.\nThe lowest dose that can be allocated to when backfilling. This option is particularly useful when there is reason to believe doses below a certain level will not be effective.\nWhether frontfilling is allowed – frontfilling allows allocating more subjects to uncleared doses than the number required to clear that dose (see this section).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#open-enrollment-backfilling-and-fine-grain-dosing",
    "href": "documentation/v71/userguides/crm.html#open-enrollment-backfilling-and-fine-grain-dosing",
    "title": "FACTS Dose Escalation CRM",
    "section": "3.9 Open Enrollment, Backfilling and Fine Grain Dosing",
    "text": "3.9 Open Enrollment, Backfilling and Fine Grain Dosing\nWhen using open enrolment and fine grain dosing, the interval defined on the Design &gt; Allocation Rule tab “Delta in dose strength considered as near +/-“, or “Max ratio of dose strengths considered as near” is crucial: it is used to define the range of doses where subjects allocated to any of them count towards clearing a dose.\n\nIf dose allocation rules are selected to apply to “Dose strength”, the interval is defined “Delta in dose strength considered as near +/-“. Thus, for example, if this is set to 2, then subjects complete on doses with strength in the range 4-8 will contribute to the dose of strength 6 being cleared. At the same time, clearing the dose of strength 6 will automatically clear the dose of strength 8.\nIf dose allocation rules are selected to apply to “Ratio of strength”, the interval is defined “Max ratio of dose strengths considered as near“. Thus, for example if this is set to 1.5, then subjects complete on doses with strength in the range 4-9 will contribute to the dose of strength 6 being cleared. At the same time, clearing the dose of strength 6 will automatically clear the dose of strength 9. These ranges also apply when assessing “OE cap 1-3”, and how many subjects have been allocated overall, or via backfilling. In backfilling, FACTS checks each dose strength and the doses in its “near” interval range, at (if frontfilling) or below the current dose, until the first dose strength is found where backfilling can take place.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#the-file-menu",
    "href": "documentation/v71/userguides/crm.html#the-file-menu",
    "title": "FACTS Dose Escalation CRM",
    "section": "6.1 The “File” Menu",
    "text": "6.1 The “File” Menu\nFACTS has a File menu with commands similar to those found in most Windows applications, but also some unique to FACTS. The commands can be found in Table 2.\n\n\n\nTable 2: List of commands in the CRM file menu\n\n\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\nNew\nAllows the user to select a trial design type and start a new design; if there are unsaved changes in the current design the user is prompted to save them first.\n\n\nOpen\nAllows the user to select an existing FACTS file and open it; if there are unsaved changes in the current design the user is prompted to save them first.\n\n\nSave\nSaves the current changes in the design to the currently open FACTS file.\n\n\nSave As\nAllows the current version of the design to be saved to a new FATCS file; this file is then the “currently open” FACTS file going forward.\n\n\nExport Project\nCreates a “Zip” archive containing the current FACTS file and all the simulation results, so these can be easily archived, emailed, saved, etc.\n\n\nRecent Projects\nContains entries for the last ten FACTS files opened: selecting one re-opens it.\n\n\nRecent Folders\nContains entries for the folders that contain the last ten FACTS files opened: selecting one opens a file browser window on that folder allowing a ‘.facts’ file in that folder to be selected (or allowing the user to navigate to some different folder and select a ‘.facts’ file there).\n\n\nExamples\nContains example projects for the different design engines: selecting one opens it.\n\n\nClose\nCloses the current FACTS file, returning the user to the FACTS introduction screen.\n\n\nExit\nCloses FACTS altogether.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#facts-settings-menu",
    "href": "documentation/v71/userguides/crm.html#facts-settings-menu",
    "title": "FACTS Dose Escalation CRM",
    "section": "6.2 FACTS Settings Menu",
    "text": "6.2 FACTS Settings Menu\nThe “Settings” command menu allows the user to do 2 things:\n\nSet various FACTS options to local settings – see below for details.\nReset the options based on the stored configuration file. This file, “config.xml”, will initially be installed during the FACTS installation process and is stored in the Windows “Program Files” folder, in the sub-folder where FACTS get installed.\nChange the stored configuration file. This command allows you to select a new configuration file and have FACTS copy it to the sub-folder within the Windows “Program Files” folder, where FACTS get installed so it becomes the new stored configuration file. This allows IT support to easily disseminate configuration changes.\nEnter a new or changed license key.\n\n\n6.2.1 Set Options\nThe FACTS Options dialog allows the user to:\n\nSet and Test the connection parameters to access a compute grid for running simulations.\nConfigure the version and location of R or R Studio that can be launched from within FACTS\nSelect how gamma distributions are parameterized.\n\n\n6.2.1.1 Grid Configuration\nA grid compute facility for running simulations will only be available if your local IT services have set one up. If they have done so, they\n\nMay have already set the appropriate parameters In the FACTS configuration file included with the FACTS installation files.\nInform you of the parameters to be set manually via this dialog\nSend a new configuration file that can be installed using the “Load Options” menu command.\n\nIf modifying the grid options manually, select the “Options” menu command and enter the values on the “Grid Configuration” tab of the displayed dialog window.\n\n\n\n\n\n\nFigure 16: Webservice Configuration\n\n\n\nFirst select the type of interface to the grid to be used, this is either:\n\nVia a network shared drive (with a “sweeper script” running on a client machine to transfer jobs to the grid management system and return results from it).\nVia a web service system using a webserver and database to communicate to a grid management system. The IT group supporting the grid should be able to tell you which interface they have implemented, if any. If access to the grid is via a Network Share it is necessary to specify:\nThe location of the network share folder, usually in the form \\&lt;server name&gt;\\&lt;folder name\\&gt;.\nWhether the grid client is running Windows or Linux (so end-of-line characters can be corrected)\nThe listener delay – this is the interval between “looks” when FACTS is waiting for simulation results to be complete\n\nOnce specified it is possible to use the “Test” button to check that the Network Shared folder is accessible and writeable.\nIf access to the grid is via a web service:\n\nThe location of the web service endpoint.\n\nClicking on “Test Configuration” and will cause FACTS will attempt to connect to the FACTS grid controller. The control will show which components of the connection are working.\nSee the FACTS Installation Guide and FACTS Simple Grid Interface Guide for more details of setting up a grid.\n\n\n6.2.1.2 R Configuration\nIn FACTS on the Simulation tab there are two controls that launch R – “Open in R” and “ Design Report” (in FACTS 6.2.0 the latter only available for FACTS Core designs).\nTo enable these to work the user must specify where the R or RStudio executable is installed and (if there is more than one version of R installed) which version of R to use.\n\n\n\n\n\n\nFigure 17: The R Configuration Dialog\n\n\n\nThe dialog allows the user to Add, Edit, Test and Remove links to versions of R.\n\n\n\n\n\n\nFigure 18: Adding a link to R\n\n\n\nClicking on “Add” opens a normal Windows directory browser window, the user must navigate to the location of an R installation (for example “C:\\Program Files\\R\\R-2.15.2\\bin”, select the file R.exe, and click “Open”. This adds a new entry on the R configuration dialog.\nClicking on “Edit” operates similarly to “Add” above, except the selected location replaces that currently selected entry on the R configuration dialog rather than adding a new one.\nClicking on “Test” checks whether the currently selected entry on the R configuration dialog is available, if it is not an error dialog is displayed:\n\n\n\n\n\n\nFigure 19: Example of R Configuration error\n\n\n\nClicking on “Remove” removes the currently selected location on the R configuration dialog.\nThe version of R to use by default is selected by clicking on the ‘Active’ check box of the version to use.\n\n\n6.2.1.3 Gamma Distribution Parameters\nIn FACTS a number of parameters require inverse gamma distributions to be specified as priors for the parameter value. There are two different parameterization of the inverse gamma provided so that the user can select the form they find the most intuitive.\n\n\n\n\n\n\nFigure 20: The parameterisation of Inverse Gamma Distributions\n\n\n\nThe first form uses parameters that are the mean of the distribution and the equivalent weight in terms of the equivalent number of observations. The second form uses an ‘Alpha’ and ‘Beta’ parameterization that some statisticians are familiar with and will find natural to use.\n\n\n\n6.2.2 Enter a license key\nIf a new license key is required, this command can be used to enter one. There are two ways of entering a new license:\n\n\n\n\n\n\nFigure 21: Enter FACTS License Key\n\n\n\nThe key can be entered directly, along with the associated Organization name, or by selecting a supplied license file.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#the-help-menu",
    "href": "documentation/v71/userguides/crm.html#the-help-menu",
    "title": "FACTS Dose Escalation CRM",
    "section": "6.3 The Help Menu",
    "text": "6.3 The Help Menu\nFACTS has a Help menu with commands to assist you with the use of FACTS, providing links to users guides, tutorial and training videos. The commands are:\n\n\n\nTable 3: List of commands in the CRM help menu\n\n\n\n\n\n\n\n\n\nCommand\nDefinition\n\n\n\n\nUser Guides\nProvides access to documents such as this one, with (mainly) one user guide to each design type within FACTS. Exceptions to this simple structure are:  1. Core Design User Guide: A guide to the options under the ’Design” tab for FACTS Core for all endpoints.  2. Staged Design User Guide: As the staged design allows the design of one FACTS Core stage followed by a second, most of the interface is common to the basic FACTS Core. This guide describes the differences and additional aspects for all endpoints.  3. Dose Escalation User Guide: This covers all the Dose Escalation engines except for N-CRM and 2D-CRM that have their own. It thus covers the 3+3, mTPI, CRM(Toxicity), CRM(Ordinal), CRM(Efficacy) and bCRM engines.\n\n\nTutorials\nProvides access to all the tutorial documents, which describes detailed examples of use of all the engines in FACTS and many of their options. The examples under the File &gt; Examples menu option largely correspond to the different tutorials described here.\n\n\nDesign Specifications\nThese are technical documents that describe the mathematical models implemented in FACTS in detail.\n\n\nExecution Guides\nThe FACTS GUI can be run in command line mode so simulations can be run/re-run from scripts. With the simulation command line flag, and passed a directory rather than a file, FACTS will run simulations for every “.facts” file in that directory – and recurse into any sub-directories and simulate any “.facts” files there too. A full guide to command line mode can be found here. The FACTS simulation engines are also available in “command line executable” form. There are guides here that document their command line parameters and how to use them to analyse a data set – e.g. to perform an interim analysis whilst executing a trial designed with FACTS.\n\n\nFACTS file XML Specs\nThese guides describe the parameters in the “.facts” files, which are text files in XML format. For expert users understanding this format allows them to use scripts to generate versions of an initial “.facts” file with slight variations in the parameters such as stopping thresholds or priors. Modification of “.facts” files outside of FACTS needs to be done with care, errors may render the file unusable by FACTS.\n\n\nVideos\nProvides access to links to the introductory, training and webinar videos that Berry Consultants has recorded and makes available over the internet to FACTS users.\n\n\nView log…\nIf an error has occurred in FACTS, often the FACTS log file can shed light on what is going wrong. The log file is hidden away in some unfashionable and hard to locate Windows folder; this command option provides easy access to it. Allowing you to email facts support with a description of what occurred, attaching a copy of this log file having saved it somewhere convenient such as your desktop.\n\n\nSupport\nLaunch a simple editor for sending an email to our support account: facts@berryconsultants.net\n\n\nAbout\nDisplays a simple “about box” that includes the detailed version number of FACTS.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#study-info",
    "href": "documentation/v71/userguides/crm.html#study-info",
    "title": "FACTS Dose Escalation CRM",
    "section": "7.1 Study Info",
    "text": "7.1 Study Info\nThe Study Info sub-tab provides parameters for specifying:\n\nWhether the trial has an Efficacy endpoint as well as a Toxicity one.\nWhether recruitment is in Cohorts or uses Open Enrolment,\nWhether the trial data is being analyzed as a single population (single group) or two groups (which could be 2 different patient types, or 2 different treatment types).\nThe option to specify that the trial should include an expansion cohort once the MTD has been identified.\nThe option (if using open enrolment) to specify the use of backfill.\n\nIncluding an efficacy endpoint – this allows the trial to include a binary efficacy outcome that is observed at the same time as the toxicity endpoint. Once the MTD has been sufficiently determined further cohorts are allocated to determine the MED (Minimum Effective Dose) as long as that is below the MTD, until the maximum sample size or MED stopping rules have been reached.\nCohort versus Open enrolment: cohort enrolment is the standard way of running a phase 1 trial, a cohort of subjects of pre-determined size are treated at the current dose and the trial pauses until all the subjects in the cohort are complete, then the dose for the next cohort is determined. A phase 1 trial using Open Enrolment recruits ‘all comers’ with a cap on the number of subjects who can be treated but have not yet had a final result. Subjects that arrive whilst this cap has been reached are deemed to be ‘lost’ to the study.\nIf Open Enrolment and Efficacy Endpoint options are being used together, then subjects who arrive who cannot be allocated to the MTD (because the cap number of subjects awaiting a final result has been reached), can be allocated to the MED (as long as that is below the MTD).\nIf the trial is analyzing 2 Groups then a joint statistical model is used with options to constrain the group 2 difference in the intercept term to be +ve or -ve, and options as to whether a common or separate estimates of the slope term are used.\nIf an expansion cohort is included, the this is a single cohort (or one per group, if 2 groups is being used) typically much larger than used during the dose escalation, that is assigned at the end of the study to the target dose. FACTS simulates the results that arise from this cohort and a final analysis.\nIf open enrolment is being used, the further option to use backfill becomes available. The parameters on this tab for backfill, are to specify the maximum number of subjects that can be allocated for escalation, and the maximum that can be allocated in backfill. These two maximums should not total less than the overall “Max subjects” that can be enrolled. If adding backfill to a trial, usually the previous “Max subjects” becomes the “Max study allocation for escalation”, and an additional sample is allowed for backfill and added to the overall Max subjects.\nIf the trial has two groups the backfill maximums are the sum of the subjects in the two groups.\nFor Cohort enrolment, the parameters are:\n\nMaximum Study Size, in cohorts: the maximum number of cohorts the trial can use, though designs can include conditions that cause them to stop earlier.\nIf the trial has two groups, the maximum number of cohorts of the second group.\nCohort size: The number of subjects in each cohort. The maximum sample size for the trial is simply: Max Trial Size (cohorts) * Cohort Size.\nCohort information delay: Normally left at zero, this allows for the trial to be simulated with cohorts recruited more quickly than if waiting for the last cohort to complete before treating the next cohort. This allows the trial to complete in shorter time, but is likely to lead to a larger incidence of toxicities. If the delay is set to 1, the second cohort will be recruited before the results for the first cohort are available, the third cohort will be recruited after the results of the first cohort are available but before the results for the second cohort are available, and so on.\nExecution rate: the time taken to recruit, treat and complete the observation of each cohort (in weeks). The value of this parameter does not affect the behavior of the simulations, but it allows a nominal “duration” of each simulation to be calculated. Unlike other FACTS simulations, this duration is not simulated stochastically, it is simply the number of cohorts * this duration. Its purpose is to give a figure to compare with open enrolment designs of the same trial.\n\n\n\n\n\n\n\nFigure 22: Study Info - Cohort Enrolment\n\n\n\n\n\n\n\n\n\nFigure 23\n\n\n\nIf rather than Cohorts, subjects are recruited using open enrolment, the parameters are:\n\nMax subjects: the maximum number of subjects who can be recruited into the study.\nTime unit – this is a text string that will change the “units” label for time on graphs. This allows data to be more easily entered when the natural time unit is not “weeks”, but “days” or “months”.\nMean recruitment rate: for simulation purposes this is the average number of subjects who will be expected to be available for recruitment during each time period. Recruitment is simulated using a standard Poisson process.\nTime until final result: the time for each subject for their final result to become available. This is simulated as a fixed length of time that is the same for all subjects.\nMaximum subjects without a final result: the cap on the number of subjects on the current dose or a backfill dose (if backfill is enabled) who can be recruited but not yet completed. This is also known as the ‘maximum queue length’. Subjects arriving and available for recruitment while the number of subjects on this dose who have been treated but have not yet completed is at this maximum, are dropped and assumed no longer available for recruitment. Once the current subjects complete the study has to await further new subjects to become available. There are three caps:\n\nMaximum subjects without final results if the dose is uncleared. This allows the design to be cautious when a new dose is used for the first time.\nMaximum subjects without final results if dose is cleared and below MTD. This allows a larger number of subjects without final results to be recruited at backfill doses or at the current escalation dose if backfill to the current escalation dose (“frontfilling”) is enabled, or at the MED in the efficacy phase of a trial that includes an efficacy endpoint.\nMaximum subjects without final results if dose is cleared and at MTD. This allows us to be more cautious if the model thinks all doses are toxic or if we are allocating at the model MTD and don’t want to expose too many subjects.\n\nBackfill – this can be enabled. Backfilling is the allocation of subjects to a dose below the current target dose, if the number of subjects allocated to the current target dose without final results has reached the maximum. Further parameters for backfill are set on the “Backfill” tab under the “Design” tab. On this tab, if backfill is enabled, two sub-maximums can optionally be specified:\n\nthe maximum number of subjects who can be allocated as part of usual allocation for escalation and MTD determination (and MED if efficacy is included in the trial),\nand the maximum number of subjects who can be allocated as part of “backfill”.\n\n\n\n\n\n\n\n\nFigure 24: Study Info - Open Enrolment\n\n\n\nGroups: a trial can be analyzed as a “single group” or as “two groups”. If analyzed as a single group, then all subjects are assumed to be the same and treated the same (except for the difference in the dose strength). If analyzed as two groups this allows either:\n\nThe subjects can be simulated as coming from two similar but distinct groups such as: adults and children, first line or recurrent, having some concomitant treatment or not. The separation into the two groups is based on some property of the subject.\nOr the subjects can be simulated as having been allocated (possibly randomized) to one of two versions of the treatment, with the same rang of dose strengths and differing in some other way such as dosing schedule, treatment duration or combination with an additional treatment. The separation of the subjects into the two groups is under the control of the protocol.\n\nIn either case the same analysis options are available (hence we use the generic term “groups” to describe this feature).\nIf enrolment is by cohort, the there are two separate “maximum study sizes” in cohorts – one for each group.\nThe Group 2 recruitment, while it overlaps in time with the Group 1 recruitment, is simulated as being in lock-step and the recruitment of the cohort in each group is concurrent and analyzed when both are complete. In the ‘cohorts.csv’ files that are output, the cohort numbers indicates which cohorts were concurrent. The options are:\n\nTo recruit group 1 first then recruit group 2 only when group 1 is complete.\nTo start recruiting both groups in parallel from the outset.\nTo start recruiting group 2 once group 1 has reached a specified dose. The first group 2 cohort is recruited in parallel with the next group 1 cohort after the first group1 cohort has been allocated the specified dose (if cohorts can be accrued before the cohort before has completed, the group 2 is accrued too – it does not wait until the group 1 cohort completes unless the next group 1 also waits).\nTo start recruiting group 2 once group 1 has recruited a specified number of subjects. The first group 2 cohort is recruited in parallel with the next group 1 cohort after the specified number of subjects had been recruited into group 1.\n\nIf enrolment is open then there are options similar to the cohort enrolment to control when enrolment into group 2 starts:\n\nTo recruit group 1 first then recruit group 2 only when group 1 is complete.\nTo start recruiting both groups in parallel from the outset.\nTo start recruiting group 2 once group 1 has reached a specified dose. The first group 2 subject can be recruited after the first group1 subject has been allocated the specified dose.\nTo start recruiting group 2 once group 1 has recruited a specified number of subjects. The first group 2 subject can recruited after the specified number of subjects had been recruited into group 1.\n\nBut in addition the user specifies the maximum number of subjects in Group 2 and how the recruitment is to be simulated:\n\nWith the group membership a property of the subject – along with a mean recruitment rate for group 2.\nWith subjects randomized between the two groups (the randomization is fixed at 1:1).\n\nThe user specifies the three “Maximum subjects without final results …” for the second group.\nIf backfill is enabled, the backfill totals apply to the total of the subjects on both groups.\n\n\n\n\n\n\nFigure 25: Study info - 2 group options with open enrolment\n\n\n\nEnable Final Expansion Cohort: if this is enabled a final cohort of specified size will be allocated the dose selected as MTD at the end of the N-CRM phase of the study:\n\nIf the study includes a control arm, the number of subjects in this expansion cohort to be allocated to control is also specified.\nIf the study has two groups, two separate expansion cohorts will be allocated, their sizes are set separately.\nIf the study includes observing efficacy then the target dose can be changed from MTD to MED or OSD.\n\n\n\n\n\n\n\nFigure 26\n\n\n\nSimulating an additional efficacy outcome is simply specified by checking the “include efficacy” checkbox.\n\n\n\n\n\n\nFigure 27: Study tab with “Include efficacy” checked\n\n\n\nSimulating an efficacy endpoint can be combined with all the other features (two groups, open enrolment, backfilling) already discussed, as well as with ordinal toxicity and fine grain dosing that are described below.\nCurrently there are two significant limitations to the simulation of an efficacy endpoint:\n\nThe endpoint is assumed to be dichotomous.\nThe endpoint is assumed to be observable at the same time as toxicity.\n\nWe hope to lift these restrictions in a later version of FACTS.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#toxicity",
    "href": "documentation/v71/userguides/crm.html#toxicity",
    "title": "FACTS Dose Escalation CRM",
    "section": "7.2 Toxicity",
    "text": "7.2 Toxicity\nThe Toxicity sub-tab provides parameters for specifying:\n\nWhether toxicity should be simulated as dichotomous or ordinal. If simulated as Ordinal, toxicity can be simulated as a 1-3 scale or 1-4 scale. In both cases ‘1’ is “no-toxicity”, 2 is “mild toxicity” and 3 is the toxicity of interest (from the point of view of defining the MTD, target toxicity band and Overdose Control. If a four category scale is selected, 4 is “sever toxicity” or death. Choosing whether to model the ordinal response is a separate option and is present on the Design &gt; Toxicity Response tab.\nType of target: this allows the user to specify whether the dose selection targets “the dose who’s estimated toxicity rate is closest to a specified target rate” or “the dose with the highest posterior probability of having a toxicity rate in a target band”. The former is the target rule used in the original CRM papers ((O’Quigley, Shen, and Gamst 1999), (deMoor et al. 1996), and the latter rule was introduced in (Neuenschwander, Branson, and Gsponer 2008).\nToxicity target (only displayed if the type of target is “a single dose”): this allows the target toxicity rate to be specified and whether the target dose is the one nearest, the one nearest but with a lower rate or the one nearest but with a higher rate.\nTarget: this panel allows the target toxicity bands to be specified along with overdose control limits. The panel is displayed and enabled even if the target type is “a single dose” to allow overdose control limits to be specified.\nType of Target: controls the selection of the dose for the next cohort – this can be to target a single dose (to replicate the original CRM behavior, see this section) or to target the dose with the highest probability that its toxicity rate lies in a target band.\n\n\n\n\n\n\n\nFigure 28: Toxicity tab targeting a toxicity band\n\n\n\n\n7.2.1 Targeting a Toxicity Interval\nTargeting a toxicity band or interval is an innovation introduced with the N-CRM design, unlike other CRM designs that select the dose that is expected to have a toxicity response closest to the desired tolerated limit, the N-CRM selects the dose that has the highest posterior probability of having a toxicity rate in a target toxicity band. This has the advantage of a) having a clearer probability statement and b) having in addition probability statements about the probability of under and overdosing (the toxicity rate being below or above the target toxicity band).\n\nThe uncertainty in the estimate of toxicity at each dose is expressed by calculating the posterior distribution of the estimate of the rate of toxicity at each dose and calculating the proportion of that distribution that falls in to each of 4 bands of toxicity: ‘Under-dosing’ (toxicity so low that it is likely that a higher dose could be used), ‘Target’ toxicity (we want to select doses whose toxicity rate is most likely to be in this band), ‘Excess’ toxicity (toxicity higher than desired) and ‘Unacceptable’ toxicity.\n\nUnder-dosing: this band always starts at 0.0; the user specifies the upper bound.\nTarget band: this band always starts at the upper-bound of the under-dosing band; the user specifies the upper bound.\nExcess toxicity: this band always starts at the upper-bound of the target band; the user specifies the upper bound.\nUnacceptable toxicity: this band always starts at the upper-bound of the target band, with an upper bound of 1.0. The graph shows the width of the different bands using a simple, fixed, example posterior probability distribution of a toxicity rate.\n\nIntervals are relative to control: if a control arm is included in the study, then toxicity bands can be defined as the difference in toxicity rate relative to control. Negative differences (a lower toxicity rate than control) are always treated as under-dosing. To enable this option it is necessary to first go to the Study &gt; Treatment Arms tab and select Include Control.\nLimit max excess/unacceptable toxicity: the ‘overdose control’ in terms of a maximum allowed posterior probability that a dose’s toxicity rate lies in either the ‘Excess’ or the ‘Unacceptable’ toxicity bands. Any dose with a posterior probability of having a toxicity rate in either of these two bands that is higher than the specified limit, cannot be selected for allocation to the next cohort, nor selected as MTD at the end of the study (this gives rise to slightly different results compared to those in (Neuenschwander, Branson, and Gsponer 2008) where the overdose control was not applied to final selection).\n\nIt is possible to have the overdose control limit vary with the number of cohorts allocated. In particular this can be used to reduce the overdose limit as the number of cohorts (and the amount of information) grows. For example for a particular prior and final level of overdose control, it may be that initial escalation is excessively constrained, one way to allow early escalation in this setting is to use these parameters to allow an higher initial overdose control limit and gradually reduce it over time to the final desired limit. Tuning the parameters will require some iteration and simulation. A varying limit is specified by the specifying amount to change the limit by per cohort and the final limit. The amount to change by is always entered as a number in the range (0,1), whether this is an increment or decrement depends on whether the target limit is greater or less than the initial limit. Leaving the change in limit at its default of 0 means the limit does not vary.\nLimit max unacceptable toxicity: as for the previous parameter, but here the overdose control is only in terms of the posterior probability that a dose’s toxicity rate lies in the ‘Unacceptable’ toxicity band.\nAs or the limit on excess/unacceptable toxicity it is possible to have the overdose control limit vary with the number of cohorts, see the description above.\n\n\n\n7.2.2 Targeting a single dose\nIt is possible to use the N-CRM design engine with a conventional CRM allocation strategy - to “allocate to the nearest / highest dose below the maximum tolerated toxicity”; this allows conventional CRM design to be simulated with some of the additional features of N-CRM:\n\nOverdose control\nEstimate both parameters of the 2 parameter logistic\nThe “Recommender” to analyze a specific data set.\n\nThe target is calculated by:\n\nIn the MCMC sampling loop finding the dose that meets the target criteria, a doses probability of being the target is then the proportion of times that dose meets the target criteria across the MCMC sampling.\nRather than selecting the dose with the highest probability, the dose at the 50% quantile is used. The cumulative probability of being the target is calculated over the doses in ascending dose strength, and the dose when the cumulative probability passes 50% is selected. This addresses some problems that can arise when very little data is available: that the dose with the highest probability is at one end of the dose range, but that probability is not that high, or that doses are not evenly spaced and a dose close to both its immediate neighbors may never have greater probability than both of them.\n\nSetting the Type of Target option to Target a single dose, modifies the tab thus:\n\n\n\n\n\n\nFigure 29: N-CRM, targeting a single dose, not a toxicity band\n\n\n\nWhen targeting a single dose FACTS allows the user to specify:\n\nThe target toxicity rate\nWhether to allocate to the dose with the mean estimate of its toxicity rate nearest the target, highest dose with a mean estimate of its toxicity rate below the target or lowest dose with a mean estimate of its toxicity rate above the target.\nAn option to use the toxicity rate relative to control, rather than the default of the absolute toxicity rate. To enable this option it is necessary to first go to the Study &gt; Treatment Arms tab and select Include Control.\n\nThe definition of the boundaries of the toxicity bands is still included in order to allow the specification of overdose control limits. These are calculated and applied in exactly the same way as when targeting a toxicity interval.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#efficacy",
    "href": "documentation/v71/userguides/crm.html#efficacy",
    "title": "FACTS Dose Escalation CRM",
    "section": "7.3 Efficacy",
    "text": "7.3 Efficacy\nIf include efficacy has been checked on the Study Info tab, a simple additional input page is included:\n\n\n\n\n\n\nFigure 30: The Efficacy tab\n\n\n\nIf simulating and modelling an efficacy endpoint is included there are two items to be specified on this tab:\n\nWhether a subject experiencing a toxicity can also count towards efficacy or not. If unchecked patients outcomes are simply sampled separately and a patient can both have a toxicity and an efficacy response. If checked, a patient’s toxicity outcome is sampled first, and only if there is no toxicity is an efficacy outcome sampled.\nThe efficacy target – this consists of:\n\nThe target efficacy rate required for the Minimum Efficacy Dose (MED).\nWhether the target dose is the nearest dose to the MED rate, the lowest dose above the MED rate or the highest dose below the MED rate.\nIf a control arm has been included, whether the target rate is absolute or relative to the observed rate on the control arm.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#treatment-arms",
    "href": "documentation/v71/userguides/crm.html#treatment-arms",
    "title": "FACTS Dose Escalation CRM",
    "section": "7.4 Treatment Arms",
    "text": "7.4 Treatment Arms\nOn this tab the number of treatment arms (doses) available to the study is specified. The user can either define a set of specific doses that can be used or a continuous dose range with some granularity.\nSelecting Explicit Doses allows the user to specify the specific doses that can be used on the trial:\n\nA single new dose or multiple doses can be added either by clicking “Add” or “Generate”. Initially each dose is defined by a simple integer name and level. The dose levels and dose names can then be edited on by clicking on them and entering the desired value. The dose level can also be set later on in the Design &gt; Toxicity Response tab.\nThere is also the option to include a control arm. Including a control arm allows the toxicity rate to be relative to the control arm.\n\n\n\n\n\n\n\nFigure 31: The Treatment Arms tab specifying explicit doses\n\n\n\n\n7.4.1 Finely Spaced Doses\nSelecting Finely Spaced Doses allows the user to specify the dose range that can be used on the trial:\n\nThe minimum and maximum dose strength to be used\nThe ‘granularity’ of the actual dose used, either as a fixed delta (Fixed spacing) or a dose ratio (the ratio specified must be greater than 1) (Ratio spacing).\nThe number of ‘bins’ or ‘doses for which to report’ – this is because FACTS will still produce summary statistics in columns, many with a “column per dose” – it is possible to use more doses than it is practical to report on (and a limit in MS Windows of 32K pixels for the width of a table means that the GUI can only display simulation results for a maximum of ~40 doses). However this limitation is only for reporting summary statistics; the dose strengths modeled and allocated in the simulations are unaffected.\n\nSelecting ‘Finely Spaced Doses’ will also affect how some of the other parameters are specified in the FACTS GUI.\n\n\n\n\n\n\nFigure 32: The Treatment Arms tab, specifying a finely spaced dose range",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#variants",
    "href": "documentation/v71/userguides/crm.html#variants",
    "title": "FACTS Dose Escalation CRM",
    "section": "7.5 Variants",
    "text": "7.5 Variants\nOn this tab the user can specify that a number of design variants should be created. Currently the only design feature that can be changed is the sample size (maximum number of cohorts).\nIf “multiple variants” is checked then the user can specify that simulations setups should be created for each simulation scenario with versions of the design with different maximum numbers of cohorts.\nThe user enters the number of variants they wish to create. Then in the resulting table, enter different “Max Cohorts” for each variant.\nThese will then appear on the simulations tab.\nIf open enrolment is being used, then the enrolment cap is specified by the number of subjects.\nIf there are two groups then separate caps are specified for each group.\n\n\n\n\n\n\nFigure 33: The Variants tab, specifying 5 variants",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#explicitly-defined",
    "href": "documentation/v71/userguides/crm.html#explicitly-defined",
    "title": "FACTS Dose Escalation CRM",
    "section": "8.1 Explicitly Defined",
    "text": "8.1 Explicitly Defined\nToxicity profiles may be added, deleted, and renamed using the table and corresponding buttons on the left hand side of the screen in Figure 35. The user enters the toxicity rate to simulate at each dose into the Probability of Toxicity column of the table, and the graphical representation of these toxicity values updates accordingly.\nThis form of toxicity profile is not available if the dose range is “finely spaced” – typically this means there are too many doses for it to be practicable to enter toxicity rates for all of them. When using “finely spaced” doses the toxicity rates to be simulated have to be specified using parametric models (see the next section).\n\n\n\n\n\n\nFigure 34: Explicitly defined toxicity - binary endpoint\n\n\n\nIf the design is using ordinal toxicity, the toxicity response rates can be specified either:\n\nOn the “Toxicity” tab by specifying the category 3 or greater toxicity rate at each dose and then two offsets – one for the category 2 or greater rate and one for the category 4 rate.\nOn the “Ordinal Toxicity” tab by separately specifying the toxicity rates for each category of toxicity at each dose.\n\nSpecifying offsets: to ensure that the specified category 3 rate plus the category 2 offset doesn’t sum to more than 1, or the category 3 rate plus the -ve category 4 offset sum to less than 0, the offsets are applied to the logit of the category 3 toxicity rate.\nThus for the category 2+ rate:\n\\[\nln(\\frac{p_{2+}}{1-p_{2+}}) = ln(\\frac{p_{3}}{1-p_{3}} + \\Delta_2)\n\\]\nwhere:\n\n\\(p_{2+}\\) is the probability of observing a category 2 or greater toxicity at a dose\n\\(p_3\\) is the probability of observing a category 3 or greater toxicity at a dose\n\\(\\Delta_2\\) is the difference in the log odds between the two probabilities\n\nThe offset is defined at the lowest dose and highest dose and then varied linearly with dose strength at the intermediate doses. The plot of the curve can either use Pr(Tox) or Log-odds(Tox) as the y-axis and dose strength or log(dose strength) as the x-axis. A graph is displayed of the toxicity rates that have been entered, and the category 2+ and category 4 toxicity rates if applicable. This graph, as with all graphs in the application, may be copied to the clipboard or to a file using the “right-click” menu.\n\n\n\n\n\n\nFigure 35: Virtual Subject Response – Explicitly-Defined – ordinal endpoint\n\n\n\n\n8.1.1 Explicitly defined – Ordinal Toxicity\nIf simulating ordinal toxicity an alternative option is to explicitly specify the rate at each toxicity level at each dose. This can be done under the Virtual Subject Response &gt; Explicitly Defined &gt; Ordinal Toxicity tab.\n\n\n\n\n\n\nFigure 36: Virtual Subject Response – Explicitly-Defined: Ordinal Toxicity tab\n\n\n\n\n\n8.1.2 Explicitly defined toxicity – when simulating 2 groups\nIf simulating toxicity as a binary outcome, when simulating 2 groups, the tab displays two Pr(Tox) columns, one for each group, and the user enters the toxicity rate to be simulated at each dose for each group.\n\n\n\n\n\n\nFigure 37: Explicitly defined toxicity - 2 groups\n\n\n\nIf simulating 2 groups and ordinal toxicity, then on the explicitly defined tab once again the tab displays two Pr(Tox) columns, one for each group, and the user enters the toxicity rate to be simulated at each dose for each group. As for a single group the Category 2 toxicity and Category 4 (if using) toxicity rates are defined by defining log odds offsets at the lowest and highest dose. Specification is limited to a single set of offsets that are applied to both groups.\n\n\n\n\n\n\nFigure 38: Explicitly defined toxicity - 2 groups and ordinal offsets\n\n\n\nAs in the single group case in addition to the Category 3 toxicity rates that are editable, columns showing the Pr(Tox 2+) and Pr(Tox 4) are shown, but these are not editable and derived from the Pr(Tox) rates and the offsets that have been specified. The ordinal toxicity rates are only shown for group 1.\n\n\n8.1.3 Explicitly defined – Ordinal Toxicity with 2 groups\nIf simulating ordinal toxicity an alternative option is to explicitly specify the rate at each toxicity level at each dose. This can be done under the Virtual Subject Response &gt; Explicitly Defined &gt; Ordinal Toxicity tab.\n\n\n\n\n\n\nFigure 39: Explicitly Defined, Ordinal Toxicity with 2 Groups\n\n\n\n\n\n8.1.4 Efficacy response profiles\nEntering efficacy response profiles is very similar to entering toxicity profiles. FACTS will construct scenarios to simulate of every combination of toxicity and efficacy response profiles.\n\n\n8.1.5 Explicitly Defined – Efficacy\nEfficacy profiles may be added, deleted, and renamed just like toxicity profiles. The user enters the efficacy rate to simulate at each dose into the Probability of Efficacy column of the table, and the graphical representation of these efficacy values updates accordingly.\nAs with toxicity this form of efficacy profile is not available if the dose range is “finely spaced” – typically this means there are too many doses for it to be practicable to enter efficacy rates for all of them. When using “finely spaced” doses the efficacy rates to be simulated have to be specified using parametric models (see the next section).\n\n\n\n\n\n\nFigure 40: Efficacy virtual subject response, explicitly defined\n\n\n\n\n\n8.1.6 Explicitly Defined – Efficacy with two groups\nIf the design included 2 groups, when explicitly defining an efficacy response profile, there is simply a second column of efficacy response rates to enter:\n\n\n\n\n\n\nFigure 41: Explicity defined efficacy response profile with 2 groups",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#sec-parametric",
    "href": "documentation/v71/userguides/crm.html#sec-parametric",
    "title": "FACTS Dose Escalation CRM",
    "section": "8.2 Parametric",
    "text": "8.2 Parametric\nToxicity scenarios may be added, deleted, and renamed using the table and corresponding buttons on the left hand side of the screen. The user selects the model to use to determine the toxicity rate to simulate at each dose, and specifies the values of the model’s parameters. The graphical representation of these toxicity values updates accordingly.\nThe graph may be copied using the context menu functionality described in the previous section.\nFour models are available:\n\nLogistic: the probability of toxicity at dose x is given by: \\(P_x=\\frac{1}{1+e^{-s(x-x_{50})}}\\) with user specified parameters, \\(s\\) (slope) and \\(x_{50}\\) (the ED50 dose). Note this can be fitted exactly by the two parameter logistic with linear effective doses \\(\\hat{x}=x-x_{ref}\\) when \\(\\beta=s\\) and \\(\\alpha=\\beta*(x_{ref}-x_{50})\\)\nEmax: the probability of toxicity at dose \\(x\\) is given by: \\(P_x=\\frac{x}{x+x_{50}}\\) with user specified parameter \\(x_{50}\\).\nLog Logistic: the probability of toxicity at dose \\(x\\) is given by: \\(P_x=\\frac{1}{1+e^{-s(ln(x)-ln(x_{50}))}}\\) with user specified parameters, \\(s\\) (slope) and \\(x_{50}\\) (the ED50 dose). Note this can be fitted exactly by the two parameter logistic with log effective doses \\(\\hat{x}=ln(\\frac{x}{x_{ref}})\\) when \\(\\beta=s\\) and \\(\\alpha=\\beta*ln(\\frac{x_{ref}}{x_{50}})\\)\nPiecewise linear: with the probability of toxicity specified at a series of knots, with the probability linearly interpolated between knots.\n\n\n\n\n\n\n\nFigure 42: Virtual Subject Response - Parametric Toxicity tab\n\n\n\nIf Ordinal toxicity is being simulated then the category 2 and greater toxicity rates and category 4 toxicity rates are specified using the logit offset methods as on the Explicitly-Defined &gt; Toxicity tab.\n\n\n\n\n\n\nFigure 43: Virtual Subject Response - Parametric Toxicity tab with Ordinal toxicity\n\n\n\nIf Ordinal Toxicity and 2 groups are being simulated then both the Cat 2+ and Cat 4 toxicities and the Group 2 toxicities are defined using the logit offset methods.\n\n\n\n\n\n\nFigure 44: Parametric definition of ordinal toxicity response with 2 groups\n\n\n\n\n8.2.1 Parametric efficacy response\nParametric efficacy response profiles function exactly like toxicity profiles, with the same parametric models to choose from and if 2 groups are present the response of the second group is again defined by 2 log-odds offsets, one at the lowest dose and one at the highest.\n\n\n\n\n\n\nFigure 45: Parametric efficacy response profile",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#external",
    "href": "documentation/v71/userguides/crm.html#external",
    "title": "FACTS Dose Escalation CRM",
    "section": "8.3 External",
    "text": "8.3 External\nSubject response data may be simulated from a PK-PD model in place of, or in addition to, choosing a response model from FACTS. The importing of subject response data (which must be in the form specified in the System Requirements Document) may be done from the External Files sub-tab depicted below (Figure 46).\nThe supplied data should be in the following format: an ascii file with data in comma separated value format with the following columns:\n\nPatient id\nDose index (1, 2, 3,… if a Control is to be included it should be index 0) this is not the user settable dose name or dose level\nToxicity (0,1)\nEfficacy (0. 1) even if efficacy not being simulated this value must be present\nGroup (*1, 2) only required if groups are being simulated\n\nThe GUI requires that the file name has a “.dat” suffix.\nSimulated subjects will be drawn from this supplied list, with replacement, to provide the simulated response values.\nTo import an external file, the user must first add a scenario to the table. After adding a scenario, the user must click “Browse” to locate the externally simulated data via a standard file browser dialog.\n\n\n\n\n\n\nFigure 46: External Data",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#x-hats",
    "href": "documentation/v71/userguides/crm.html#x-hats",
    "title": "FACTS Dose Escalation CRM",
    "section": "9.1 X-Hats",
    "text": "9.1 X-Hats\nOn this tab the user specifies the reference dose \\(d^*\\) for use in calculating the adjusted dose value (the “x-hat” values). The default value to use is Median dose is reference, this uses the median of the dose range for the reference dose, minimizing the correlation in the sampled values of \\(\\alpha\\) and \\(\\beta\\). Note though that when allocation is restricted to explicit doses it is also recommended that the value of the reference dose is not the same as an actual dose that can be used (at this dose \\(\\hat{x}\\) will be 0 and the data on this dose can have undue weight on the estimate of \\(\\alpha\\)).\nDifferent reference doses can easily be used however – between the two doses thought most likely to be MTD, just below the lowest dose, just above the highest dose. The bi-variate Normal prior for \\((\\alpha, ln(\\beta))\\) will need to be recalibrated to take the change into account.\nX-Hats are log(dose strength) allows the user to select between:\n\nlinear effective dose \\(\\hat{x}_j = d_j - d^*\\)\n\\(log(\\hat{x}_j) = ln(\\frac{d_j}{d^*})\\)\n\nIf you have entered linear dose strengths for the doses (1, 2, 3, 4, … or 100, 150, 200, 250, …) then use the linear effective dose. If however the dose strengths that have been entered are non-linear (12.5, 25, 50, 100, …) but expected to be roughly linear in effect, then use the log of the dose ratio.\n\n\n\n\n\n\nFigure 47: Specifying the dose transformation - the “x-hats”.\n\n\n\n\n9.1.1 The Pro’s & Con’s of using the median dose as the reference dose\nThe reason the median dose is recommended as the reference is that this minimizes the correlation in the fit of \\(\\alpha\\) and \\(ln(\\beta)\\), the parameters of the BLRM, and it maximises the flexibility of the fit of the model over the dose range.\nHowever care needs to be taken that the prior on \\(\\alpha\\) is not more restrictive than that on \\(ln(\\beta)\\) in order to avoid a phenomena observed when preparing tutorials: observing “no toxicities” below the reference dose resulted in a model with increased probability of toxicity above the reference dose compared to observing a toxicity below the reference dose. For a given value of \\(\\alpha\\), higher values of \\(ln(\\beta)\\) correspond to lower toxicity below the reference dose – as the \\(\\hat{x}\\)̂ values are -ve below the reference dose. The fitted curve thus “pivots” about the value of \\(\\alpha\\) at the reference dose.\nThere are two solutions to this:\n\nmove the reference dose, which involves a choice between two options\n\nmoving it to the first dose or below (normally allowing a relatively constrained prior around a low value for \\(\\alpha\\)),\nor to the highest dose or above (with a relatively uninformative prior).\n\nWe have seen both solutions perform well against the chosen scenarios – but the choice needs checking and refining with a full range of scenarios that represent the full uncertainty in the true response.\nor modify the priors on \\(\\alpha\\) and \\(ln(\\beta)\\) making the prior on \\(\\alpha\\) less informative (in particular increase the probability of low values) and make the prior on \\(ln(\\beta)\\) more informative (in particular lower the probability of high values less). Because the prior distribution on \\(\\beta\\), is on \\(ln(\\beta)\\), it is easy to make large values of \\(\\beta\\) more probable than intended.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/crm.html#toxicity-response",
    "href": "documentation/v71/userguides/crm.html#toxicity-response",
    "title": "FACTS Dose Escalation CRM",
    "section": "9.2 Toxicity Response",
    "text": "9.2 Toxicity Response\nThe parameters that can be specified on this page are:\n\nThe parameters of the bivariate Normal distribution for \\(\\alpha\\) and \\(ln(\\beta)\\). Specifying the mean and standard deviation of \\(\\alpha\\) \\((\\mu_{\\alpha}, \\sigma_{\\alpha})\\), and \\(ln(\\beta)\\) \\((\\mu_{ln(\\beta)},\\sigma_{ln(\\beta)})\\) and the correlation coefficient \\(\\rho\\).\n\nIf ordinal toxicity is being simulated, it is possible to model the ordinal toxicity, specifying the mean and standard deviation of \\(\\alpha_2\\) and \\(\\alpha_4\\). These priors are separate from the \\(\\alpha_3\\) and \\(ln(\\beta)\\) prior, there is no correlation term in the prior. There is the constraint in the model that \\(\\alpha_2 &gt; \\alpha_3 &gt; \\alpha_4\\).\nUse fixed Alpha: the value of Alpha can be fixed to allow the N-CRM model to behave like the traditional CRM models. [Where \\(\\alpha\\) was set to 3 and the reference dose is set above the top of the available dose range]\n\n\nRather than entering the priors directly, they can be derived based on indirect prior information or beliefs, see ‘Deriving the Prior’ below.\n\nThe Minimum and Maximum rates that the model is to be fitted too. The model fits the range \\((0,1)\\), asymptotically approaching each limit as the adjusted dose value tends to \\(-\\infty\\) or \\(+\\infty\\). By specifying an alternative minimum and maximum, inside the range \\((0,1)\\), the user can have the model scaled to fit data to fit event rates where the asymptotic rates are not \\(0\\) or \\(1\\). For instance if the event being observed has a non-zero background rate (probability of being observed in placebo treated subjects), then the model may fit better if the minimum is set to the lower limit of this expected rate. Similarly if, even at the most toxic dose the event being observed is only expected to effect a proportion of subjects, the model may fit better if the maximum is set to the upper limit of this expected rate.\nIf a control arm is present, the user can specify to have this modelled separately, and if so the user specifies the parameters for a prior Beta distribution – in terms of numbers of prior observations on control of subjects with and without a toxicity.\nGroup 2 priors: if a second ‘Group’ is being simulated – whether this is a subset of subjects, or a modified treatment that subjects can be randomized to, then the BLRM is jointly fitted to the responses for both groups, with group 2 having offsets \\(a\\) and \\(b\\) from the first group’s \\(\\alpha\\) and \\(\\beta\\). The priors for \\(a\\) and \\(b\\) can be full bivariate Normal or can use constraints such as \\(b = 1\\), or \\(a &gt; 0\\) or \\(a &lt; 0\\).\n\n\n\n\n\n\n\nFigure 48\n\n\n\n\n9.2.1 Deriving the prior\nThe priors of \\(\\alpha\\) and \\(ln(\\beta)\\), can be specified directly or derived in one of four ways. When entered explicitly, the user specifies the parameters of the prior bivariate-normal distribution for \\(\\alpha\\) and \\(ln(\\beta)\\): the means, standard deviations and the correlation term \\(\\rho\\).\nAlternatively, the user may click the ‘derive prior’ button and select from:\n\nQuantiles at the lowest and highest dose: (based on the “uninformative prior” given in the paper (Neuenschwander, Branson, and Gsponer 2008), for details see this section) - the user specifies the probability of an unacceptable toxicity at the lowest dose, and the probability of under-dosing at the highest dose (0.1 for both is the default, and 0.05 for both is the value used in the paper). Optionally the probability that toxicity is less than the mid-point of the target toxicity band at the median dose can be specified. (Prior to FACTS 6.5 this third data point was not optional and constrained to be at the reference dose, but this had problems if the reference dose was not the media dose – it might also be the lowest dose for example).\nNote this method does not work so well if the reference dose is outside the dose range.\n\n\n\n\n\n\nFigure 49\n\n\n\nScenarios: the model is fitted to each of the toxicity response scenarios (MLE), the parameters of the bivariate normal are then calculated from resulting set of pairs of values for \\(\\alpha\\) and \\(ln(\\beta)\\).\n\n\n\n\n\n\nFigure 50\n\n\n\nSpecific quantiles: The user selects which doses and toxicity rates to provide an expectation – a prior probability that the toxicity rate on the dose will be the specified rate or less. At least 3 such expectations using at least 2 different doses strengths must be supplied. If a large number of specific quantiles are specified (e.g. reproducing the all quantiles method) the large number of different beta distributions sampled from, with the monotonicity constraint applied, results in losing too much variability. So this should only be used quantiles specified at 2-4 doses.\n\n\n\n\n\n\n\nFigure 51\n\n\n\n\nAll quantiles: the user specifies the prior expected toxicity rate at the 2.5%, 50% and 97% quantiles for each dose. (Only available when using explicitly defined doses, not a continuous dose range). Note that using Create Prior with this option will require the facts file to be saved and for there to be at least one virtual subject response profile.\n\n\n\n\n\n\n\nFigure 52\n\n\n\nIn all cases once prior values have been derived they are displayed along with a graph of 100 sampled curves from the prior. The user can accept the values, change derivation method, or cancel the derivation.\nThe plot of the samples can either be viewed as Pr(Tox) or Log-odds(Tox) vs relative dose (“x-hat”).\n\n\n9.2.2 Derivation of the Prior from Quantiles\nDerivation of the parameters of the bivariate Normal prior for \\(\\alpha\\) and \\(ln(\\beta)\\)) in the Quantiles at lowest and highest dose, Specific quantiles and All quantiles cases:\n\nMinimally informative unimodal Beta distributions are fitted for each of the doses where a prior expectation of a toxicity has been specified. For doses where no prior expectation has been specified, the median expected toxicity rate are derived by assuming that the median expected toxicity is linear in log dose on the logit scale, and again a minimally informative unimodal Beta distribution is fitted with the same median.\nPreviously and following (Neuenschwander, Branson, and Gsponer 2008), the parameters of the bivariate Normal distribution were found using a stochastic fit to the prior expectations of toxicity, minimizing the error in the prior toxicity rates at the 2.5%, 50% and 97.5% quantiles. This is still used in the All quantiles and Legacy prior cases. However experience with this method with the standard priors (previously called “uninformative”) showed that it yielded priors with too little uncertainty in the \\(ln(\\beta)\\)) and too high a value for the correlation parameter for many cases and certainly for the prior to be called “uninformative”.\nConsequently, in the Quantiles at lowest and highest dose and Specific quantiles cases, the prior is now derived by sampling from the minimally informative unimodal Beta distributions, and fitting the model to each set of sampled toxicity rates. The parameters of the bivariate normal are then calculated from resulting set of pairs of values for \\(\\alpha\\) and \\(ln(\\beta)\\).\n\nIf a control arm has been included, it may be included in the model, or modelled separately using a beta-binomial model, the user specifies the prior values for the Beta distribution.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "FACTS Dose Escalation CRM"
    ]
  },
  {
    "objectID": "get.html",
    "href": "get.html",
    "title": "Get FACTS",
    "section": "",
    "text": "FACTS is a powerful software tool that is trusted by half of the top 20 pharma companies to help them design efficient and successful clinical trials. We are proud that also numerous academic, government and regulatory institutions trust FACTS.\n\n\nIndustry\nWe offer a 3-months free FACTS Evaluation License to showcase the power and features of our FACTS simulation tool. Please contact us to get a free demo, or learn more about this offer and our regular licenses.\n\n\nAcademia / Charities / Regulatory Bodies / Government\nTo academic and other non-profit research institutions and regulatory bodies, we will generally offer a free FACTS license under certain conditions. Please contact us to see if your organization qualifies."
  },
  {
    "objectID": "introduction/index.html",
    "href": "introduction/index.html",
    "title": "Introduction",
    "section": "",
    "text": "Landing Page for Introduction.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "introduction/tutorials/tutorial2.html",
    "href": "introduction/tutorials/tutorial2.html",
    "title": "Tutorial 2",
    "section": "",
    "text": "Second tutorial",
    "crumbs": [
      "Introduction",
      "Tutorials",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "notes/index.html",
    "href": "notes/index.html",
    "title": "News",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPost1\n\n\n\n\n\n\nWebinar\n\n\nCRM\n\n\n\nSmall Text Description\n\n\n\n\n\nOct 14, 2024\n\n\nFACTS Development Team\n\n\n\n\n\n\n\n\n\n\n\n\nPost2\n\n\n\n\n\n\nWebinar\n\n\nDose Escalation\n\n\n\nSmall Text Description\n\n\n\n\n\nOct 13, 2024\n\n\nFACTS Development Team\n\n\n\n\n\n\n\n\n\n\n\n\nPost3\n\n\n\n\n\n\nPaper\n\n\nDose Escalation\n\n\n\nSmall Text Description\n\n\n\n\n\nOct 12, 2024\n\n\nFACTS Development Team\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notes/posts/2024-10-13.html",
    "href": "notes/posts/2024-10-13.html",
    "title": "Post2",
    "section": "",
    "text": "TEXT TEXT\nTEXT"
  },
  {
    "objectID": "releaseNotes/index.html",
    "href": "releaseNotes/index.html",
    "title": "Release Notes",
    "section": "",
    "text": "Landing page for Release Notes.",
    "crumbs": [
      "Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts610.html",
    "href": "releaseNotes/v6/facts610.html",
    "title": "FACTS 6.1.0 Release Notes",
    "section": "",
    "text": "1 Introducing FACTS 6.1.0\nBerry Consultants is delighted to announce that FACTS 6.1.0 is ready for release! Building on FACTS 6.0.0, FACTS 6.1.0 adds two new Dose Escalation simulation types: “FACTS 2D-CRM” and “FACTS mTPI”:\n\nFACTS “2D-CRM” is a simulator that runs simulations of dose escalation trials testing combinations of doses from 2 drugs. The implementation follows that of the 2D-CRM prototype that was available earlier this year.\n\n\n\n\n\n\n\nFACTS mTPI is an implementation of Yuan Ji’s “Modified toxicity probability interval method for dose-finding trials”.\n\n\n\n\n\n\nFACTS 6.1.0 also adds a major piece of simulation functionality across (almost) all FACTS engines: ‘Design Variants’, these allow you to have within one “.facts” file, multiple designs with different maximum sample sizes. This makes it much easier to estimate the required sample size for a design. The feature includes the ability to mark specific treatment arms or groups as ‘correct choices’, and FACTS now summarizes not only the proportions of successful and unsuccessful trials, but also proportions of successful trials that also made correct choices.\n\n\n\n\n\nFACTS 6.1.0 is fully backwards compatible with FACTS 6.0.0 and 5 – it can load and run all your FACTS 6.0.0 and FACTS 5 designs – and then use new FACTS 6.1.0 features with those designs. You can have FACTS 6.1.0 and FACTS 6.0.0 installed on the same machine, so it’s easy to have a transition period as you move to the new version.\n\n\n2 Key New Features\n\nFACTS Dose Escalation:\n\nDesign Variants in N-CRM.\n2D-CRM\nmTPI\n\nFACTS Enrichment Designs:\n\nDesign Variants\nThe ability to extend hierarchical modeling with clustered model.\n\nFACTS Core:\n\nDesign Variants\nBetter control over which frequentist calculations are performed.\nThe ability to use p-value QOIs for early success/futility decision making.\n\nFACTS Staged Design:\n\nDesign Variants\nThere is now an ‘Analysis’ tab in Staged Design.\n\n\n\n\n3 Downloading FACTS 6.1.0\nThe FACTS 6.1.0 release is available for download from the Berry Consultants FACTS 6 ftp repository at http://berry1.berryconsultants.com/facts_6/.\nLogin using:\n\nUsername: facts_6\nPassword: DynIrgyur4\n\nThere are, as usual, 4 files to download: Documents.zip, Examples.zip, Setup.msi, setup.exe. Obfuscated versions of setup.exe and Setup.msi have been included for those of you accessing through firewalls that prevent the download of .exe and .msi files. Having downloaded setup.e_e and Setup.m_i simply rename the file suffix before using.\n\n\n4 Installing FACTS 6.1.0\nAs with previous version of FACTS, FACTS 6.1.0 installs on a PC. Simply place the downloaded files on the PC / laptop it is to be installed on and run the file “setup.exe”. You will need a new FACTS license key for this new version. It will be sent to you separately.\nFor any support questions or issues, please contact us.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.1.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts620.html",
    "href": "releaseNotes/v6/facts620.html",
    "title": "FACTS 6.2.0 Release Notes",
    "section": "",
    "text": "1 Introducing FACTS 6.2.0\nBerry Consultants is delighted to announce that FACTS 6.2.0 is ready for release!\nBuilding on FACTS 6.1.0, FACTS 6.2.0 adds new features to “FACTS N-CRM”, the ability to generate a “Design Report” from FACTS Core designs and extending the ability to compute predictive probabilities to FACTS Core TTE and FACTS Staged TTE.\n\nFACTS N-CRM extensions. FACTS has had versions of the CRM with an efficacy endpoint, ordinal toxicity endpoint and 2 groups since its inception. But these were in separate engines and used the old CRM model for analysis. We have now added all these features as options to the N-CRM so they can be used with the 2 parameter Bayesian Logistic Regression model, targeting toxicity bands and the option to use overdose control. These features cannot only now but used with this better methodology, but can be used in combination with each other, and in combination with the other advanced features that were already included in the FACTS DE N-CRM simulator such as, run ins, stopping rules, escalation rules, fine grain dosing and open enrollment.\n\n\n\n\nNew N-CRM Graph\n\n\n\nFACTS Design Report. In FACTS Core there is now the ability to generate a “Design Report” as a MS Word file that describes the design and simulation results. The file is not intended as the final article but as something where the bulk of the straightforward text (and equations) have been provided and should just require polishing, particularly with the details of the indication and trial setting that FACTS is inevitably unaware of.\n\n\n\n\nNew Design Report\n\n\n\nFACTS 6.2 completes the implementation of predictive probabilities. Predictive probabilities in the current trial with a TTE endpoint are considerably more complex than predictive probabilities in the other endpoints. For the other endpoints the expected about of information after full enrollment and full follow-up is known, for time-to-event it can depend on multiple things such as accrual rate and the expected number of events so a degree of simulation within the simulation is required.\n\nFACTS 6.2.0 is fully backwards compatible with FACTS 6.1.0, 6.0.0 and 5 – it can load and run all your FACTS 6.0.0 and FACTS 5 designs – and then use new FACTS 6.2.0 features with those designs. You can have FACTS 6.2.0 and FACTS 6.1.0 installed on the same machine, so it’s easy to have a transition period as you move to the new version.\n\n\n2 Key New Features\n\nFACTS Dose Escalation, the N-CRM (also known as Bayesian Logistic Regression) now has options for:\n\nAn ordinal toxicity endpoint\nTo simulate a trial across 2 groups (e.g. Adults and Pediatrics)\nAn additional binary Efficacy endpoint\nThese options can be combined with each other and all the other N-CRM options.\n\nFACTS Core TTE\n\nThe ability to compute the predictive probability of success at the full enrollment of the current trial.\n\nFACTS Staged Design TTE\n\nThe ability to compute the predictive probability of success\n\nin Stage 1 at full enrollment\nof Stage 2 (whilst in Stage 1)\nin Stage 2 at full enrollment (whilst in Stage 2).",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.2.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts625.html",
    "href": "releaseNotes/v6/facts625.html",
    "title": "FACTS 6.2.5 Release Notes",
    "section": "",
    "text": "Berry Consultants would like to announce a new maintenance release, FACTS 6.2.5. FACTS 6.2.5 contains the following improvements to the FACTS 6.2.4 version:\nThis release addresses three rare situations in FACTS 6.2.4. If any of your designs replicate these exact circumstances you are recommended to upgrade to FACTS 6.2.5:\n\nIn FACTS Staged Design with a Time-to-Event end point and a predictor, if using, in stage 1, a predictive probability of success in stage 2, the imputation from the predictor was not being performed correctly.\nIn FACTS Staged Design, if all recruitment is completed in the first stage, so that only follow up remains in the second stage, if the second stage contains interims by time, these interims were not simulated.\nIn FACTS Core, if a Dunnett’s adjusted p-value QOI was defined and there was an additional p-value QOI defined after it, the results reported for the Dunnett’s adjusted QOI were corrupted.\n\nThe remaining, minor enhancement is in the FACTS 6.2.5 GUI:\n\nIn FACTS Core TTE, if QOIs using a Predictor endpoint were defined over and above the default ones, the GUI could delete these on re-opening the “.facts” file. Should this have happened to you, you would have seen FACTS display a warning message that it was deleting these QOIs. The GUI has been fixed so that this deletion no longer occurs. There have been no changes to Dose Escalation or Enrichment Designs. There have been no updates to the documentation or examples.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.2.5 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts640.html",
    "href": "releaseNotes/v6/facts640.html",
    "title": "FACTS 6.4.0 Release Notes",
    "section": "",
    "text": "FACTS 6.4.0 is now available for official release. Please contact us regarding any questions.\nThe key features of this release are:\n\nThree new dose response models in FACTS (Staged) Core designs.\nAlternative parametrizations to Posterior Probability Quantities of Interest (QOIs) in FACTS (Staged) Core Dichotomous and Time-to-Event designs.\nThe ability to run FACTS from R and to run FACTS in command-line mode on Linux (Enterprise licensees only).\n\nIn detail the new features in FACTS 6.4.0 are:\n\nThree new dose response models have been added across all FACTS (Staged) Core designs. These new options will appear in the model selection dropdown on the Dose Response tab. The new models are as follows:\n\nThe Simple Hierarchical model – a model in which the mean responses for each of the arms in the design are drawn from a normal distribution, whose mean and variance are estimated by FACTS. The control arm can be included in the hierarchical model, or modeled separately, in which case it has its own prior mean and variance. The control arm cannot be included in this model for Time-to-Event designs.\nThe Simple Linear model – a linear model which assumes that the mean responses for each of the arms in the design are linear functions of the associated arm strength. In particular, the arm with the largest mean response is guaranteed to be either the largest dose or the smallest arm in this model. Note that the “2-Parameter Logistic” model in FACTS (Staged) Core Dichotomous designs has been replaced by the “Simple Linear model”. FACTS (Staged) Core Dichotomous designs making use of the 2-Parameter Logistic model will be automatically migrated to the Simple Linear model.\nThe Simple Hierarchical Linear model – a model which uses a linear model as a base dose-response structure but allows deviations from linearity in a manner similar to the Hierarchical Logistic dose response model. Given appropriate priors, if the data and prior distributions are consistent with linearity, the hierarchical variance parameter will be estimated to be small and the model fit will be essentially linear, but if the data is non-linear the variance parameter will be large allowing a significantly non-linear model fit.\n\nIn FACTS (Staged) Core Dichotomous and TTE designs, Posterior Probability QOIs with alternative parametrizations can be set when creating a new QOI. This can be achieved by selecting the appropriate option in the “Compare” dropdown of the QOI dialog. The options are as follows:\n\nFor FACTS (Staged) Core Dichotomous designs, Posterior Probability QOIs comparing the log-odds ratio of the response rate for each arm against that of a given arm can now be created. Previously, only the response rates could be compared.\nFor FACTS (Staged) Core TTE designs, Posterior Probability QOIs comparing the hazard rates of the response for each arm against that of a given arm can now be created. Previously, only the hazard ratios (HR) could be compared.\n\nEnterprise FACTS licensees will now be able to access and run FACTS Core and Enrichment Design (ED) analysis models from R via an R wrapper, the output of which is an MCMC file pertaining to the model. This can be used to simulate trials that require posterior quantities that FACTS does not include (e.g., probability that a dose has a treatment effect in a certain range) or simulate trials that make decisions that FACTS does not include (e.g., sample size re-assessment).\nEnterprise FACTS licensees will also now be able to run FACTS in command-line mode on Linux via a separate executable: FACTS Linux File Loader Lite (FLFLL). Mono 6.8.0+ is a pre-requisite for running FLFLL. Executing a valid FACTS design with FLFLL will generate the same results output as its Windows GUI counterpart; in particular, it will generate the simulations, summary, weeks and patients files. FLFLL can be used to automate the simulation of multiple (potentially related) FACTS designs and, more generally, can be used as a key component of a more complex trial design simulation pipeline.\n\nThe following features were also implemented in FACTS 6.4.0:\n\nThe control arm can now be modelled separately in TTE predictor dose response models within FACTS (Staged) Core TTE designs.\nFACTS Core designs will now report the time of the stopping decision of the trial through a new simulations output column named “EarlySuccess Time”.\nFACTS now computes lower and upper frequentist CI bounds, bias and coverage at the simulation level for all design types and summarized them in the associated summary file.\nA command line option for the number of samples per imputation called “samples-per-imputation” has now been added to FACTS when run in command-line mode. This applied to FACTS (Staged) Core and ED designs.\nThe analysis tab now accepts subject files with missing values for intermediate visits (denoted by -9999).\nThe analysis tab in Multiple Endpoint now accepts data files when the design includes visits where none of the endpoints are observed.\nThe “Interim vs Final” Scatter plot graph in the “Across Scenarios” now handles interactive selection of QOI and setting of thresholds, including the use of p-value QOIs.\nThe FACTS installer will now include an option to share basic, anonymous usage and crash data with the FACTS team. This option can also be enabled/disabled by going to Setting &gt; Options &gt; Analytics. Any change in this area will take effect the next time FACTS is loaded. By default, FACTS will NOT collect any usage/crash data. However, we strongly encourage licensees to enable this option to help the FACTS team proactively improve the software in the areas that matter the most. We take our licensee’s data privacy and security very seriously, so do not hesitate to get in touch if you have any questions about this feature.\nFACTS will now, by default, automatically calculate the simulation parallelization packet size based on the number of requested simulations. A manual parallelization packet size can be set instead by setting the “Parallelization packet size” checkbox on the Simulation tab. In FACTS command-line mode, the packet size is automatically set unless the user explicitly specifies the “-p” flag.\nInformation about the FACTS license, namely its expiry date, is now available in Help &gt; About.\n[Enterprise licensees only] FACTS will automatically retry any actions involving communication with the FACTS HPC server if initial communication fails (e.g., due to an intermittent connectivity). The following FACTS infrastructure changes were performed as a part of our roadmap to modernize FACTS to make use of the latest available tech stack. Please communicate the following information to your IT team as needed:\nFACTS 6.4.0 will now target .NET Framework 4.5.2. Previous versions of FACTS target .NET Framework 4. Future versions of FACTS will target the latest available .NET Framework version.\nFACTS 6.4.0 is now a 64-bit application and will be installed on the target machine’s Program Files area. Previous versions of FACTS were 32-bit applications installed on the target machine’s Program Files (x86) area. This release addresses some situations in FACTS 6.3.0 and older versions that could cause different simulation results. If any of your designs replicate these circumstances, you are recommended to upgrade to FACTS 6.4.0:\nThe “Pause accrual and wait for completers if stopping rules are met” option on the Stopping Criteria tab of FACTS Dose Escalation N-CRM designs making use of open enrollment did not have the correct behavior when the option was unchecked. This is fixed in FACTS 6.4.0.\nThe standard deviation (SD) of the number of subjects having observed a Cat 2 Toxicity in FACTS Dose Escalation N-CRM designs was calculated incorrectly. This is fixed in FACTS 6.4.0.\nFACTS Dose Escalation N-CRM designs simulations results differed between Windows and Linux (including Windows VMs running on top of Linux) when the Toxicity response Rho parameter was non-zero. The Linux results are now consistent with the Windows results in FACTS 6.4.0.\nFACTS (Staged) Core TTE designs with interims triggered by complete predictor data were not respecting any specified minimum information required on the number of predictor completers before an interim can be triggered. This is fixed in FACTS 6.4.0.\nFACTS (Staged) Core TTE designs with interims triggered by complete predictor data an addition interim at “full predictor data” was being simulated even if not asked for. This is fixed in FACTS 6.4.0.\nFACTS (Staged) Core TTE designs with interims in stage 2 by time, after full accrual a circumstance can arise when follow up stops prematurely and an “inconclusive” result declared. This is fixed in FACTS 6.4.0.\nFACTS Staged TTE with a predictor endpoint and stage 1 data included in stage 2, any stage 1 subjects who had not had their predictor observed by the end of stage 1 had their predictor outcome censored rather than observed in stage 2. This is fixed in FACTS 6.4.0. Finally, there are two unique situations and areas identified in FACTS 6.4.0 (and prior versions) that will be continued developed and improved in future releases:\nIn FACTS Staged Design TTE, where the data inclusion is: “included where we have neither observed an event or the predictor and they are on an arm that is kept in stage 2” and stage 2 interim timings are based on “complete predictor data” and “stage 2 and included stage 1 data”, then FACTS is failing to include the included stage 1 subjects in calculating the timings of the interims in stage 2.\nIn FACTS Stage Design TTE where events are censoring for predictor outcomes, this censoring is not taken into account in the timing of interims by “Predictor Complete”. Resulting in the interims being too early.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.4.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v6/facts650.html",
    "href": "releaseNotes/v6/facts650.html",
    "title": "FACTS 6.5.0 Release Notes",
    "section": "",
    "text": "1 Introduction\nFACTS 6.5.0 is now available for download via App Center. Please contact us regarding any questions.\nFACTS users can now:\n\nSpecify frequentist margins (“deltas”) in the calculation of p-value and predictive probability QOIs for FACTS Core and Staged designs (except Time-to-Event designs).\nCreate designs with interims triggered based on predictor events for FACTS Core and Staged Time-to-Event designs with a Time-to-Event predictor.\nCreate designs where the final event endpoint analysis can be performed without any imputation based on the predictor endpoint for FACTS Core and Staged Time-to-Event designs with a predictor endpoint.\nObserve significant improvements in the mixing of MCMC chains within the Bayesian Augmented Control and Active Comparator (BAC and BAAC respectively) hierarchical models for FACTS Core and Staged and Enrichment designs.\nGenerate design reports for FACTS Core Multiple Endpoint designs, FACTS Enrichment designs (Continuous, Dichotomous and Time-to-Event) and FACTS N-CRM designs.\n\n\n\n2 FACTS Core and Staged Improvements\n\nIn FACTS Core and Staged designs (except Time-to-Event designs), FACTS users can now globally specify a frequentist super-superiority/non-inferiority margin on the Quantities of Interest tab under the Standard Evaluation Variables area, which will be applied to the calculation of all p-value QOIs and “Current Trial” Predictive Probability QOIs. Note that this globally defined margin does not apply to “Future Trial” Predictive Probability QOIs, which can have their own separate margin defined. In addition, users now have the option on the “Frequentist Analysis” tab to use the frequentist super-superiority/non-inferiority margin in the frequentist analysis.\nIn FACTS Core and Staged Time-to-Event designs with a Time-to-Event predictor, users can now specify designs with interims triggered based on the number of predictor events that have been observed. In addition, and independently of how interims are triggered, users can now specify maximum event caps based on either Final events or Predictor events.\nIn FACTS Core and Staged Time-to-Event designs with a predictor endpoint, users can now specify the final endpoint analysis to not depend on any imputation from the predictor endpoint. This can be achieved by selecting the “No imputation” option within the “Imputation on Predictor” panel on the Design &gt; Predictor Model &gt; Relationship to Endpoint tab.\nIn FACTS Core and Staged designs, the mixing of MCMC chains within Bayesian Augmented Control and Active Comparator (BAC and BAAC respectively) hierarchical models has been improved significantly; in particular, when the prior on tau^2 in the hierarchical model is forced to be small.\nFACTS Core Multiple Endpoint now provides the ability to generate a design report once the design has been simulated. As a result, all FACTS Core design types can now generate design reports.\nFACTS Core and Staged designs now correctly display a trial as having stopped for futility if all arms have been dropped.\nFACTS Core and Staged designs now correctly prevent interims from being performed beyond full enrollment when the “Discontinue interim analysis beyond full enrolment” setting on the Interims tab is selected.\nFACTS Staged Time-to-Event designs now correctly handle interim timings in Stage 2 for the various data inclusion rules as specified on the Data Inclusion tab, and interim information based on “Just Stage 2 data” or “Stage 2 and included Stage 1 data”, as specified on the Stage 2 Interims tab.\nFACTS Staged Time-to-Event designs now correctly handles interim timings based on complete predictor data, when a predictor is included in the design and the “Primary endpoint is censoring for intermediate predictor” setting is selected.\nFACTS Core and Staged Time-to-Event designs now correctly handle predictor based imputation when using a dichotomous predictor endpoint.\nOn the Analysis tab in FACTS Core and Staged Time-to-Event designs, current trial predictive probabilities that estimate an accrual rate no longer require input data to be sorted by accrual time.\nFACTS Core Multiple Endpoint and FACTS Staged Dichotomous designs will now correctly output p-value trend test QOIs as a single output column, rather than one output column per dose, in summary files.\nFACTS Staged Multiple Endpoint designs will now correctly display the endpoint number when outputting p-value trend test QOIs in summary files.\nFACTS (Staged) Multiple Endpoint designs will now correctly display the posterior probability QOI comparison options (“Rates” and “Log-odds”) for dichotomous endpoints. Changing the endpoint from being dichotomous to continuous will delete posterior probability QOIs using the “Log-odds” comparison.\nFACTS Core and Staged Multiple Endpoint analyses will now correctly handle endpoints with visits schedules. Namely, when an endpoint contains only one visit schedule or when an endpoint’s visit schedule involved non-consecutive visits.\nFACTS Core and Staged Multiple Endpoint analyses will now correctly handle endpoints whose visit schedule contains missing data.\n\n\n\n3 FACTS Enrichment Design Improvements\n\nFACTS Enrichment designs (Continuous, Dichotomous and Time-to-Event) now provide the ability to generate design reports once the designs have been simulated. As a result, all FACTS Enrichment design types can now generate design reports.\nThe mixing of MCMC chains within Bayesian Augmented Control (BAC) hierarchical model has been improved significantly; in particular, when the prior on tau^2 in the hierarchical model is forced to be small.\nThe clustering in Enrichment designs has been improved for situations when the prior on tau^2 is chosen to be small (e.g. 0.01 with weight 1).\nThe patients file output from simulations (patients.csv) now correctly populates the dropout state of patients, and can now be used as subject data input on the Analysis tab without requiring modification.\nMCMC Trace plots are now available for all Enrichment design types when viewing simulation results graphs and when performing analyses. To view these graphs, at least one MCMC file needs to be generated. This can be done by going to the Simulations tab &gt; MCMC Settings.\nExternal data file validation has been improved.\n\n\n\n4 FACTS Dose Escalation Improvements\n\nN-CRM now provides the ability to generate design reports once the design has been simulated.\nIn N-CRM designs which include efficacy, the “Maximum cohorts used to determine MTD” setting on the Allocation Rule tab is now observed correctly.\nIn N-CRM designs, when deriving toxicity/efficacy priors from quantiles at the lowest and highest doses, the “middle” probability option now refers to the median dose rather than the reference dose and is now optional. When pre-6.5 FACTS files are loaded in FACTS 6.5, the “middle” probability option will be ignored and replaced by 0.5.\nIn N-CRM designs, the specification of at least two dose levels is now required when deriving toxicity/efficacy priors from specific quantiles. Previously, the specification of at least three dose levels was required.\n\nFACTS Command Line mode and FLFLL (FACTS Linux File Loader Lite) now correctly handle the processing of N-CRM designs whose prior was derived using the “Legacy Prior” option.\nIn N-CRM designs using open enrollment without accrual pausing, FACTS will now output entries in the cohort file for subjects that have been lost following stopping rules being met.\nIn N-CRM designs using open enrollment, FACTS will no longer prematurely apply stopping conditions when there are still subjects whose outcomes have been observed, but not yet processed.\nIn N-CRM designs using open enrollment, FACTS will now report the selected MTD/MED/OSD and associated state to be the dose where the stopping conditions were first met, unless the MTD has subsequently decreased post stopping rules being met.\nIn N-CRM designs using open enrollment, dose escalation rules when using fine-grained dosing will behave correctly.\nIn N-CRM designs using open enrollment and two groups, stopping rules and dose escalations rules will now apply to the correct group.\n\n\n\n5 General Improvements\n\nFACTS now targets .NET Framework 4.8, the latest major version of the .NET Framework.\nA new “Simulation Duration” table can be viewed when right-clicking on a simulation design scenario. The Simulation Duration table gives a granular view of simulation start and end times, as well as its total duration.\nSeveral major improvements to FLFLL (enterprise licensees only): in particular, the ability to process specific scenarios of a design, the ability to process all FACTS files contained within a specified directory, and the reporting of design scenario validation errors. See FLFLL documentation for details.\nIn FACTS Command Line mode and FLFLL, a new flag is available to specify the number of MCMC samples to generate for imputation purposes.\nIn FACTS Command Line mode, the ability to generate a design report has been added. This can be achieved by adding the -report flag and the -rpath flag, where the latter is used to specify the path to the R executable.\nFACTS now provides links to FACTS introductory videos hosted on YouTube via the Help menu.\nSimulation engine errors in FACTS are now displayed in the GUI more informatively.\nThe remaining time left on a FACTS license is now displayed correctly on the FACTS splash screen and Help menu.\nFACTS can now output up to 99,999 patients/weeks/frequentist/MCMC files. Previously, this was capped at 9,999 files.\nAll designs supporting design report generation can have their design report generated without having to perform an additional command execution step in RStudio, by selecting a valid R installation under Settings &gt; Options &gt; R Configuration.\nFACTS will now correctly handle the serialization/deserialization of text inputs involving the following characters: “&gt;”, “&lt;”, “&”, “ ’ ” and “\\”.\nWhen viewing FACTS simulation results through the GUI, estimates of responses, effects and hazard ratios (for Time-to-Event designs) will be display more obviously in the results column headers.",
    "crumbs": [
      "Release Notes",
      "FACTS 6 Release Notes",
      "FACTS 6.5.0 Release Notes"
    ]
  },
  {
    "objectID": "releaseNotes/v7/facts710.html",
    "href": "releaseNotes/v7/facts710.html",
    "title": "FACTS 7.1.0 Release Notes",
    "section": "",
    "text": "1 Introduction\nFACTS 7.1.0 is now available for download via App Center. FACTS users can now:\n\nPerform concurrent control analyses using posterior probabilities, predictive probabilities and p-values in Platform Trial designs.\nMake interim and final decisions based on conditional power as well as Bayesian predictive probabilities.\nExport the data associated with the in-built graphs FACTS provides into a CSV file.\nExplore, via integration with AIRSHIP, simulation results graphically in a much more generic, versatile way; namely, by allowing the user to view the impact of simulation input dimensions through dynamic filtering of the simulation results.\nCreate designs which use an independent Beta Binomial dose response model for analyzing (simulated) data for dichotomous endpoints in Core and Staged designs.\n\nCreate designs where frequentist (p-value) calculations are performed using the Fisher exact test rather than a normal approximation for dichotomous endpoints.\nProvide three separate patient queue lengths for Continual Reassessment Methods (CRM) designs, based on dose clearance and the current model estimate of the MTD. In addition, the ability to backfill to the current escalation dose (“frontfill”) is now available.\nView explanations of some of the most important inputs in Core Continuous/Dichotomous designs through informative tooltips.\nSet different random number seeds when simulating multiple design scenarios.\nCreate designs where decision QOIs can be used in multiple stopping criteria simultaneously.\n\n\n\n2 FACTS Core and Staged Improvements\n\nIn Core and Staged designs making use of dichotomous endpoints, FACTS users can specify a beta binomial model to independently model the response rate on each arm. With this model, the user specifies a Beta distribution prior on the response rate.\nIn Core and Staged designs which perform frequentist analyses on dichotomous endpoints, users can now specify whether p-value calculations (including Current Trial Predictive Probability QOIs) should be performed using a normal approximation as currently, or using a Fisher exact test. The latter is of particular use when sample sizes are small.\nIn Staged designs, the reported Early Success Time will now correctly only be reported for simulations which have stopped for early success. Previously, simulations which have graduated early to stage 2 in stage 1 were being reported as having an Early Success Time.\nWhen running analyses in FACTS Core and Staged designs, the user can now specify the number of MCMC samples to generate per imputation of missing data modelled by a longitudinal model.\nIn Core and Staged designs with a dichotomous endpoint, the 95% confidence interval of the raw treatment estimates will now be reported correctly in relevant graphs.\nIn Core and Staged designs, a new Operating Characteristics graph displaying the cumulative proportion of simulations having stopped at a given duration, sample size or number of events (in Time-to-Event) has been added.\nIn Core designs, two new summary columns “Ppn Overall Success” and “Ppn Overall Futility” have been added, which simply sum up the existing columns “Ppn Early Success” and “Ppn Late Success”, and “Ppn Early Futility” and “Ppn Late Futility”, respectively. This allows users to quickly view the estimated type I error and power of the design.\nIn Core and Staged designs, the number of participants at the end of each simulated trial who have had outcomes (“completers”) will now be summarized. The interim subject information (reported in the weeks file “Complete Info” columns) will now also be computed at the final analysis, reported in the simulations file and summarized.\nIn Staged designs, the Stage 2 “Explore” Final Success/Futility graphs will now have the option to include/exclude simulations which have stopped in Stage 1.\nIn Core and Staged designs, the criteria for selecting a dose at the end of the trial have moved from the “Variants” tab to the Success/Futility tab. These criteria will be used when reporting the proportion of times the correct/incorrect arm was selected at the end of the trial (as reported in the “Ppn Correct/Incorrect Arm” columns, which are now reported in the summary file).\nIn Core and Staged Multiple Endpoint designs, designs not using a control arm will no longer crash when adding a new endpoint, and no longer crash when adding a new treatment to a design which uses Virtual Subject Response external data files.\nIn Core and Staged designs, the “Legacy Second Order NDLM” dose response model and the “Legacy Adaptation” allocation option have been removed. Older designs making use of these features will be migrated over to the “Second Order NDLM” dose response model and the “Fixed Allocation” allocation option, respectively, when loaded in FACTS 7.1. A warning prompt will appear for such designs.\nUsers can now choose a decision QOI in multiple stopping criteria simultaneously. Previously, after a stopping rule was created based on a certain decision QOI, any additional stopping rule could not use this decision QOI.\nIn Core and Staged Designs, a new class of QOI as a sub-category of Predictive Probabilities was introduced: Conditional Power. Contrary to the existing Bayesian Predictive Probabilities, Conditional Power assumes the observed treatment effect estimates to be the truth and then calculates the probability of being successful either: 1) at a later final analysis, 2) after the currently enrolled subjects are followed up or 3) in a future trial.\nFACTS will now correctly calculate the Bayesian Predictive Probabilities of success at the final analysis when a continuous endpoint and change from baseline as the final endpoint are used.\nIn Core and Staged Time-to-Event designs, minimum information required to trigger an interim will now be available when interims are based on predictor events.\nIn Core and Staged Time-to-Event designs, the complete information columns report at interims with the weeks files will now display the correct information when interims are based on predictor events.\nIn Core and Staged Time-to-Event designs with a Time-to-Event predictor, when interim information events and the event max cap differ (e.g. max cap on final events but interims based on predictor events), simulations will correctly stop at the specified max event cap.\nIn Core and Staged Time-to-Event designs with a Time-to-Event predictor, current trial predictive probability QOIs are now handled correctly when max event caps refer to predictor events.\nIn Staged Time-to-Event designs with a Time-to-Event predictor, current trial predictive probability QOIs are now handled correctly when interim information events and the event max cap differ (e.g. max cap on final events but interims based on predictor events).\nIn Staged Time-to-Event designs, the censoring and event time of subjects in Stage 2 which have not observed their event in Stage 1 will now be handled correctly for both their final and predictor endpoints.\nIn Core and Staged design, (Continuous, Dichotomous, and TTE) when a trial stops for early success or early futility and the option to continue follow-up after that decision is not selected, the final analysis model is no longer run. The data at the final analysis would be identical to the data at the interim analysis that the stopping threshold was hit at, so the model output for the final is now identical to the interim.\nTime Course Hierarchical longitudinal model has improved performance with informative priors on the variance components.\nIn Staged designs, FACTS will now correctly handle the Stage 1, Stage 2 and overall sample size caps (maximum number of subject caps and maximum number of event caps) specified in the Variants tab.\nIn Core and Staged Time-to-Event designs, the Cox Proportional Hazards current trial predictive probability calculation has been corrected.\nIn Core and Staged designs, when using predictive probabilities that predict success at trial maximum, but the trial is stopped at an interim, the predictive probability is now calculated based on the originally specified number of subjects at trial maximum rather that assigning the predictive probability a value of 0 or 1 depending on the p-value of the interim data.\nIn Core and Staged designs, when using predictive probabilities, visit values are now correctly imputed when there is only baseline visit data available.\nIn Core and Staged designs, when using a dichotomous endpoint and predictive probabilities of treatment versus control, FACTS now performs a Farrington and Manning Test when there is a superiority or non-inferiority margin.\nIn Staged design, the arm selection logic has been updated to properly account for arm-dropping in stage 1 when selecting a single arm from each group.\n\n\n\n3 FACTS Enrichment Design Improvements\n\nIn Enrichment Dichotomous designs, users can now perform frequentist calculations using a normal approximation as currently, or using a Fisher exact test. The latter is of particular use when sample sizes are small.\nIn Enrichment Time-to-Event designs, the GUI will now correctly calculate the mean frequentist estimated treatment effect and its standard error.\nWhen running analyses in Enrichment designs, the user can now specify the number of MCMC samples to generate per imputation of missing data modelled by a longitudinal model.\nIn Enrichment Dichotomous designs, the 95% confidence interval of the raw treatment estimates will now be reported correctly in relevant graphs.\nIn Enrichment designs, a new Operating Characteristics graph displaying the cumulative proportion of simulation having stopped at a given duration, sample size or number of events (in Time-to-Event) has been added.\nIn Enrichment designs, two new summary columns “Ppn Overall Success” and “Ppn Overall Futility” have been added, which simply sum up the existing columns “Ppn Early Success” and “Ppn Late Success”, and “Ppn Early Futility” and “Ppn Late Futility”, respectively. This allows users to quickly view the estimated type I error and power of the design.\nIn Enrichment designs, the number of participants at the end of each simulated trial who have had outcomes (“completers”) will now be summarized. The interim subject information (reported in the weeks file “Complete Info” columns) will now also be computed at the final analysis, reported in the simulations file and summarized.\nIn Enrichment designs, the frequentist test reported in the frequentist simulations file will now make it clear whether the performed test is a one-sided or two-sided test. In the associated frequentist summary file, the proportion of frequentist results for each test type that are significant will now correctly take into account the correct alpha level depending on whether the test is one-sided or two-sided.\n\n\n\n4 FACTS Platform Trial Improvements\n\nBREAKING CHANGE: in Platform trial designs, the numerical value representing the outcomes for late futility and early futility have been swapped in FACTS 7.1.0. Any older designs with futility criteria will need to be re-simulated. Decision numeric values in FACTS Platform Trials and FACTS Core now match.\nIn Platform Trial designs, users can now specify whether Posterior Probability QOIs, Predictive Probability QOIs or p-value QOIs should be calculated based on the entire control population in the trial (as previously) or based on the given treatment’s concurrent control population. These concurrent control QOIs can be used as treatment stopping criteria like any other QOI.\nA time window allowing a treatment’s concurrent controls to additionally include control patients a certain number of weeks from the treatment entering the trial can also be specified.\nPr(Max) Target Dose QOIs can now be calculated based on all arms in the trial (as previously), only active arms or only randomizing arms.\nIn Platform Trial Dichotomous designs, the 95% confidence interval of the raw treatment estimates will now be reported correctly in relevant graphs.\nIn Platform Trial designs, a new Operating Characteristics graph displaying the cumulative proportion of simulation having stopped at a given duration or sample size has been added.\nIn Platform trial designs, users can now specify different variants of the design by modifying both the maximum number of participants per treatment as well as the maximum number of concurrent treatments. These variants will display as separate scenarios on the Simulations tab.\nIn Platform trial designs, the number of participants at the end of each simulated trial who have had outcomes (“completers”) will now be summarized. The interim subject information (reported in the weeks file “Complete Info” columns) will now also be computed at the final analysis, reported in the simulations file and summarized.\nIn Platform trial designs, the “Per Sim: Arm and Participant Arrival” graph will now correctly display the accrual period for the control arm to end when the last treatment’s accrual period ends.\nUsers can now choose a decision QOI in multiple stopping criteria simultaneously. Previously, after a stopping rule was created based on a certain decision QOI, any additional stopping rule could not use this decision QOI.\nFACTS will now correctly calculate the Bayesian Predictive Probabilities of success at the final analysis when a continuous endpoint and change from baseline as the final endpoint are used.\n\n\n\n5 FACTS Dose Escalation Improvements\n\nThe Dose Escalation design types CRM(Toxicity), CRM(Ordinal), bCRM and CRM(Efficacy) have all been deprecated. Users can still create new designs or open existing designs with these design types. We recommend using the more general and versatile “Continual Reassessment Methods (CRM)” design type (formerly known as “N-CRM”) for any 1D model based CRM designs.\nIn CRM with open enrollment, users can now specify whether they want to allow backfilling to the highest dose (“frontfilling”) and conditions under which to do so. Users can choose whether to count these patients towards the backfill subject cap or regular allocation cap.\nIn CRM with open enrollment, previously two queues (maximum number of subjects on uncleared doses and maximum number of subjects on cleared doses) determined the allocation behavior. In order to give users more flexibility and control, there are now three queue concepts (maximum number of subjects on uncleared doses, maximum number of subjects on cleared doses at MTD and maximum number of subjects below MTD). These queues are now used in the same way in the MTD and MED phase of the trial. The concept of max cleared dose and the new queues are now harmonized.\nIn CRM, the stopping rule checker design was updated. In case of regular dosing, a concept of near doses like that of fine spaced dosing was introduced and both concepts aligned for both stopping in the MTD and MED phase. The stopping rule checker now also correctly checks the hierarchies and join conditions.\nIn CRM with open enrollment, backfill will now correctly evaluate all cleared doses for eligibility.\nIn CRM with open enrollment and fine spaced dosing, near doses are now correctly evaluated in regular allocation, backfill and for the purposes of stopping.\nIn CRM designs, FACTS will now correctly apply study size constraints and queue size constraints when the underlying toxicity model considers all doses to be toxic. This also includes preventing an expansion cohort from being allocated in this situation.\nIn Dose Escalation designs, a new Operating Characteristics graph displaying the cumulative proportion of simulation having stopped at a given duration or sample size has been added.\nIn 2D-CRM designs, the dose response model’s eta parameter can now be specified in log-normal space.\nIn 2D-CRM designs with custom run-in, FACTS now proceeds to the chosen escalation scheme more promptly, without first allocating more than one full-size cohort unless they are specified in the run-in.\nThe “Per Sim Allocation History Grouped” plot will now be displayed correctly if, previously, the “Per Sim Allocation History Group 1” plot had been set to space interims equally.\nIn CRM with an initial run-in, escalation will now be performed correctly and maximum cleared dose tracked correctly in all circumstances.\nIn CRM with small-cohort pre-escalation, we now only switch to regular escalation based on observed toxicities, not MTD estimate or overdose control rules.\nIn CRM, introduce the notion of “Selected MTD”, “Selected OSD” and “Selected MED” at the end of trial as a function of the respective model estimates and the max cleared dose.\nIn CRM with two groups that enroll consecutively, there are now several options regarding what dose level to start escalation at in group 2.\nIn CRM with fine grained dosing, the concept of near doses is now correctly applied in the escalation phase, when calculating the max cleared dose and adjusted for the new queue concepts.\nIn CRM, cohort expansion will now enroll the correct number of patients even when accrual is very fast.\nIn CRM, when using a cohort expansion or a two group design, the trial state on which both of these concepts depends is now the final state of the previous trial, not the state of the previous trial when its stopping criteria were met.\nIn CRM, when using two groups and expansion cohorts in both groups, the group 2 expansion cohort now correctly uses its own cap regarding maximum number of subjects. In the same setting, a rare circumstance led to the allocation in the group 1 cohort expansion to continue beyond the max cap – this is now resolved.\nIn CRM, stopping based on the max cap of subjects for escalation now does not lead to an overrun in patients in rare circumstances.\nIn CRM with both an MTD and an MED phase (toxicity and efficacy endpoints), the transition between the phases is now handled correctly.\nIn CRM, improved labels and default values in the GUI, such as improved values for the overdose control and open enrollment queue lengths and clearer labels in the Allocation tab.\nSeveral GUI stability improvements in the CRM engine.\nIn CRM, there are several improvements to the “Per Sim Allocation History”, “Alloc and Tox History”, “Cohort Band Probabilities” and “Cohort Response” graphs, including showing the cohort expansions subjects separately, showing the max cleared dose at any point in time and showing the selected MTD/MED at the end of the trial.\n\n\n\n6 General Improvements\n\nFACTS has now been integrated with AIRSHIP, which allows simulation results to be explored graphically in a much more generic, versatile way. Once simulation have completed, results can be explored with AIRSHIP by clicking on “Explore Results…” &gt; “Compare Scenarios in AIRSHIP”. Note that use of AIRSHIP requires at least two scenarios to have been simulated and their results aggregated.\nThe process of making the FACTS inputs more intuitive has started as of FACTS 7.1.0. In FACTS Core Continuous/Dichotomous designs, tooltips will appear against many of the inputs (when hovering over the relevant input) with explanatory text about their use and impact on the design. Tooltips can be disabled by going to Settings &gt; Options &gt; Tooltip Configuration.\nThe data associated with all graphs displayed in FACTS can now be exported into a CSV format. In addition, hovering over these graphs will display the associated data point value as a tooltip.\nWhen simulating multiple scenarios, each simulated scenario can now be simulated with a different random number seed.\nWhen running simulations for a directory of FACTS files in FACTS Command Line or FLFLL, a different base seed can be set for each design within the directory.\nThe order of scenarios to simulate as displayed on the Simulation tab has been set to be consistently displayed in alphabetical order.\nWhen aggregating simulation results for a design using variants, the relevant variant number will now correctly be displayed in the aggregated files.\nSeveral bug fixes and improvements have been made to all design reports.\nThe associated engine executable now provides a new -o output flag argument specifying the location where to output all files generated by the engine [Enterprise licensees only].\n\nPlease contact us regarding any questions.",
    "crumbs": [
      "Release Notes",
      "FACTS 7 Release Notes",
      "FACTS 7.1.0 Release Notes"
    ]
  }
]