[
  {
    "objectID": "documentation/v71/userguides/dr.html",
    "href": "documentation/v71/userguides/dr.html",
    "title": "Design Report",
    "section": "",
    "text": "This document describes usage and how to update the installation of the Design Report Generator, an automated report generation tool, included with FACTS. It is intended for anyone concerned with using the automated report generation facility. The Report Generator is available only for the desktop version of FACTS.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#purpose-and-scope-of-this-document",
    "href": "documentation/v71/userguides/dr.html#purpose-and-scope-of-this-document",
    "title": "Design Report",
    "section": "",
    "text": "This document describes usage and how to update the installation of the Design Report Generator, an automated report generation tool, included with FACTS. It is intended for anyone concerned with using the automated report generation facility. The Report Generator is available only for the desktop version of FACTS.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#software-prerequisites",
    "href": "documentation/v71/userguides/dr.html#software-prerequisites",
    "title": "Design Report",
    "section": "Software prerequisites",
    "text": "Software prerequisites\nIn order to run the report generator directly from FACTS, you will need the following installed on your Windows machine on which you are using FACTS:\n\nA reasonably recent version of R (v3.5.3+) along with the R libraries ‘rmarkdown’, ‘xtable’ and ‘stringi’ installed.\nRStudio (the Design Report Generator uses two packages that come with RStudio – “mathjax” and “pandoc”, these can now be obtained separately but given the ubiquity of RStudio FACTS simply requires you to have that installed).\nMicrosoft Word or Open Office\nFACTS v7.1 or later\n\n\n\n\n\n\n\nNote\n\n\n\nRecently we’ve experienced some problems with “pandoc”, downloading and installing from the pandoc website (https://pandoc.org), then re-starting Windows has fixed them.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#setup",
    "href": "documentation/v71/userguides/dr.html#setup",
    "title": "Design Report",
    "section": "Setup",
    "text": "Setup\nYou will need to inform FACTS of the location of R and RStudio on your computer.\nTo do this start FACTS and go to menu option: “Settings &gt; Options” and then to the “R Configuration” tab.\n\n\n\n\n\n\nFigure 1\n\n\n\nSelect the R and RStudio versions you would like to use.\nIf the version you wish to use isn’t shown, or the path is incorrect, use the “Edit” button to open a file browser to navigate to the version of R that you wish to use and select the appropriate version of “R.exe”. Similarly for RStudio.exe.\n\n\n\n\n\n\nFigure 2",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#steps-for-generating-a-design-report",
    "href": "documentation/v71/userguides/dr.html#steps-for-generating-a-design-report",
    "title": "Design Report",
    "section": "Steps for generating a design report",
    "text": "Steps for generating a design report\nTo generate a design report from FACTS, you will need to do the following sequence of steps:\n\nOption 1\n\nSimulate your design in FACTS.\n\n\n\n\n\n\n\nNote\n\n\n\nIn case you have previously generated a report for your design using the report generator, you will need to make sure that the previous version of the report is not open in Word when you generate a new report.\n\n\n\nAfter setting valid R and RStudio versions/paths in Settings &gt; Options, go to the “Simulation” tab and click on the “Design Report” button. A command prompt Window will open detailing the report generation process. The very first run of the design report generation process will take a bit longer than subsequent runs as it will have to install all relevant R packages in a FACTS specific location.\nOnce the command prompt closes, the Word document will be automatically opened. It will first give you a warning regarding the document containing fields that may refer to other files, click “Yes” and then a subsequent warning regrading update the Table of Contents will appear. Click “Update entire table” and your report should appear.\n\n\n\n\n\n\n\nFigure 3: Example FACTS design report for a Core continuous endpoint design\n\n\n\n\n\nOption 2\n\nSet up your Rstudio configuration in FACTS Options &gt; R Configuration\nSimulate your design in FACTS Core or Platform Trials engines.\nClick the “Design Report” button on the Simulation tab in the Results Options section. This button only shows up when simulations have been successfully run.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#usage-notes",
    "href": "documentation/v71/userguides/dr.html#usage-notes",
    "title": "Design Report",
    "section": "Usage Notes",
    "text": "Usage Notes\n\nLocation of the generated Word file\nThe generated report document is stored in the “results” folder of your FACTS simulation (e.g., if your FACTS project is saved as CoreDesign.facts, the folder named CoreDesign_results is the corresponding ‘results’ folder).\n\n\nSuggested steps after generating the report\nA typical workflow after initially generating the report is as follows:\n\nReview the generated report for correctness, and fix minor typographical and formatting errors if any.\nIf you would like to use a predefined Word template, you could apply the template to your report.\nModify the default table style and add table cross-references as needed.\nAdd additional text and figures as needed. For example, you can copy graphs displayed in the FACTS GUI by clicking on the “Export options” button next to the r graph, selecting “Copy image to clipboard” and pasting it in the generated report.\n\n\n\nLocation of the Report Generator source files\nThe Design Report Generator uses R and Rmarkdown to create the report document. The script files used by the Report Generator are stored in the “ReportGenerator” folder under your FACTS installation folder. (It might be named something like C:\\Program Files (x86)\\BerryConsultants\\FACTS 7.1.0\\ReportGenerator). The files within this folder with file extensions of “.R”, and “.Rmd” are the ones required by the Report Generator. If an updated version of the Report Generator is made available either as a bug-fix or intermediate release, it will consist of updated “.R” and “.Rmd” files. Simply replacing the corresponding files in the original installation folder will deploy the updated version.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html",
    "title": "Continuous and Dichotomous Output",
    "section": "",
    "text": "To enable swift visualization and analysis of the simulation results, FACTS has a number of pre-defined graphs it can display. Full and detailed simulation results are available in ‘csv’ format files that can be loaded into other analysis tools allowing any aspect of the simulation to be explored. These files are described below.\nTo view the graphs, select a row of scenario results by clicking on it and then click on the ‘View Graph’ button.\nBelow we have often shown full screen shots of the graphs in the graph manager, but the graph display supports copying just the graph to the clipboard to facilitate pasting them into documents and presentations. Right clicking on a graph brings up a short menu that allows the image of the graph to be copied to the clipboard or saved in ‘png’ format to a file.\nTo view the graphs of the results of the simulations of a particular design variant in a particular scenario, select that row of scenario results by clicking on it and then click on the ‘View Graph’ button and select “Show Per Scenario Graphs”.\nTo view multiple graphs showing the results of the simulations of possibly all the design variants and all the scenarios click on the ‘View Graph’ button and select “Show Across Scenario Graphs”. This launches a graph display that displays multiple graphs in a trellis plot. You can select the graph type, filter the design variants and filter which scenarios displayed:\n\n\n\n\n\n\nFigure 1: Pop up to select scenarios and variants to display.\n\n\n\nThe graph display supports copying an image of the graph to the clipboard, to facilitate pasting them into documents and presentations. Right clicking on a graph brings up a short menu that allows the image of the graph to be copied to the clipboard or saved in ‘.png’ format to a file.\nMany graphs have a number of controls to allow the graph to be tailored, standard graph controls available on most graphs are:\n\nSet Y axis – this displays a dialog boxing allowing the user to fix the minimum and maximum of each of the Y axes and the number of ‘tick’ marks (Not displayed if the ‘y’ value must lie in the interval 0-1.)\nSpace doses evenly – if the x-value is ‘dose’, then data for each dose can either be spaced equally or proportionate to the doses’ effective dose strength.\nIf using a 2D treatment arm model then it is possible to display graphs where the different doses (or “arms”) form the x-axis, then there is an option to show the row factors as separate series – otherwise the different combinations are displayed in effective strength order\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Arms shown in effective strength order\n\n\n\n\n\n\n\n\n\n\n\n(b) Arms shown with row factors as a separate series\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Arms shown in effective strength order\n\n\n\n\n\n\n\n\n\n\n\n(b) Arms shown with row factors as a separate series\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\n\n\nThe mean probability is plotted as a large dot.\nThe median value is plotted as a dashed line.\nThe 25-75th quantile range is plotted as the “box” portion of each point.\nThe “whiskers” extend to the largest and smallest values within 1 ½ times the interquartile range from either end of the box.\nPoints outside the whisker range are considered outliers, and are plotted as small blue dots. Note that it may be difficult to see all of these symbols if they are plotted at the same value.\n\n\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 4: Distribution of Subject Allocation Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Distribution of Subject Allocation Across Simulations.\n\n\n\n\n\n\nThis graph displays a box and whisker plot of the number of subjects recruited into each arm. These plots show:\nThe distribution over all simulations of the number of subjects allocated to each arm shown as a box and whisker plot. If the design is not adaptive, the number allocated will be the same in every simulation and the box and whiskers collapse to a single line.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 6: Response and Subject Allocation.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Response and Subject Allocation.\n\n\n\n\n\n\nThis graph shows for each treatment arm, the mean subject allocation, mean response and the 2.5%-97.5% boundaries of the estimated means over the simulations.\n\nThe blue bars show the mean number of subjects allocated.\nThe black line shows the true mean response being simulated.\nThe green dashed line shows the mean of the estimated response across the simulations\nThe green ‘error bars’ show the spread of the central 95% of the estimated mean response across the simulations (if less than 20 simulations have been run it simply shows the full spread).\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 8: Response and QOI Selection.\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Response and QOI Selection.\n\n\n\n\n\n\nThese plots show the true simulated mean response and the mean and 95% spread of the mean fitted mean responses along with bars showing the proportion of simulations the different treatment arms are the selected target arm for each of the “Probability of being target” QOIs, such as Pr(Max), Pr(EDq relative to ..: Quantile=q) and Pr(MED relative to…: Delta=\\(\\delta\\)).\n\n\n\nThis set of graphs show the distribution over the simulations of the posterior probability estimates of quantities of interest for each dose. All the Posterior Probability, Predictive Probability, P-value and Probability of being Target QOIs that have been defined are available for plotting, via a drop down list.\nNote that in any one analysis the Probability of being Target will sum to 1 across the doses (and can sum to less than one in the case of the MED target if none of the doses look likely to be better than the CSD), whereas all the other QOIs are assessed individually for each dose.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Distribution of \\(P\\)(\\(\\theta_d\\) - \\(\\theta_{Control}\\) &gt; 0.1) Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribution of \\(P\\)(MED relative to Control: Delta}=0.1) Across Simulations.\n\n\n\n\n\n\n\nFigure 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Distribution of \\(P\\)(\\(P_d\\) - \\(P_{Control}\\) &gt; 0.15) Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribution of \\(P\\)(MED relative to Control: Delta}=0.2) Across Simulations.\n\n\n\n\n\n\n\nFigure 11\n\n\n\n\n\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 12: Posterior Mean Response at P(MED relative to Control: Delta}=0.1) vs. Total Sample Size per Simulation Run\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Posterior Mean Response at P(MED relative to Control: Delta}=0.2) vs. Total Sample Size per Simulation Run\n\n\n\n\n\n\nThis graph shows a scatter plot of trial outcomes with the selected Target QOI as the y-axis and total number of subjects recruited as the x-axis. The trials are plotted with a symbol that indicated the final outcome:\n\nA light blue circle indicates a trial that stopped early for success\nA dark blue circle indicates a trial that was a late success\nA dark red square indicates a trial that was a late futility\nA light red square indicates a trial that stopped early for futility\nA light pink diamond indicates a trial that stopped early for success but where the final analysis was futility\nA dark pink diamond indicates a trial that stopped early for futility but where the final analysis was success\nA yellow cross indicates a trial that completed full enrolment but was inconclusive at the end.\n\nThese graphs are not particularly useful if there is no early stopping.\nIf the design does allow early stopping this graph shows\n\nThe overall distribution of sample sizes – in particular is stopping evenly distributed from the moment stopping is possible, or is there are large cohort of trials that stop as soon as it is possible?\nWhen and with what mean response trials stop incorrectly, in particular having trials stopping and the decision being reversed suggests stopping is allowed to soon or the criteria is not conservative enough.\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Duration\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Subjects\n\n\n\n\n\n\n\nFigure 14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Duration\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Subjects\n\n\n\n\n\n\n\nFigure 15\n\n\n\n\n\n\nThere are two graphs, one that shows the cumulative proportion of durations across all simulations, and the other shows the cumulative proportion of subjects across all simulations.\n\n\n\nThere are two graphs, one that shows the distribution over time for stopping for futility and one for stopping for success.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Futility Over Time\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Success Over Time\n\n\n\n\n\n\n\nFigure 16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Futility Over Time\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Success Over Time\n\n\n\n\n\n\n\nFigure 17\n\n\n\n\n\n\nThese plots show as cumulative curves the proportion of the simulations that stopped at different time points from the start of the trial. The user can select whether time or subject enrollment is used as the x-axis.\n\n\n\nIf the design has used arm dropping, the following graphs are available.\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 18: Response and Proportion Arm Dropped\n\n\n\n\n\n\n\n\n\n\n\nFigure 19: Response and Proportion Arm Dropped\n\n\n\n\n\n\nThis graph shows the true (simulated) mean response and the average fitted response with 2.5% & 97.5% quantiles.\nThe histogram bars show for each arm the proportion of simulations for which the arm was dropped.\n\n\n\nThis graph shows, for each arm, the cumulative proportion of simulations when it was dropped. The user can select whether time or number of subjects allocated to the arm is used as the x-axis.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 20: Cumulative Proportion of Trials where Arm Dropped\n\n\n\n\n\n\n\n\n\n\n\nFigure 21: Cumulative Proportion of Trials where Arm Dropped\n\n\n\n\n\n\n\n\n\nThis graph shows, for each arm, the cumulative proportion of simulations when the arm was retained. The user can select whether time or number of subjects allocated to the arm is used as the x-axis. This is simply the inverse of the arm dropping graph above.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 22: Cumulative Proportion of Trials where Arm Retained\n\n\n\n\n\n\n\n\n\n\n\nFigure 23: Cumulative Proportion of Trials where Arm Retained\n\n\n\n\n\n\n\n\n\nThis graph shows, for each arm, the simple proportion of simulations where the arm was retained.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 24: Arm Retention Proportion\n\n\n\n\n\n\n\n\n\n\n\nFigure 25: Arm Retention Proportion\n\n\n\n\n\n\n\n\n\n\nThese graphs are available if frequentist analysis is enabled.\n\n\nThese graphs are the box and whisker plots of various p-values that are automatically calculated (that is to say they do not need to be defined as QOIs for them to be calculated) for the final analysis. The user can select from Unadjusted, Bonferroni and Dunnett's and LOCF, BOCF (if baseline is simulated) or PP (per-protocol) treatment of missing values.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 26: Distribution of P(LOCF. Bonferroni Adjusted Significance) Across Simulations\n\n\n\n\n\n\n\n\n\n\n\nFigure 27: Distribution of P(LOCF. Unadjusted Adjusted Significance) Across Simulations\n\n\n\n\n\n\n\n\n\nThis graph plots the mean and 2.5-97.5 percentile of the mean across the simulations or the simple frequentist estimate of the response for each arm, along with a histogram plot of the ppn of times the response on each arm was significant. The user can select from Unadjusted, Bonferroni or Dunnett’s and LOCF, BOCF (if baseline is simulated) or PP (per-protocol) treatment of missing values.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 28: Response and Ppn LOCF. Bonferroni Significance\n\n\n\n\n\n\n\n\n\n\n\nFigure 29: Response and Ppn Fail. Dunnett Significance\n\n\n\n\n\n\n\n\n\n\nThis graph shows the final analysis at the end of individual simulations.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 30: Response and Subject Allocation\n\n\n\n\n\n\n\n\n\n\n\nFigure 31: Response and Subject Allocation\n\n\n\n\n\n\nThis graph includes a control that allows the user to select which simulation to graph the results from. On each graph\n\nThe black line shows the ‘True’ mean response being simulated.\nThe brown circles and arms show the mean raw data and its 95% CI for each arm.\nThe green solid line shows the estimate of the mean response.\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of the response.\nBlue bars showing the number of subjects allocated on each treatment arm.\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 32: Response and Subject Allocation with the side panel that allows for specification of the simulation for which the plot should be shown.\n\n\n\n\n\n\n\n\n\n\n\nFigure 33: Response and Subject Allocation with the side panel that allows for specification of the simulation for which the plot should be shown.\n\n\n\n\n\n\nControl to select the individual simulation results to be displayed\n\n\n\nThis graph shows the final analysis at the end of individual simulations, including the distribution of a selected QOI.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 34: Response and Pr(MED relative to Control: Delta = 0.1) Probability\n\n\n\n\n\n\n\n\n\n\n\nFigure 35: Response and Pr(EDq relative to Control: Quantile = 0.9) Probability\n\n\n\n\n\n\nThis graph includes a control that allows the user to select which simulation to graph the results from. On each graph\n\nThe black line shows the ‘True’ mean response being simulated.\nThe brown circles and arms show the mean raw data and its 95% CI for each arm.\nThe green solid line shows the estimate of the mean response.\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of the response.\nBrown bars showing the final value of the selected QOI for each arm at the end of the simulated trial.\n\nThe user can select from any of the Posterior Probability, Predictive Probability or Target Probability QOIs to plot.\n\n\n\nThis is an identical set of graphs to the Per Sim graphs, the difference is that in addition to a control to select which simulation to graph the results from, there is a control to select which interim within the simulation to graph the results from. These graphs are only available for those simulations for which ‘weeks’ files have been output (by default the first 100).\nNote the ‘Interim’ control in both of the below figures.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 36: Response and Pr(MED relative to Control: Delta = 0.1) Probability with side panel allowing for selection of simulation, interim, and quantity of interest.\n\n\n\n\n\n\n\n\n\n\n\nFigure 37: Response and Subject Allocation with side panel allowing for selection of simulation and interim number.\n\n\n\n\n\n\n\n\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Satisfying Final Futility Criteria by Threshold\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Satisfying Final Success Criteria by Threshold\n\n\n\n\n\n\n\nFigure 38\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Satisfying Final Futility Criteria by Threshold\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Satisfying Final Success Criteria by Threshold\n\n\n\n\n\n\n\nFigure 39\n\n\n\n\n\n\nThese graphs can be used to explore what proportion of simulated trials of a particular scenario would have been a success/failure at final evaluation. Using the two drop down controls the user can select the target dose to use: e.g. Pr(Max), and set and lower/upper limits to explore for the threshold (setting the range used on the x-axis). The graphs show for all the decision QOIs defined for the selected Target Dose the proportion of simulations that would have met the threshold values.\nAs in the examples above, the plots will be somewhat jagged if only a small number of simulations have been run. These graphs can be used to select thresholds that can be expected to yield a certain level of type-1 or power, but the user must remember these will only be approximate (depending on the number of simulations) but can be useful to understand the designs sensitivity to the thresholds and to set initial thresholds early on in the design / simulation process that will get close to the desired type-1 error and power from the outset.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Simulations Satisfying Futility Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Simulations Satisfying Success Criterion by Interim\n\n\n\n\n\n\n\nFigure 40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Simulations Satisfying Futility Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Simulations Satisfying Success Criterion by Interim\n\n\n\n\n\n\n\nFigure 41\n\n\n\n\n\n\nThese graphs can be used to explore what proportion of simulated trials of a particular scenario would have stopped early for success/futility. NOTE these graphs require weeks files to have been output, they are also most use where the design has been simulated with interims but no early stopping (unlike the examples above where the shape of the “existing stopping rules” line indicates that early stopping occurred in these simulations).\nUsing the two drop down controls, the user can select which decision QOI is evaluated and from which interim onwards stopping will be permitted. Lines are then displayed for the proportion of simulations that would have stopped by each interim for a fixed set of thresholds.\nTypically these can be used to see at what threshold (and starting at what interim) stopping for success or futility introduces an unacceptably level of ‘incorrect’ early stopping – stopping for futility in successful scenarios and stopping for success in futile scenarios and whether at below/above these levels there may be a useful probability of correct stopping.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 42: Cumulative Proportion of Simulations Where Selected Arm Satisfies Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\nFigure 43: Cumulative Proportion of Simulations Where Selected Arm Satisfies Criterion by Interim\n\n\n\n\n\n\nThis graph is similar to the Explore Early Success/Futility Criteria graph but for arm dropping criteria. The user has an additional control to select which dose the proportion of trials in which the arm would be dropped is displayed.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Reaching Futility for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Reaching Success for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\nFigure 44\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Reaching Futility for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Reaching Success for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\nFigure 45\n\n\n\n\n\n\nThese graphs allow early stopping and final evaluation criteria to be considered jointly. Like the explore early stopping criteria plots, these graphs require weeks files to have been output and will work best if interims were evaluated but no trials actually stopped early.\nThe user selects the decision QOI to plot, the first interim at which early stopping is allowed, and the upper/lower limit of the threshold to consider.\nFACTS will then plot contours where (final evaluation threshold, early stopping threshold) yield the same proportion of trials that are successful/futile. Contours are only plotted where final evaluation threshold &lt; early stopping threshold for success and vice versa for futility. Early stopping criteria should not be less strict than final criteria.\nAgain the example graphs shown are based on only 100 simulations with weeks files, so any threshold derived will only very approximately yield these success/futility rates.\n\n\n\n\n\nDichotomous\n\n\n\n\n\n\n\n\nFigure 46: Trace plot of an MCMC parameter.\n\n\n\n\n\n\nIf an MCMC sample file has been output for one or more simulations (the default is to not output MCMC sample files due to their size), then for each of those simulations it is possible to view the MCMC trace of the sampled values for each of the parameters sampled in the MCMC.\nIf the design is adaptive, the user can select which interim (“update”) the samples are from, as well as which parameter’s samples to plot.\n\n\n\n\n\nThis graph shows a bar chart for each scenario and variant selected. Each chart shows how often each arm was ‘selected’ by the target QOI specified on the Study &gt; Variants tab. Each bar uses a stacked bar to show the proportion of times that arm was:\n\n“Successful” –the arm was correctly selected (marked as “Should succeed” on the VSR tab) and the trial was successful.\n“Should not succeed” – the arm was incorrectly selected (not marked as “Should succeed” on the VSR tab) and the trial was successful.\nUnsuccessful – the arm was selected and the trial failed.\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 47: Across scenario graph for selected arms with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 48: Across scenario graph for selected arms with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a box and whisker plot for each scenario and variant selected. Each plot shows the distribution of the values of a selected QOI for each arm. There is a drop down control to allow the selection of the QOI to be displayed. Any Posterior probability, Predictive probability, p-value or target QOI can be selected.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 49: Across scenario graph for showing QOIs per arm with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 50: Across scenario graph for showing QOIs per arm with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis grouped bar chart shows a bar for the proportion of successful simulations for each variant, grouped by scenario.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 51: Across scenario graph for showing the proportion of trials that result in success with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 52: Across scenario graph for showing the proportion of trials that result in success with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a dose response plot for each scenario and variant selected. Each plot shows the mean estimate over the simulations and the 95%-ile interval of the mean estimates over the simulations. The graph also shoes the “true response” i.e. the mean response being simulated.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 53: Across scenario graph for showing the average estimated dose response model vs. the true dose responses with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 54: Across scenario graph for showing the average estimated dose response model vs. the true dose responses with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a box and whisker plot for each scenario and variant selected. Each plot shows the distribution of the number of subjects allocated to each arm over the simulations.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 55: Across scenario graph for showing the distribution of allocation per arm with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 56: Across scenario graph for showing the distribution of allocation per arm with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows the mean sample size for each scenario at different maximum sample sizes (the different variants).\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 57: Across scenario graph for showing the mean sample size of the study with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 58: Across scenario graph for showing the mean sample size of the study with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis is an interactive plot that shows the outcome of each simulation over all the scenarios of a selected variant.\nThe x-axis shows the value of the selected decision QOI at the specified interim, and the y-axis shows the final value of a (possibly different) selected decision QOI. As well as selecting a decision QOI for the final decision, the graph can use the actual final decision in the simulations – the value of the QOI used in the first criteria is used for the decision is used for the y-axis.\nNote the graph is based just on the values at the selected interim, what might happen at other interims is ignored.\nThresholds can be set to specify early and late success/futility. Each scenario is then coloured to show its outcome – and stacked bar graphs are displayed to show the proportion of each outcome for each scenario. The thresholds can be changed and the graph re-drawn. If the selected QOI uses a p-value the checks for success are that it is “&lt;” than the threshold, (and vice-versa for futility), otherwise the checks for success are that it is “&gt;” the threshold (and vice-versa for futility).\nThe graph can only display the results for simulations for which cohorts files have been output, and for simulations that reached the specified interim. Thus the graph works best if interims have been specified, but the simulations run without any early stopping enabled – so each simulation has the results for every interim.\nWith 1,000 simulations per scenario and cohorts files for each simulation, the graph will take several seconds to re-draw. To allow several parameters to be set before redrawing (rather than having to wait for the redraw after each change) the graph is only redrawn after the ‘Redraw’ button is clicked.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 59: Across scenario graph showing an interim QOI plotted against a final analysis QOI with the decision dictating the point color. Additionally, the bars on the right hand side represent the proportion of trials that made each decision based on the decision rules specified in the plot controls.\n\n\n\n\n\n\n\n\n\n\n\nFigure 60: Across scenario graph showing an interim QOI plotted against a final analysis QOI with the decision dictating the point color. Additionally, the bars on the right hand side represent the proportion of trials that made each decision based on the decision rules specified in the plot controls.\n\n\n\n\n\n\n\n\n\nThis graph plots the relative proportion of successful simulations in the scenarios compared to the proportion of successes in one specific scenario. The intended use of this is to yield a “Receiver Operating Characteristics” (ROC) curve. This is done as follows:\n\nSelect the decision QoI that is to be used to determine final success/futility. (The graph only supports the simple case where just one is being used).\nSelect a scenario that represents the ‘Null’ case – where determining success is a type-1 error.\nIf multiple variants have been simulated, select which variant to plot.\n\nFACTS computes for the null scenario, for a range of decision threshold values, what proportion of the ‘Null’ scenario sims would have been successful (giving the estimated type-1 error rate), these proportions form the x-values for each point. The corresponding threshold values are shown on the x-axis at the top of the graph, the type-1 error rate on the x-axis at the bottom of the graph.\nFACTS then computes for each of the other scenarios in turn the proportion of sims that would have been successful and selected a “should succeed” dose so it is necessary for doses to have been specified as “should succeed” on the Virtual Subject Response profiles (giving the estimate of power for that scenario – where ‘power’ also requires correct dose selection), at each of the threshold values, these proportions are then shown on the y-axis of the graph.\nThus for each scenario we can see the estimated power of the design to determine success for a given type-1 error rate in the specified Null scenario.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 61: Across scenario graph showing ROC curves of the power of one selected design variant under different scenarios as a function of the type I error in the selected null scenario.\n\n\n\n\n\n\n\n\n\n\n\nFigure 62: Across scenario graph showing ROC curves of the power of one selected design variant under different scenarios as a function of the type I error in the selected null scenario.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#per-scenario-graphs",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#per-scenario-graphs",
    "title": "Continuous and Dichotomous Output",
    "section": "",
    "text": "ContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 4: Distribution of Subject Allocation Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Distribution of Subject Allocation Across Simulations.\n\n\n\n\n\n\nThis graph displays a box and whisker plot of the number of subjects recruited into each arm. These plots show:\nThe distribution over all simulations of the number of subjects allocated to each arm shown as a box and whisker plot. If the design is not adaptive, the number allocated will be the same in every simulation and the box and whiskers collapse to a single line.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 6: Response and Subject Allocation.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Response and Subject Allocation.\n\n\n\n\n\n\nThis graph shows for each treatment arm, the mean subject allocation, mean response and the 2.5%-97.5% boundaries of the estimated means over the simulations.\n\nThe blue bars show the mean number of subjects allocated.\nThe black line shows the true mean response being simulated.\nThe green dashed line shows the mean of the estimated response across the simulations\nThe green ‘error bars’ show the spread of the central 95% of the estimated mean response across the simulations (if less than 20 simulations have been run it simply shows the full spread).\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 8: Response and QOI Selection.\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Response and QOI Selection.\n\n\n\n\n\n\nThese plots show the true simulated mean response and the mean and 95% spread of the mean fitted mean responses along with bars showing the proportion of simulations the different treatment arms are the selected target arm for each of the “Probability of being target” QOIs, such as Pr(Max), Pr(EDq relative to ..: Quantile=q) and Pr(MED relative to…: Delta=\\(\\delta\\)).\n\n\n\nThis set of graphs show the distribution over the simulations of the posterior probability estimates of quantities of interest for each dose. All the Posterior Probability, Predictive Probability, P-value and Probability of being Target QOIs that have been defined are available for plotting, via a drop down list.\nNote that in any one analysis the Probability of being Target will sum to 1 across the doses (and can sum to less than one in the case of the MED target if none of the doses look likely to be better than the CSD), whereas all the other QOIs are assessed individually for each dose.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Distribution of \\(P\\)(\\(\\theta_d\\) - \\(\\theta_{Control}\\) &gt; 0.1) Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribution of \\(P\\)(MED relative to Control: Delta}=0.1) Across Simulations.\n\n\n\n\n\n\n\nFigure 10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Distribution of \\(P\\)(\\(P_d\\) - \\(P_{Control}\\) &gt; 0.15) Across Simulations.\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribution of \\(P\\)(MED relative to Control: Delta}=0.2) Across Simulations.\n\n\n\n\n\n\n\nFigure 11\n\n\n\n\n\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 12: Posterior Mean Response at P(MED relative to Control: Delta}=0.1) vs. Total Sample Size per Simulation Run\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Posterior Mean Response at P(MED relative to Control: Delta}=0.2) vs. Total Sample Size per Simulation Run\n\n\n\n\n\n\nThis graph shows a scatter plot of trial outcomes with the selected Target QOI as the y-axis and total number of subjects recruited as the x-axis. The trials are plotted with a symbol that indicated the final outcome:\n\nA light blue circle indicates a trial that stopped early for success\nA dark blue circle indicates a trial that was a late success\nA dark red square indicates a trial that was a late futility\nA light red square indicates a trial that stopped early for futility\nA light pink diamond indicates a trial that stopped early for success but where the final analysis was futility\nA dark pink diamond indicates a trial that stopped early for futility but where the final analysis was success\nA yellow cross indicates a trial that completed full enrolment but was inconclusive at the end.\n\nThese graphs are not particularly useful if there is no early stopping.\nIf the design does allow early stopping this graph shows\n\nThe overall distribution of sample sizes – in particular is stopping evenly distributed from the moment stopping is possible, or is there are large cohort of trials that stop as soon as it is possible?\nWhen and with what mean response trials stop incorrectly, in particular having trials stopping and the decision being reversed suggests stopping is allowed to soon or the criteria is not conservative enough.\n\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Duration\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Subjects\n\n\n\n\n\n\n\nFigure 14\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Duration\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Subjects\n\n\n\n\n\n\n\nFigure 15\n\n\n\n\n\n\nThere are two graphs, one that shows the cumulative proportion of durations across all simulations, and the other shows the cumulative proportion of subjects across all simulations.\n\n\n\nThere are two graphs, one that shows the distribution over time for stopping for futility and one for stopping for success.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Futility Over Time\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Success Over Time\n\n\n\n\n\n\n\nFigure 16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Futility Over Time\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Success Over Time\n\n\n\n\n\n\n\nFigure 17\n\n\n\n\n\n\nThese plots show as cumulative curves the proportion of the simulations that stopped at different time points from the start of the trial. The user can select whether time or subject enrollment is used as the x-axis.\n\n\n\nIf the design has used arm dropping, the following graphs are available.\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 18: Response and Proportion Arm Dropped\n\n\n\n\n\n\n\n\n\n\n\nFigure 19: Response and Proportion Arm Dropped\n\n\n\n\n\n\nThis graph shows the true (simulated) mean response and the average fitted response with 2.5% & 97.5% quantiles.\nThe histogram bars show for each arm the proportion of simulations for which the arm was dropped.\n\n\n\nThis graph shows, for each arm, the cumulative proportion of simulations when it was dropped. The user can select whether time or number of subjects allocated to the arm is used as the x-axis.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 20: Cumulative Proportion of Trials where Arm Dropped\n\n\n\n\n\n\n\n\n\n\n\nFigure 21: Cumulative Proportion of Trials where Arm Dropped\n\n\n\n\n\n\n\n\n\nThis graph shows, for each arm, the cumulative proportion of simulations when the arm was retained. The user can select whether time or number of subjects allocated to the arm is used as the x-axis. This is simply the inverse of the arm dropping graph above.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 22: Cumulative Proportion of Trials where Arm Retained\n\n\n\n\n\n\n\n\n\n\n\nFigure 23: Cumulative Proportion of Trials where Arm Retained\n\n\n\n\n\n\n\n\n\nThis graph shows, for each arm, the simple proportion of simulations where the arm was retained.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 24: Arm Retention Proportion\n\n\n\n\n\n\n\n\n\n\n\nFigure 25: Arm Retention Proportion\n\n\n\n\n\n\n\n\n\n\nThese graphs are available if frequentist analysis is enabled.\n\n\nThese graphs are the box and whisker plots of various p-values that are automatically calculated (that is to say they do not need to be defined as QOIs for them to be calculated) for the final analysis. The user can select from Unadjusted, Bonferroni and Dunnett's and LOCF, BOCF (if baseline is simulated) or PP (per-protocol) treatment of missing values.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 26: Distribution of P(LOCF. Bonferroni Adjusted Significance) Across Simulations\n\n\n\n\n\n\n\n\n\n\n\nFigure 27: Distribution of P(LOCF. Unadjusted Adjusted Significance) Across Simulations\n\n\n\n\n\n\n\n\n\nThis graph plots the mean and 2.5-97.5 percentile of the mean across the simulations or the simple frequentist estimate of the response for each arm, along with a histogram plot of the ppn of times the response on each arm was significant. The user can select from Unadjusted, Bonferroni or Dunnett’s and LOCF, BOCF (if baseline is simulated) or PP (per-protocol) treatment of missing values.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 28: Response and Ppn LOCF. Bonferroni Significance\n\n\n\n\n\n\n\n\n\n\n\nFigure 29: Response and Ppn Fail. Dunnett Significance\n\n\n\n\n\n\n\n\n\n\nThis graph shows the final analysis at the end of individual simulations.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 30: Response and Subject Allocation\n\n\n\n\n\n\n\n\n\n\n\nFigure 31: Response and Subject Allocation\n\n\n\n\n\n\nThis graph includes a control that allows the user to select which simulation to graph the results from. On each graph\n\nThe black line shows the ‘True’ mean response being simulated.\nThe brown circles and arms show the mean raw data and its 95% CI for each arm.\nThe green solid line shows the estimate of the mean response.\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of the response.\nBlue bars showing the number of subjects allocated on each treatment arm.\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 32: Response and Subject Allocation with the side panel that allows for specification of the simulation for which the plot should be shown.\n\n\n\n\n\n\n\n\n\n\n\nFigure 33: Response and Subject Allocation with the side panel that allows for specification of the simulation for which the plot should be shown.\n\n\n\n\n\n\nControl to select the individual simulation results to be displayed\n\n\n\nThis graph shows the final analysis at the end of individual simulations, including the distribution of a selected QOI.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 34: Response and Pr(MED relative to Control: Delta = 0.1) Probability\n\n\n\n\n\n\n\n\n\n\n\nFigure 35: Response and Pr(EDq relative to Control: Quantile = 0.9) Probability\n\n\n\n\n\n\nThis graph includes a control that allows the user to select which simulation to graph the results from. On each graph\n\nThe black line shows the ‘True’ mean response being simulated.\nThe brown circles and arms show the mean raw data and its 95% CI for each arm.\nThe green solid line shows the estimate of the mean response.\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of the response.\nBrown bars showing the final value of the selected QOI for each arm at the end of the simulated trial.\n\nThe user can select from any of the Posterior Probability, Predictive Probability or Target Probability QOIs to plot.\n\n\n\nThis is an identical set of graphs to the Per Sim graphs, the difference is that in addition to a control to select which simulation to graph the results from, there is a control to select which interim within the simulation to graph the results from. These graphs are only available for those simulations for which ‘weeks’ files have been output (by default the first 100).\nNote the ‘Interim’ control in both of the below figures.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 36: Response and Pr(MED relative to Control: Delta = 0.1) Probability with side panel allowing for selection of simulation, interim, and quantity of interest.\n\n\n\n\n\n\n\n\n\n\n\nFigure 37: Response and Subject Allocation with side panel allowing for selection of simulation and interim number.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#post-simulation-boundary-finding-graphs",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#post-simulation-boundary-finding-graphs",
    "title": "Continuous and Dichotomous Output",
    "section": "",
    "text": "ContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Satisfying Final Futility Criteria by Threshold\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Satisfying Final Success Criteria by Threshold\n\n\n\n\n\n\n\nFigure 38\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Satisfying Final Futility Criteria by Threshold\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Satisfying Final Success Criteria by Threshold\n\n\n\n\n\n\n\nFigure 39\n\n\n\n\n\n\nThese graphs can be used to explore what proportion of simulated trials of a particular scenario would have been a success/failure at final evaluation. Using the two drop down controls the user can select the target dose to use: e.g. Pr(Max), and set and lower/upper limits to explore for the threshold (setting the range used on the x-axis). The graphs show for all the decision QOIs defined for the selected Target Dose the proportion of simulations that would have met the threshold values.\nAs in the examples above, the plots will be somewhat jagged if only a small number of simulations have been run. These graphs can be used to select thresholds that can be expected to yield a certain level of type-1 or power, but the user must remember these will only be approximate (depending on the number of simulations) but can be useful to understand the designs sensitivity to the thresholds and to set initial thresholds early on in the design / simulation process that will get close to the desired type-1 error and power from the outset.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Simulations Satisfying Futility Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Simulations Satisfying Success Criterion by Interim\n\n\n\n\n\n\n\nFigure 40\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Cumulative Proportion of Simulations Satisfying Futility Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\n(b) Cumulative Proportion of Simulations Satisfying Success Criterion by Interim\n\n\n\n\n\n\n\nFigure 41\n\n\n\n\n\n\nThese graphs can be used to explore what proportion of simulated trials of a particular scenario would have stopped early for success/futility. NOTE these graphs require weeks files to have been output, they are also most use where the design has been simulated with interims but no early stopping (unlike the examples above where the shape of the “existing stopping rules” line indicates that early stopping occurred in these simulations).\nUsing the two drop down controls, the user can select which decision QOI is evaluated and from which interim onwards stopping will be permitted. Lines are then displayed for the proportion of simulations that would have stopped by each interim for a fixed set of thresholds.\nTypically these can be used to see at what threshold (and starting at what interim) stopping for success or futility introduces an unacceptably level of ‘incorrect’ early stopping – stopping for futility in successful scenarios and stopping for success in futile scenarios and whether at below/above these levels there may be a useful probability of correct stopping.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 42: Cumulative Proportion of Simulations Where Selected Arm Satisfies Criterion by Interim\n\n\n\n\n\n\n\n\n\n\n\nFigure 43: Cumulative Proportion of Simulations Where Selected Arm Satisfies Criterion by Interim\n\n\n\n\n\n\nThis graph is similar to the Explore Early Success/Futility Criteria graph but for arm dropping criteria. The user has an additional control to select which dose the proportion of trials in which the arm would be dropped is displayed.\n\n\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Reaching Futility for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Reaching Success for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\nFigure 44\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Proportion of Simulations Reaching Futility for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\n\n\n\n\n(b) Proportion of Simulations Reaching Success for Early/Late Criterion Thresholds\n\n\n\n\n\n\n\nFigure 45\n\n\n\n\n\n\nThese graphs allow early stopping and final evaluation criteria to be considered jointly. Like the explore early stopping criteria plots, these graphs require weeks files to have been output and will work best if interims were evaluated but no trials actually stopped early.\nThe user selects the decision QOI to plot, the first interim at which early stopping is allowed, and the upper/lower limit of the threshold to consider.\nFACTS will then plot contours where (final evaluation threshold, early stopping threshold) yield the same proportion of trials that are successful/futile. Contours are only plotted where final evaluation threshold &lt; early stopping threshold for success and vice versa for futility. Early stopping criteria should not be less strict than final criteria.\nAgain the example graphs shown are based on only 100 simulations with weeks files, so any threshold derived will only very approximately yield these success/futility rates.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#mcmc-trace-plots",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#mcmc-trace-plots",
    "title": "Continuous and Dichotomous Output",
    "section": "",
    "text": "Dichotomous\n\n\n\n\n\n\n\n\nFigure 46: Trace plot of an MCMC parameter.\n\n\n\n\n\n\nIf an MCMC sample file has been output for one or more simulations (the default is to not output MCMC sample files due to their size), then for each of those simulations it is possible to view the MCMC trace of the sampled values for each of the parameters sampled in the MCMC.\nIf the design is adaptive, the user can select which interim (“update”) the samples are from, as well as which parameter’s samples to plot.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#across-scenario-graphs",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#across-scenario-graphs",
    "title": "Continuous and Dichotomous Output",
    "section": "",
    "text": "This graph shows a bar chart for each scenario and variant selected. Each chart shows how often each arm was ‘selected’ by the target QOI specified on the Study &gt; Variants tab. Each bar uses a stacked bar to show the proportion of times that arm was:\n\n“Successful” –the arm was correctly selected (marked as “Should succeed” on the VSR tab) and the trial was successful.\n“Should not succeed” – the arm was incorrectly selected (not marked as “Should succeed” on the VSR tab) and the trial was successful.\nUnsuccessful – the arm was selected and the trial failed.\n\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 47: Across scenario graph for selected arms with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 48: Across scenario graph for selected arms with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a box and whisker plot for each scenario and variant selected. Each plot shows the distribution of the values of a selected QOI for each arm. There is a drop down control to allow the selection of the QOI to be displayed. Any Posterior probability, Predictive probability, p-value or target QOI can be selected.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 49: Across scenario graph for showing QOIs per arm with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 50: Across scenario graph for showing QOIs per arm with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis grouped bar chart shows a bar for the proportion of successful simulations for each variant, grouped by scenario.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 51: Across scenario graph for showing the proportion of trials that result in success with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 52: Across scenario graph for showing the proportion of trials that result in success with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a dose response plot for each scenario and variant selected. Each plot shows the mean estimate over the simulations and the 95%-ile interval of the mean estimates over the simulations. The graph also shoes the “true response” i.e. the mean response being simulated.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 53: Across scenario graph for showing the average estimated dose response model vs. the true dose responses with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 54: Across scenario graph for showing the average estimated dose response model vs. the true dose responses with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows a box and whisker plot for each scenario and variant selected. Each plot shows the distribution of the number of subjects allocated to each arm over the simulations.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 55: Across scenario graph for showing the distribution of allocation per arm with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 56: Across scenario graph for showing the distribution of allocation per arm with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis graph shows the mean sample size for each scenario at different maximum sample sizes (the different variants).\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 57: Across scenario graph for showing the mean sample size of the study with 5 scenarios and 5 design variants.\n\n\n\n\n\n\n\n\n\n\n\nFigure 58: Across scenario graph for showing the mean sample size of the study with 3 scenarios and 3 design variants.\n\n\n\n\n\n\n\n\n\nThis is an interactive plot that shows the outcome of each simulation over all the scenarios of a selected variant.\nThe x-axis shows the value of the selected decision QOI at the specified interim, and the y-axis shows the final value of a (possibly different) selected decision QOI. As well as selecting a decision QOI for the final decision, the graph can use the actual final decision in the simulations – the value of the QOI used in the first criteria is used for the decision is used for the y-axis.\nNote the graph is based just on the values at the selected interim, what might happen at other interims is ignored.\nThresholds can be set to specify early and late success/futility. Each scenario is then coloured to show its outcome – and stacked bar graphs are displayed to show the proportion of each outcome for each scenario. The thresholds can be changed and the graph re-drawn. If the selected QOI uses a p-value the checks for success are that it is “&lt;” than the threshold, (and vice-versa for futility), otherwise the checks for success are that it is “&gt;” the threshold (and vice-versa for futility).\nThe graph can only display the results for simulations for which cohorts files have been output, and for simulations that reached the specified interim. Thus the graph works best if interims have been specified, but the simulations run without any early stopping enabled – so each simulation has the results for every interim.\nWith 1,000 simulations per scenario and cohorts files for each simulation, the graph will take several seconds to re-draw. To allow several parameters to be set before redrawing (rather than having to wait for the redraw after each change) the graph is only redrawn after the ‘Redraw’ button is clicked.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 59: Across scenario graph showing an interim QOI plotted against a final analysis QOI with the decision dictating the point color. Additionally, the bars on the right hand side represent the proportion of trials that made each decision based on the decision rules specified in the plot controls.\n\n\n\n\n\n\n\n\n\n\n\nFigure 60: Across scenario graph showing an interim QOI plotted against a final analysis QOI with the decision dictating the point color. Additionally, the bars on the right hand side represent the proportion of trials that made each decision based on the decision rules specified in the plot controls.\n\n\n\n\n\n\n\n\n\nThis graph plots the relative proportion of successful simulations in the scenarios compared to the proportion of successes in one specific scenario. The intended use of this is to yield a “Receiver Operating Characteristics” (ROC) curve. This is done as follows:\n\nSelect the decision QoI that is to be used to determine final success/futility. (The graph only supports the simple case where just one is being used).\nSelect a scenario that represents the ‘Null’ case – where determining success is a type-1 error.\nIf multiple variants have been simulated, select which variant to plot.\n\nFACTS computes for the null scenario, for a range of decision threshold values, what proportion of the ‘Null’ scenario sims would have been successful (giving the estimated type-1 error rate), these proportions form the x-values for each point. The corresponding threshold values are shown on the x-axis at the top of the graph, the type-1 error rate on the x-axis at the bottom of the graph.\nFACTS then computes for each of the other scenarios in turn the proportion of sims that would have been successful and selected a “should succeed” dose so it is necessary for doses to have been specified as “should succeed” on the Virtual Subject Response profiles (giving the estimate of power for that scenario – where ‘power’ also requires correct dose selection), at each of the threshold values, these proportions are then shown on the y-axis of the graph.\nThus for each scenario we can see the estimated power of the design to determine success for a given type-1 error rate in the specified Null scenario.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\nFigure 61: Across scenario graph showing ROC curves of the power of one selected design variant under different scenarios as a function of the type I error in the selected null scenario.\n\n\n\n\n\n\n\n\n\n\n\nFigure 62: Across scenario graph showing ROC curves of the power of one selected design variant under different scenarios as a function of the type I error in the selected null scenario.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#summary-per-scenario",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#summary-per-scenario",
    "title": "Continuous and Dichotomous Output",
    "section": "Summary per Scenario",
    "text": "Summary per Scenario\nBy default, only a subset of all columns of output are provided when simulations are complete. This set of columns is called “Highlights.” To get access to further columns, you can right click anywhere on the simulation output table and click “Summary Results: ….” for whichever set of columns you would like to see. There is a “Summary Results: All” option that will provide a pop up containing every column available for summary results.\nThe following sections break down which columns are available by sorting to which column subset.\n\nHighlights\nThese are the columns displayed on the simulations tab after simulations are completed, the can also be displayed in the separate “Highlights” results window.\n\nThe columns that are displayed by default in the simulations tab after continuous or dichotomous simulations have been run.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nSelect\n1\nNot an output column, this column contains check box to allow the user to select which scenario to simulate. The ‘Select All’ button causes them all to be checked.\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response’,\n’Virtual Subject Response &gt; Explicitly Defined &gt; Control Hazard rates,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Predictor’,\nThis is the same name as used for the results directory\n\n\nRandom Number Seed\n1\nBase random number seed used to perform the simulations.\n\n\nNum Sims\n1\nThe number of simulations that were run to produce the displayed results.\n\n\nMean Subj.\n1\nThis is the mean (over the simulations) of the number of subjects recruited in this scenario.\n\n\nPpn Overall Success\n1\nThis is the proportion of simulations that stopped for success, either early success or late success (as defined below).\n\n\nPpn Early Success\n1\nThis is the proportion of simulations that stopped early for success (and did not regress to futility in the final analysis – though they might have regressed to ‘inconclusive’).\n\n\nPpn Late Success\n1\nThis is the proportion of simulations that did not stop early but were successful in the final analysis.\n\n\nPpn Overall Futility\n1\nThis is the proportion of simulations that stopped for futility, either early futility or late futility (as defined below).\n\n\nPpn Late Futility\n1\nThis is the proportion of simulations that did not stop early but were futile in the final analysis.\n\n\nPpn Early Futility\n1\nThis is the proportion of simulations that stopped early for futility (and did not regress to success in the final analysis – though they might have regressed to ‘inconclusive’).\n\n\nPpn S uc-&gt;Fut Flipflop\n1\nThis is the proportion of simulations that stopped early for success but regressed to futility in the final analysis.\n\n\nPpn F ut-&gt;Suc Flipflop\n1\nThis is the proportion of simulations that stopped early for futility but regressed to success in the final analysis.\n\n\nPpn Inco nclusive\n1\nThis is the proportion of simulations that did not stop early and were neither successful nor futile in the final analysis.\n\n\nEarly Success Time\n1\nThis is the average time to an early decision to stop for success (i.e. the time excluding final follow up) over those simulations that did decide early to stop for success.\n\n\nMean Trt. &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the hazard ratio of the treatment arms to control. The HZ for the control arm is always 1.\n\n\nMean Duration\n1\nThe mean over the simulations of the total duration from the start of enrolment to end of follow up.\n\n\nPPn Arms Drop: &lt; Dose&gt;&gt;\nOne per arm\nThis is the number of times (over the simulations) that each arm was dropped.\n\n\nMean LP Enrolled\n1\nThis is the mean, in weeks (over the simulations) of the duration of the trial from first patient first visit to Last Patient First Visit (i.e. the duration of accrual).\n\n\nPpn Correct Arm\n1\nThe proportion of simulations that met the success criteria and selected (by the target QOI specified on the Study &gt; Variant tab) one of the arms marked as “should succeed” on the Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response tab\n\n\nPpn I ncorrect Arm\n1\nThe proportion of simulations that met the success criteria and selected (by the target QOI specified on the Study &gt; Variant tab) one of the arms not marked as “should succeed” on the Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response tab\n\n\nVersion\n1\nThe FACTS version number at the time the simulations were run.\n\n\n\n\n\nAllocation\nBy right clicking and selecting the allocation columns, a pop-out will appear that provides the following columns.\n\nThe allocation columns provided in FACTS output for continuous or dichotomous trials.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response’,\n’Virtual Subject Response &gt; Explicitly Defined &gt; Control Hazard rates,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Predictor’,\nThis is the same name as used for the results directory\n\n\nMean Subj.\n1\nThis is the mean (over the simulations) of the number of subjects recruited in this scenario.\n\n\nSD Mean Subj.\n1\nThis is the standard deviation across the simulations of the number of subjects recruited.\n\n\n80%-ile Subj\n1\nThis is the eightieth percentile across the simulations of the number of subjects recruited into the trial.\n\n\nMean Alloc.: &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the number of subjects recruited into each arm in this scenario.\n\n\nSD Alloc.: &lt;Dose&gt;\nOne per arm\nThis is the SD of the means (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\n\n\n\nResponse\n\nContinuousDichotomous\n\n\n\nResponse columns available in FACTS output for continuous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Trt.: &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the estimate of the mean response on this dose.\n\n\nSD Trt.: &lt;Dose&gt;\nOne per arm\nThis is the standard deviation (over the simulations) of the estimate of the response on this dose.\n\n\nMean Sigma\n1\nThe mean (over the simulations) of the estimate of the SD of the dose response across all the treatment arms (‘sigma’)\n\n\nSD Mean Sigma\n1\nThe SD (over the simulations) of the estimate of the SD of the dose response across all the treatment arms.\n\n\nTrue Mean Resp: &lt;Dose&gt;\nOne per arm\nThis is the true mean response from which the simulation data was sampled for each treatment arm.\n\n\nSD True Resp.: &lt;Dose&gt;\nOne per arm\nThis is the true SD of the dose response for each treatment arm\n\n\nMean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used.\nThis is the mean (over the simulations) of the estimate of the mean response for a particular dose at a particular visit, based on the independent estimate of the dose response (omega_d), scaled by the longitudinal model's estimate of the proportion of the final effect observed at the visit.\n\n\nSD Mean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit\nThis is the SD ( over the simulations) of the longitudinal model estimate of the response at intermediate visits (see above)\n\n\nMean Baseline Beta\n\nThis is the mean (over the simulations) of the estimate of “Beta” in the Baseline Adjusted dose response model.\n\n\nSD Baseline Beta\n\nThis is the SD (over the simulations) of the estimate of “Beta” in the Baseline Adjusted dose response model.\n\n\nMean Baseline\n1\nThis is the mean (over the simulations) of the estimate of the mean baseline score.\n\n\nSD Baseline\n1\nThis is the SD (over the simulations) of the estimate of the mean baseline score.\n\n\nTrue Mean Baseline\n1\nThis is the true mean from which baseline scores where simulated (including accounting for possible truncation of the baseline scores)\n\n\nTrue SD Baseline\n1\nThis is the true SD of the distribution from which baseline scores were simulated (including accounting for possible truncation of the baseline scores)\n\n\n\n\n\n\nResponse columns available in FACTS output for dichotomous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Trt.: &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the estimate of the response on this dose.\n\n\nSD Trt.: &lt;Dose&gt;\nOne per arm\nThis is the standard deviation (over the simulations) of the estimate of the response on this dose.\n\n\nTrue Mean Resp: &lt;Dose&gt;\nOne per arm\nThis is the true response rate from which the simulation data was sampled.\n\n\n\n\n\n\n\n\nObserved\n\nObserved columns available in FACTS output for continuous or dichotomous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Complete &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the number of subjects recruited per arm which have had their endpoint observed in this scenario.\n\n\nMean Complete Info &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of information observed per arm as defined on the Interims tab (Subjects enrolled, Complete Data at Specified Visit, Opportunity to Complete at Specified Visit) in this scenario.\n\n\nMean Dropouts &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit\nThis is the mean (over the simulations) of dropouts per arm per visit in this scenario.\n\n\n\n\n\nProbabilities\n\nProbabilities columns available in FACTS output for continuous or dichotomous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\n&lt;QOI&gt; &lt;Dose&gt;\nOne per arm per QOI\nFor each Posterior Probability and Predictive Probability QOI defined on this endpoint, this is the mean over the simulations of the estimate of the probability of the QOI for each dose. (P-value QOIs are reported in the frequentist results table).\nFor each Target QOI this is the proportion of simulations where this dose was selected at the end of the trial as the dose with the greatest probability of meeting the target condition.\nThe probability that each dose is the target at the end of a simulated trial is its marginal probability (the number of times it was the dose closest to the target in the MCMC sampling of the analysis at the end of the trial). The target of having the Max response on this endpoint, or some fraction of it (EDq) is always identifiable, so the Ppn(target) for these QOIs will sum to 1 across the doses.\nAn MED target is not guaranteed to be identifiable, if no dose meets the CSD criteria in any MCMC sample so all doses have a 0 probability of having a response greater than Control (or AC) by the CSD then no dose is the MED. So the sum of each Ppn(target) QOI across the doses should sum to between 0 and 1 inclusive.\nDecision QOI’s are not reported here separately, but their component QOIs – the vector of values and target QOI used to select from them are.\n\n\n\n\n\nModel Parameters\n\nContinuousDichotomous\n\n\n\nModel Parameters columns available in FACTS output for continuous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Sigma\n1\nThis is the mean (over the simulations) of the posterior estimate of sigma, the SD in the subject’s final responses.\n\n\nSD Mean Sigma\n1\nThis is the SD (over the simulations) of the estimate of sigma.\n\n\nMean Baseline Beta\n1\nThis is the mean (over the simulations) of the estimate of the Beta parameter when Baseline Adjustment is Modeled.\n\n\nSD Baseline Beta\n1\nThis is the SD (over the simulations) of the estimate of the Beta parameter when Baseline Adjustment is Modeled.\n\n\nBAC Mean\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC Mean\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC tau\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC Mean\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC tau\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\n\n\n\n\nModel Parameters columns available in FACTS output for dichotomous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nD*V\nThese are only calculated and written out if the ITP longitudinal model is being used.\nThis is the mean (over the simulations) of the estimate of the mean response for a particular dose at a particular visit.\n\n\nSE Mean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nD*V\nThis is the standard error (over the simulations) of the longitudinal model estimate of the response at intermediate visits (see above)\n\n\nBAC Mean\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC Mean\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC tau\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC Mean\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC tau\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#detailed-per-simulation-results",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#detailed-per-simulation-results",
    "title": "Continuous and Dichotomous Output",
    "section": "Detailed Per Simulation Results",
    "text": "Detailed Per Simulation Results\nAfter simulation has completed and simulation results have been loaded, the user may examine detailed results for any scenario with simulations output in the table by double-clicking on the appropriate row. A separate window pops up and displays the results for each individual simulation. This is a “prettier” view of the contents of the “simulations.csv” file, which is described below. The simulations results are partitioned into the same results groupings as the summary results. These can be accessed from the “right click” menu, along with opening the results folder, opening the weeks file for a particular simulation and opening the simulated patients file for a particular simulation (where a “weeks” file or a “patients” file has been output).\n\n\n\n\n\n\nFigure 63: The simulation results pop out viewer showing simulation highlights.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-summary.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-summary.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of summary.csv",
    "text": "Contents of summary.csv\nThe first line is a header line, starting with a ‘#’, containing the FACTS GUI version number, the name of the FACTS file, the name of the scenario, and the time stamp of the start of the simulation.\nThe second line is a header line, starting with a ‘#’, containing the following column headings.\n\nContinuousDichotomous\n\n\n\nContents of the summary.csv file for continuous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nProject\n1\nThe name of the facts file\n\n\nScenario\n1\nThe name of the scenario\n\n\nTimestamp\n1\nThe time the simulations were run\n\n\nVersion\n1\nThe version of FACTS that was used to run the simulations\n\n\nNSim\n1\nThe number of simulation run.\n\n\nRandom Number Seed\n1\nThe random number seed\n\n\nNo. Subj\n1\nThe mean, over the simulations, of the total number of subjects recruited in the trial.\n\n\nSE Subj.\n1\nThe standard error of the total number of subjects recruited into the trials.\n\n\nNo.Subj 80%ile\n1\nThe 80th percentile, over the simulations, of the total number of subjects recruited in the trial.\n\n\nPpn Overall Success\n1\nThe proportion of simulations that were successful (P(ES) + P(LS))\n\n\nPpn Overall Futility\n1\nThe proportion of simulations that were futile (P(EF) + P(LF))\n\n\nP(ES)\n1\nThe proportion of simulations that stopped early for success.\n\n\nP(LS)\n1\nThe proportion of simulations that did not stop early, and were successful on final evaluation.\n\n\nP(LF)\n1\nThe proportion of simulations that did not stop early, and were futile on final evaluation.\n\n\nP(EF)\n1\nThe proportion of simulations that stopped early for futility.\n\n\nSFFF\n1\nThe proportion of simulations that stopped early for success, but at final analysis were futile (Success-Futility ‘flip-flops’).\n\n\nFSFF\n1\nThe proportion of simulations that stopped early for futility, but at final analysis were successful (Futility- Success ‘flip-flops’).\n\n\nUndec.\n1\nThe proportion of simulations that did not stop early, and met neither the success or futility final evaluation criteria and hence are counted as ‘undecided’.\n\n\nUnused\n3\nThree unused columns for other outcome types.\n\n\nEarly Success Time\n1\nThis is the mean early decision time (over the simulations stopped early for success), it is the time from the start of the trial to the interim where early success was declared. It does not include the subsequent follow up time.\n\n\nMean Alloc &lt;Dose&gt;\nD\nThe mean (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nSE Alloc &lt;Dose&gt;\nD\nThe standard error (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nMean Resp &lt;Dose&gt;\nD\nThe mean of the estimates of response of each treatment arm.\n\n\nSE Resp &lt;Dose&gt;\nD\nThe standard error, over the simulations, of the estimate of response of each treatment arm.\n\n\nMean Sigma\n1\nThe mean of the estimate of sigma – the average standard deviation of the dose response\n\n\nSE Mean Sigma\n1\nThe standard error of the estimate of sigma – the average standard deviation of the dose response\n\n\nTrue Mean resp &lt;Dose&gt;\nD\nThe true response for each treatment arm used when sampling the simulated subject responses.\n\n\nTrue SD resp &lt;Dose&gt;\nD\nThe true SD of the response for each treatment arm of the simulated subject responses\n\n\nMean Longmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used.\nThis is the mean (over the simulations) of the estimate of the mean response for a particular dose at a particular visit.\n\n\nSE Mean Longmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThis is the standard error (over the simulations) of the longitudinal model estimate of the response at intermediate visits (see above)\n\n\nMean Complete &lt;Dose&gt;\nD\nThe mean number of completers for each treatment arm\n\n\nMean Complete Info &lt;Dose&gt;\nD\nThe mean number of complete information (as specified by the interim information type on the Interims tab) for each treatment arm\n\n\nNo .Dropouts &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThe mean number of dropouts per treatment arm per visit\n\n\nMean Beta\n1\nThe mean of the estimates of the coefficient of baseline adjustment\n\n\nSE beta\n1\nThe standard error of the estimates of the coefficient of baseline adjustment\n\n\nMean Baseline\n1\nThe mean of the estimate of the mean of the baseline score\n\n\nSE Mean Baseline\n1\nThe standard error of the estimate of the mean of the baseline score\n\n\nSD Baseline\n1\nThe mean of the estimate of the SD of the baseline score\n\n\nSE SD Baseline\n1\nThe standard error of the estimate of the SD of the baseline score\n\n\nTrue Mean Baseline\n1\nThe true mean of the baseline score (accounting for possible truncation)\n\n\nTrue SD Baseline\n1\nThe true SD of the baseline score (accounting for possible truncation)\n\n\nBAC Mean\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Mean\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Tau\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Mean\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Tau\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nMean Duration\n1\nThe mean, over the simulations, of the overall duration of the trials, from first person first visit, to last person last visit.\n\n\nPpn Arms Dropped &lt;Dose&gt;\nD\nThe proportion of the simulations in which each arm was dropped. These will be zero if arm dropping is not selected as the means of adaptive allocation.\n\n\nMean LPFV time\n1\nThe mean, over the simulations, of the accrual period of the trials, from first person first visit, to last person first visit (LPFV).\n\n\nPpn Correct Arm\n1\nThe proportion of the simulations where the correct arm has been selected, where an arm is deemed “correct” based on whether it was marked as “Should Succeed” for the relevant scenario on the VSR tab.\n\n\nPpn Incorrect Arm\n1\nThe proportion of the simulations where the incorrect correct arm has been selected, where an arm is deemed “incorrect” based on whether it wasn’t marked as “Should Succeed” for the relevant scenario on the VSR tab.\n\n\nQOI Columns\n\nSee next section.\n\n\n\n\n\n\nContents of the summary.csv file for dichotomous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nProject\n1\nThe name of the facts file\n\n\nScenario\n1\nThe name of the scenario\n\n\nTimestamp\n1\nThe time the simulations were run\n\n\nVersion\n1\nThe version of FACTS that was used to run the simulations\n\n\nNSim\n1\nThe number of simulation run.\n\n\nRandom Number Seed\n1\nThe random number seed\n\n\nNo. Subj\n1\nThe mean, over the simulations, of the total number of subjects recruited in the trial.\n\n\nSE Subj.\n1\nThe standard error of the total number of subjects recruited into the trials.\n\n\nNo.Subj 80%ile\n1\nThe 80th percentile, over the simulations, of the total number of subjects recruited in the trial.\n\n\nPpn Overall Success\n1\nThe proportion of simulations that were successful (P(ES) + P(LS))\n\n\nPpn Overall Futility\n1\nThe proportion of simulations that were futile (P(EF) + P(LF))\n\n\nP(ES)\n1\nThe proportion of simulations that stopped early for success.\n\n\nP(LS)\n1\nThe proportion of simulations that did not stop early, and were successful on final evaluation.\n\n\nP(LF)\n1\nThe proportion of simulations that did not stop early, and were futile on final evaluation.\n\n\nP(EF)\n1\nThe proportion of simulations that stopped early for futility.\n\n\nSFFF\n1\nThe proportion of simulations that stopped early for success, but at final analysis were futile (Success-Futility ‘flip-flops’).\n\n\nFSFF\n1\nThe proportion of simulations that stopped early for futility, but at final analysis were successful (Futility- Success ‘flip-flops’).\n\n\nUndec.\n1\nThe proportion of simulations that did not stop early, and met neither the success or futility final evaluation criteria and hence are counted as ‘undecided’.\n\n\nUnused\n3\nThree unused columns for other outcome types.\n\n\nEarly Success Time\n1\nThis is the mean early decision time (over the simulations stopped early for success), it is the time from the start of the trial to the interim where early success was declared. It does not include the subsequent follow up time.\n\n\nMean Alloc &lt;Dose&gt;\nD\nThe mean (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nSE Alloc &lt;Dose&gt;\nD\nThe standard error (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nMean Resp &lt;Dose&gt;\nD\nThe mean of the estimates of response of each treatment arm.\n\n\nSE Resp &lt;Dose&gt;\nD\nThe standard error, over the simulations, of the estimate of response of each treatment arm.\n\n\nTrue Mean resp &lt;Dose&gt;\nD\nThe true response for each treatment arm used when sampling the simulated subject responses.\n\n\nMean Longmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used.\nThis is the mean (over the simulations) of the estimate of the mean response for a particular dose at a particular visit.\n\n\nSE Mean Longmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThis is the standard error (over the simulations) of the longitudinal model estimate of the response at intermediate visits (see above)\n\n\nMean Complete &lt;Dose&gt;\nD\nThe mean number of completers for each treatment arm\n\n\nMean Complete Info &lt;Dose&gt;\nD\nThe mean number of complete information (as specified by the interim information type on the Interims tab) for each treatment arm\n\n\nNo .Dropouts &lt;Dose&gt; &lt;Visit&gt;\nD*V\nThe mean number of dropouts per treatment arm per visit\n\n\nBAC Mean\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Mean\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Tau\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Mean\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Tau\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nMean Duration\n1\nThe mean, over the simulations, of the overall duration of the trials, from first person first visit, to last person last visit.\n\n\nPpn Arms Dropped &lt;Dose&gt;\nD\nThe proportion of the simulations in which each arm was dropped. These will be zero if arm dropping is not selected as the means of adaptive allocation.\n\n\nMean LPFV time\n1\nThe mean, over the simulations, of the accrual period of the trials, from first person first visit, to last person first visit (LPFV).\n\n\nPpn Correct Arm\n1\nThe proportion of the simulations where the correct arm has been selected, where an arm is deemed “correct” based on whether it was marked as “Should Succeed” for the relevant scenario on the VSR tab.\n\n\nPpn Incorrect Arm\n1\nThe proportion of the simulations where the incorrect correct arm has been selected, where an arm is deemed “incorrect” based on whether it wasn’t marked as “Should Succeed” for the relevant scenario on the VSR tab.\n\n\nQOI Columns\n\nSee next section.\n\n\n\n\n\n\n\nQOI Columns\nThe QOI columns depend on the QOIs that have been defined for this design. The columns in the following order:\n\n\n\n\n\n\n\nStatistic\nDescription\n\n\n\n\nPosterior Probabilities\nThe summary file contains the mean (over the simulations) of the posterior probability for each dose.\n\n\nPredictive Probabilities\nThe summary file contains the mean (over the simulations) of the predictive probability for each dose.\n\n\nP-Values\nThe summary file contains the mean (over the simulations) of the p-value for each dose.\n\n\nTarget Probabilities\nThe summary file contains the proportion of times (over the simulations) each dose had the greatest probability of being the target.\n\n\nDecision QOIs\nThe summary file contains the mean (over the simulations) of the final value of the decision QOI at the target.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-summary_freq_missingnesstype.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-summary_freq_missingnesstype.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of Summary_freq_{missingnessType}.csv",
    "text": "Contents of Summary_freq_{missingnessType}.csv\nThere is a frequentist summary file for each type of treatment of missing values.\nThe first line is a header line, starting with a ‘#’, containing the FACTS GUI version number, the name of the FACTS file, the name of the scenario, and the time stamp of the start of the simulation.\nThe second line is a header line, starting with a ‘#’, containing the following column headings.\n\nContinuousDichotomous\n\n\n\nContents of the summary_freq_{missingnessType}.csv file for continuous simulations.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nMean Theta &lt;Dose&gt;\nD\nThe mean response per dose.\n\n\nSE Theta &lt;Dose&gt;\nD\nThe standard error of the response per dose\n\n\nMean Beta (b aseline)\n1\nThe mean of the estimate of the baseline coefficient.\n\n\nSE Mean Beta (b aseline)\n1\nThe standard error of the estimate of the baseline coefficient\n\n\nPpn Signif\n1\nThe proportion of simulations where at least one of the unadjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the unadjusted p-value is less than the user specified one-sided alpha.\nThe marginal probability of significance per dose (using unadjusted p-values.\n\n\nBias &lt;Dose&gt;\nD\nThe difference between the estimated mean response and the true (simulated) mean response per dose\n\n\nCoverage &lt;Dose&gt;\nD\nThe proportion of simulations where the unadjusted confidence interval for the response contains the true mean response used to simulate subject responses.\n\n\nPpn Signif Dunnett\n1\nThe proportion of simulations where at least one of the Dunnett adjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif Dunnett &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Dunnett adjusted p-value is less than the user specified one-sided alpha.\n\n\nCoverage Dunnett &lt;Dose&gt;\nD\nThe proportion of simulations where the Dunnett adjusted confidence interval contains the true mean response used to simulate subjects responses.\n\n\nPpn Signif Bonf\n1\nThe proportion of simulations where at least one of the Bonferroni adjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif Bonf &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Bonferroni adjusted p-value is less than the user specified one-sided alpha.\n\n\nCoverage Bonf &lt;Dose&gt;\nD\nThe proportion of simulations where the Bonferroni adjusted confidence interval contains the true mean response used to simulate subjects responses.\n\n\nPpn Signif Trend\n1\nThe proportion of simulations where the trend test p-value is less than the user specified one-sided alpha.\n\n\n\n\n\n\nContents of the summary_freq_{missingnessType}.csv file for dichotomous simulations.\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\n\nMean Theta &lt;Dose&gt;\nD\nThe mean response per dose.\n\n\n\nSE Theta &lt;Dose&gt;\nD\nThe standard error of the response per dose\n\n\n\nPpn Signif\n1\nThe proportion of simulations where at least one of the unadjusted p-values is less than the user specified one-sided alpha.\n\n\n\nPpn Signif &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of | simulations where the unadjusted p-value is | less than the user specified one-sided alpha. | | The marginal probability of significance per | dose (using unadjusted p-values).\n\n\nBias &lt;Dose&gt;\nD\nThe difference between the estimated mean response and the true (simulated) mean response per dose\n\n\n\nCoverage &lt;Dose&gt;\nD\nThe proportion of simulations where the unadjusted confidence interval for the response contains the true mean response used to simulate subject responses.\n\n\n\nPpn Signif Dunnett\n1\nThe proportion of simulations where at least one of the Dunnett adjusted p-values is less than the user specified one-sided alpha.\n\n\n\nPpn Signif Dunnett &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Dunnett adjusted p-value is less than the user specified one-sided alpha.\n\n\n\nCoverage Dunnett &lt;Dose&gt;\nD\nThe proportion of simulations where the Dunnett adjusted confidence interval contains the true mean response used to simulate subjects responses.\n\n\n\nPpn Signif Bonf\n1\nThe proportion of simulations where at least one of the Bonferroni adjusted p-values is less than the user specified one-sided alpha.\n\n\n\nPpn Signif Bonf &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Bonferroni adjusted p-value is less than the user specified one-sided alpha.\n\n\n\nCoverage Bonf &lt;Dose&gt;\nD\nThe proportion of simulations where the Bonferroni adjusted confidence interval contains the true mean response used to simulate subjects responses.\n\n\n\nPpn Signif Trend\n1\nThe proportion of simulations where the trend test p-value is less than the user specified one-sided alpha.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-simulations.csv-and-weeksnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-simulations.csv-and-weeksnnnnn.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of simulations.csv and weeksNNNNN.csv",
    "text": "Contents of simulations.csv and weeksNNNNN.csv\nThe simulations.csv file holds the FACTS summary of the final analysis for each simulation (one per row).\nThe weeksNNNNN.csv file holds the FACTS summary of every analysis for the NNNNNth simulation. It contains a row for each interim in the trial and a row for the final analysis (Interim number 999).\nThe final analysis occurs after all the planned data is collected. If the trial does not stop early, the final analysis occurs after full follow-up for all subjects. If the trial does stop early at an interim analysis, then the timing of the final analysis depends on the status of the check boxes on the Interims tab. If follow-up is collected after the particular interim decision, then an analysis after full follow-up of the subjects recruited up to the point of the interim when the stopping decision was taken. If there is no follow-up intended after the interim analysis decision, then the final analysis occurs immediately (at the same time as the interim analysis), and the final analysis criteria are checked.\nThe first line is a header line, starting with a ‘#’, containing the FACTS GUI version number, the name of the FACTS file, the name of the scenario, and the time stamp of the start of the simulation.\nThe second line is a header line, starting with a ‘#’, containing the following column headings.\nMost of the columns are common to the two file types, but the weeks file does not contain columns for the ‘final’ values of the evaluation criteria.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nIn simulations file\nIn weeks file\nDescription\n\n\n\n\n# Weeks (Duration)\n1\n\n✔\nThe week of the analysis\n\n\n#Sim\n1\n✔\n\nThe number of the simulation.\n\n\nRandom Number Seed\n1\n✔\n✔\nBase random number seed.\n\n\nLastInterim\n1\n✔\n\nThe index of the last interim performed the index of the interim immediately before the final interim (index ‘999’). Note this is not necessarily the interim when the trial stopped if the design includes follow-up after stopping.\n\n\n#Subjects\n1\n✔\n✔\nThe number of subjects recruited in the simulation.\n\n\nOutcome\n1\n✔\n✔\nA flag categorizing final study outcome:1 = Early success2 = Late success3 = Late futility4 = Early futility5 = Success to futility flip-flop6 = Futility to success flip-flop7 = Inconclusive\n\n\nEarly Success Time\n1\n✔\n✔\nThis is the time to the early success decision (-9999 if there was no early success decision). The from the start of the trial to the interim where the early success conditions were first met. It does not include the subsequent follow up time.\n\n\nAlloc &lt;Dose&gt;\nD\n✔\n✔\nThe number of subjects allocated to each arm.\n\n\nPr(Alloc) &lt;Dose&gt;\nD\n✔\n✔\nThe probability of allocation to the different arms following the interim.\n\n\nMean resp &lt;Dose&gt;\nD\n✔\n✔\nThe estimated response of each treatment arm.\n\n\nSD Mean resp &lt;Dose&gt;\nD\n✔\n✔\nThe standard deviation of the estimate of response of each treatment arm.\n\n\nTrue Mean resp &lt;Dose&gt;\nD\n✔\n✔\nThe true mean response of each treatment arm for this simulation.\n\n\nTrue SD resp &lt;Dose&gt;\nD\n✔\n✔\nThe true SD of the response of each treatment arm for this simulation\n\n\nSigma\n1\n✔\n✔\nThe pooled estimate of the SD of the response across all the treatment arms\n\n\nSD_Sigma\n1\n✔\n✔\nThe SD of the pooled estimate of the SD of the response across all the treatment arms\n\n\nBeta\n1\n✔\n✔\nThe estimate of ‘Beta’ the baseline adjustment coefficient, if baseline adjustment is being used.\n\n\nSD_Beta\n1\n✔\n✔\nThe SD of the estimate of ‘Beta’ the baseline adjustment coefficient.\n\n\nMean Baseline\n1\n✔\n✔\nThe estimate of the mean baseline score.\n\n\nSE Mean Baseline\n1\n✔\n✔\nThe standard error of the estimate of the mean baseline score.\n\n\nSD Baseline\n1\n✔\n✔\nThe estimate of the SD of the baseline score.\n\n\nTrue Mean Baseline\n1\n✔\n✔\nThe true mean of the simulated baseline score\n\n\nTrue SD Baseline\n1\n✔\n✔\nThe true SD of the simulated baseline score\n\n\nMean Raw Response &lt;Dose&gt;\nD\n✔\n✔\nThe observed mean response on each treatment arm (unadjusted by any modeling).\n\n\nSE Mean Raw Response &lt;Dose&gt;\nD\n✔\n✔\nThe SE of the estimate of the mean raw response on each dose.\n\n\nComplete &lt;Dose&gt;\nD\n✔\n✔\nThe number of completed subjects on each treatment arm at the time of the analysis.\n\n\nComplete Information &lt;Dose&gt;\nD\n✔\n✔\nThe number of subject who count as complete for the purposes of timing interims – whether complete or opportunity to complete and at which visit is as defined on the Interims tab. If interims are by enrolment then CompleteInformation is the number of subjects that have completed – final endpoint data is available.\n\n\n#Dropouts &lt;Dose&gt; &lt;Visit&gt;\nD * V\n✔\n✔\nThe number of subjects dropped out on each treatment arm and each visit.\n\n\nDR Param &lt;Param&gt;\n10\n✔\n✔\nThe estimate of the mean value of each of the response model parameters. The response models require up to 10 parameters, most less. The model parameters are labeled \\(\\alpha_1\\), \\(\\alpha_2\\), .. the subscripts corresponding to the index “&lt;Param&gt;”.\n\n\nSd DR Param &lt;Param&gt;\n4\n✔\n✔\nThe standard deviation of the estimate of the mean value of the corresponding response model parameter.\n\n\nLongmod_ &lt;Model&gt; &lt;Parameter&gt; &lt;Visit&gt;\nLM * LMP * V\n✔\n✔\nThe estimate of the mean value of each of the longitudinal model parameters. The number of models depends on the number of “model instances” the user has specified. For linear regression the parameters reported are: - Alpha – per visit – the mean estimate of the constant offset in the change in response from this visit to the final visit - Beta – per visit – the mean estimate of the coefficient of change in response from this visit to the final visit - Lambda – per visit – the mean estimate of the SD of the residual error term in the predicted final visit response based on the response at this visit. For time course hierarchical the parameters reported are: - Alpha – per visit – the mean estimate of the exponential coefficient of the proportion of the dose response and per-subject response seen at this visit.. - Lambda – per visit – the mean estimate of the SD of the residual error term in the predicted final visit response based on the response at this visit. - Tau – the mean estimate of the SD of the per subject random effect For ITP the parameters are: - K – per model – the mean estimate of the ITP shape parameter - Tau – per model - the mean estimate of the SD of the per subject random effect - Lambda – per model – the mean estimate of the Sd of the residual error. - Omega – per treatment arm – the mean estimate of the mean treatment arm effect. For LOCF & Kernel Density there are no estimated parameters.\n\n\nLongmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD * V\n✔\n✔\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used. This is the mean response for a particular dose at a particular visit.\n\n\nBAC Mean\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Mean SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nBAAC Mean SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean comparator responses.\n\n\nBAAC Tau\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nBAAC Tau SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nDuration\n1\n✔\n✔\nThe time in weeks to the analysis shown.\n\n\nArm Drop Time &lt;Dose&gt;\nD\n✔\n✔\nFor each treatment arm, the time in weeks when it was decided to drop the arm.\n\n\nLPFV\n1\n✔\n✔\nThe time in weeks to the last patient first visit.\n\n\nQOI Columns\n\n✔\n✔\nSee next section.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nIn simulations file\nIn weeks file\nDescription\n\n\n\n\n# Weeks (Duration)\n1\n\n✔\nThe week of the analysis\n\n\n#Sim\n1\n✔\n\nThe number of the simulation\n\n\nLastInterim\n1\n✔\n\nThe index of the last interim performed the index of the interim immediately before the final interim (index ‘999’). Note this is not necessarily the interim when the trial stopped if the design includes follow-up after stopping\n\n\n#Subjects\n1\n✔\n✔\nThe number of subjects recruited in the simulation\n\n\nOutcome\n1\n✔\n✔\nA flag categorizing final study outcome:1 = Early success2 = Late success3 = Late futility4 = Early futility5 = Success to futility flip-flop6 = Futility to success flip-flop7 = Inconclusive\n\n\nEarly Success Time\n1\n✔\n✔\nThis is the time to the early success decision (-9999 if there was no early success decision). The from the start of the trial to the interim where the early success conditions were first met. It does not include the subsequent follow up time\n\n\nAlloc &lt;Dose&gt;\nD\n✔\n✔\nThe number of subjects allocated to each arm\n\n\nPr(Alloc) &lt;Dose&gt;\nD\n✔\n✔\nThe probability of allocation to the different arms following the interim\n\n\nMean resp &lt;Dose&gt;\nD\n✔\n✔\nThe estimated response of each treatment arm\n\n\nSD resp &lt;Dose&gt;\nD\n✔\n✔\nThe standard deviation of the estimate of response of each treatment arm\n\n\nMean resp (lower CI) &lt;Dose&gt;\nD\n✔\n✔\nThe lower bound of the 95% Credible Interval of the estimate of response for each treatment arm\n\n\nMean resp (upper CI) &lt;Dose&gt;\nD\n✔\n✔\nThe upper bound of the 95% Credible Interval of the estimate of response for each treatment arm\n\n\nTrue Mean resp &lt;Dose&gt;\nD\n✔\n✔\nThe true mean response of each treatment arm for this simulation\n\n\nMean Raw Response &lt;Dose&gt;\nD\n✔\n✔\nThe observed rate of response on each treatment arm (unadjusted by any modeling)\n\n\nComplete &lt;Dose&gt;\nD\n✔\n✔\nThe number of completed subjects on each treatment arm at the time of the analysis\n\n\nComplete Information &lt;Dose&gt;\nD\n✔\n✔\nThe number of subjects that have achieved the information criteria as specified on the Interims tab. May be the number enrolled, complete, or with the opportunity to complete. If complete or opportunity to complete, then the visit that should be complete is also specified.\n\n\n#Dropouts &lt;Dose&gt; &lt;Visit&gt;\nD * V\n✔\n✔\nThe number of subjects dropped out on each treatment arm and each visit\n\n\nDR Param &lt;Param&gt;\n4\n✔\n✔\nThe estimate of the mean value of each of the response model parameters. The response models require up to 4 parameters, some less. The model parameters are labeled \\(\\alpha_1\\), \\(\\alpha_2\\), .. the subscripts corresponding to the column their value appears in here\n\n\nSd DR Param &lt;Param&gt;\n4\n✔\n✔\nThe standard deviation of the estimate of the mean value of the corresponding response model parameter\n\n\nLongmod_ &lt;Model&gt; &lt;Parameter&gt; &lt;Visit&gt;\nLM * LMP * V\n✔\n✔\nThe estimate of the mean value of each of the longitudinal model parameters. The number of models depends on the number of “model instances” the user has specified. Each value is reported per visit unless otherwise stated.For Beta-Binomial the parameters reported are:• Alpha0 & Beta 0 – The beta binomial alpha & beta parameters for the probability that the final result will be 1 if the result at the visit is 0• Prob01 – the mean probability of the Beta(Alpha0, Beta0) – the probability of 1 being the final result if the result at the visit is 0• Alpha1 & Beta 1 – The beta binomial alpha & beta parameters for the probability that the final result will be 1 if the result at the visit is 1• Prob11 – the mean probability of the Beta(Alpha1, Beta1) – the probability of 1 being the final result if the result at the visit is 1For logistic regression the parameters reported are: • Prob11 – the probability of 1 being the final result if the result at the visit is 1and • Prob01 – the probability of 1 being the final result if the result at the visit is 0For restricted Markov the parameters reported are:• Alpha0 – Alpha for state 0• AlphaS – Alpha for stable state• Alpha1 – Alpha for state 1• Prob0 – Transition probability to state 0• ProbS – Probability of remaining stable• Prob1 – Transition probability to state 1(values are for the transition to the next visit, so thre are no values for the final visit)If using a dichotomized continuous response, these columns will be for the selected continuous longitudinal model:For linear regression the parameters reported are:• Alpha – the mean estimate of the constant offset in the change in response from this visit to the final visit• Beta – the mean estimate of the coefficient of change in response from this visit to the final visit• Lambda – the mean estimate of the SD of the residual error term in the predicted final visit response based on the response at this visit.For ITP the parameters are:• K – single value per model – the mean estimate of the ITP shape parameter• Tau – single value per model - the mean estimate of the SD of the per subject random effect• Lambda – single value per model – the mean estimate of the Sd of the residual error.• Omega – per treatment arm not visit – the mean estimate of the mean treatment arm effect.For LOCF & Kernel Density there are no estimated parameters.\n\n\nLongmod Resp: &lt;Dose&gt; &lt;Visit&gt;\nD * V\n✔\n✔\nThese are only calculated and written out if the ITP longitudinal model is being used for a dichotomized continuous endpoint.This is the mean response for a particular dose at a particular visit.\n\n\nBAC Mean\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses\n\n\nBAC Mean SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses\n\n\nBAC Tau\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses\n\n\nBAC Tau SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses\n\n\nBAAC Mean\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses\n\n\nBAAC Mean SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean comparator responses\n\n\nBAAC Tau\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses\n\n\nBAAC Tau SD\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses\n\n\nDuration\n1\n✔\n✔\nThe time in weeks to the analysis shown\n\n\nArm Drop Time &lt;Dose&gt;\nD\n✔\n✔\nFor each treatment arm, the time in weeks when it was decided to drop the arm\n\n\nLPFV\n1\n✔\n✔\nThe time in weeks to the last patient first visit\n\n\nQOI Columns\n\n✔\n✔\nSee next section.\n\n\n\n\n\n\n\nQOI Columns\nThe QOI columns depend on the QOIs that have been defined for this design. The columns are grouped in the following order:\n\n\n\n\n\n\n\nQOI Type\nDescription\n\n\n\n\nPosterior Probabilities\nThe posterior probability for each QOI for each dose.\n\n\nPredictive Probabilities\nThe predictive probability for each QOI for each dose.\n\n\nP-Values\nThe p-value for each QOI for each dose.\n\n\nTarget Probabilities\nThe probability of being the target for each QOI for each dose.\n\n\nDecision QOIs\nThe value of the decision QOI at the target.\n\n\nSuccess Futile\nA flag for each QOI decision criteria indicating if the decision QOI was evaluated and compared to a threshold at the interim (weeks file) or final analysis (simulation file). The flag value is -1 if the decision QOI was not evaluated, 0 if it did not meet the threshold and 1 if it did.\n\n\nSuccess / Futile Combined\nFlags indicating if the interim or final analysis determined success or futility taking all the factors defined for Success/Futility into account: 0 if the conditions were not met, 1 it the conditions were met. If success and futility conditions have been defined that are not mutually exclusive and both sets of combined conditions are met, FACTS will pick one of the outcomes as met but not the other. In order to discourage defining Success and Futility rules that can both be true FACTS does not guarantee which outcome will be selected.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-simulations_freq_missingnesstype.csv-weeks_freq_missingnesstype.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-simulations_freq_missingnesstype.csv-weeks_freq_missingnesstype.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of Simulations_freq_{missingnessType}.csv, Weeks_freq_{missingnessType}.csv",
    "text": "Contents of Simulations_freq_{missingnessType}.csv, Weeks_freq_{missingnessType}.csv\nThese file contain the frequentist results after an interim analysis (weeks file) or final analysis (simulations file), apart for the first column, the columns are the same in the two types of file, and the same across the different methods for treating missing data.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\n# Trial\n1\nThe number of the simulation (simulations_freq_…csv only)\n\n\n# Weeks\n1\nThe week of the interim (weeks_freq_…csv only)\n\n\nTheta\nD\nUnadjusted estimate of response per treatment arm\n\n\nTheta SD\nD\nThe SD of the estimate of response per treatment arm\n\n\nTrt Effect\nD\nThe relative size of the treatment effect compared to control per arm (treatment effect for control is always 0). The direction of the comparison takes into account whether a response represents a subject’s condition improving or worsening, so that a positive treatment effect shows the response on the dose is better than on control.\n\n\nt-Stat\nD\nThe t-test statistic per treatment arm (for control this is always 0)\n\n\np-Value\nD\nThe unadjusted t-test p-value per arm (for control this is always 0)\n\n\nlower CI\nD\nThe unadjusted lower bound of the alpha confidence interval of the estimated treatment effect per treatment arm (for control this is always 0).\n\n\nupper CI\nD\nThe unadjusted upper bound of the alpha confidence interval of the estimated treatment effect per treatment arm (for control this is always 0).\n\n\nMin p-Value\n1\nThe smallest of the t-test p-values\n\n\np-Value Dunnett\nD\nThe Dunnett adjusted t-test p-value per arm (for control this is always 0).\n\n\nlower CI Dunnett\nD\nThe Dunnett adjusted lower bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nupper CI Dunnett\nD\nThe Dunnett adjusted upper bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nMin p-Value Dunnett\n1\nThe smallest of the Dunnett adjusted p-values.\n\n\np-Value Bonf\nD\nThe Bonferroni adjusted t-test p-value per arm.\n\n\nlower-CI Bonf\nD\nThe Bonferroni adjusted lower bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nupper-CI Bonf\nD\nThe Bonferroni adjusted upper bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nMin p-Value Bonf\n1\nThe smallest of the Bonferroni adjusted t-test value per arm.\n\n\nt-Stat trend\n1\nThe t statistic from the trend test.\n\n\np-Value trend\n1\nThe p-value from the trend test.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-patientsnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-patientsnnnnn.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of PatientsNNNNN.csv",
    "text": "Contents of PatientsNNNNN.csv\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nSubject\n1\nThe subject id number, starting at 1.\n\n\nRegion\n1\nWhich region the subject was recruited in.\n\n\nDate\n1\nThe date, in weeks from the start of the trial, of the subject’s baseline visit and randomization.\n\n\nDose\n1\nThe index number (1, …) of the treatment arm the subject belongs to.\n\n\nLastVisit#\n1\nThe index of the last visit for which the subjects data was collected, if the subject did not complete all of its visits it could be because they dropped-out, the subject’s treatment arm was dropped (and there was no follow-up), or the study stopped early (and there was no follow-up).\n\n\nDropout\n1\nWhether the subject dropped out of the trial (1) or not (0) before reaching their final visit.\n\n\nBaseline\n1\nSubject baseline response, if simulated. If not simulated, then fixed at -9999.\n\n\nVisit &lt;Visit&gt;\nV\nSubject’s response at each visit.\n\n\n\n\n\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nSubject\n1\nThe subject id number, starting at 1.\n\n\nRegion\n1\nWhich region the subject was recruited in.\n\n\nDate\n1\nThe date, in weeks from the start of the trial, of the subject’s baseline visit and randomization.\n\n\nDose\n1\nThe index number (1, …) of the treatment arm the subject belongs to.\n\n\nLastVisit#\n1\nThe index of the last visit for which the subjects data was collected, if the subject did not complete all of its visits it could be because they dropped-out, the subject’s treatment arm was dropped (and there was no follow-up), or the study stopped early (and there was no follow-up).\n\n\nDropout\n1\nWhether the subject dropped out of the trial (1) or not (0) before reaching their final visit.\n\n\nBaseline\n1\nAlways -9999 since there’s no baseline in dichotomous response trials.\n\n\nVisit &lt;Visit&gt;\nV\nSubject’s response at each visit.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-mcmcnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/contanddichot.html#contents-of-mcmcnnnnn.csv",
    "title": "Continuous and Dichotomous Output",
    "section": "Contents of MCMCNNNNN.csv",
    "text": "Contents of MCMCNNNNN.csv\nThe MCMC file if requested for output by the user, contains all the MCMC samples for the fitted parameters in the design. There is one row per sample (including the burnin) and the samples from all the analyses in the simulation are included. The first two columns are the analysis index and the sample (within analysis) index. The remaining columns are the parameters whose sample values are being reported, the number and constituents of these columns are highly variable depending on design of the statistical analysis.\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nAnalysis\n1\nThe index of the analysis (interim) in the simulation.\n\n\nSample\n1\nThe index of the sample within the analysis.\n\n\nTheta &lt;Dose&gt;\nD\nThe estimate of the mean response for each dose, based on the dose response model fitted.\n\n\nSigma\n1\nThe estimate of the SD of the endpoint.\n\n\nBeta\n1\nIf baseline is included in the simulated data and using the “Baseline Adjusted Model”, this is the value of “Beta”, the baseline coefficient.\n\n\nA &lt;1-8&gt; / Tau\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod &lt;Model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nIf the analysis includes longitudinal modelling then the samples of the parameters of the longitudinal models are output. The number of models depends on the number of different longitudinal fits the user has specified (one over all arms, one for control and one for all treatment arms, model all arms separately, etc.), the number of parameters the model has, and if these are fitted per visit (which depends on the model being fitted), then the number of visits.\n\n\n\n\n\nIf using a dichotomized continuous variable, then the parameters for the LM are the same as for the continuous model MCMC output listed in the Continuous tab.\nIf using a dichotomous longitudinal model, then the following parameters are output in the MCMC file.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nAnalysis\n1\nThe index of the analysis (interim) in the simulation.\n\n\nSample\n1\nThe index of the sample within the analysis.\n\n\nPi &lt;Dose&gt;\nD\nThe estimate of the response rate for each dose, based on the dose response model fitted.\n\n\nA &lt;1-8&gt; / Tau\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod &lt;Model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nIf the analysis includes longitudinal modelling then the samples of the parameters of the longitudinal models are output. The number of models depends on the number of different longitudinal fits the user has specified (one over all arms, one for control and one for all treatment arms, model all arms separately, etc.), the number of parameters the model has, and if these are fitted per visit (which depends on the model being fitted), then the number of visits.\n\n\n\nIf using a restricted markov model, then the following parameters are output in the MCMC file.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nAnalysis\n1\nThe index of the analysis (interim) in the simulation.\n\n\nSample\n1\nThe index of the sample within the analysis.\n\n\nPi &lt;Dose&gt;\nD\nThe estimate of the response rate for each dose, based on the dose response model fitted.\n\n\nA &lt;1-8&gt; / Tau\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod &lt;Model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nCurrently the values of Alpha0, Alpha1, AlphaS (the parameters to the Dirichlet distribution) are (unnecessarily – these values are not sampled) output, along with the values for P0, P1 and PS the transition probabilities of each model at each visit.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Continuous/Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/continuous.html",
    "href": "documentation/v71/userguides/core/study/continuous.html",
    "title": "Study Tab - Continuous Endpoint",
    "section": "",
    "text": "The Study Info sub-tab provides parameters for specifying rules and methods for common clinical trial simulation features. These include accrual style, visit schedule, whether interim analyses will be simulated, and more.\n\n\n\n\n\n\nFigure 1: The study tab for a continuous trial.\n\n\n\n\n\nIn the design options section of the Study tab the user gets check boxes for whether they want to enable adaptive features, use longitudinal modelling, or include simulation of baseline. These options have the following effects on the trial simulation.\n\n\nWhether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether longitudinal modeling is going to be used. If longitudinal modeling is not selected, some longitudinal specific parameters and tabs are hidden. If use longitudinal modeling is selected, FACTS expects that the early endpoint data will be used, it cannot be ignored. If intermediate data is not intended to be used in the modeling, then it should not be simulated in FACTS.\n\n\n\nWhether to include simulation of subject’s baseline score, and if so, whether the response to be modeled is change from baseline or final endpoint value.\n\n\n\n\nThe study information section allows the user to specify how subject accrual should be simulated, and whether a larger endpoint value indicates improvement or not.\n\n\nSubject accrual can be configured to be done continuousl, in cohorts, or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited in cohorts the user specifies:\n\nThe size of the first cohort\nThe size of subsequent cohorts\nThe maximum number of cohorts\nThe time (in weeks) to recruit each cohort\n\nThe “Maximum number of subjects” and “Maximum trial duration” fields are automatically updated to reflect the cohort parameters entered.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nIndicate whether a larger endpoint value indicates subjects improvement or if a lower endpoint value is better. The value provided here informs the  direction of frequentist hypothesis tests All FACTS frequentist tests are 1-sided.  and with the evaluation of QOIs like Pr(Max) and predictive probabilities.\n\n\n\nIf “Use longitudinal modeling” is not checked, then the post baseline visit specification is simple. The only required entry is the time it takes to observe a subject’s final endpoint.\nIf “Use longitudinal modeling” is checked, the follow-up period for subjects is slightly more involved. Visits are specified one at a time, by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.\n\n\n\n\n\n\nFigure 2: The control for setting up the visit schedule.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Continuous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/continuous.html#design-options",
    "href": "documentation/v71/userguides/core/study/continuous.html#design-options",
    "title": "Study Tab - Continuous Endpoint",
    "section": "",
    "text": "In the design options section of the Study tab the user gets check boxes for whether they want to enable adaptive features, use longitudinal modelling, or include simulation of baseline. These options have the following effects on the trial simulation.\n\n\nWhether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether longitudinal modeling is going to be used. If longitudinal modeling is not selected, some longitudinal specific parameters and tabs are hidden. If use longitudinal modeling is selected, FACTS expects that the early endpoint data will be used, it cannot be ignored. If intermediate data is not intended to be used in the modeling, then it should not be simulated in FACTS.\n\n\n\nWhether to include simulation of subject’s baseline score, and if so, whether the response to be modeled is change from baseline or final endpoint value.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Continuous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/continuous.html#study-information",
    "href": "documentation/v71/userguides/core/study/continuous.html#study-information",
    "title": "Study Tab - Continuous Endpoint",
    "section": "",
    "text": "The study information section allows the user to specify how subject accrual should be simulated, and whether a larger endpoint value indicates improvement or not.\n\n\nSubject accrual can be configured to be done continuousl, in cohorts, or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited in cohorts the user specifies:\n\nThe size of the first cohort\nThe size of subsequent cohorts\nThe maximum number of cohorts\nThe time (in weeks) to recruit each cohort\n\nThe “Maximum number of subjects” and “Maximum trial duration” fields are automatically updated to reflect the cohort parameters entered.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nIndicate whether a larger endpoint value indicates subjects improvement or if a lower endpoint value is better. The value provided here informs the  direction of frequentist hypothesis tests All FACTS frequentist tests are 1-sided.  and with the evaluation of QOIs like Pr(Max) and predictive probabilities.\n\n\n\nIf “Use longitudinal modeling” is not checked, then the post baseline visit specification is simple. The only required entry is the time it takes to observe a subject’s final endpoint.\nIf “Use longitudinal modeling” is checked, the follow-up period for subjects is slightly more involved. Visits are specified one at a time, by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.\n\n\n\n\n\n\nFigure 2: The control for setting up the visit schedule.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Continuous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/continuous.html#d-treatment-arm-model",
    "href": "documentation/v71/userguides/core/study/continuous.html#d-treatment-arm-model",
    "title": "Study Tab - Continuous Endpoint",
    "section": "2D Treatment Arm Model",
    "text": "2D Treatment Arm Model\nIf the user checks the “Use 2D treatment arm model” option, the screen changes to allow the treatment strengths to be specified on 2 axes, and to specify which of the treatment combinations thus created will actually included as arms in the trial.\n\n\n\n\n\n\nFigure 4: The Study &gt; Treatment Arms tab when using a 2D treatment arm model.\n\n\n\nThe user now specifies strengths as “Column Factors” and “Row factors”. For example, the Column factors could be different dose strengths and the row factors could be different dosing regimens, or different treatments that the investigational treatment could be combined with. Because of the way the factors are shown in FACTS graphs it is better to use the factor with the greater number of values as the column factor. From the point of view of the analysis however the factors are treated symmetrically. In FACTS we have adopted the neutral term “factor” to avoid the impression that these designs can only apply to doses and dosing regimens[^3].\nFACTS then shows all the potential combinations of column and row factors in the list “Select doses to be used in trial” in which the user selects which of the factor combinations that will be present as arms in the trial. FACTS constructs the “effective strengths” opf the combinations by simply adding together the strengths of the two factors, but while the strengths of the factors (like the strengths of “doses” in the 1D setting) cannot be simply changed (because of the problems of managing the ordering of the factors), strengths of combinations can be directly edited, and indeed must be edited to resolve any “ties”. All combinations must have unique strengths so that they can be ranked in order.\nIf a control treatment arm is included in the trial then a “Control” factor is included in the Column factors and the user selects which combination of this factor and a Row factor is the Control combination. This combination is given the effective strength 0 and moved to the head of the list of doses. If the “include a control treatment arm” option is checked, there must be a combination that acts as control dose. If the option is not checked there will be no control dose.\nFACTS displays the resulting ordered list of combinations in the “Doses in trial” column.\nThere is also a “Show grid” option that will display a small graphic of the 2D layout of these “Doses in trial”:\n\n\n\n\n\n\nFigure 5: The dosing grid for a 2D dosing model with 2 row factor levels and 4 column factor levels.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Continuous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html",
    "href": "documentation/v71/userguides/core/study/multendpt.html",
    "title": "Study Tab - Multiple Endpoint",
    "section": "",
    "text": "The Study Info sub-tab provides parameters for specifying rules and methods for common clinical trial simulation features. These include accrual style, visit schedule, whether interim analyses will be simulated, and more.\n\n\n\n\n\n\nFigure 1: The Study &gt; Study Info tab for a multiple endpoint trial\n\n\n\nThe study tab is simpler for multiple endpoint than it is for other FACTS Core design engines (Continuous, Dichotomous, or Time-to-event). Some options that are endpoint specific have been moved to the Endpoints tab, which only exists in the multiple endpoint engine.\n\n\nIn the design options section of the Study tab the user gets a check box for whether they want to enable adaptive features or not. Endpoint specific choices about using longitudinal modelling or special longitudinal options are moved to the Endpoints tab.\n\n\nSpecify whether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\n\nThe study information section allows the user to specify how many subjects to accrue and how subject accrual should be simulated.\n\n\nSpecify the maximum number of subjects that can be enrolled in the trial. Adaptive designs may stop sooner than this value, but no simulation can ever go past it.\n\n\n\nIn multiple endpoint, subject accrual can only be done continuously or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nThe overall visit schedule is specified here. It’s called the “overall” visit schedule in the multiple endpoint engine because the visits entered here make up the set of all visits where any of the endpoints can be observed. When the details of the different endpoints are entered on the Endpoints tab, you will be able to specify which of these visits each endpoint is observed at and which visit will be the final observation for that endpoint.\n\n\n\n\n\n\nFigure 2: The Study Tab in the Multiple Endpoint engine.\n\n\n\nVisits can be specified one at a time by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#design-options",
    "href": "documentation/v71/userguides/core/study/multendpt.html#design-options",
    "title": "Study Tab - Multiple Endpoint",
    "section": "",
    "text": "In the design options section of the Study tab the user gets a check box for whether they want to enable adaptive features or not. Endpoint specific choices about using longitudinal modelling or special longitudinal options are moved to the Endpoints tab.\n\n\nSpecify whether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#study-information",
    "href": "documentation/v71/userguides/core/study/multendpt.html#study-information",
    "title": "Study Tab - Multiple Endpoint",
    "section": "",
    "text": "The study information section allows the user to specify how many subjects to accrue and how subject accrual should be simulated.\n\n\nSpecify the maximum number of subjects that can be enrolled in the trial. Adaptive designs may stop sooner than this value, but no simulation can ever go past it.\n\n\n\nIn multiple endpoint, subject accrual can only be done continuously or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nThe overall visit schedule is specified here. It’s called the “overall” visit schedule in the multiple endpoint engine because the visits entered here make up the set of all visits where any of the endpoints can be observed. When the details of the different endpoints are entered on the Endpoints tab, you will be able to specify which of these visits each endpoint is observed at and which visit will be the final observation for that endpoint.\n\n\n\n\n\n\nFigure 2: The Study Tab in the Multiple Endpoint engine.\n\n\n\nVisits can be specified one at a time by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#d-treatment-arm-model",
    "href": "documentation/v71/userguides/core/study/multendpt.html#d-treatment-arm-model",
    "title": "Study Tab - Multiple Endpoint",
    "section": "2D Treatment Arm Model",
    "text": "2D Treatment Arm Model\nIf the user checks the “Use 2D treatment arm model” option, the screen changes to allow the treatment strengths to be specified on 2 axes, and to specify which of the treatment combinations thus created will actually included as arms in the trial.\n\n\n\n\n\n\nFigure 4: The Study &gt; Treatment Arms tab when using a 2D treatment arm model.\n\n\n\nThe user now specifies strengths as “Column Factors” and “Row factors”. For example, the Column factors could be different dose strengths and the row factors could be different dosing regimens, or different treatments that the investigational treatment could be combined with. Because of the way the factors are shown in FACTS graphs it is better to use the factor with the greater number of values as the column factor. From the point of view of the analysis however the factors are treated symmetrically. In FACTS we have adopted the neutral term “factor” to avoid the impression that these designs can only apply to doses and dosing regimens.\nFACTS then shows all the potential combinations of column and row factors in the list “Select doses to be used in trial” in which the user selects which of the factor combinations that will be present as arms in the trial. FACTS constructs the “effective strengths” opf the combinations by simply adding together the strengths of the two factors, but while the strengths of the factors (like the strengths of “doses” in the 1D setting) cannot be simply changed (because of the problems of managing the ordering of the factors), strengths of combinations can be directly edited, and indeed must be edited to resolve any “ties”. All combinations must have unique strengths so that they can be ranked in order.\nIf a control treatment arm is included in the trial then a “Control” factor is included in the Column factors and the user selects which combination of this factor and a Row factor is the Control combination. This combination is given the effective strength 0 and moved to the head of the list of doses. If the “include a control treatment arm” option is checked, there must be a combination that acts as control dose. If the option is not checked there will be no control dose.\nFACTS displays the resulting ordered list of combinations in the “Doses in trial” column.\nThere is also a “Show grid” option that will display a small graphic of the 2D layout of these “Doses in trial”:\n\n\n\n\n\n\nFigure 5: The dosing grid for a 2D dosing model with 2 row factor levels and 4 column factor levels.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#create-endpoints",
    "href": "documentation/v71/userguides/core/study/multendpt.html#create-endpoints",
    "title": "Study Tab - Multiple Endpoint",
    "section": "Create Endpoints",
    "text": "Create Endpoints\nThe small table on the middle-left side of the screen allows for the creation of up to 4 endpoints. The name of each of the endpoints can be changed in the table by clicking on the entry. The order of the non-first endpoints can be changed by clicking on an endpoint and then clicking on the up or down arrows to the right of the table.\n\n\n\n\n\n\nFigure 6: The Treatments tab with the first endpoint (U1: Pain) selected.\n\n\n\nFor each endpoint, the Endpoint Properties section allows for the endpoint specific characteristics to be supplied.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#endpoint-properties",
    "href": "documentation/v71/userguides/core/study/multendpt.html#endpoint-properties",
    "title": "Study Tab - Multiple Endpoint",
    "section": "Endpoint Properties",
    "text": "Endpoint Properties\n\nContinuous Endpoints\nFor continuous endpoints, the first value provided is whether a higher response is subject improvement, or if a lower response is subject improvement.\nThen, you select whether to simulate a baseline value for subjects. If yes, then specify whether the VSR (Virtual Subject Response) will be specified as a change from the baseline value or as a standalone final endpoint value.\nNext, specify whether to use longitudinal modeling for this endpoint. If the “Use longitudinal Modeling” option is checked, then select one or more visits that subjects will observe this endpoint at. If not using longitudinal modeling, then select which visit is considered the final observed value for this endpoint. Each endpoint can have its own visit schedule, as long as those visits are included as part of the overall visit schedule on the Study Info tab.\n\n\nDichotomous Endpoints\nFor dichotomous endpoints, the first value provided is whether an observed response is a positive outcome or a negative outcome.\nNext, specify whether to use longitudinal modeling for this endpoint. If the “Use longitudinal Modeling” option is checked, then the user can decide if they would like to use the restricted markov model to simulate longitudinal data or the standard transition matrix method. If using the restricted Markov model, specify whether subjects that reach the end of their follow-up without going to either absorbing states should be considered a success or a failure. Then, select one or more visits that subjects will observe this endpoint at.\nIf not using longitudinal modeling, select which visit is considered the final observed value for this endpoint. Each endpoint can have its own visit schedule, as long as those visits are included as part of the overall visit schedule on the Study Info tab.\n\n\nUtility Function\nThe Multiple Endpoint design engine allows clinical trials to be designed and simulated where the within-trial and end-of-trial decisions can be based on multiple endpoints by using a composite score, or utility, derived by combining the different endpoint estimates. The utility function approach is incredibly open-ended and flexible, able to cope with different types of endpoints, different endpoint scales and different endpoint interrelations.\nThe utility function approach has two stages:\n\nFirst, each endpoint is converted to its own utility score for each dose.\nThen, the endpoint specific utilities are combined into a single overall utility for each dose.\n\nEach endpoint has its own utility function, as described above. Utilities are flexible piecewise functions of the estimated response for the endpoint.\nFirst use the “Add” button to add the knots of the utility function – these are the segment boundaries in the range of the endpoint measure where different functions will be specified in each segment. For each segment created by adding a “knot” a row is created in the table, allowing the user to specify the coefficients of the utility function in that segment specifically.\nThe components of the utility that can be weighted based on their coefficients are: fixed, linear, quadratic, exponential, and log terms.\nThe coefficients that can be specified are:\n\nAlpha: the coefficient of the quadratic term\nBeta: the coefficient of the linear term\nGamma: the coefficient of the fixed term\nDelta: the coefficient of the exponential term\nEpsilon: the coefficient of x in the exponential term\nPhi: the coefficient of the log term\nPsi: the coefficient of x in the log term\n\nFinally, the user specified whether the \\(x\\) in the utility function is relative to control or not. If the “Parameterize response relative to control” is checked, then \\(x=\\theta_d - \\theta_0\\) for a continuous endpoint, and \\(x = P_d - P_0\\) for a dichotomous endpoint. If the “Parameterize response relative to control” is checked, then \\(x=\\theta_d\\) for a continuous endpoint and \\(x=P_d\\) for a dichtomous endpoint.\nFor a continuous endpoint, the utility function is defined on the range of \\(x \\in (-\\infty, \\infty)\\). For dichotomous endpoints, if \\(x\\) is relative to control, then the utility is on the range \\(x \\in (-1, 1)\\), and if \\(x\\) is not relative to control, then the utility is on the range \\(x \\in (0, 1)\\).\n\n\n\n\n\n\nNote on the coefficients of the utility function\n\n\n\nIt is not the intention that all, or even most, of the available coefficients are used in any one segment, typically only one or two are. The different terms are provided so that the required form can be selected for each segment – flat linear, quadratic, exponential or log. The default values of the coefficients are set so that only the linear component of the utility contributes.\n\n\n\n\nEstimation of Utility in FACTS\nAn important aspect of the way FACTS estimates utility is that it estimates a probability density for the utility within the MCMC sampling. That is, the utility is calculated for every parameter sample within the MCMC, and the final distribution of the utility is based on those samples just like the estimates for the model parameters.\nEach dose has a distribution of utility scores - not a single value. The utility is not estimated from the mean estimates of the dose response from the different endpoints.\nThis has some notable effects on the estimates of utility. If, for example, the utility function is a step function – for example if its value is 1 for response rates below a threshold and 0 above – as the estimate of the response rate will have some uncertainty then when the mean response estimates are around the threshold value, the estimate of utility will be between 0 and 1, based on the proportion of MCMC samples the fitted response rate was below the threshold. Indeed, the utility can be interpreted as the ‘probability the response rate is below the threshold’, and thus be useful or even exactly what is required.\nSimilarly, any utility function that has a floor or ceiling will result in a bias in the estimate of the utility to be above the floor or below the ceiling. – because in the distribution of the values for the utility the lowest the value can be is the floor and the final estimate of the utility would only be at the floor if all the values for the utility sampled in the MCMC were at the floor. Another effect of utilities with a floor or ceiling is that the estimate of the mean utility has a smaller standard error the further the value of the estimate of the mean of the underlying response is from an inflexion point (or “knot”).\nThese are not errors, nor does it mean utility functions with steps, ceilings or floors should be avoided, but these artefacts need to be understood – particularly when graphs of the estimated utility and the true utility are compared.\n\n\n\n\n\n\nNote about FACTS’s utilities\n\n\n\nFACTS’ utility is based on the estimates of the response on each endpoint in each treatment arm. It is not the utility of outcome for each individual that would be a composite score and an endpoint in itself. To use that kind of utility, simulate the external subjects and their scores outside of FACTS using a program or script and calculate the composite score for each individual and write the results to a file in FACTS external virtual subject response format, this can then be used to drive simulations in FACTS of trial designs using that composite score. This might be a single endpoint (FACTS Core Continuous) design, or a Multiple Endpoint design, with the Composite score as the primary endpoint and up to 3 of the component scores as auxiliary endpoints.\nIn this latter case, the design would probably be making decisions based solely on the composite score (so the utility based criteria are unused), and FACTS Multiple Endpoint’s result summarization and charting is used to understand how when different responses are simulated on the component scores this translates into the composite score and the likely trial results.\n\n\n\n\nCalculation of Arms’ probability of having the greatest utility\nLike other probabilities in FACTS this is calculated during the MCMC sampling – the probability that an arm has the greatest probability is based on the proportion of MCMC samples when that arm had the greatest utility. It is not estimated from the utility of the mean estimates of the dose response for the different endpoints.\nIn any given sample if several arms have the same maximum toxicity, the arm with the lowest dose strength is selected. This is particularly useful when using dose response models with plateau features (the Plateau and U-shaped models). It means that where the utility is driven by this model, the arm that will be ranked most likely to have the greatest utility will be the one that lies at the start of the flat maximum response section. However it has a less desirable effect when the overall utility is formed by multiplying the utilities of individual endpoints and one of the endpoint utility functions has a segment where the utility is 0.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/multendpt.html#component-utility-combination-method",
    "href": "documentation/v71/userguides/core/study/multendpt.html#component-utility-combination-method",
    "title": "Study Tab - Multiple Endpoint",
    "section": "Component Utility Combination Method",
    "text": "Component Utility Combination Method\nIn order to derive the overall utility score for a dose we first need to decide how the different utilities are to be used how they are to be combined.\nAt the top of the Endpoint tab is a control that is displayed regardless of which endpoint is being specified. It allows the formula to be selected that defines the values of the individual utility scores for each endpoint are to be combined to form the overall utility. The only operators supported are addition and multiplication, but all logically distinct combinations (given that the user can re-order the auxiliary endpoints) are provided:\n\n\n\n\n\n\nFigure 7: All combinations of endpoint specific utilities into the overall utility.\n\n\n\n\n\n\n\n\n\nGuide for Utility Combination\n\n\n\nUtilities can be combined by multiplying them together or adding together, so when there are just two endpoints there are just two methods of combination: U1 + U2 and U1 * U2. With more endpoints there are more possible combinations. These allow utilities to be formed for a number of circumstances:\n\nOne efficacy and one safety/tolerability endpoint, U1 * U2. Here the purpose of the combination is to scale back the efficacy score if there are safety or tolerability issues. At its simplest, the utility function of the safety / tolerability endpoint is defined so that the estimate of the probability of an adverse event or lack of tolerability is transformed to so the utility is 0 where the safety / tolerability is completely unacceptable, and 1 where it is completely acceptable, with possibly a transition region in between. The utility of the efficacy endpoint could be simply the value of the efficacy endpoint.\nThis is not intended to replace SAE monitoring and the withdrawal of treatments arms that are unsafe, the safety monitoring may be for indicators of potential safety problems when the drug is taken for a longer duration than can be studied, or it may be for tolerability issues that would give compliance problems, or acceptability problems given the other treatments available.\nSome possible variants are: where current treatments have a level of unpleasant side effects, the utility of the probability of a side effect for our drug may be &gt;1 for side effect rates below this. The utility of the efficacy outcome may be 0 below a certain floor efficacy and capped at a maximum above a ceiling efficacy, perhaps to stop undue weight being given to an outcome that this thought unfeasible or avoid a level of utility on the efficacy score that would yield an overall utility that would be judged viable at a poor (but not utility 0) level of safety / tolerability.\nTwo efficacy endpoints, U1 + U2. Here the purpose of the combination is to allow success if either the response on either endpoint is very good, or is quite good on both endpoints. Some care will be required to define the utility functions of the endpoints so that different combinations of efficacy correctly yield sufficient utility or insufficient utility.\nAn efficacy endpoint and a ‘necessary but not sufficient’ biomarker, U1 * U2. Here the purpose of the combination is to yield an overall utility of 0 if the biomarker is not observed at the necessary levels, otherwise the utility is driven by the primary endpoint that is observed much later. This allows early stopping for futility, arm dropping, or adaptive allocation away from arms with poor levels of biomarker, but for success to be determined only on the basis of the primary endpoint.\n\nUtilities with more than two endpoints are usually some form of combination of the above, for example a primary secondary and secondary endpoint and a safety/tolerability endpoint: (U1 + U2) * U3.\n\n\nDevising and agreeing upon utility functions with a clinical team is part art and part science (and possibly, part politics). Some have expressed the opinion that these methods could never be used in practice because it would be impossible to get agreement, but experience shows agreement is possible. Generally, the process followed is roughly as follows:\n\nThe team agrees how the endpoints will be combined and specifies some key utility points – at specific combinations of response at the different endpoints – for example:\n\nIf there were no observed side effects, what is the minimum level of efficacy that would be a useful drug?\nIf the maximum expected level of efficacy was observed, what is the maximum level of side effects that could be observed that would leave a useful drug\nSee “Dose-Finding Based On Efficacy-Toxicity Trade-Offs” by Thall and Cook (2004), for a description of such an elicitation process.\n\nThe statistician creates utility functions for the endpoints that yield the desired overall utility value at the specified points.\nUsing FACTS some simple trials are simulated and example simulated datasets and analyses are studied and reviewed with the team. The team is asked the question “Given the data that was simulated, (and the distributions they were simulated from) what do they think of the utility assigned to the treatment arms?”\nThe statistician adjusts the utility functions and iterates the process of simulating and reviewing with the team.\nOnce the team is happy with individual examples of how utility is assigned, a larger number of simulations can be run and the estimates of the operating characteristics considered and other aspects of the trials design considered.\n\n\nEstimation of Utility in FACTS\nAn important aspect of the way FACTS estimates utility is that it estimates a probability density for the utility within the MCMC sampling. That is, the utility is calculated for every parameter sample within the MCMC, and the final distribution of the utility is based on those samples just like the estimates for the model parameters.\nEach dose has a distribution of utility scores - not a single value. The utility is not estimated from the mean estimates of the dose response from the different endpoints.\nThis has some notable effects on the estimates of utility. If, for example, the utility function is a step function – for example if its value is 1 for response rates below a threshold and 0 above – as the estimate of the response rate will have some uncertainty then when the mean response estimates are around the threshold value, the estimate of utility will be between 0 and 1, based on the proportion of MCMC samples the fitted response rate was below the threshold. Indeed, the utility can be interpreted as the ‘probability the response rate is below the threshold’, and thus be useful or even exactly what is required.\nSimilarly, any utility function that has a floor or ceiling will result in a bias in the estimate of the utility to be above the floor or below the ceiling. – because in the distribution of the values for the utility the lowest the value can be is the floor and the final estimate of the utility would only be at the floor if all the values for the utility sampled in the MCMC were at the floor. Another effect of utilities with a floor or ceiling is that the estimate of the mean utility has a smaller standard error the further the value of the estimate of the mean of the underlying response is from an inflexion point (or “knot”).\nThese are not errors, nor does it mean utility functions with steps, ceilings or floors should be avoided, but these artefacts need to be understood – particularly when graphs of the estimated utility and the true utility are compared.\n\n\nCalculation of Arms’ probability of having the greatest utility\nLike other probabilities in FACTS this is calculated during the MCMC sampling – the probability that an arm has the greatest probability is based on the proportion of MCMC samples when that arm had the greatest utility. It is not estimated from the utility of the mean estimates of the dose response for the different endpoints.\nIn any given sample if several arms have the same maximum toxicity, the arm with the lowest dose strength is selected. This is particularly useful when using dose response models with plateau features (the Plateau and U-shaped models). It means that where the utility is driven by this model, the arm that will be ranked most likely to have the greatest utility will be the one that lies at the start of the flat maximum response section. However it has a less desirable effect when the overall utility is formed by multiplying the utilities of individual endpoints and one of the endpoint utility functions has a segment where the utility is 0.\n\n\n\n\n\n\nCaution when using 0 in your utilities\n\n\n\nHaving segments of utility 0 for an endpoint, and calculating the overall utility by multiplying the component utilities will lead to segments of 0 in the overall utility. If in only a proportion of the MCMC samples all arms have a utility of 0, this will result in that proportion of the probability of being the arm with the maximum utility being placed on the arm with the lowest dose strength, which might be odd given the utility in the other samples. It can lead to counter intuitive and sometimes undesired adaptations, such as in the adaptive allocation of subjects between the arms.\nThe solution is to not use 0 for the segments of low utility, but a small value such as 0.01, the multiplication with the utility of the other endpoints will then not flatten them all to exactly 0, but retain the utility profile at attenuated values.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html",
    "href": "documentation/v71/userguides/core/design/doseresponse.html",
    "title": "Dose Response Models",
    "section": "",
    "text": "Dose response models in FACTS may be more accurately called final endpoint models. They create and model a relationship across the doses specified in the Treatment Arms tab. Often, but not always, the dose strength, called “Effective Dose Strength” in the Study &gt; Treatment Arms tab of FACTS, is used in the dose response models to determine the order of doses, and which doses are more related to others.\nThe dose response models can be simple, and model the doses largely independently, as is done with the Independent Dose Model or the Independent Beta Binomial Model (dichotomous only). They can have logistic style models with interpretable parameters, like the 3-parameter logistic or the \\(E_{max}\\) model (called Sigmoidal in FACTS). The dose response model can also be a model that creates a smooth, spline like, model over the doses using a normal dynamic linear model (NDLM), a monotonic NDLM, or a 2nd order NDLM.\nFor all endpoints, we model the response at each dose, d, in terms of \\(\\theta_d\\) on a continuous scale, allowing a consistent and rich range of dose response models to be used for all endpoint types. Transformations (see below) of the dichotomous and time-to-event responses are used to achieve this.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#independent-dose-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#independent-dose-model",
    "title": "Dose Response Models",
    "section": "Independent Dose Model",
    "text": "Independent Dose Model\nThe “Independent Dose Model” providing a simple pair-wise comparison between the study drug arms and the control arm and/or the active comparator arm. The doses are modelled as independent and normally distributed with a prior of:\n\\[\\theta_d \\sim \\text{N}(\\mu_d, \\nu_d^2)\\]\nWhere \\(\\mu_d\\) and \\(\\nu_d^2\\) are specified in FACTS and can either be the same or vary across arms.\nThis model is useful:\n\nWhen there is only one or two experimental arms\nWhen the study drug arms don’t differ by dose but in other ways, so there is no ordered sequence of treatments – e.g. each arm is the study drug in combination with a different additional drug.\nFor simulating simple trial designs\nFor simulating a ‘conventional’ or ‘strawman’ design to compare more complex designs against\n\nOtherwise for trials with multiple related arms that differ by dose, it is usually more efficient to use a dose-response model.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#independent-beta-binomial-model-dichotomous-only",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#independent-beta-binomial-model-dichotomous-only",
    "title": "Dose Response Models",
    "section": "Independent Beta-Binomial Model (Dichotomous Only)",
    "text": "Independent Beta-Binomial Model (Dichotomous Only)\nThis is a “no model” option similar to the above, but only available for the Dichotomous endpoint. Unlike any other dose response model, this model uses the beta distribution to model the probability of response directly rather than fitting a model to the log-odds of the probability.\nThe final endpoint response \\(Y_i\\) is modeled as:\n\\[Y_i \\sim \\text{Bernoulli}(P_d)\\] where \\(P_d\\) is the probability that a patient is a response at the final endpoint for subjects randomized to dose \\(d\\). With posterior\n\\[P_d \\sim \\text{Beta}(\\alpha_d + \\text{responders}_d, \\beta_d + \\text{non-responders}_d)\\]\nWhere \\(\\alpha_d\\), \\(\\beta_d\\) are the priors for the arm \\(d\\), \\(\\text{responders}_d\\) is the number of responders on arm \\(d\\) and \\(\\text{non-responders}_d\\) is the number of non-responders on arm \\(d\\).\nThis model has the advantages of an easier to understand prior, and better estimation of \\(P_d\\) when the number of responders and non-responders is small (either is &lt; 5) compared to the log-odds model. As it’s a independent dose model, it is well suited to analyzing single arm, two arm or three arm trials, or trials where the experimental arms are unrelated, and so there is no basis on which to borrow information between them. With trials with multiple arms of the same treatment at different doses it is usually more advantageous to fit a dose response model.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#simple-ndlm",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#simple-ndlm",
    "title": "Dose Response Models",
    "section": "Simple NDLM",
    "text": "Simple NDLM\nThe Normal Dynamic Linear Model (NDLM) estimates the final endpoint as a smoothed curve across doses included in the model. Doses are tied directly to their nearest neighbor, and the prior expectation for a dose is that it is equal to its neighboring doses, tending to a constant dose response across doses in the absence of data. The model is defined as follows:\nLet doses \\(d=d', \\ldots, D\\) be doses in the dose response model and \\(\\theta_d\\) be the estimated dose response for dose \\(d\\). The initial dose \\(d'=1\\) if there is no control or control is included in the dose response model, and \\(d'=2\\) if the control arm is modeled separately.\nThe dose response of the first dose, \\(d'\\), has a prior of:\n\\[\\theta_{d'} \\sim N\\left(\\mu_{d'},\\tau^2_{d'}\\right)\\]\nwhere \\(\\mu_{d'}\\) and \\(\\tau_{d'}^2\\) are specified directly in FACTS. Subsequent dose response estimates \\(\\theta_{d'+1}, \\ldots, \\theta_D\\) have priors centered at the previous dose response with variances based on the distance between the dose \\(d\\) strength and the dose \\(d-1\\) strength. Specifically,\n\\[\\theta_d \\sim N\\left(\\theta_{d-1},\\tau^2_{d-1}\\right) \\text{ for } d=d'+1, \\ldots, D\\]\nwhere for dose strengths \\(\\nu_d\\) and \\(\\nu_{d-1}\\), \\(\\tau_{d-1}^2\\) is defined as \\[\\tau^2_{d-1}=\\tau^2\\left(\\nu_d-\\nu_{d-1}\\right)\\]\nThe prior distribution for the “drift” parameter, which controls the amount of smoothing is:\n\\[\\tau^{2}\\sim IG\\left( \\frac{\\tau_{n}}{2},\\frac{\\tau_{\\mu}^{2}\\tau_{n}}{2} \\right)\\]\nwhere \\(\\tau_\\mu\\) and \\(\\tau_n\\) are specified in the Dose Response tab in FACTS under Model Parameters. See here for help with specifying an inverse gamma distribution with center and weight.\nIn the continuous case the residual error around the estimated dose response is\n\\[\\sigma^{2}\\sim IG\\left( \\frac{\\sigma_{n}}{2},\\frac{\\sigma_{\\mu}^{2}\\sigma_{n}}{2} \\right)\\]\nwhere \\(\\sigma_\\mu\\) and \\(\\sigma_n\\) are specified on the Dose Response tab in FACTS under Error Parameters.\nThe Simple NDLM is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Simple NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.\nIn a null scenario where the response on all the doses is the same as control, the simple NDLM reduces type-1 error. The estimate of \\(\\tau^2\\) tends towards zero and the estimate of the dose response tends to a flat line. The smoothing of the estimates of the response reduces the random fluctuations in the estimates from dose to dose and is a very effective counter to the problem of type-1 error inflation due to the multiplicity of doses being tested. A small prior for the mean value of \\(\\tau\\) will accentuate this effect. The price to be paid for this benefit is a tendency to underestimate large changes in response or where there is a peak in the response. This over-smoothing can reduce power. A prior for the mean of \\(\\tau\\) centered at large values will minimize over-smoothing, and a very large prior would simply remove any smoothing effect at all. A standard prior for the mean of \\(\\tau\\) would be the expected average change in response from dose to dose, scaled to take into account the differences in the specified effective dose strengths.\nUsually, the choice of prior for \\(\\tau^2\\) is tuned based on simulation results, trading off reducing type-1 error in the null case against loss of power and reduced estimate of maximum response in the effective scenario with the largest jump in response or steepest peak.\n\n\n\n\n\n\nNote on the use of an NDLM with doses without subjects\n\n\n\n\n\nWhen using the NDLM model or any of its alternatives (2\\(^{nd}\\) order or Monotonic NDLM), and including doses in a design that receive no subject allocation (ie. Allocation ratio set to 0), some important characteristics of the model should be considered in the interpretation of results. First, the NDLM model “borrows” information from neighboring doses, and therefore including unallocated intermediate doses will increase uncertainty in the fitted response. Information must “pass through” these intermediate doses, and uncertainty should be expected to increase as the number of intermediate unallocated doses between two allocated doses increases. Secondly, the NDLM model estimates the response at unallocated doses, but without subject data at these doses the uncertainty in the estimate can be considerably larger than doses with subject data. This high degree of uncertainty can lead to a vestigial probability that an unallocated dose is the target dose (Pr(EDq), Pr(MED), Pr(Max)) even though the mean response estimate and probabilities at neighboring doses with subject data would not suggest this to be the case.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#monotonic-ndlm",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#monotonic-ndlm",
    "title": "Dose Response Models",
    "section": "Monotonic NDLM",
    "text": "Monotonic NDLM\nThe Monotonic NDLM endpoint model is similar to the NDLM in the sense that it smooths dose response estimates using neighboring doses, but is constrained to be either monotonically increasing or monotonically decreasing across doses. The direction of monotonicity depends on the value specified in the “Monotonic:” selection in the Model Parameters section of the Monotonic NDLM Dose Response page.\nThe use of this model is generally limited to endpoints where a strong presumption of increasing/decreasing response with dose is reasonable – such as a biomarker or a toxicity endpoint.\nLet doses \\(d = d', \\ldots, D\\) be doses in the dose response model and \\(\\theta_d\\) be the estimated dose response for dose \\(d\\). The initial dose \\(d'=1\\) if there is no control or control is included in the dose response model, and \\(d'=2\\) if the control arm is modeled separately. The following model is the monotonically positive NDLM:\n\\[\\theta_{d'} \\sim N\\left(\\mu_{d'},\\tau^2_{d'}\\right)\\]\nand\n\\[\\theta_d \\sim N^+\\left(\\theta_{d-1},\\tau^2_{d-1}\\right) \\mbox{ for } d = d', \\ldots, D,\\] where \\(\\tau_{d-1}^2\\) is defined as in the NDLM, and \\(X \\sim \\text{N}^+(\\mu, \\sigma^2)\\) refers to a positive truncated normal distribution with density function:\n\\[f_{X}(x) = \\frac{1 - \\Phi\\left( - \\frac{\\mu}{\\sigma} \\right)}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{ - \\frac{1}{2\\sigma^{2}}(x - \\mu)^{2} \\right\\} \\text{ for } x&gt;0\\]\nThe result of this dose-response model is that the curve is monotonically increasing, in that \\(\\theta_d&gt;\\theta_{d-1}\\).\nThe monotonically decreasing NDLM is similar except: \\[\\theta_d \\sim N^-\\left(\\theta_{d-1},\\tau^2_{d-1}\\right) \\mbox{ for } d = d', \\ldots, D,\\]\nwhere \\(X \\sim \\text{N}^-(\\mu, \\sigma^2)\\) refers to a negative truncated normal distribution:\n\\[f_{X}(x) = \\frac{\\Phi\\left( - \\frac{\\mu}{\\sigma} \\right)}{\\sqrt{2\\pi}\\sigma}\\exp\\left\\{ - \\frac{1}{2\\sigma^{2}}(x - \\mu)^{2} \\right\\} \\text{ for } x&lt;0\\]\nThe result of this dose-response model is that the curve is monotonically decreasing, in that \\(\\theta_d&lt;\\theta_{d-1}\\).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#second-order-ndlm",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#second-order-ndlm",
    "title": "Dose Response Models",
    "section": "Second Order NDLM",
    "text": "Second Order NDLM\nThe second order NDLM serves as a “smoother” similar to the NDLM, however it tends to smooth toward a linear fit with a slope (the NDLM itself tends to shrink each dose’s fit toward its neighbors, while the second order NDLM prefers any trend in the neighbors).\nLet doses \\(d=d', \\ldots, D\\) be doses in the dose response model and \\(\\theta_d\\) be the estimated dose response for dose \\(d\\). The initial dose \\(d'=1\\) if there is no control arm or control is included in the dose response model, and \\(d'=2\\) if the control arm is modelled separately. The initial dose \\(d'\\) is modeled:\n\\[\\theta_{d'} \\sim N\\left(\\mu_{0},\\tau^2_{0}\\right)\\]\nwhere \\(\\mu_0\\) and \\(\\tau_0^2\\) are specified directly in FACTS.\nIn the case of a time-to-event endpoint, the initial dose \\(d'\\) is the control arm, and has a \\(\\theta_{d'}= 0\\) by definition, so no prior distribution is needed.\nThe prior distribution for the dose response for the dose directly after the initial dose is specified on the difference between the \\(d'\\) and \\(d'+1\\) level doses:\n\\[\\theta_{d'+1} - \\theta_{d'} \\sim N\\left(\\mu_{1},\\tau^2_{1}\\right)\\]\nSuccessive doses are then modeled based on differences in slope between the dose and the two doses below them. Let:\n\\[\\theta_{d} = \\theta_{d - 1} + \\Delta_{d}\\zeta_{d} + \\frac{\\Delta_{d}}{\\Delta_{d - 1}}\\left( \\theta_{d - 1} - \\theta_{d - 2} \\right)\\]\nfor doses \\(d=d'+2,\\ldots,D\\), where \\(\\Delta_d=\\nu_d-\\nu_{d-1}\\) and \\(\\Delta_{d-1}=\\nu_{d-1}-\\nu_{d-2}\\). The priors for the dose response smoothing terms \\(\\zeta_d\\) are:\n\\[\\zeta_d \\sim \\text{N}(0, \\tau_2^2)\\] The smoothing is determined by the parameter \\(\\tau_2\\). Small values of \\(\\tau_2\\) lead to more smoothing, while large values of \\(\\tau_2\\) lead to little information sharing between doses (above dose 1). Note that “small” and “large” is dependent on the scale of the doses. The prior on the smoothing parameter is:\n\\[\\tau_{2}^{2}\\sim \\text{IG}\\left(\\frac{\\tau_{n}}{2},\\frac{\\tau_{\\mu}^{2}\\tau_{n}}{2} \\right)\\]\nwhere \\(\\tau_\\mu\\) is a central value for \\(\\tau_2\\), and \\(\\tau_n\\) is the prior weight. See here for help with specifying an inverse gamma distribution with center and weight.\nNote that that in this formulation, \\(\\tau_2^2\\) can be thought of as the deviation from linearity. The linear scaling of deviations thus leads to a conditional variance that scales as the square of the dose difference:\n\\[\\text{Var}[\\theta_d \\mid \\theta_{d-1}, \\theta_{d-2}]=\\tau_2^2\\cdot (\\nu_d-\\nu_{d-1})^2\\]\nThe second order NDLM, like the simple NDLM, is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Second Order NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.\nIn a null scenario where the response on all the doses is the same as control the Second Order NDLM, like the Simple NDLM, tends to reduce type-1 error. As the estimate of \\(\\tau^2\\) tends to zero the estimate of the dose response tends to a line (with non-zero slope if appropriate).\nThe second order NDLM has more power than the Simple NDLM when the dose response is smooth, but will tend to shrink estimates to the control by more than the Simple NDLM if there are marked peaks or steps in the response. Because it borrows from two neighboring doses, it is better at estimating a response for a dose where there is no data than the simple NDLM can, and can be used with burn-in’s where not all doses have been allocated to, but doesn’t cope well if there are consecutive doses where there is no data.\nHowever, unlike the simple NDLMs where the variance structure is preserved if doses are added to or dropped from the design, this is not true for the 2nd order NLDM. Thus, if using the 2nd order NDLM and the doses that are available to the model are changed, then the parameters for the prior for \\(\\tau_2^2\\) may need to be re-visited.\nThe simple NDLM is likely to be preferred where there are fewer doses (4-5), and the second order NDLM is often preferred when there are 7 or more (it will depend on the expected smoothness of the response – the smoother it is the more useful the second order NDLM will be).\nAs with the simple NDLM, the choice of prior for \\(\\tau_2^2\\) can be tuned based on simulation results: balancing having a smaller prior that limits type-1 error in the null case, against having a larger prior that yields more power and better estimate of maximum response in the effective scenarios with the large jumps in response or pronounced peaks.\n\n\n\n\n\n\nNote on the Second Order NDLM before FACTS 4.0\n\n\n\n\n\nThe second order NDLM described in this section is the version utilized in FACTS version 4.0 and later. The model labelled “Second Order NDLM” in versions before 4.0 is was maintained as the model labelled “Legacy 2nd Order NDLM” until the release of FACTS 7.1, at which time it was removed.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#parameter-logistic",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#parameter-logistic",
    "title": "Dose Response Models",
    "section": "3-Parameter Logistic",
    "text": "3-Parameter Logistic\nThe 3-parameter logistic dose response model estimates efficacy as a smooth curve using an intuitive parameterization. The dose response for a dose \\(d\\) with effective dose strength \\(\\nu_d\\) is:\n\\[\\theta_{d} = a_{1} + \\frac{a_{2}v_{d}}{v_{d} + a_{3}}\\]\nWhere the \\(a\\) parameters have the following description:\n\n\\(a_1\\)\n\nthe estimated dose response for a dose of strength 0\n\n\\(a_2\\)\n\nthe estimated change in dose response for a dose with strength ∞ when compared to a dose of strength 0.\n\n\\(a_3\\)\n\nthe estimated ED50, the dose that has 50% of the dose response maximum (\\(a_2\\))\n\n\nThe shape of the 3-parameter logistic curve can vary wildly based on the parameter values, but always starts at \\(a_1\\) at dose strength 0 and monotonically increases to \\(a_1+a_2\\) as the effective dose strength goes to infinity.\nThe following independent prior distributions are assumed:\n\\[a_1\\sim \\text{N}(\\Lambda_1, \\lambda_1^2)\\] \\[a_2\\sim \\text{N}(\\Lambda_2, \\lambda_2^2)\\] \\[a_3\\sim \\text{N}^+(\\Lambda_3, \\lambda_3^2)\\]\nIn the continuous case, the prior distribution for the error term in the 3-Parameter Logistic is Inverse Gamma:\n\\[\\sigma^{2}\\sim IG\\left( \\frac{\\sigma_{n}}{2},\\frac{\\sigma_{\\mu}^{2}\\sigma_{n}}{2} \\right)\\]\nAn advantage of the 3-Parameter Logistic model is that it is has a small number of parameters that have defined, intuitive interpretations. Since there are few parameters it’s generally easy to estimate the parameters even on small amounts of data. Because of the limited flexibility of the logistic curve, the 3-parameter logistic model should only be used when there is evidence that it is appropriate. See the Hierarchical Logistic and Sigmoid (Emax) models for dose response models with a similar pattern, but slightly more flexibility in shape.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-logistic",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-logistic",
    "title": "Dose Response Models",
    "section": "Hierarchical Logistic",
    "text": "Hierarchical Logistic\nThe  hierarchical logistic model Scott Berry’s favorite dose response model.  is an extension of the 3-parameter logistic with the form:\n\\[\\theta_{d} = a_{1} + \\frac{a_{2}v_{d}}{v_{d} + a_{3}} + \\zeta_{d}\\]\nwhere \\(\\zeta_d\\) is a random intercept term that modifies \\(a_1\\) differently for each dose under the constraint that all \\(\\zeta_d\\) must sum to 0.\nThe additional term \\(\\zeta_d\\) is a per dose ‘off-curve’ effect. It allows for a secondary non-parametric dose effect over and above the logistic model. It has been used in circumstances in which there is actually some falling away of effect at the highest dose. This is an example mean fit from 100 simulations. The model fit and error bars are in green, and the true dose responses are shown by the black line.\n\n\n\n\n\n\nFigure 1: An example of a fit from the hierarchical logistic model averaged over 100 simulations. The black line shows the truth, and the green line with error bars shows the model fits.\n\n\n\n\\(\\zeta_d\\) is modelled as:\n\\[\\zeta_d \\sim \\text{N}(0, a_4^2)\\]\nconditioned that\n\\[\\sum_{d}^{}\\zeta_{d} = 0\\]\nAnd \\(a_4^2\\) has an inverse gamma prior:\n\\[a_{4}^{2}\\sim IG\\left( \\frac{\\Lambda_{n}}{2},\\frac{\\Lambda_{\\mu}^{2}\\Lambda_{n}}{2} \\right)\\]\nThe following independent prior distributions are assumed:\n\\[a_1\\sim \\text{N}(\\Lambda_1, \\lambda_1^2)\\] \\[a_2\\sim \\text{N}(\\Lambda_2, \\lambda_2^2)\\] \\[a_3\\sim \\text{N}^+(\\Lambda_3, \\lambda_3^2)\\]\nA typical recommended value for the center of the prior distribution of \\(\\alpha_4\\) is the largest expected likely deviation in true response from the underlying logistic with a weight of 1. The effect of this prior is then checked through simulation of a range of plausible dose response profiles, with a range of designs to check the sensitivity of the final estimate of response to this prior. Additionally, see here for help with specifying an inverse gamma distribution with center and weight.\nIn this model, compared to the ‘plain’ 3-parameter logistic above, it is important that the true ED50 lies within the expected dose range, and that the prior for the ED50, \\(a_3\\), has the majority of its probability mass in the available dose range. For example, if the range of the effective dose strengths is from 0 to \\(\\nu_D\\) then a typical ‘weakly informative’ prior for \\(a_3\\) would be:\n\\[a_{3}\\sim N^{+}\\left( \\frac{\\nu_{D}}{2},\\left( \\frac{\\nu_{D}}{2} \\right)^{2} \\right)\\]\nUsing a weaker prior, such as \\(\\text{N}^+(\\nu_D, \\nu_D^2)\\) leads to a more linear fit. With just this change to the prior for \\(a_3\\) the average of the estimated of the mean response changes from the graph above to:\n\n\n\n\n\n\nFigure 2: An example of hierarchical logistic model fits using a prior that results in a flatter dose response model fit.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#sigmoid-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#sigmoid-model",
    "title": "Dose Response Models",
    "section": "Sigmoid Model",
    "text": "Sigmoid Model\nA sigmoid model (\\(\\text{E}_{\\text{max}}\\)) provides a coherent parameterization of the dose response trend similar to the 3-parameter logistic, but with one extra shape parameter, \\(a_4\\).\nThe model formula is:\n\\[\\theta_{d} = a_{1} + \\frac{(a_{2} - a_{1})v_{d}^{a_{4}}}{{a_{3}}^{a_{4}} + v_{d}^{a_{4}}}\\]\nThe interpretation of the four parameters is:\n\n\\(a_1\\)\n\nthe estimated dose response for a dose of strength 0\n\n\\(a_2\\)\n\nthe estimated dose response for a dose of strength \\(\\infty\\) (slight difference from Logistic models)\n\n\\(a_3\\)\n\nthe estimated ED50, the dose that has 50% of the dose response maximum attainable effect (\\(a_2-a_1\\))\n\n\\(a_4\\)\n\ncontrols the slope of the dose response model at the ED50. A larger value of \\(a_4\\) corresponds to a steeper slope. A value of \\(a_4=1\\) makes the Sigmoid model equivalent to a Three Parameter Logistic model with \\(a_2\\) equal to \\(a_1 + a_2\\) from the Sigmoid model. A value of \\(a_4\\) approaching 0 corresponds to a dose response model that is nearly flat at \\(\\frac{a_{1} + a_{2}}{2}\\). By differentiation, it can be seen that the slope where the effective dose \\(\\nu_d=a_3\\) is \\((a_{2} - a_{1})\\frac{a_{4}}{4a_{3}}\\).\n\n\nThe following independent prior distributions are assumed:\n\\[a_1\\sim \\text{N}(\\Lambda_1, \\lambda_1^2)\\] \\[a_2\\sim \\text{N}(\\Lambda_2, \\lambda_2^2)\\] \\[a_3\\sim \\text{N}^+(\\Lambda_3, \\lambda_3^2)\\] \\[a_3\\sim \\text{N}^+(\\Lambda_4, \\lambda_4^2)\\]\nThe advantage of this model is that it is considerably more flexible than the logistic, but still more efficient to estimate than an NDLM. This model (if applicable) is ideal if the target is an Effective Dose (ED) such as an ED90. Estimating an ED requires estimating the response on control, the maximum response, and the gradient which is requires a lot of data to do well if using no model or a smoothing model such as one of the NDLMs. With the 4-parameter Sigmoid model (or 3-parameter logistic – but that has a more limited applicability due to being significantly less flexible in shape), it’s usually not an issue to estimate the EDx well.\nThe caveats to using this model are:\n\nWhilst being much more flexible than the logistic, it still has model assumptions, in particular monotonicity, that must be met for this to be a reasonable model to be used.\nThe curve is only well estimated if the true ED50 lies within the doses tested.\nLike the hierarchical logistic model above, the prior for \\(a_3\\) should be weakly informative, with the majority of its probability mass in the available dose range. So similarly, if the range of the effective dose strengths is from 0 to \\(\\nu_D\\) then a typical ‘weakly informative’ prior for \\(a_3\\) would be: \\[a_3 \\sim N^{+}\\left( \\frac{\\nu_{D}}{2},\\left( \\frac{\\nu_{D}}{2} \\right)^{2} \\right)\\]\n\n\n\n\n\n\n\nFigure 3: Example of a sigmoid model with \\(\\alpha_1=5\\), \\(\\alpha_2=10\\), \\(\\alpha_3=3\\), and \\(\\alpha_4=5\\).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#u-shaped-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#u-shaped-model",
    "title": "Dose Response Models",
    "section": "U-Shaped Model",
    "text": "U-Shaped Model\nThe U-shaped model when the allows for an initial increase (decrease) in the dose response with dose, followed by a leveling out of the mean, then a decrease (increase). Whether the U-Shaped model increases then decreases or decreases then increases is specified by the user on the Dose Response tab. An example curve for this model is given in the figure below.\nThe dose-response curve can be characterized in four different regions of doses. For the first region, which contains the lowest doses, \\(0&lt;\\nu_d&lt;p_{min}\\), the dose-response curve is increasing (decreasing):\n\\[\\theta_{d} = \\theta_{0} + S \\cdot \\delta \\cdot \\left( \\frac{\\nu_{d}}{p_{\\min}} \\right)^{\\alpha}\\]\nThe next region is the plateau, where the dose-response curve is constant. For \\(p_{min} &lt; \\nu_d &lt; p_{min}+p_{width}\\): \\[\\theta_d=\\theta_0 + S\\cdot\\delta\\] For the third region, the dose-response curve is decreasing (increasing). For \\(p_{min}+p_{width} &lt; \\nu_d &lt; p_{min}+p_{width} + w_{width}\\),\n\\[\\theta_{d} = \\theta_{0} + S \\cdot \\delta \\cdot \\left( 1 - \\frac{\\nu_{d} - \\left( p_{\\min} + p_{width} \\right)}{w_{width}} \\right)^{\\beta}\\]\nFor the final region, the dose-response curve is again constant, at the same level as the zero-dose. For \\(\\nu_d &gt; p_{min}+p_{width} + w_{width}\\), \\[\\theta_d = \\theta_0\\]\nThe parameters of the model are described below:\n\n\\(S\\) is \\(1\\) or \\(-1\\), as determined by the Model is increasing/decreasing radio buttons. \\(S=1\\) if Model is Increasing is selected, indicating that the model starts increasing at low doses.\n\\(\\theta_0\\) represents the zero-strength dose response. Its prior is: \\[\\theta_0 \\sim \\text{N}(\\mu_0, \\sigma_0^2)\\]\n\\(\\delta\\) represents the maximal change in response from the zero-strength dose. It is restricted to be positive, and has a prior of: \\[\\delta \\sim \\text{N}^+(\\mu_\\delta, \\sigma_\\delta^2)\\]\n\\(p_{min}\\) represents the lowest dose at which the maximal change in response from the zero-strength is achieved. It is restricted to be positive, and has a prior of: \\[p_{min} \\sim \\text{N}^+(\\mu_{min}, \\sigma_{min}^2)\\]\n\\(p_{width}\\) represents the width of the plateau – the region where all doses achieve maximal change in response from the zero-strength dose. It is restricted to be positive, and has a prior of: \\[p_{width} ~ \\sim \\text{N}^+(\\mu_{width}, \\sigma_{width}^2)\\]\n\\(w_{width}\\) represents the width of the region for doses beyond the plateau, where response is returning to the zero-strength dose level. It is restricted to be positive, and has a prior of: \\[w_{width} ~ \\sim \\text{N}^+(\\mu_{w}, \\sigma_{w}^2)\\]\n\\(\\alpha\\) determines the rate of change of the dose response curve for doses below the plateau. Values less than \\(1\\) indicate a rapid initial change from baseline, with slower change as the plateau is reached. Values greater than \\(1\\) indicate a slow initial change from baseline, with more rapid change as the plateau is reached. To help avoid identifiability issues, \\(\\alpha\\) is restricted to be between \\(10^{-1}\\) and \\(10^{1}\\). \\(\\alpha\\)’s prior is: \\[\\alpha \\sim \\text{LN}^*(\\mu_\\alpha, \\sigma_\\alpha^2)\\] where \\(\\text{LN}^*()\\) represents the lognormal distribution with truncation constraints at \\(10^{-1}\\) and \\(10^{1}\\).\n\\(\\beta\\) determines the rate of change of the dose response curve for doses beyond the plateau. Values less than \\(1\\) indicate a slow initial change from the plateau level, with more rapid change subsequently. Values greater than \\(1\\) indicate a rapid initial change from the plateau level, with slower change subsequently. To help avoid identifiability issues, \\(\\beta\\) is restricted to be between \\(10^{-1}\\) and \\(10^{1}\\). The prior on \\(\\beta\\) is: \\[\\beta \\sim \\text{LN}^*(\\mu_\\beta, \\sigma_\\beta^2)\\]\n\nThe U-shaped model has seven free parameters, and thus it is inadvisable to use such a model for dose-finding trial designs that contain only a few dose levels. When a small number of doses are available, it may help to constrain the values of \\(\\alpha\\) and \\(\\beta\\) by utilizing small standard deviations in the priors.\n\n\n\n\n\n\nFigure 4: An example dose response curve for the U-shaped model. In this example, \\(\\alpha&lt;1\\) and \\(\\beta &gt; 1\\).",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#plateau-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#plateau-model",
    "title": "Dose Response Models",
    "section": "Plateau Model",
    "text": "Plateau Model\nThe plateau model is a special case of the U-shaped model, in which \\(p_{width}=\\infty\\). That is, there is no return to baseline for high doses. This model eliminates three parameters from the U-Shaped model, since \\(p_{width}\\), \\(w_{width}\\), and \\(\\beta\\) are not used. See the figure below to see an example dose response model for the plateau model that mimics the beginning of the U-Shaped model above.\n\n\n\n\n\n\nFigure 5: An example dose response curve for the Plateau model.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#parameter-exponential-logistic-dichotomous-only",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#parameter-exponential-logistic-dichotomous-only",
    "title": "Dose Response Models",
    "section": "3 Parameter Exponential Logistic (Dichotomous Only)",
    "text": "3 Parameter Exponential Logistic (Dichotomous Only)\nThe 3-parameter exponential logistic model has the following structure:\n\\[\\theta_d = a_1 + a_2 \\nu_d^{a_3}\\]\nWhere \\(\\nu_d\\) is the effective dose strength of dose \\(d\\). This is a logistic model for the dichotomous endpoint because \\(\\theta_d\\) is the log odds ratio of the probability of the response, \\(P_d\\) at dose \\(d\\).\nThe exponent parameter \\(\\alpha_3\\) allows the change in slope at the lower end of the curve to be asymmetric in comparison to the change in curve at the upper end of the curve.\nThe priors for the parameters are:\n\\[a_1\\sim \\text{N}(\\Lambda_1, \\lambda_1^2)\\] \\[a_2\\sim \\text{N}(\\Lambda_2, \\lambda_2^2)\\] \\[a_3\\sim \\text{N}^+(\\Lambda_3, \\lambda_3^2)\\] The interpretations of the parameters defining this model are:\n\n\\(a_1\\)\n\nthe dose response for a dose with strength 0\n\n\\(a_2\\)\n\nthe slope associated with the exponentiated dose strength\n\n\\(a_3\\)\n\na shape parameter modifying the effective dose strength through exponentiation.\n\n\nThe figure below shows an example of two different 3-parameter exponential logistic model fits. Notably, the fit shown in green has an \\(a_3\\) parameter greater than \\(1\\), which leads to faster increases of the response rate model as the effective dose strength increases.\n\n\n\n\n\n\nFigure 6: Two different examples of 3-parameter exponential logistic model fits. The green model has an \\(\\alpha_3\\) parameter greater than 1, which leads to faster increases of the sigmoid model as the effective dose strength increases.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-model",
    "title": "Dose Response Models",
    "section": "Hierarchical Model",
    "text": "Hierarchical Model\nLike the Independent Dose Model, the hierarchical model treats the arms as if they are an unordered set of treatments, but unlike the Independent Dose Model the Hierarchical Model shares information between doses included in the model. The hierarchical model is a way of encouraging the estimates of arm responses to be similar, and the degree of this encouragement can be controlled using parameters of the prior distribution. The hierarchical model assumes that the arm parameters are drawn from the same normal distribution:\n\\[\\theta_d \\sim \\text{N}(\\mu, \\tau^2)\\]\nWhere \\(d\\) is the set of doses included in the model. The prior distributions for \\(\\mu\\) and \\(\\tau^2\\) are\n\\(\\mu \\sim \\text{N}(\\Lambda_\\mu, \\lambda_\\mu^2)\\)\nand\n\\[\\tau^{2}\\sim \\text{IG}\\left(\\frac{\\tau_{n}}{2},\\frac{\\tau_{\\mu}^{2}\\tau_{n}}{2} \\right)\\]\nwhere \\(\\tau_\\mu\\) is a central value for \\(\\tau\\), and \\(\\tau_n\\) is the prior weight. \\(\\tau^2\\) governs the amount of information shared between doses in the model. The estimates of the dose parameters can be encouraged to be close together by choosing a small value for \\(\\tau_\\mu\\) and a large value for \\(\\tau_n\\). See here for a tool to help understand the inverse gamma distribution specified by center and weight parameters.\nThe control arm can be included in the hierarchical model if it is desired to encourage the experimental arms to be similar to the control arm, or excluded from it if the experimental arms are encouraged to be similar to each other but not necessarily to the control arm. This is not true with time-to-event data, when the control arm can only be excluded from the hierarchical model.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#linear-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#linear-model",
    "title": "Dose Response Models",
    "section": "Linear Model",
    "text": "Linear Model\nThe linear model uses a strong assumption of exact linearity between the responses and the dose strengths. (For dichotomous models, the linearity is on the log-odds scale, and the linearity is on the log hazard ratio scale for TTE models.) The model is\n\\[\\theta_d=\\alpha+\\beta\\nu_d\\] for all doses \\(d\\) in the model. Both \\(\\alpha\\) and \\(\\beta\\) are given normal prior distributions:\n\\[\\alpha \\sim \\text{N}(\\Lambda_\\alpha, \\lambda_\\alpha^2)\\] \\[\\beta \\sim \\text{N}(\\Lambda_\\beta, \\lambda_\\beta^2)\\]\nThe linear model is appropriate when there is strong scientific knowledge that the shape of the response curve should be linear as a function of dose strength. Note that if an arm has a dose strength between two other arms in the model, its response will always be estimated to be between the responses of those two arms. As a result, the linear model may not be appropriate in combination with certain decision quantities such as Pr(Max), because some doses are guaranteed to have probability zero of being the best arm. If the control arm is included in the linear model and it has the smallest dose value, then all experimental arms will always have exactly the same probability of being better than control.\nWe recommend creating scenarios where the true parameters deviate from linearity and simulating them to test the robustness of a design based on the linear model.\n\n\n\n\n\n\nNote\n\n\n\nFor dichotomous models, the linear model replaces the 2-parameter logistic model available in FACTS versions before 6.4. The two models are identical.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-linear-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-linear-model",
    "title": "Dose Response Models",
    "section": "Hierarchical Linear Model",
    "text": "Hierarchical Linear Model\nA more flexible version of the linear model is the hierarchical linear model. This model encourages the arm responses to have a linear-like shape, but also includes a term allowing parameters to deviate from linearity when appropriate. The arm parameters satisfy the relationship\n\\[\\theta_d = \\alpha + \\beta \\nu_d + \\zeta_d\\] where the \\(\\alpha\\) and \\(\\beta\\) parameters are as in the linear model, with prior distributions\n\\[\\alpha \\sim \\text{N}(\\Lambda_\\alpha, \\lambda_\\alpha^2)\\] \\[\\beta \\sim \\text{N}(\\Lambda_\\beta, \\lambda_\\beta^2)\\] and the \\(\\zeta_d\\) parameters are the deviations from linearity. These deviations are assumed to have a normal distribution constrained so that their average value is zero:\n\\[\\zeta_d \\sim \\text{N}(0, \\tau^2) \\text{ with } \\sum_d\\zeta_d=0.\\]\nThe prior distribution for \\(\\tau^2\\) is\n\\[\\tau^{2}\\sim\\text{IG}\\left(\\frac{\\tau_{n}}{2},\\frac{\\tau_{\\mu}^{2}\\tau_{n}}{2} \\right)\\]\nIf \\(\\tau^2\\) is small, which can be encouraged by choosing \\(\\tau_\\mu\\) to be small and \\(\\tau_n\\) to be large, then the dose parameter estimates will lie close to a line. See here for help understanding FACTS’s parameterization of the inverse gamma distribution.\nThe hierarchical linear model is a good choice when, for example, one expects a linear relationship between the dose strengths and the response but one is not prepared to assume exact linearity. It can also be a good way of encouraging, but not requiring, monotonicity in the response.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#d-continuous-factorial-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#d-continuous-factorial-model",
    "title": "Dose Response Models",
    "section": "2D Continuous Factorial Model",
    "text": "2D Continuous Factorial Model\nThe 2D Continuous Factorial Model fits a regression on the dose response that uses the numeric dose strength as a continuous valued covariate. The dose response (with \\(\\eta_r\\) and \\(\\zeta_c\\) denoting dose strength of the row level and column level, respectively) is modeled as:\n\\[\\theta_{rc} = \\alpha_0 + \\alpha_1 \\zeta_c + \\alpha_2 \\eta_r + \\alpha_3\\zeta_c \\eta_r\\] With priors\n\\[\\alpha_0 \\sim \\text{N}(\\mu_0, \\sigma_0^2)\\] \\[\\alpha_1 \\sim \\text{N}(\\mu_1, \\sigma_1^2)\\] \\[\\alpha_2 \\sim \\text{N}(\\mu_2, \\sigma_2^2)\\] \\[\\alpha_3 \\sim \\text{N}(\\mu_3, \\sigma_3^2)\\]\nThen, \\(\\alpha_0\\) is the response at the control combination, \\(\\alpha_1\\) is the linear coefficient of the response to the column factor strengths \\(\\zeta_c\\), and \\(\\alpha_2\\) is the linear coefficient of the response to the row factor strengths \\(\\eta_r\\).\nThe user has the option to simplify the model and exclude the interaction term \\(\\alpha_3\\), which is the coefficient of the product of the two factor strengths.\nNote that despite being called “continuous” this dose response model applies to all endpoints. It’s called continuous because the coefficients act on the dose strengths as continuous measures of strength.\n\n\n\n\n\n\nFigure 7: 2D Continuous Factorial Dose Response model specification page.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#d-discrete-factorial-model",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#d-discrete-factorial-model",
    "title": "Dose Response Models",
    "section": "2D Discrete Factorial Model",
    "text": "2D Discrete Factorial Model\nThe 2D Discrete Factorial Model fits a regression on the dose response that uses the dose strength as a factor covariate rather than a numeric dose strength. Each dose is an independent level within each row or column factor, so any dose is equidistant from all other doses\n\\[\\theta_{rc} = \\alpha + \\gamma_r + \\beta_c\\]\nWith priors\n\\[\\alpha \\sim \\text{N}(\\mu_\\alpha, \\sigma_\\alpha^2)\\]\n\\[\\beta_c \\sim \\text{N}(\\mu_{\\beta_c}, \\sigma_{\\beta_c}^2)\\] \\[\\gamma_r \\sim \\text{N}(\\mu_{\\gamma_r}, \\sigma_{\\gamma_r}^2)\\]\nThe parameters associated with lowest level of each factor, \\(\\gamma_0\\) and \\(\\beta_0\\), are constrained to be \\(0\\).\n\n\n\n\n\n\nFigure 8: 2D Discrete Factorial Dose Response model specification page.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#d-ndlm",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#d-ndlm",
    "title": "Dose Response Models",
    "section": "2D NDLM",
    "text": "2D NDLM\nThe 2-D NDLM Model takes the idea of smoothing across doses that was used in the standard NDLM model, but smooths across row factors and column factors separately.\n\nThe Base Model, with Control Included\nThe treatment effect for the combination of level \\(r\\) in the row factor and level \\(c\\) in the column factor is denoted as \\(\\theta_{rc}\\), and \\(Y_{rc}\\) is the observed data in that cell. The borrowing parameters are denoted as \\(\\phi\\) for the row factor smoothing, and \\(\\tau\\) for the column factor smoothing. The dose strengths are denoted as \\(\\nu_r\\) for the row factors, and \\(\\omega_c\\) for the column factors. Let \\(\\Delta \\nu_r = \\nu_r - \\nu_{r-1}\\) and \\(\\Delta \\omega_c = \\omega_c - \\omega_{c-1}\\) (for \\(r&gt;0\\) and \\(c&gt;0\\)). For notational convenience at the grid edge, let \\(\\theta_{-1, c} = 0\\), \\(\\theta_{r,-1}\\), \\(\\Delta\\nu_0\\equiv\\infty\\), and \\(\\Delta\\omega_0\\equiv\\infty\\).\nThe 2-D NDLM Model with control included in the model can then be specified as:\n\\[\\theta_{0,0} \\sim \\text{N}(\\mu_0, \\tau_0^2)\\] \\[\\theta_{rc} \\sim \\text{N}(\\mu_{rc}, \\tau_{rc}^2)\\] where\n\\[\\tau_{rc}^{2} = \\left( \\frac{1}{\\mathrm{\\Delta}\\nu_{r}\\phi^{2}} + \\frac{1}{\\mathrm{\\Delta}\\omega_{c}\\tau^{2}} \\right)^{- 1}\\]\n\\[\\mu_{rc} = \\tau_{rc}^{2}\\left( \\frac{\\theta_{r - 1,c}}{\\mathrm{\\Delta}\\nu_{r}\\phi^{2}} + \\frac{\\theta_{r,c - 1}}{\\mathrm{\\Delta}\\omega_{c}\\tau^{2}} \\right)\\]\nwith priors\n\\[\\tau^{2}\\sim\\text{IG}\\left( \\frac{\\tau_{n}}{2},\\frac{\\tau_{\\mu}^{2}\\tau_{n}}{2} \\right)\\]\n\\[\\phi^{2}\\sim\\text{IG}\\left( \\frac{\\phi_{n}}{2},\\frac{\\phi_{\\mu}^{2}\\phi_{n}}{2} \\right)\\]\nNote: that not all combinations of \\(r\\) and \\(c\\) will have data associated with them. However, FACTS will still evaluate the prior at all combinations. Thus, in the situation depicted below where the grayed-out point indicates a treatment combination with no allocation, \\(\\theta_{1,2}\\) is not modeled conditioned only on \\(\\theta_{1,1}\\). \\(\\theta_{0,1}\\) also informs on \\(\\theta_{1,2}\\) via \\(\\theta_{0,2}\\).\n\n\n\n\n\n\nFigure 9: 2D dosing grid example with no data for (0,2).\n\n\n\n\n\nFix smoothing ratio for row factor and column factor\nOptionally, the user might want to specify the row factor borrowing as a function of the column factor borrowing:\n\\[\\phi\\equiv k \\cdot \\tau\\] where \\(k\\) is a user-specified constant. This can be performed by selecting “Fixed smoothing ratio” in the \\(\\phi^2\\) prior specification area.\n\n\nControl not in model, no zero-level doses\nIf neither treatment arm allows zero-level doses (e.g. like one would expect if the column factor represented doses and the row factor represented frequency), then a prior for the lowest dose would instead be needed as input from the GUI:\n\\[\\theta_{1,1} \\sim \\text{N}(\\mu_1, \\tau_1^2)\\]\n\n\n\n\n\n\nFigure 10: 2D NDLM Dose Response model specification page.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-priors",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#hierarchical-priors",
    "title": "Dose Response Models",
    "section": "Hierarchical Priors",
    "text": "Hierarchical Priors\nIf a hierarchical prior is used for either the Control or Active Comparator arm, then FACTS will estimate a prior for that arm using external data that the user provides. This prior is estimated through a hierarchical model, and then the in-study data collected on subjects randomized to that arm are used to estimate the posterior distribution for the arm.\nTo specify a hierarchical prior, the user specifies the sufficient statistics from each historical study. These are:\n\nContinuous: the mean response and the SD of the response of the control or active comparator arm and the number of subjects observed.\nDichotomous: the observed number of responders and the number of subjects observed in the study.\nTime-to-Event: the number of events and the amount of exposure within each bin in the piecewise model.\n\nThe information from the historical studies can be ‘down-weighted’ by decreasing the effective information in the sample size. For continuous, this can be done by decreasing the sample size by a percentage. For dichotomous, both the number of responders and the number of subjects would be decreased by a percentage. For time-to-event, multiplying the number of events and the exposure by the same fraction will reduce the information in the study without changing the reported hazard rate.\n\n\n\n\n\n\nFigure 11: The Hierarchical Priors tab for a continuous study when both the Control and Active Comparator are given hierarchical priors.\n\n\n\nThe hierarchical models for the control or active comparator rates are very similar across the endpoints. They are briefly described below.\n\nContinuousDichotomousTime-to-Event\n\n\nThe model used for incorporating data from previous trials is as follows:\n\\[\\theta_{0t} \\sim \\text{N}(\\mu_0, \\tau_0^2) \\text{ for } \\tau=0,1,2,\\ldots,T\\] where \\(\\theta_{0t}\\) is the mean for the control arm in trial \\(t\\) (\\(t=0\\) for the current trial and \\(t=1,2,\\ldots,T\\) for previous trials). A user needs to specify appropriate priors for the hyper-parameters:\n\\[\\mu_0 \\sim \\text{N}(m_0, \\sigma_0^2)\\] \\[\\tau_0^2 \\sim \\text{IG}(a_0, b_0)\\]\n\n\nThe model used for incorporating data from previous trials is as follows:\n\\[\\theta_{0t} \\sim \\text{N}(\\mu_0, \\tau_0^2) \\text{ for } \\tau=0,1,2,\\ldots,T\\] where \\(\\theta_{0t}\\) is the log-odds for the control arm in trial \\(t\\) (\\(t=0\\) for the current trial; \\(t=1,2,\\ldots,T\\) for previous trials). A user needs to specify appropriate priors for the hyper-parameters:\n\\[\\mu_0 \\sim \\text{N}(m_0, \\sigma_0^2)\\] \\[\\tau_0^2 \\sim \\text{IG}(a_0, b_0)\\]\nThe prior distributions for the hyper-parameters of the hierarchical model. The hyper-parameters are the mean and standard deviation of Normal distribution for the log hazard ratios of the event rates of the historical studies and the current study.\n\n\nThe model used for incorporating data from previous trials is as follows:\n\\[\\lambda_{st}=\\lambda_s \\exp(\\gamma_t) \\text{ for } t=0,1,2,\\ldots,T\\] where \\(\\lambda_{st}\\) is the hazard rate for the control arm in segment \\(s\\) (\\(s=1,2,\\ldots,S\\)) for previous trial \\(t\\) (\\(t=1,2,\\ldots,T\\)) and \\(\\lambda_{s0}\\) is the hazard rate for the current control arm in segment \\(s\\); \\(\\lambda_s\\) is a base hazard for segment \\(s\\); and \\(\\gamma_t\\) is the log hazard ratio between that base rate and the \\(\\lambda_{st}\\) values.\nThe following hierarchical model is used\n\\[\\gamma_t \\sim \\text{N}(\\mu_\\gamma, \\tau_\\gamma^2) \\text{ for } t=0,1,2,\\ldots,T\\] Users specify priors for the hyper-parameters:\n\\[\\mu_\\gamma \\sim \\text{N}(m_\\gamma, t_\\gamma^2)\\] \\[\\tau^2 \\sim \\text{IG}(a_\\gamma, b_\\gamma)\\]\nThe formulation above is not identifiable as changes in \\(\\lambda_s\\) can be compensated for by changes in the \\(\\gamma_t\\) values (thus, one can use different combination of \\(\\lambda_s\\) and \\(\\gamma_t\\), but acquire the same set of values \\(\\lambda_{st}\\) and thus the same likelihood). To avoid this difficulty, we use the above formulation but fix \\(\\gamma_0 = 0\\). In addition to preserving the identifiability of the structure, this constraint allows \\(\\lambda_s\\) to have the interpretation of being the hazard rate for the current control arm, and thus the prior on \\(\\lambda_s\\) from the main dose response may be used as the prior for \\(\\lambda_s\\).\n\n\n\n\nSetting Priors for Hierarchical Model Hyper Parameters\nUnless the intent is to add information that is not included in the historic studies, the hyper parameters can and should be set so that they are ‘weak’ priors, centered on the expected values.\nIn this case the following would be reasonable:\n\nSet the prior mean value for Mu as the mean of the mean responses on the control arm in the historic studies\nSet the prior SD for Mu equal to the average SD of response divided by the square root of the number of studies.\nSet the center for tau to the same value as the prior SD for Mu.\nSet the weight for tau to be &lt; 1.\n\nOne can traverse the spectrum from ‘complete pooling of data’ to ‘completely separate analyses’ through the prior for tau. If the weight of the prior for tau is small (relative to the number of studies), then (unless set to a very extreme value) the mean of the prior for tau will have little impact and the degree of borrowing will depend on the observed data.\nTo give some prior preference towards pooling or separate analysis the weight for tau has to be large (relative to the number of historic studies) – to have a design that is like pooling all the historic studies the mean for tau needs to be small (say 10% or less of the value suggested above). For there to be no borrowing from the historic studies the value for tau needs to be large (say 10x or more the value suggested above).\nThe best way to understand the impact of the priors is try different values and run simulations.\n\n\nBayesian Augmented Control (BAC) Example:\nIt is easiest to study the impact of BAC in a simplified version of the trial being designed, for example use a 2 arm fixed design with ‘no model’, no adaptation, no longitudinal modeling, etc.\nFor instance, in a continuous setting with an expected sample size of 50 on control, a mean response of 5 and an SD in the response of 2, looking at the effect of having 4 prior, similarly sized studies:\n\n\n\nExternal Study Sufficient Statistics\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of subjects\n\n\nMean Response\n\n\nSD of Response\n\n\n\n\n\n\nStudy 1\n\n\n50\n\n\n4.76\n\n\n2\n\n\n\n\nStudy 2\n\n\n50\n\n\n4.93\n\n\n2\n\n\n\n\nStudy 3\n\n\n50\n\n\n5.07\n\n\n2\n\n\n\n\nStudy 4\n\n\n50\n\n\n5.24\n\n\n2\n\n\n\n\nFor simplicity we have just varied the means of the studies – they are all consistent with a normally distributed estimate, with mean of 5 and a standard error of \\(\\frac{2}{\\sqrt{50}}\\).\nBy simulating a fixed trial with a sample size of 100 and fixed 1:1 allocation between control and a study arm we can easily observe the effects of a BAC on the control arm. Creating 6 VSR profiles with sigma = 2, and the same mean response for control and the study arm in each profile of: 4.53, 4.76, 5.07, 5.24 and 5.47 we can look at the bias of the final estimate and the shrinkage in the SD of the estimate that could be brought about by using BAC:\n\n\n\nQuick simulation study of how the hierarchical model for BAC effects estimates of the control rate under different true control rate scenarios.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrue Mean\n\n\nRaw mean\n\n\nRaw SD\n\n\nEstimate inc BAC\n\n\nSD inc BAC\n\n\nBias\n\n\nEffective additional Subjects\n\n\n\n\n\n\n4.53\n\n\n4.55\n\n\n0.28\n\n\n4.64\n\n\n0.255\n\n\n2.1%\n\n\n11.1\n\n\n\n\n4.76\n\n\n4.78\n\n\n0.28\n\n\n4.83\n\n\n0.250\n\n\n1.0%\n\n\n13.5\n\n\n\n\n4.93\n\n\n4.95\n\n\n0.28\n\n\n4.96\n\n\n0.248\n\n\n0.2%\n\n\n14.3\n\n\n\n\n5.07\n\n\n5.09\n\n\n0.28\n\n\n5.07\n\n\n0.248\n\n\n-0.4%\n\n\n14.2\n\n\n\n\n5.24\n\n\n5.26\n\n\n0.28\n\n\n5.20\n\n\n0.250\n\n\n-1.1%\n\n\n13.2\n\n\n\n\n5.46\n\n\n5.49\n\n\n0.28\n\n\n5.38\n\n\n0.255\n\n\n-1.9%\n\n\n10.7\n\n\n\n\nNote it is important to use the column “SD Mean resp 1” from the simulations file to see the SD of the estimate and not use the SD of the estimates in the summary table.\nThe small shrinkage in the SD is more impressive when viewed in terms of how many additional subjects would have to be recruited to achieve the same shrinkage in the raw estimate. These are useful savings for small additional bias.\nThe “effective additional subjects” was calculated: \\[\\left( \\frac{\\text{True sigma}}{\\text{AVG(SD Mean resp)}} \\right)^{2} - \\left( \\frac{\\text{True sigma}}{\\text{AVG(SE Mean Raw Response)}} \\right)^{2}\\] where in this example \\(\\text{True sigma}\\) was 2.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/design/doseresponse.html#time-to-event-missingness",
    "href": "documentation/v71/userguides/core/design/doseresponse.html#time-to-event-missingness",
    "title": "Dose Response Models",
    "section": "Time-to-Event Missingness",
    "text": "Time-to-Event Missingness\nFor a time-to-event endpoint, as is the convention in this endpoint, subjects are observed up to the time they have an event (or the end of follow up), so no subject drops out after having had an event. Subjects that do drop-out are included in the analysis as not having had an event up to the last observation of the subject.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Design",
      "Dose Response Models"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/tte.html",
    "href": "documentation/v71/userguides/core/study/tte.html",
    "title": "Study Tab - Time-to-Event Endpoint",
    "section": "",
    "text": "The Study Info sub-tab provides parameters for specifying rules and methods for common clinical trial simulation features. These include whether interim analyses will be simulated, if a predictor is used to impute subject event times, sample size, maximum number of events, follow-up times, and more.\n\n\n\n\n\n\nFigure 1: The study tab for a time-to-event trial.\n\n\n\n\n\n\n\nWhether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether an early predictor is to be included in the design. An early predictor can be a continuous or dichotomous outcome, or a precursor event. The user specifies whether higher score, a response, or precursor event is a positive or negative outcome for the subject (this is used in the comparison with the CSD – not in the relation between the predictor and the final event, that is solely down to the parameters entered on the virtual subject response tabs). For continuous or dichotomous predictors, the user specifies after what time (weeks after randomization) the predictor is observed. For all predictors a clinically significant difference can be specified which can be used to specify early stopping or final evaluation conditions on the predictor. If the predictor is continuous, the value is delta on the mean difference between a study arm and control, if dichotomous, the value is the difference in rate and if the predictor is a precursor event then the value is a clinically significant hazard ratio.\nIf an early predictor is included, then a ‘Predictor’ tab is added to the Virtual Subject Response tabs, and a Predictor tab is added to the Design tabs, with a predictor Dose Response sub-tab and Relationship to Endpoint sub-tab.\n\n\n\n\n\n\nThe maximum number of subjects that can be recruited into the study and the maximum number of events to be observed (if there is a time-to-event predictor, the maximum events to be observed can be specified to be the predictor events).\n\n\n\nDetermine what counts as an event when determining when the trial should be stopped due to reaching the number of events specified in the “Maximum number of events” box. The options are “Final events” and “Predictor events.”\n\n\n\nThe maximum number of events (type of event specified above) allowed in the trial. When this value is reached the trial moves on to the final analysis stage.\n\n\n\nThe maximum follow-up time per subject. No subject will be followed for longer than this. If the study does not stop early it will stop when every subject recruited has reached their maximum follow-up time or has had an event. With this option all subjects have the same maximum follow-up.\n\n\n\nThe follow-up time after full enrolment. If the study does not stop early then it will stop the specified time after full enrolment or when every subject has had an event. With this option subjects recruited earlier may be follow-up for longer than subjects recruited later in the trial and the overall amount of exposure is maximized.\n\n\n\nWhether an event indicates a success (time to recovery) or a failure (death or progression) for a subject. The value specified here also dictates the direction of frequentist tests and predictive probabilities.\n\n\n\nDictate whether subjects are recruited sequentially or deterministically.\nIf recruited sequentially, the user recruitment will be simulated stochastically using a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Time-to-Event"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/tte.html#design-options",
    "href": "documentation/v71/userguides/core/study/tte.html#design-options",
    "title": "Study Tab - Time-to-Event Endpoint",
    "section": "",
    "text": "Whether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether an early predictor is to be included in the design. An early predictor can be a continuous or dichotomous outcome, or a precursor event. The user specifies whether higher score, a response, or precursor event is a positive or negative outcome for the subject (this is used in the comparison with the CSD – not in the relation between the predictor and the final event, that is solely down to the parameters entered on the virtual subject response tabs). For continuous or dichotomous predictors, the user specifies after what time (weeks after randomization) the predictor is observed. For all predictors a clinically significant difference can be specified which can be used to specify early stopping or final evaluation conditions on the predictor. If the predictor is continuous, the value is delta on the mean difference between a study arm and control, if dichotomous, the value is the difference in rate and if the predictor is a precursor event then the value is a clinically significant hazard ratio.\nIf an early predictor is included, then a ‘Predictor’ tab is added to the Virtual Subject Response tabs, and a Predictor tab is added to the Design tabs, with a predictor Dose Response sub-tab and Relationship to Endpoint sub-tab.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Time-to-Event"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/tte.html#study-information",
    "href": "documentation/v71/userguides/core/study/tte.html#study-information",
    "title": "Study Tab - Time-to-Event Endpoint",
    "section": "",
    "text": "The maximum number of subjects that can be recruited into the study and the maximum number of events to be observed (if there is a time-to-event predictor, the maximum events to be observed can be specified to be the predictor events).\n\n\n\nDetermine what counts as an event when determining when the trial should be stopped due to reaching the number of events specified in the “Maximum number of events” box. The options are “Final events” and “Predictor events.”\n\n\n\nThe maximum number of events (type of event specified above) allowed in the trial. When this value is reached the trial moves on to the final analysis stage.\n\n\n\nThe maximum follow-up time per subject. No subject will be followed for longer than this. If the study does not stop early it will stop when every subject recruited has reached their maximum follow-up time or has had an event. With this option all subjects have the same maximum follow-up.\n\n\n\nThe follow-up time after full enrolment. If the study does not stop early then it will stop the specified time after full enrolment or when every subject has had an event. With this option subjects recruited earlier may be follow-up for longer than subjects recruited later in the trial and the overall amount of exposure is maximized.\n\n\n\nWhether an event indicates a success (time to recovery) or a failure (death or progression) for a subject. The value specified here also dictates the direction of frequentist tests and predictive probabilities.\n\n\n\nDictate whether subjects are recruited sequentially or deterministically.\nIf recruited sequentially, the user recruitment will be simulated stochastically using a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Time-to-Event"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/dichotomous.html",
    "href": "documentation/v71/userguides/core/study/dichotomous.html",
    "title": "Study Tab - Dichotomous Endpoint",
    "section": "",
    "text": "The Study Info sub-tab provides parameters for specifying rules and methods for common clinical trial simulation features. These include accrual style, visit schedule, whether interim analyses will be simulated, and more.\n\n\n\n\n\n\nFigure 1: The study tab for a dichotomous trial.\n\n\n\n\n\nIn the design options section of the Study tab the user gets check boxes for whether they want to enable adaptive features, use longitudinal modelling, or include simulation of baseline. These options have the following effects on the trial simulation.\n\n\nWhether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether longitudinal modeling is going to be used. If longitudinal modeling is not selected, some longitudinal specific parameters and tabs are hidden. If use longitudinal modeling is selected, FACTS expects that the early endpoint data will be used, it cannot be ignored. If intermediate data is not intended to be used in the modeling, then it should not be simulated in FACTS.\n\n\n\nIf “Use Longitudinal Modeling” is selected, then special longitudinal options can be turned on.\n\n\nIf this option is selected, then the endpoint is actually simulated as a dichotomized continuous response – e.g. a “responder analysis” where a subject with a change from baseline above (or below) a certain threshold is a ‘responder’ and otherwise is not.\nWhen using a dichotomized response, the longitudinal analysis is on the underlying continuous response rather than the dichotomous responder endpoint. After imputing subject values based on intermediate subject data they are dichotomized.\n\n\n\nWhen using the restricted Markov model a subject can be in one of 3 states “Success”, “Failure” or “Stable.” Once the subject has become a “Success” or “Failure” they are  fixed in that state Success and Failure are called “absorbing states. , and it will be their final outcome.\nAll subjects are initially in the “Stable” state and may or may not transition to another state during follow-up. If a subject finishes follow-up in the “Stable” state, they must be classified as failure or success.\n\n\n\n\n\nThe study information section allows the user to specify how subject accrual should be simulated, and whether a larger endpoint value indicates improvement or not.\n\n\nSubject accrual can be configured to be done continuousl, in cohorts, or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited in cohorts the user specifies:\n\nThe size of the first cohort\nThe size of subsequent cohorts\nThe maximum number of cohorts\nThe time (in weeks) to recruit each cohort\n\nThe “Maximum number of subjects” and “Maximum trial duration” fields are automatically updated to reflect the cohort parameters entered.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nIndicate whether a response indicates the subject improving or worsening (and thus whether a higher or lower response rate is a good thing). The value provided here informs the  direction of frequentist hypothesis tests All FACTS frequentist tests are 1-sided.  and the evaluation of QOIs like Pr(Max) and predictive probabilities.\n\n\n\nIf “Use longitudinal modeling” is not checked, then the post baseline visit specification is simple. The only required entry is the time it takes to observe a subject’s final endpoint.\nIf “Use longitudinal modeling” is checked, the follow-up period for subjects is slightly more involved. Visits are specified one at a time, by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.\n\n\n\n\n\n\nFigure 2: The control for setting up the visit schedule.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/dichotomous.html#design-options",
    "href": "documentation/v71/userguides/core/study/dichotomous.html#design-options",
    "title": "Study Tab - Dichotomous Endpoint",
    "section": "",
    "text": "In the design options section of the Study tab the user gets check boxes for whether they want to enable adaptive features, use longitudinal modelling, or include simulation of baseline. These options have the following effects on the trial simulation.\n\n\nWhether the design is adaptive or fixed. If “adaptive features” are enabled, some adaptive specific parameters and tabs are added to the GUI, such as the tabs for defining interims, early stopping criteria, and adaptive allocation.\n\n\n\nWhether longitudinal modeling is going to be used. If longitudinal modeling is not selected, some longitudinal specific parameters and tabs are hidden. If use longitudinal modeling is selected, FACTS expects that the early endpoint data will be used, it cannot be ignored. If intermediate data is not intended to be used in the modeling, then it should not be simulated in FACTS.\n\n\n\nIf “Use Longitudinal Modeling” is selected, then special longitudinal options can be turned on.\n\n\nIf this option is selected, then the endpoint is actually simulated as a dichotomized continuous response – e.g. a “responder analysis” where a subject with a change from baseline above (or below) a certain threshold is a ‘responder’ and otherwise is not.\nWhen using a dichotomized response, the longitudinal analysis is on the underlying continuous response rather than the dichotomous responder endpoint. After imputing subject values based on intermediate subject data they are dichotomized.\n\n\n\nWhen using the restricted Markov model a subject can be in one of 3 states “Success”, “Failure” or “Stable.” Once the subject has become a “Success” or “Failure” they are  fixed in that state Success and Failure are called “absorbing states. , and it will be their final outcome.\nAll subjects are initially in the “Stable” state and may or may not transition to another state during follow-up. If a subject finishes follow-up in the “Stable” state, they must be classified as failure or success.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/dichotomous.html#study-information",
    "href": "documentation/v71/userguides/core/study/dichotomous.html#study-information",
    "title": "Study Tab - Dichotomous Endpoint",
    "section": "",
    "text": "The study information section allows the user to specify how subject accrual should be simulated, and whether a larger endpoint value indicates improvement or not.\n\n\nSubject accrual can be configured to be done continuousl, in cohorts, or deterministically.\nIf recruited continuously, the user recruitment will be simulated stochastically with a Poisson process, using the parameters specified on the Execution &gt; Accrual tab.\nIf recruited in cohorts the user specifies:\n\nThe size of the first cohort\nThe size of subsequent cohorts\nThe maximum number of cohorts\nThe time (in weeks) to recruit each cohort\n\nThe “Maximum number of subjects” and “Maximum trial duration” fields are automatically updated to reflect the cohort parameters entered.\nIf recruited deterministically, the user specifies the recruitment date of every subject recruited by uploading a file of dates on the Execution &gt; Accrual tab.\n\n\n\nIndicate whether a response indicates the subject improving or worsening (and thus whether a higher or lower response rate is a good thing). The value provided here informs the  direction of frequentist hypothesis tests All FACTS frequentist tests are 1-sided.  and the evaluation of QOIs like Pr(Max) and predictive probabilities.\n\n\n\nIf “Use longitudinal modeling” is not checked, then the post baseline visit specification is simple. The only required entry is the time it takes to observe a subject’s final endpoint.\nIf “Use longitudinal modeling” is checked, the follow-up period for subjects is slightly more involved. Visits are specified one at a time, by entering the required week value for the visit and then clicking ‘Add’, or by specifying a regularly spaced sequence: select ‘Auto-Generate’, enter the number of visits, the week of the first visit and the number of weeks between each visit and then click ‘Generate’.\nIndividual visits can be deleted by selecting them in the list and clicking ‘Delete’. The default visit names can be edited by clicking the visit name and typing. The week and the index cannot be changed. Should it be necessary to change the week of a visit, the incorrect visit must be deleted and a new one with the correct week number added.\n\n\n\n\n\n\nFigure 2: The control for setting up the visit schedule.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/study/dichotomous.html#d-treatment-arm-model",
    "href": "documentation/v71/userguides/core/study/dichotomous.html#d-treatment-arm-model",
    "title": "Study Tab - Dichotomous Endpoint",
    "section": "2D Treatment Arm Model",
    "text": "2D Treatment Arm Model\nIf the user checks the “Use 2D treatment arm model” option, the screen changes to allow the treatment strengths to be specified on 2 axes, and to specify which of the treatment combinations thus created will actually included as arms in the trial.\n\n\n\n\n\n\nFigure 4: The Study &gt; Treatment Arms tab when using a 2D treatment arm model.\n\n\n\nThe user now specifies strengths as “Column Factors” and “Row factors”. For example, the Column factors could be different dose strengths and the row factors could be different dosing regimens, or different treatments that the investigational treatment could be combined with. Because of the way the factors are shown in FACTS graphs it is better to use the factor with the greater number of values as the column factor. From the point of view of the analysis however the factors are treated symmetrically. In FACTS we have adopted the neutral term “factor” to avoid the impression that these designs can only apply to doses and dosing regimens.\nFACTS then shows all the potential combinations of column and row factors in the list “Select doses to be used in trial” in which the user selects which of the factor combinations that will be present as arms in the trial. FACTS constructs the “effective strengths” opf the combinations by simply adding together the strengths of the two factors, but while the strengths of the factors (like the strengths of “doses” in the 1D setting) cannot be simply changed (because of the problems of managing the ordering of the factors), strengths of combinations can be directly edited, and indeed must be edited to resolve any “ties”. All combinations must have unique strengths so that they can be ranked in order.\nIf a control treatment arm is included in the trial then a “Control” factor is included in the Column factors and the user selects which combination of this factor and a Row factor is the Control combination. This combination is given the effective strength 0 and moved to the head of the list of doses. If the “include a control treatment arm” option is checked, there must be a combination that acts as control dose. If the option is not checked there will be no control dose.\nFACTS displays the resulting ordered list of combinations in the “Doses in trial” column.\nThere is also a “Show grid” option that will display a small graphic of the 2D layout of these “Doses in trial”:\n\n\n\n\n\n\nFigure 5: The dosing grid for a 2D dosing model with 2 row factor levels and 4 column factor levels.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Study",
      "Dichotomous"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html",
    "title": "Multiple Endpoint Output",
    "section": "",
    "text": "To enable swift visualization and analysis of the simulation results, FACTS has a number of pre-defined graphs it can display. Full and detailed simulation results are available in ‘.csv’ format files that can be loaded into other analysis tools allowing any aspect of the simulation to be explored. These files are described below.\nThe graphs in the multiple endpoint engine are largely the same as the graphs in the single endpoint engine, except that the graphs from the single endpoint core engines that show responses for an endpoint now have a control allowing for the selection of which endpoint the plot should be made for.\nThis page will attempt to highlight differences between the single endpoint and the multiple endpoint engines, largely focusing on plots that do not exist in the single endpoint output. See Continuous/Dichotomous Simulation Output for full details about the single endpoint graphs in FACTS.\n\n\nMany of the multiple endpoint graphs are repeated from single endpoint, potentially with the ability to view for any of the simulated endpoints. When the endpoint to use can be selected in the controls for a plot, it is common that the utility can also be selected instead of an endpoint. This will allow for assessment of the distribution of the combined utility in addition to the response estimates for the individual endpoints. The repeated graphs are listed here:\n\nAllocation Box and Whisker Plot\n&lt;Endpoint&gt; Response and Subject Allocation\n&lt;Endpoint&gt; Response and Target Selection\nPer Dose: QOI Box and Whisker Plots\nTarget Response by Sample Size Scatter Plot\nCumulative Operating Characteristics Plot\nTime Course for Stopping\nTime Course for Arm Dropping/Retention\nArm Retention Proportion\nFrequentist P(significance)\nFrequentist Response and Significance\nPer Sim: &lt;Endpoint&gt; Response Alloc\nPer Sim: &lt;Endpoint&gt; Response Dist\nPer Interim: &lt;Endpoint&gt; Response Alloc\nPer Interim: &lt;Endpoint&gt; Response Dist\nExplore Final Success/Futility Criteria\nExplore Early Success/Futility Criteria\nExplore Arm Dropping Criteria\nExplore Success/Futility Contours\n\n\n\n\n\n\n\n\n\nFigure 1: Utility and Subject Allocation.\n\n\n\nThis graph displays a histogram of the mean subject allocation and a line graph of the mean estimated utility. These plots show:\n\nThe blue bars show the mean number of subjects allocated to each arm over the simulations.\nThe green dashed line is the average of the mean estimate of utility over the simulations\nThe black line is the true utility of the combination of the underlying response profiles being simulated for all the endpoints.\nThe green vertical lines around the green dashed line shows the range of the central 95% of mean estimates of utility over the simulations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Utility and Ppn Greatest Pr(UMax)\n\n\n\n\n\n\n\n\n\n\n\n(b) Utility and Ppn Greatest Pr(UMin absolute: Delta=0.5)\n\n\n\n\n\n\n\nFigure 2\n\n\n\nThese plots show the utility of the true simulated response profiles and the mean and 95% spread of the mean estimate of utility ratios along with bars showing the proportion of simulations the different treatment arms are the finally selected target:\n\nThe dose with the maximum utility (left)\nThe Minimum Acceptable Utility Dose (Umin), the dose most likely to be the minimum dose that exceeds the Clinically Significant Minimum Utility (CSMU) of 0.5 (right)\n\n\n\n\nThis box and whisker plot shows the distribution of the estimate of utility for each dose:\n\n\n\n\n\n\nFigure 3: Utility Boxplot\n\n\n\n\n\n\nThis set of graphs show the final utility analysis at the end of individual simulations.\n\n\n\n\n\n\nFigure 4: Estimated Utility for all endpoints and overall, as well as the number of subjects allocated to each arm.\n\n\n\nThese graphs includes a control that allows the user to select which simulation to graph the results from.\nOn each graph\n\nThe black line shows the ‘True’ overall utility of the response profiles being simulated.\nThe green solid line shows the estimate of overall utility\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of utility.\nThe additional lines (here khaki, blue and brown) show the estimates of utility of the individual endpoints.\nThe blue bars show the number of subjects finally allocated to each arm.\n\n\n\n\nThis set of graphs show the final utility analysis at the end of individual simulations. This is the graph that’s shown when the Endpoint control is chosen to be “Utility” in the “Per Sim: Utility/Response Dist” plotting controls.\n\n\n\n\n\n\nFigure 5: Estimated Utility for all endpoints and overall, as well as the estimate of a chosen QOI\n\n\n\nOn each graph\n\nThe black line shows the ‘True’ overall utility of the response profiles being simulated.\nThe green solid line shows the estimate of overall utility\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of utility.\nThe additional lines (here khaki, blue and brown) show the estimates of utility of the individual endpoints.\nThe blue bars show the final values of a selected Utility QOI.\n\n\n\n\nThis is an identical set of graphs to the Per Sim: Utility and Subject Allocation and Per Sim: Utility and QOI plots, except that in addition to the control to select which simulation to graph the results from, there is a control to select which interim within the simulation to graph the results from. These graphs are only available for those simulations for which ‘weeks’ files have been output (by default the first 100). number of files to be read and subsequent processing of the data.\n\n\n\n\nThe Across Scenario graphs for the multiple endpoint engine are the same as the graphs available in the individual continuous and dichotomous engines.\nFor reference, these are:\n\nSelected Arms\nQOI Box Plots\nPpn Success\nResponse/Utility\nAllocation\nInterim vs Final Scatter Plot\nReceiver Operating Characteristics\n\nThe only differences from the single endpoint across scenario graphs are:\n\nQOI Box Plots graph now has Utility as a selectable endpoint and the utility QOIs are available to be plotted\nRespnnse/Utility is the same as the single endpoint Response graph, except that Utility is a selectable endpoint\nInterim vs Final Scatter Plot now has utility QOIs\nReceiver Operating Characteristics plots now have utility QOIs.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#per-scenario-graphs",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#per-scenario-graphs",
    "title": "Multiple Endpoint Output",
    "section": "",
    "text": "Many of the multiple endpoint graphs are repeated from single endpoint, potentially with the ability to view for any of the simulated endpoints. When the endpoint to use can be selected in the controls for a plot, it is common that the utility can also be selected instead of an endpoint. This will allow for assessment of the distribution of the combined utility in addition to the response estimates for the individual endpoints. The repeated graphs are listed here:\n\nAllocation Box and Whisker Plot\n&lt;Endpoint&gt; Response and Subject Allocation\n&lt;Endpoint&gt; Response and Target Selection\nPer Dose: QOI Box and Whisker Plots\nTarget Response by Sample Size Scatter Plot\nCumulative Operating Characteristics Plot\nTime Course for Stopping\nTime Course for Arm Dropping/Retention\nArm Retention Proportion\nFrequentist P(significance)\nFrequentist Response and Significance\nPer Sim: &lt;Endpoint&gt; Response Alloc\nPer Sim: &lt;Endpoint&gt; Response Dist\nPer Interim: &lt;Endpoint&gt; Response Alloc\nPer Interim: &lt;Endpoint&gt; Response Dist\nExplore Final Success/Futility Criteria\nExplore Early Success/Futility Criteria\nExplore Arm Dropping Criteria\nExplore Success/Futility Contours\n\n\n\n\n\n\n\n\n\nFigure 1: Utility and Subject Allocation.\n\n\n\nThis graph displays a histogram of the mean subject allocation and a line graph of the mean estimated utility. These plots show:\n\nThe blue bars show the mean number of subjects allocated to each arm over the simulations.\nThe green dashed line is the average of the mean estimate of utility over the simulations\nThe black line is the true utility of the combination of the underlying response profiles being simulated for all the endpoints.\nThe green vertical lines around the green dashed line shows the range of the central 95% of mean estimates of utility over the simulations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Utility and Ppn Greatest Pr(UMax)\n\n\n\n\n\n\n\n\n\n\n\n(b) Utility and Ppn Greatest Pr(UMin absolute: Delta=0.5)\n\n\n\n\n\n\n\nFigure 2\n\n\n\nThese plots show the utility of the true simulated response profiles and the mean and 95% spread of the mean estimate of utility ratios along with bars showing the proportion of simulations the different treatment arms are the finally selected target:\n\nThe dose with the maximum utility (left)\nThe Minimum Acceptable Utility Dose (Umin), the dose most likely to be the minimum dose that exceeds the Clinically Significant Minimum Utility (CSMU) of 0.5 (right)\n\n\n\n\nThis box and whisker plot shows the distribution of the estimate of utility for each dose:\n\n\n\n\n\n\nFigure 3: Utility Boxplot\n\n\n\n\n\n\nThis set of graphs show the final utility analysis at the end of individual simulations.\n\n\n\n\n\n\nFigure 4: Estimated Utility for all endpoints and overall, as well as the number of subjects allocated to each arm.\n\n\n\nThese graphs includes a control that allows the user to select which simulation to graph the results from.\nOn each graph\n\nThe black line shows the ‘True’ overall utility of the response profiles being simulated.\nThe green solid line shows the estimate of overall utility\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of utility.\nThe additional lines (here khaki, blue and brown) show the estimates of utility of the individual endpoints.\nThe blue bars show the number of subjects finally allocated to each arm.\n\n\n\n\nThis set of graphs show the final utility analysis at the end of individual simulations. This is the graph that’s shown when the Endpoint control is chosen to be “Utility” in the “Per Sim: Utility/Response Dist” plotting controls.\n\n\n\n\n\n\nFigure 5: Estimated Utility for all endpoints and overall, as well as the estimate of a chosen QOI\n\n\n\nOn each graph\n\nThe black line shows the ‘True’ overall utility of the response profiles being simulated.\nThe green solid line shows the estimate of overall utility\nThe green dashed lines show the boundaries of the 95% credible interval for the estimate of utility.\nThe additional lines (here khaki, blue and brown) show the estimates of utility of the individual endpoints.\nThe blue bars show the final values of a selected Utility QOI.\n\n\n\n\nThis is an identical set of graphs to the Per Sim: Utility and Subject Allocation and Per Sim: Utility and QOI plots, except that in addition to the control to select which simulation to graph the results from, there is a control to select which interim within the simulation to graph the results from. These graphs are only available for those simulations for which ‘weeks’ files have been output (by default the first 100). number of files to be read and subsequent processing of the data.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#across-scenario-graphs",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#across-scenario-graphs",
    "title": "Multiple Endpoint Output",
    "section": "",
    "text": "The Across Scenario graphs for the multiple endpoint engine are the same as the graphs available in the individual continuous and dichotomous engines.\nFor reference, these are:\n\nSelected Arms\nQOI Box Plots\nPpn Success\nResponse/Utility\nAllocation\nInterim vs Final Scatter Plot\nReceiver Operating Characteristics\n\nThe only differences from the single endpoint across scenario graphs are:\n\nQOI Box Plots graph now has Utility as a selectable endpoint and the utility QOIs are available to be plotted\nRespnnse/Utility is the same as the single endpoint Response graph, except that Utility is a selectable endpoint\nInterim vs Final Scatter Plot now has utility QOIs\nReceiver Operating Characteristics plots now have utility QOIs.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#summary-per-scenario",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#summary-per-scenario",
    "title": "Multiple Endpoint Output",
    "section": "Summary per Scenario",
    "text": "Summary per Scenario\nBy default, only a subset of all columns of output are provided when simulations are complete. This set of columns is called “Highlights.” To get access to further columns, you can right click anywhere on the simulation output table and click “Summary Results: ….” for whichever set of columns you would like to see. There is a “Summary Results: All” option that will provide a pop up containing every column available for summary results.\nThe following sections break down which columns are available by sorting to which column subset.\n\nHighlights\nThese are the columns displayed on the simulations tab after simulations are completed, the can also be displayed in the separate “Highlights” results window.\n\nThe columns that are displayed by default in the simulations tab after multiple endpoint simulations have been run.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nSelect\n1\nNot an output column, this column contains check box to allow the user to select which scenario to simulate. The ‘Select All’ button causes them all to be checked.\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response’,\n’Virtual Subject Response &gt; Explicitly Defined &gt; Control Hazard rates,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Predictor’,\nThis is the same name as used for the results directory\n\n\nRandom Number Seed\n1\nBase random number seed used to perform the simulations.\n\n\nNum Sims\n1\nThe number of simulations that were run to produce the displayed results.\n\n\nMean Subj.\n1\nThis is the mean (over the simulations) of the number of subjects recruited in this scenario.\n\n\nPpn Overall Success\n1\nThis is the proportion of simulations that stopped for success, either early success or late success (as defined below).\n\n\nPpn Early Success\n1\nThis is the proportion of simulations that stopped early for success (and did not regress to futility in the final analysis – though they might have regressed to ‘inconclusive’).\n\n\nPpn Late Success\n1\nThis is the proportion of simulations that did not stop early but were successful in the final analysis.\n\n\nPpn Overall Futility\n1\nThis is the proportion of simulations that stopped for futility, either early futility or late futility (as defined below).\n\n\nPpn Late Futility\n1\nThis is the proportion of simulations that did not stop early but were futile in the final analysis.\n\n\nPpn Early Futility\n1\nThis is the proportion of simulations that stopped early for futility (and did not regress to success in the final analysis – though they might have regressed to ‘inconclusive’).\n\n\nPpn Succ -&gt; Fut Flipflop\n1\nThis is the proportion of simulations that stopped early for success but regressed to futility in the final analysis.\n\n\nPpn Fut -&gt; Succ Flipflop\n1\nThis is the proportion of simulations that stopped early for futility but regressed to success in the final analysis.\n\n\nPpn Inconclusive\n1\nThis is the proportion of simulations that did not stop early and were neither successful nor futile in the final analysis.\n\n\nEarly Success Time\n1\nThis is the average time to an early decision to stop for success (i.e. the time excluding final follow up) over those simulations that did decide early to stop for success.\n\n\nMean Trt. &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the hazard ratio of the treatment arms to control. The HZ for the control arm is always 1.\n\n\nMean Duration\n1\nThe mean over the simulations of the total duration from the start of enrolment to end of follow up.\n\n\nPPn Arms Drop: &lt;Dose&gt;\nOne per arm\nThis is the number of times (over the simulations) that each arm was dropped.\n\n\nMean LP Enrolled\n1\nThis is the mean, in weeks (over the simulations) of the duration of the trial from first patient first visit to Last Patient First Visit (i.e. the duration of accrual).\n\n\nPpn Correct Arm\n1\nThe proportion of simulations that met the success criteria and selected (by the target QOI specified on the Study &gt; Variant tab) one of the arms marked as “should succeed” on the Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response tab\n\n\nPpn Incorrect Arm\n1\nThe proportion of simulations that met the success criteria and selected (by the target QOI specified on the Study &gt; Variant tab) one of the arms not marked as “should succeed” on the Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response tab\n\n\nVersion\n1\nThe FACTS version number at the time the simulations were run.\n\n\n\n\n\nAllocation\nBy right clicking and selecting the allocation columns, a pop-out will appear that provides the following columns.\n\nThe allocation columns provided in FACTS output for multiple endpoint trials.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Dose Response’,\n’Virtual Subject Response &gt; Explicitly Defined &gt; Control Hazard rates,\n‘Virtual Subject Response &gt; Explicitly Defined &gt; Predictor’,\nThis is the same name as used for the results directory\n\n\nMean Subj.\n1\nThis is the mean (over the simulations) of the number of subjects recruited in this scenario.\n\n\nSD Mean Subj.\n1\nThis is the standard deviation across the simulations of the number of subjects recruited.\n\n\n80%-ile Subj\n1\nThis is the eightieth percentile across the simulations of the number of subjects recruited into the trial.\n\n\nMean Alloc.: &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the number of subjects recruited into each arm in this scenario.\n\n\nSD Alloc.: &lt;Dose&gt;\nOne per arm\nThis is the SD of the means (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\n\n\n\nUtility\n\nThe utility columns provided in FACTS output for multiple endpoint trials.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Utility: &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the posterior estimate of the overall utility of this dose, this is the utility of each endpoint at the dose, combined using the specified utility combination method.\n\n\nSD Utility: &lt;Dose&gt;\nOne per arm\nThis is the SD (over the simulations) of the posterior estimate of the overall utility of this dose.\n\n\n\n\n\nProbabilities\n\nThe Utility QOIs, which are visible when Probabilities columns are selected in simulation output for multiple endpoint trials.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\n&lt;QOI&gt; &lt;Dose&gt;\nOne per arm per Utility QOI\nFor each Utility Posterior Probability QOI this is the mean over the simulations of the estimate of the posterior probability of the QOI for each dose.\nFor each Utility Target QOI this is the proportion of simulations where this dose was selected at the end of the trial as the dose with the greatest probability of meeting the target condition.\nThe probability that each dose is the target at the end of a simulated trial is its marginal probability (the number of times it was the dose closest to the target in the MCMC sampling of the analysis at the end of the trial). The Max Utility target is always identifiable, so the Ppn(target) should sum to 1 across the doses.\nA Umin target is not guaranteed to be identifiable, if no dose meets the CSMU criteria in any MCMC sample so all doses have a 0 probability of having greater utility than Control then no dose is the Umin. So the sum of each Ppn(target) QOI across the doses should sum to between 0 and 1 inclusive.\n\n\n\n\n\n&lt;Endpoint&gt; Response\nThe columns that appear when selecting &lt;Endpoint&gt; Response vary depending on whether the selected endpoint is continuous or dichotomous.\n\nContinuousDichotomous\n\n\n\nThe columns provided if selecting endpoint specific response for a continuous endpoint.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Response (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nSD Response (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the standard deviation (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nMean Sigma (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the estimate of the standard deviation of the response (across all doses) on this endpoint.\n\n\nSD Mean Sigma (&lt;Endpoint&gt;)\n1\nThis is the standard deviation (over the simulations) of the estimate of the standard deviation of the response (across all doses) on this endpoint\n\n\nTrue Mean Resp (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the true change from baseline / response rate from which the simulation data was sampled.\n\n\nTrue SD Resp.: &lt;Dose&gt;\n1\nIf the endpoint is continuous these columns are included and report the true standard deviation of the simulated response. If baseline and “baseline adjustment of the simulated subject response” is used, this reported SD will include that impact of that and be different from the value(s) for sigma entered on the VSR &gt; Dose Response tab.\n\n\nMean Utility (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the posterior estimate of the utility of this endpoint on this dose.\n\n\nSD Utility (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the SD (over the simulations) of the posterior estimate of the overall utility of this dose.\n\n\n\n\n\n\nThe columns provided if selecting endpoint specific response for a dichotomous endpoint.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Response (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nSD Response (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the standard deviation (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nTrue Mean Resp (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the true change from baseline / response rate from which the simulation data was sampled.\n\n\nMean Utility (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the posterior estimate of the utility of this endpoint on this dose.\n\n\nSD Utility (&lt;Endpoint&gt;): &lt;Dose&gt;\nOne per arm\nThis is the SD (over the simulations) of the posterior estimate of the overall utility of this dose.\n\n\n\n\n\n\n\n\n&lt;Endpoint&gt; Probabilities\n\nThe endpoint specific QOI columns for simulation output in the multiple endpoint engine.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\n&lt;QOI&gt; &lt;Dose&gt;\nOne per arm per QOI defined on this endpoint\nFor each Posterior Probability and Predictive Probability QOI defined on this endpoint, this is the mean over the simulations of the estimate of the probability of the QOI for each dose. (P-value QOIs are reported in the frequentist results table).\nFor each Target QOI this is the proportion of simulations where this dose was selected at the end of the trial as the dose with the greatest probability of meeting the target condition.\nThe probability that each dose is the target at the end of a simulated trial is its marginal probability (the number of times it was the dose closest to the target in the MCMC sampling of the analysis at the end of the trial). The target of having the Max response on this endpoint, or some fraction of it (EDq) is always identifiable, so the Ppn(target) for these QOIs will sum to 1 across the doses.\nAn MED target is not guaranteed to be identifiable, if no dose meets the CSD criteria in any MCMC sample so all doses have a 0 probability of having a response greater than Control (or AC) by the CSD then no dose is the MED. So the sum of each Ppn(target) QOI across the doses should sum to between 0 and 1 inclusive.\nDecision QOI’s are not reported here separately, but their component QOIs – the vector of values and target QOI used to select from them are.\n\n\n\n\n\n&lt;Endpoint&gt; Baseline – Continuous Endpoints Only\n\nThe baseline columns shown when &lt;Endpoint&gt; Baseline is selected. Only available for continuous endpoints.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Baseline Beta (&lt;Endpoint&gt;)\n1\nIf a baseline adjusted dose response model is being used then this is the mean (over the simulations) of the estimate of the baseline adjustment parameter ‘Beta’.\n\n\nSD Baseline Beta (&lt;Endpoint&gt;)\n1\nIf a baseline adjusted dose response model is being used then this is the standard deviation (over the simulations) of the estimate of the baseline adjustment parameter ‘Beta’.\n\n\nMean Baseline (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the mean observed baseline score.\n\n\nSD Baseline (&lt;Endpoint&gt;)\n1\nThis is the standard deviation (over the simulations) of the mean observed baseline score.\n\n\nTrue Mean Baseline (&lt;Endpoint&gt;)\n1\nThis is the true mean of the baseline distribution used to simulate the baseline scores.\n\n\nTrue SD Baseline (&lt;Endpoint&gt;)\n1\nThis is the true standard deviation of the distribution used to simulate the baseline scores.\n\n\n\n\n\n&lt;Endpoint&gt; Observed\n\nThe columns shown when &lt;Endpoint&gt; Observed is selected.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nMean Complete &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of the number of subjects recruited per arm which have had their endpoint observed in this scenario.\n\n\nMean Complete Info &lt;Dose&gt;\nOne per arm\nThis is the mean (over the simulations) of information observed per arm as defined on the Interims tab (Subjects enrolled, Complete Data at Specified Visit, Opportunity to Complete at Specified Visit) in this scenario.\n\n\nMean Dropouts &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit\nThis is the mean (over the simulations) of dropouts per arm per visit in this scenario.\n\n\n\n\n\n&lt;Endpoint&gt; Model Params\n\nThe columns shown when &lt;Endpoint&gt; Model Params is selected for a specific endpoint.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\nBAC Mean (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC Mean (&lt;Endpoint&gt;)\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSD BAC Tau (&lt;Endpoint&gt;)\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC Mean (&lt;Endpoint&gt;)\n1\nThis is the SD (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau (&lt;Endpoint&gt;)\n1\nThis is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC Tau (&lt;Endpoint&gt;)\n1\nThis is the SD (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\n\n\n\nFrequentist Results (&lt;Missingness&gt; &lt;Endpoint&gt;)\n\nThe columns available when selecting Frequentist results for a specific endpoint and missingness handling method.\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\n\nStatus\n1\nThis column reports on the current status of simulations: Completed, Running, No Results, Out of date, Error. It is updated automatically.\n\n\n\nScenario\n1\nThis column gives the name of the scenario, concatenating together the profile names from the following tabs:\n‘Execution &gt; Accrual’,\n‘Execution &gt; Dropout Rate’,\n’Virtual Subject Response &gt; Composite,\nThis is the same name as used for the results directory\n\n\n\nMean Theta (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\n\nThe mean response per dose.\n\n\n\nSD Mean Theta (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\n\nThe standard error of the response per dose\n\n\n\nPpn Signif (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of | simulations where the unadjusted p-value is | less than the user specified one-sided alpha. | | The marginal probability of significance per | dose (using unadjusted p-values).\n\n\n\nBias (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nThe difference between the estimated mean response and the true (simulated) mean response per dose\n\n\n\nCoverage (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nThe proportion of simulations where the unadjusted confidence interval for the treatment difference compared to control contains the true mean treatment difference compared to control used to simulate subject responses.\n\n\n\nPpn Signif Dunnett (&lt;Missingness&gt; &lt;Endpoint&gt;)\n1\nFor each treatment arm, the proportion of simulations where at least one of the Dunnett adjusted p-value is less than the user specified one-sided alpha.\n\n\n\nPpn Signif Dunnett (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Dunnett adjusted p-value is less than the user specified one-sided alpha.\n\n\n\nCoverage Dunnett (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nThe proportion of simulations where the Dunnett adjusted confidence interval for the treatment difference compared to control contains the true mean treatment difference compared to control used to simulate subjects responses.\n\n\n\nPpn Signif Bonf (&lt;Missingness&gt; &lt;Endpoint&gt;)\n1\nThe proportion of simulations where at least one of the Bonferroni adjusted p-values is less than the user specified one-sided alpha.\n\n\n\nPpn Signif Bonf (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Bonferroni adjusted p-value is less than the user specified one-sided alpha.\n\n\n\nCoverage Bonf (&lt;Missingness&gt; &lt;Endpoint&gt;) &lt;Dose&gt;\nD\nThe proportion of simulations where the Bonferroni adjusted confidence interval contains the true mean response used to simulate subjects responses.\n\n\n\nPpn Signif Trend (&lt;Missingness&gt; &lt;Endpoint&gt;)\n1\nThe proportion of simulations where the trend test p-value is less than the user specified one-sided alpha.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#detailed-per-simulation-results",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#detailed-per-simulation-results",
    "title": "Multiple Endpoint Output",
    "section": "Detailed Per Simulation Results",
    "text": "Detailed Per Simulation Results\nAfter simulation has completed and simulation results have been loaded, the user may examine detailed results for any scenario with simulations output in the table by double-clicking on the appropriate row. A separate window pops up and displays the results for each individual simulation. This is a “prettier” view of the contents of the “simulations.csv” file, which is described below. The simulations results are partitioned into the same results groupings as the summary results. These can be accessed from the “right click” menu, along with opening the results folder, opening the weeks file for a particular simulation and opening the simulated patients file for a particular simulation (where a “weeks” file or a “patients” file has been output).\n\n\n\n\n\n\nFigure 6: The simulation results pop out viewer showing simulation highlights.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-summary.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-summary.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of summary.csv",
    "text": "Contents of summary.csv\nThe first two lines are header lines, starting with a ‘#’, containing the column headings. The first line contains the lengthy “human readable” form of the QOI names, the second line contains the shorter “computer readable” alternate QOI names. For columns that are not QOI values, the column names are the same in the two rows.\n\nContents of the summary.csv file for the multiple endpoint engine.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nProject\n1\nThe name of the “.facts” file – not including the file extension.\n\n\nScenario\n1\nThe scenario name as used in FACTS – made by concatenating the names of the various profiles that make up the scenario\n\n\nTimestamp\n1\nThe time the simulations started\n\n\nVersion\n1\nThe overall version of FACTS that ran the simulations (not the version of the specific design engine)\n\n\nNSim\n1\nThe number of simulation runs.\n\n\nNo. Subj\n1\nThe mean, over the simulations, of the total number of subjects recruited in the trial.\n\n\nSE Subj.\n1\nThe standard error of the total number of subjects recruited into the trials.\n\n\nNo.subj 80%-ile\n1\nThe 80th percentile, over the simulations, of the total number of subjects recruited in the trial.\n\n\nP(ES)\n1\nThe proportion of simulations that stopped early for success.\n\n\nP(LS)\n1\nThe proportion of simulations that did not stop early, and were successful on final evaluation.\n\n\nP(LF)\n1\nThe proportion of simulations that did not stop early, and were futile on final evaluation.\n\n\nP(EF)\n1\nThe proportion of simulations that stopped early for futility.\n\n\nSFFF\n1\nThe proportion of simulations that stopped early for success, but at final analysis were futile (Success-Futility ‘flip-flops’).\n\n\nFSFF\n1\nThe proportion of simulations that stopped early for futility, but at final analysis were successful (Futility- Success ‘flip-flops’).\n\n\nUndec.\n1\nThe proportion of simulations that did not stop early, and met neither the success or futility final evaluation criteria and hence are counted as ‘undecided’.\n\n\nUnused\n3\nThree unused columns for other outcome types.\n\n\nEarly Success Time\n1\nThis is the mean early decision time (over the simulations stopped early for success), it is the time from the start of the trial to the interim where early success was declared. It does not include the subsequent follow up time.\n\n\nMean Alloc &lt;Dose&gt;\nD\nThe mean (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nSE Alloc &lt;Dose&gt;\nD\nThe standard error (over the simulations) of the number of subjects allocated to each treatment arm.\n\n\nNo. Dropouts &lt;Dose&gt;\nD\nThe mean (over the simulations) of the number of dropouts for each treatment arm.\n\n\nMean Util &lt;Dose&gt;\nD\nThis is the mean (over the simulations) of the posterior estimate of the utility of this dose.\n\n\nSE Util &lt;Dose&gt;\nD\nThis is the SD (over the simulations) of the posterior estimate of the utility of this dose.\n\n\nMean Resp &lt;Endpoint&gt;&lt;Dose&gt;\nD per endpoint\nThis is the mean (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nSE Resp &lt;Dose&gt;\nD per endpoint\nThis is the standard deviation (over the simulations) of the estimate of the response on this endpoint on this dose.\n\n\nMean Sigma\n1 per continuous endpoint\nThis is the mean (over the simulations) of the estimate of the standard deviation of the response (across all doses) on this endpoint.\n\n\nSE Mean Sigma\n1 per continuous endpoint\nThis is the standard deviation (over the simulations) of the estimate of the standard deviation of the response (across all doses) on this endpoint\n\n\nTrue Mean resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per endpoint\nThis is the true change from baseline / response rate from which the simulation data was sampled.\n\n\nTrue SD resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per endpoint\nIf the endpoint is continuous these columns are included and report the true standard deviation of the simulated response. If baseline and “baseline adjustment of the simulated subject response” is used, this reported SD will include that impact of that and be different from the value(s) for sigma entered on the VSR &gt; Dose Response tab.\n\n\nMean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit per endpoint\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used.\nThis is the mean (over the simulations) of the estimate of the mean response for a particular dose at a particular visit, based on the independent estimate of the dose response (omega_d), scaled by the longitudinal model’s estimate of the proportion of the final effect observed at the visit.\n\n\nSE Mean Longmod Resp: &lt;Dose&gt;\n&lt;Visit&gt;\nOne per arm per visit per endpoint\nThis is the SD ( over the simulations) of the longitudinal model estimate of the response at intermediate visits (see above)\n\n\nMean Util &lt;Endpoint&gt; &lt;Dose&gt;\nD per endpoint\nThis is the mean (over the simulations) of the mean estimate of the utility of this endpoint on this dose.\n\n\nSE Util &lt;Endpoint&gt; &lt;Dose&gt;\nD per endpoint\nThis is the standard error (over the simulations) of the mean estimate of the utility of this endpoint on this dose.\n\n\nMean Beta &lt;Endpoint&gt;\n1 per continuous endpoint\nIf a baseline adjusted dose response model is being used then this is the mean (over the simulations) of the estimate of the baseline adjustment parameter ‘Beta’.\n\n\nSE Beta &lt;Endpoint&gt;\n1 per continuous endpoint\nIf a baseline adjusted dose response model is being used then this is the standard error (over the simulations) of the estimate of the baseline adjustment parameter ‘Beta’.\n\n\nMean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the mean (over the simulations) of the mean observed baseline score.\n\n\nSE Mean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the standard error (over the simulations) of the mean observed baseline score.\n\n\nSD Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the mean (over the simulations) of the SD of the observed baseline score.\n\n\nSE SD Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the standard error (over the simulations) of the mean of the observed baseline score.\n\n\nTrue Mean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the true mean of the baseline distribution used to simulate the baseline scores.\n\n\nTrue SD Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\nThis is the true SD of the baseline distribution used to simulate the baseline score.\n\n\nBAC Mean (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Mean (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Control is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nSE of BAC Tau (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Control is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Mean (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Active Comparator is being used this is the mean (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSE of BAAC Tau (&lt;Endpoint&gt;)\n1\nIf a hierarchical prior for Active Comparator is being used this is the standard error (over the simulations) of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nMean Duration\n1\nThe mean, over the simulations, of the overall duration of the trials, from first person first sit, to last person last visit.\n\n\nPpn Arms Dropped &lt;Dose&gt;\nD\nThe proportion of the simulations in which each arm was dropped. These will be zero if arm dropping is not selected as the means of adaptive location.\n\n\nMean LPFV time\n1\nThe mean, over the simulations, of the accrual period of the trials, from first person first sit, to last person first visit (LPFV).\n\n\nQOI Columns\n\n\n\nThe QOI Columns depend on the QOIs that have been defined for this design. The columns are grouped, so that first all of the Utility QOIs are listed, then all of the Endpoint 1 QOIs are listed, and so on. Within the utility or an endpoint group, the QOIs are arranged in the following order:\n\n\n\n\n\n\n\nStatistic\nDescription\n\n\n\n\nPosterior Probabilities\nThe summary file contains the mean (over the simulations) of the posterior probability for each dose.\n\n\nPredictive Probabilities\nThe summary file contains the mean (over the simulations) of the predictive probability for each dose.\n\n\nP-Values\nThe summary file contains the mean (over the simulations) of the p-value for each dose.\n\n\nTarget Probabilities\nThe summary file contains the proportion of times (over the simulations) each dose had the greatest probability of being the target.\n\n\nDecision QOIs\nThe summary file contains the mean (over the simulations) of the final value of the decision QOI at the target.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-summary_freq_missing_endpoint.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-summary_freq_missing_endpoint.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of Summary_freq_<missing>_<Endpoint>.csv",
    "text": "Contents of Summary_freq_&lt;missing&gt;_&lt;Endpoint&gt;.csv\nThere is a frequentist summary file for each type of treatment of missing values for each endpoint.\nThe first line is a header line, starting with a ‘#’, containing the FACTS GUI version number, the name of the FACTS file, the name of the scenario, and the time stamp of the start of the simulation.\nThe second line is a header line, starting with a ‘#’, containing the following column headings.\n\nThe contents of the Summary_freq_&lt;missing&gt;_&lt;Endpoint&gt;.csv file.\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\nMean Theta &lt;Dose&gt;\nD\nThe mean response per dose.\n\n\nSE Mean Theta &lt;Dose&gt;\nD\nThe standard error of the response per dose\n\n\nMean Beta (baseline)\n1 if endpoint continuous\nThe mean of the estimate of the baseline coefficient.\n\n\nSE Mean Beta (baseline)\n1 if endpoint continuous\nThe standard error of the estimate of the baseline coefficient\n\n\nPpn Signif\n1\nThe proportion of simulations where at least one of the unadjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the unadjusted p-value is less than the user specified one-sided alpha.\nThe marginal probability of significance per dose (using unadjusted p-values.\n\n\nBias &lt;Dose&gt;\nD\nThe difference between the mean response and the true (simulated) response per dose\n\n\nCoverage &lt;Dose&gt;\nD\nThe proportion of simulations where the unadjusted confidence interval for the response contains the true response rate used to simulate subject responses.\n\n\nPpn Signif Dunnett\n1\nThe proportion of simulations where at least one of the Dunnett adjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif Dunnett &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Dunnett adjusted p-value is less than the user specified one-sided alpha.\n\n\nCoverage Dunnett &lt;Dose&gt;\nD\nThe proportion of simulations where the Dunnett adjusted confidence interval contains the true response rate used to simulate subjects responses.\n\n\nPpn Signif Bonf\n1\nThe proportion of simulations where at least one of the Bonferroni adjusted p-values is less than the user specified one-sided alpha.\n\n\nPpn Signif Bonf &lt;Dose&gt;\nD\nFor each treatment arm, the proportion of simulations where the Bonferroni adjusted p-value is less than the user specified one-sided alpha.\n\n\nCoverage Bonf &lt;Dose&gt;\nD\nThe proportion of simulations where the Bonferroni adjusted confidence interval contains the true response rate used to simulate subjects responses.\n\n\nPpn Signif Trend\n1\nThe proportion of simulations where the trend test p-value is less than the user specified one-sided alpha.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-simulations.csv-and-weeksnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-simulations.csv-and-weeksnnnnn.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of simulations.csv and weeksNNNNN.csv",
    "text": "Contents of simulations.csv and weeksNNNNN.csv\nThe simulations.csv file holds the FACTS summary of the final analysis for each simulation (one per row).\nThe weeksNNNNN.csv file holds the FACTS summary of every analysis for the NNNNNth simulation. It contains a row for each interim in the trial and a row for the final analysis (Interim number 999).\nThe final analysis occurs after all the planned data is collected. If the trial does not stop early, the final analysis occurs after full follow-up for all subjects. If the trial does stop early at an interim analysis, then the timing of the final analysis depends on the status of the check boxes on the Interims tab. If follow-up is collected after the particular interim decision, then an analysis after full follow-up of the subjects recruited up to the point of the interim when the stopping decision was taken. If there is no follow-up intended after the interim analysis decision, then the final analysis occurs immediately (at the same time as the interim analysis), and the final analysis criteria are checked.\nThe first line is a header line, starting with a ‘#’, containing the FACTS GUI version number, the name of the FACTS file, the name of the scenario, and the time stamp of the start of the simulation.\nThe second line is a header line, starting with a ‘#’, containing the following column headings.\nMost of the columns are common to the two file types, but the weeks file does not contain columns for the ‘final’ values of the evaluation criteria.\n\nThe contents of the simulations.csv file and the weeksNNNNN.csv file for the multiple endpoint engine.\n\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nIn simulations file\nIn weeks file\nDescription\n\n\n# Weeks (Duration)\n1\n\n✔\nThe week of the analysis.\n\n\n#Sim\n1\n✔\n\nThe number of the simulation.\n\n\nLastInterim\n1\n✔\n\nThe index of the last interim performed the index of the interim immediately before the final interim (index 999). Note this is not necessarily the interim when the trial stopped if the design includes follow-up after stopping.\n\n\n#Subjects\n1\n✔\n✔\nThe number of subjects recruited in the simulation.\n\n\nOutcome\n1\n✔\n✔\nA flag categorizing final study outcome:\n\n= Early success\n= Late success\n= Late futility\n= Early futility\n= Success to futility flip-flop\n= Futility to success flip-flop\n= Inconclusive\n\n\n\nMean Utility &lt;Dose&gt;\nD\n✔\n✔\nThe mean estimate of utility per dose\n\n\nSD Utility &lt;Dose&gt;\nD\n✔\n✔\nThe SD of the estimate of utility\n\n\nEarly Success\n1\n✔\n✔\nThis is the time to the early success decision (-9999 if there was no early success decision). The from the start of the trial to the interim where the early success conditions were first met. It does not include the subsequent follow up time.\n\n\nAlloc &lt;Dose&gt;\nD\n✔\n✔\nThe number of subjects allocated to each arm.\n\n\nPr(Alloc) &lt;Dose&gt;\nD\n✔\n✔\nThe probability of allocation to the different arms following the interim.\n\n\nComplete &lt;Dose&gt;\nD\n✔\n✔\nThe number of subjects on each dose that have completed – final endpoint data is available.\n\n\nComplete Information &lt;Dose&gt;\nD\n✔\n✔\nThe number of subject who count as complete for the purposes of timing interims – whether complete or opportunity to complete and at which visit is as defined on the Interims tab.\nIf interims are by enrolment then CompleteInformation is the number of subjects that have completed – final endpoint data is available.\n\n\n#Dropouts &lt;Dose&gt; &lt;Visit&gt;\nD*V\n✔\n✔\nThe number of subjects that have dropped out on each arm at each visit\n\n\nMean resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe estimated response of each treatment arm.\n\n\nSD resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe standard deviation of the estimate of response of each treatment arm.\n\n\nTrue Mean resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe true mean response of each treatment arm for this simulation.\n\n\nTrue SD resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe true SD of the response of each treatment arm for this simulation\n\n\nSigma &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe pooled estimate of the SD of the response across all the treatment arms\n\n\nSD Sigma &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe SD of the pooled estimate of the SD of the response across all the treatment arms\n\n\nBeta &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe estimate of Beta the baseline adjustment coefficient, if baseline adjustment is being used.\n\n\nSD Beta &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe SD of the estimate of Beta the baseline adjustment coefficient.\n\n\nMean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe estimate of the mean baseline score.\n\n\nSE Mean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe standard error of the estimate of the mean baseline score.\n\n\nSD Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe estimate of the SD of the baseline score.\n\n\nTrue Mean Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe true mean of the simulated baseline score\n\n\nTrue SD Baseline &lt;Endpoint&gt;\n1 per continuous endpoint\n✔\n✔\nThe true SD of the simulated baseline score\n\n\nMean Utility &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe mean estimate of the utility of this endpoint\n\n\nSD Utility &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe SD of the estimate of utility of this endpoint\n\n\nMean Raw Response &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe mean raw response based solely on the observed data on each dose.\n\n\nSE mean Raw Response &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe SE of the estimate of the mean raw response on each dose.\n\n\nComplete &lt;Endpoint&gt; &lt;Dose&gt;\nD per continuous endpoint\n✔\n✔\nThe number of subjects with final data on this endpoint on each arm at the end of the trial / time of the interim.\n\n\nDR Param &lt;Endpoint&gt; &lt;Param&gt;\n10 per continuous endpoint\n✔\n✔\nThe estimate of the mean value of each of the response model parameters. The response models require up to 10 parameters, most less. The model parameters are labeled α1, α2, .. the subscripts corresponding to the column index &lt;Param&gt;.\n\n\nSd DR Param &lt;Endpoint&gt; &lt;Param&gt;\n10 per continuous endpoint\n✔\n✔\nThe standard deviation of the estimate of the mean value of the corresponding response model parameter.\n\n\nLongmod &lt;Endpoint&gt; &lt;Model&gt; &lt;Param&gt; &lt;Visit&gt;\nLM*LMP*V per continuous endpoint\n✔\n✔\nThe estimate of the mean value of each of the longitudinal model parameters. The number of models depends on the number of model instances the user has specified.\nFor linear regression the parameters reported are:\n\nAlpha – per visit – the mean estimate of the constant offset in the change in response from this visit to the final visit\nBeta – per visit – the mean estimate of the coefficient of change in response from this visit to the final visit\nLambda – per visit – the mean estimate of the SD of the residual error term in the predicted final visit response based on the response at this visit.\n\nFor time course hierarchical the parameters reported are:\n\nAlpha – per visit – the mean estimate of the exponential coefficient of the proportion of the dose response and per-subject response seen at this visit..\nLambda – per visit – the mean estimate of the SD of the residual error term in the predicted final visit response based on the response at this visit.\nTau – the mean estimate of the SD of the per subject random effect\n\nFor ITP the parameters are:\n\nK – per model – the mean estimate of the ITP shape parameter\nTau – per model - the mean estimate of the SD of the per subject random effect\nLambda – per model – the mean estimate of the Sd of the residual error.\nOmega – per treatment arm – the mean estimate of the mean treatment arm effect.\n\nFor LOCF & Kernel Density there are no estimated parameters.\n\n\nLongmod Resp &lt;Endpoint&gt; &lt;Dose&gt; &lt;Visit&gt;\nD*V per continuous endpoint\n✔\n✔\nThese are only calculated and written out if the Time Course Hierarchical or ITP longitudinal models are being used.\nThis is the mean response for a particular dose at a particular visit.\n\n\nMean resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe estimated response of each treatment arm.\n\n\nSD resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe standard deviation of the estimate of response of each treatment arm.\n\n\nMean resp (loser CI) &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe lower bound of the 95% Credible Interval of the estimate of response for each treatment arm.\n\n\nMean resp (upper CI) &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe upper bound of the 95% Credible Interval of the estimate of response for each treatment arm.\n\n\nTrue Mean resp &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe true response rate of each treatment arm for this simulation.\n\n\nMean Utility &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe mean estimate of the utility of this endpoint\n\n\nSD Utility &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe SD of the estimate of utility of this endpoint\n\n\nMean Raw Response &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe mean raw response based solely on the observed data on each dose.\n\n\nComplete &lt;Endpoint&gt; &lt;Dose&gt;\nD per dichotomous endpoint\n✔\n✔\nThe number of subjects with final data on each arm at the end of the trial / time of the interim.\n\n\nDR Param &lt;Endpoint&gt; &lt;Param&gt;\n4 per dichotomous endpoint\n✔\n✔\nThe estimate of the mean value of each of the response model parameters. The response models require up to 4 parameters, some less. The model parameters are labeled α1, α2, .. the subscripts corresponding to the column their value appears in here.\n\n\nSd DR Param &lt;Endpoint&gt; &lt;Param&gt;\n4 per dichotomous endpoint\n✔\n✔\nThe standard deviation of the estimate of the mean value of the corresponding response model parameter.\n\n\nLongmod &lt;Endpoint&gt; &lt;Model&gt; &lt;Visit&gt;\nLM*LMP*V per dichotomous endpoint\n✔\n✔\nThe estimate of the mean value of each of the longitudinal model parameters. The number of models depends on the number of model instances the user has specified.\nFor Beta-Binomial the parameters reported are:\n\nAlpha0 & Beta 0 – The beta binomial alpha & beta parameters for the probability that the final result will be 1 if the result at the visit is 0\nProb01 – the mean probability of the Beta(Alpha0, Beta0) – the probability of 1 being the final result if the result at the visit is 0\nAlpha1 & Beta 1 – The beta binomial alpha & beta parameters for the probability that the final result will be 1 if the result at the visit is 1\nProb11 – the mean probability of the Beta(Alpha1, Beta1) – the probability of 1 being the final result if the result at the visit is 1\n\nFor logistic regression the parameters reported are:\n\nProb11 – the probability of 1 being the final result if the result at the visit is 1and\nProb01 – the probability of 1 being the final result if the result at the visit is 0\n\nFor restricted Markov the parameters reported are:\n\nAlpha0 – Alpha for state 0\nAlphaS – Alpha for stable state\nAlpha1 – Alpha for state 1\nProb0 – Transition probability to state 0\nProbS – Probability of remaining stable\nProb1 – Transition probability to state 1\n\n(values are for the transition to the next visit, so there are no values for the final visit)\n\n\nBAC Mean &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Mean SD &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAC Tau SD &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Control (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Mean &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nBAAC Mean SD &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the SD of the posterior estimate of the mean of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean control responses.\n\n\nBAAC Tau &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nSD BAAC Tau &lt;Endpoint&gt;\n1\n✔\n✔\nThis is the SD of the posterior estimate of the SD of the Bayesian Augmented Active Comparator (Hierarchical Prior) distribution of mean active comparator responses.\n\n\nDuration\n1\n✔\n✔\nThe time in weeks to the analysis shown.\n\n\nArm Drop Time &lt;Dose&gt;\nD\n✔\n✔\nFor each treatment arm, the time in weeks when it was decided to drop the arm.\n\n\nLPFV\n1\n✔\n✔\nThe time in weeks to the last patient first visit.\n\n\nQOI Columns\n\n\n\n\n\n\n\nThe QOI Columns depend on the QOIs that have been defined for this design. The columns are grouped, so that first all of the Utility QOIs are listed, then all of the Endpoint 1 QOIs are listed, and so on. Within the utility or an endpoint group, the QOIs are arranged in the following order:\n\n\n\n\n\n\n\nQOI Type\nDescription\n\n\n\n\nPosterior Probabilities\nThe posterior probability for each QOI for each dose.\n\n\nPredictive Probabilities\nThe predictive probability for each QOI for each dose.\n\n\nP-Values\nThe p-value for each QOI for each dose.\n\n\nTarget Probabilities\nThe probability of being the target for each QOI for each dose.\n\n\nDecision QOIs\nThe value of the decision QOI at the target.\n\n\nSuccess Futile\nA flag for each QOI decision criteria indicating if the decision QOI was evaluated and compared to a threshold at the interim (weeks file) or final analysis (simulation file). The flag value is -1 if the decision QOI was not evaluated, 0 if it did not meet the threshold and 1 if it did.\n\n\nSuccess / Futile Combined\nFlags indicating if the interim or final analysis determined success or futility taking all the factors defined for Success/Futility into account: 0 if the conditions were not met, 1 it the conditions were met. If success and futility conditions have been defined that are not mutually exclusive and both sets of combined conditions are met, FACTS will pick one of the outcomes as met but not the other. In order to discourage defining Success and Futility rules that can both be true FACTS does not guarantee which outcome will be selected.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-simulations_freq_missingness_endpoint.csv-weeks_freq_missingness_endpoint.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-simulations_freq_missingness_endpoint.csv-weeks_freq_missingness_endpoint.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of Simulations_freq_<missingness>_<Endpoint>.csv, Weeks_freq_<missingness>_<Endpoint>.csv",
    "text": "Contents of Simulations_freq_&lt;missingness&gt;_&lt;Endpoint&gt;.csv, Weeks_freq_&lt;missingness&gt;_&lt;Endpoint&gt;.csv\nThese file contain the frequentist results after an interim analysis (weeks file) or final analysis (simulations file), apart for the first column, the columns are the same in the two types of file, and the same across the different methods for treating missing data and different endpoints.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\n# Trial\n1\nThe number of the simulation (simulations_freq_…csv only)\n\n\n# Weeks\n1\nThe week of the interim (weeks_freq_ only)\n\n\nTheta\nD\nUnadjusted estimate of response per treatment arm\n\n\nTheta SD\nD\nThe SD of the estimate of response per treatment arm\n\n\nTrt Effect\nD\nThe relative size of the treatment effect compared to control per arm (treatment effect for control is always 0). The direction of the comparison takes into account whether a response represents a subject’s condition improving or worsening, so that a positive treatment effect shows the response on the dose is better than on control.\n\n\nt-Stat\nD\nThe t-test statistic per treatment arm (for control this is always 0)\n\n\np-Value\nD\nThe unadjusted t-test p-value per arm (for control this is always 0)\n\n\nlower CI\nD\nThe unadjusted lower bound of the alpha confidence interval of the estimated treatment effect per treatment arm (for control this is always 0).\n\n\nupper CI\nD\nThe unadjusted upper bound of the alpha confidence interval of the estimated treatment effect per treatment arm (for control this is always 0).\n\n\nMin p-Value\n1\nThe smallest of the t-test p-values\n\n\np-Value Dunnett\nD\nThe Dunnett adjusted t-test p-value per arm (for control this is always 0).\n\n\nlower CI Dunnett\nD\nThe Dunnett adjusted lower bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nupper CI Dunnett\nD\nThe Dunnett adjusted upper bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nMin p-Value Dunnett\n1\nThe smallest of the Dunnett adjusted p-values.\n\n\np-Value Bonf\nD\nThe Bonferroni adjusted t-test p-value per arm.\n\n\nlower-CI Bonf\nD\nThe Bonferroni adjusted lower bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nupper-CI Bonf\nD\nThe Bonferroni adjusted upper bound of the alpha confidence interval of the estimated treatment effect (for control this is always 0).\n\n\nMin p-Value Bonf\n1\nThe smallest of the Bonferroni adjusted t-test value per arm.\n\n\nt-Stat trend\n1\nThe t statistic from the trend test.\n\n\np-Value trend\n1\nThe p-value from the trend test.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-patientsnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-patientsnnnnn.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of PatientsNNNNN.csv",
    "text": "Contents of PatientsNNNNN.csv\n\n\n\n\n\n\n\n\nColumn Title\nNumber of columns\nDescription\n\n\n\n\n#Subject\n1\nThe subject id number, starting at 1.\n\n\nRegion\n1\nWhich region the subject was recruited in\n\n\nDateInWeeks\n1\nThe date, in weeks, from the start of the trial, of the subject’s baseline visit and randomization.\n\n\nDose\n1\nThe index number (1, …) of the treatment arm the subject belongs to.\n\n\nLastVisit Overall\n1\nThe time of the last observation of the subject – the index of the visit of the observation from the overall visit list. NOTE this is the index of the last visit using the overall visit index (index of all visits). E.g. for a patient with 6 visits (index: 1, 2, …6), and an endpoint observed on 3 visits: visits 2, 4 and 6 of the overall schedule, if that patients last observed data was the second time this endpoint was observed (last visit for that endpoint will be “2”), the last visit overall will be “4”.\n\n\nDropout\n1\nWhether the subject dropped out of the trial (1) or not (0) before reaching their final visit.\n\n\nLastVisit &lt;Endpoint&gt;\n1\nThe time of the last observation of this endpoint – the index of the visit of the observation from the visit list for the endpoint\n\n\nBaseline &lt;Endpoint&gt;\n1\nThe baseline score for the subject, if baseline is simulated. If no baseline, or the endpoint is dichotomous, then this column is -9999.\n\n\nResponse &lt;Endpoint&gt; &lt;Visit&gt;\nV\nOne column per visit from the visit list from the endpoint, recording the observed endpoint value at that visit.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-mcmcnnnnn.csv",
    "href": "documentation/v71/userguides/core/simulation/multendpt.html#contents-of-mcmcnnnnn.csv",
    "title": "Multiple Endpoint Output",
    "section": "Contents of MCMCNNNNN.csv",
    "text": "Contents of MCMCNNNNN.csv\nThe MCMC file, if requested for output by the user, contains all the MCMC samples for the estimated responses for each arm on each endpoint. There is one row per sample (including the burnin) and the samples from all the analyses in the simulation are included. The first two columns are the analysis index and the sample (within analysis) index. The next set of columns are the MCMC samples for the first endpoint. This includes response rate estimates and, if the endpoint is continuous, a sigma. Then, various longitudinal model parameters are reported if used for that endpoint.\nThen second endpoint’s MCMC columns begin, again providing response estimates with or without sigma and longitudinal model parameters (if used). The other endpoints proceed in kind.\nThe first two columns are:\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nAnalysis\n1\nThe index of the analysis (interim) in the simulation.\n\n\nSample\n1\nThe index of the sample within the analysis.\n\n\n\nThen, the endpoint specific output is provided for each endpoint. For a particular endpoint index, &lt;Endpoint&gt;, the columns output are:\n\nContinuousDichotomous\n\n\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nTheta_&lt;Endpoint&gt; &lt;Dose&gt;\nD\nThe estimate of the mean response for each dose, based on the dose response model fitted.\n\n\nSigma_&lt;Endpoint&gt;\n1\nThe estimate of the SD of the endpoint.\n\n\nBeta_&lt;Endpoint&gt;\n1\nIf baseline is included in the simulated data and using the “Baseline Adjusted Model”, this is the value of “Beta”, the baseline coefficient.\n\n\nA&lt;1-8&gt;_&lt;Endpoint&gt; / Tau_&lt;Endpoint&gt;\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod_&lt;Endpoint&gt; &lt;model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nIf the analysis includes longitudinal modelling then the samples of the parameters of the longitudinal models are output. The number of models depends on the number of different longitudinal fits the user has specified (one over all arms, one for control and one for all treatment arms, model all arms separately, etc.), the number of parameters the model has, and if these are fitted per visit (which depends on the model being fitted), then the number of visits.\n\n\n\n\n\nIf using a dichotomized continuous variable, then the parameters for the LM are the same as for the continuous model MCMC output listed in the Continuous tab.\nIf using a dichotomous longitudinal model, then the following parameters are output in the MCMC file.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nPi_&lt;Endpoint&gt; &lt;Dose&gt;\nD\nThe estimate of the response rate for each dose, based on the dose response model fitted.\n\n\nA&lt;1-8&gt;_&lt;Endpoint&gt; / Tau_&lt;Endpoint&gt;\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod_&lt;Endpoint&gt; &lt;model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nIf the analysis includes longitudinal modelling then the samples of the parameters of the longitudinal models are output. The number of models depends on the number of different longitudinal fits the user has specified (one over all arms, one for control and one for all treatment arms, model all arms separately, etc.), the number of parameters the model has, and if these are fitted per visit (which depends on the model being fitted), then the number of visits.\n\n\n\nIf using a restricted markov model for the endpoint, then the following columns are output in the MCMC file for that endpoint.\n\n\n\n\n\n\n\n\nColumn\nNumber of columns\nDescription\n\n\n\n\nPi_&lt;Endpoint&gt; &lt;Dose&gt;\nD\nThe estimate of the response rate for each dose, based on the dose response model fitted.\n\n\nA&lt;1-8&gt;&lt;Endpoint&gt; / Tau&lt;Endpoint&gt;\nP\nIf the dose response model estimates parameters then the samples of these are listed next. The number and name of the parameters will vary depending on the model being fitted. Check the Design &gt; Dose Response tab for a listing of the parameters.\n\n\nLongmod_&lt;Endpoint&gt; &lt;model&gt; &lt;Param&gt; &lt;Visit&gt;\nL*P*V\nCurrently the values of Alpha0, Alpha1, AlphaS (the parameters to the Dirichlet distribution) are (unnecessarily – these values are not sampled) output, along with the values for P0, P1 and PS the transition probabilities of each model at each visit.",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Phase II & III Designs",
      "Simulation",
      "Multiple Endpoint"
    ]
  },
  {
    "objectID": "documentation/index.html",
    "href": "documentation/index.html",
    "title": "Documentation",
    "section": "",
    "text": "Welcome to the Documentation section — your go-to repository of in-depth user guides and practical examples that illuminate every aspect of FACTS. Whether you’re just getting started or delving into advanced functionalities, these resources are designed to help you navigate our software with confidence and ease.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation/index.html#what-youll-find-here",
    "href": "documentation/index.html#what-youll-find-here",
    "title": "Documentation",
    "section": "What You’ll Find Here",
    "text": "What You’ll Find Here\n\nUser Guides: Access detailed manuals covering the full range of our engines. From foundations to advanced features, learn how to set up your desired trial design, learn about best practices and obtain focused understanding of the subject matter, and troubleshoot common issues.\n\n3+3 and mTPI - Rule Based Dose Escalation\nPhase II & III Designs\nCRM - Model Based Dose Escalation\n2D CRM - 2D Model Based Dose Escalation\nFACTS/R - How to Call FACTS from R\nFLFLL - FACTS Linux File Loader Light\nPlatform Trials\nFACTS Design Report\n\nExamples: Explore a range of constructed and real-world studies that demonstrate FACTS’s capabilities in action and discover strategies to optimize performance.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation/index.html#how-to-get-the-most-out-of-this-section",
    "href": "documentation/index.html#how-to-get-the-most-out-of-this-section",
    "title": "Documentation",
    "section": "How to Get the Most Out of This Section",
    "text": "How to Get the Most Out of This Section\nThis section contains resources for the current and past versions of FACTS, which you can choose in the sidebar. If necessary, begin by reviewing the installation guides. Later, you may consult engine-specific user manuals for deeper insights, and explore our curated examples to bring theory into practice. With these resources at your fingertips, you’ll gain a richer, more informed understanding of FACTS and maximize your potential for success.",
    "crumbs": [
      "Documentation"
    ]
  },
  {
    "objectID": "documentation/v71/userguides/dr.html#sec-setup",
    "href": "documentation/v71/userguides/dr.html#sec-setup",
    "title": "Design Report",
    "section": "Setup",
    "text": "Setup\nYou will need to inform FACTS of the location of R and RStudio on your computer.\nTo do this start FACTS and go to menu option: “Settings &gt; Options” and then to the “R Configuration” tab.\n\n\n\n\n\n\nFigure 1\n\n\n\nSelect the R and RStudio versions you would like to use.\nIf the version you wish to use isn’t shown, or the path is incorrect, use the “Edit” button to open a file browser to navigate to the version of R that you wish to use and select the appropriate version of “R.exe”. Similarly for RStudio.exe.\n\n\n\n\n\n\nFigure 2",
    "crumbs": [
      "Documentation",
      "Version 7.1",
      "User Guides",
      "Design Report"
    ]
  }
]