<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Core Designs - Shared Features</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../../">
<script src="../../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">



<!-- Roboto Serif -->

<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:wght@400;700&amp;display=swap" rel="stylesheet">



<!-- Roboto Sans -->

<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../../media/FACTS_logo.jpg" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../introduction/index.html"> 
<span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../../../documentation/index.html" aria-current="page"> 
<span class="menu-text">Documentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../concepts/index.html"> 
<span class="menu-text">Concepts</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../../notes/index.html"> 
<span class="menu-text">Field Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../releaseNotes/index.html"> 
<span class="menu-text">Release Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../get.html"> 
<span class="menu-text">Get FACTS</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../../contact.html"> 
<span class="menu-text">Contact</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Version 7.1</li><li class="breadcrumb-item">User Guides</li><li class="breadcrumb-item"><a href="../../../../documentation/v71/userguides/core/aa_coreOverview.html">FACTS Core Designs</a></li><li class="breadcrumb-item"><a href="../../../../documentation/v71/userguides/core/aa_coreOverview.html">Core Designs - Shared Features</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Documentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Glossary</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Version 7.1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">User Guides</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">FACTS Core Designs</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth3 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/aa_coreOverview.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Core Designs - Shared Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/study.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Study</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">Virtual Subject Response</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/vsr/continuous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Continuous Endpoints</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/vsr/dichotomous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dichotomous Endpoints</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/vsr/tte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time-to-event Endpoints</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/execution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Execution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/qois.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Quantities of Interest</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Design</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth4 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Design Tab Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/doseresponse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dose Response Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/frequentistanalysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Frequentist Analysis</span></a>
  </div>
</li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false">
 <span class="menu-text">Longitudinal Models</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth5 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/longitudinalmodels/overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Longitudinal Models Overview</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/longitudinalmodels/continuous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Continuous Endpoints</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/longitudinalmodels/dichotomous.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Dichotomous Endpoint</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/longitudinalmodels/tte.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Time-to-event Endpoint</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/allocation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Allocation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/interims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Interims</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/design/successfutility.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Success/Futility Criteria</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/simulation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Simulation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/core/analysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Analysis</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/crm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FACTS Dose Escalation CRM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/FACTSfromR.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Calling FACTS from R</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/flfll.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FACTS Linux File Loader Light - FLFLL</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/userguides/installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FACTS Installation Guide</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true">
 <span class="menu-text">Examples</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false">
 <span class="menu-text">CRM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-8" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-8" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/examples/CRM/example1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/examples/CRM/example2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 2</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false">
 <span class="menu-text">Staged</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-9" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-9" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/examples/Staged/example1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/v71/examples/Staged/example2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 2</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../../documentation/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1</span> Introduction</a>
  <ul>
  <li><a href="#purpose-of-this-document" id="toc-purpose-of-this-document" class="nav-link" data-scroll-target="#purpose-of-this-document"><span class="header-section-number">1.1</span> Purpose of this document</a></li>
  <li><a href="#scope-of-this-document" id="toc-scope-of-this-document" class="nav-link" data-scroll-target="#scope-of-this-document"><span class="header-section-number">1.2</span> Scope of this document</a></li>
  <li><a href="#context-of-this-issue" id="toc-context-of-this-issue" class="nav-link" data-scroll-target="#context-of-this-issue"><span class="header-section-number">1.3</span> Context of this Issue</a></li>
  <li><a href="#citing-facts" id="toc-citing-facts" class="nav-link" data-scroll-target="#citing-facts"><span class="header-section-number">1.4</span> Citing FACTS</a></li>
  </ul></li>
  <li><a href="#facts-core-overview" id="toc-facts-core-overview" class="nav-link" data-scroll-target="#facts-core-overview"><span class="header-section-number">2</span> FACTS Core Overview</a></li>
  <li><a href="#simulating-virtual-subjects" id="toc-simulating-virtual-subjects" class="nav-link" data-scroll-target="#simulating-virtual-subjects"><span class="header-section-number">3</span> Simulating Virtual Subjects</a>
  <ul>
  <li><a href="#subject-responses" id="toc-subject-responses" class="nav-link" data-scroll-target="#subject-responses"><span class="header-section-number">3.1</span> Subject Responses</a></li>
  <li><a href="#accrual" id="toc-accrual" class="nav-link" data-scroll-target="#accrual"><span class="header-section-number">3.2</span> Accrual</a>
  <ul class="collapse">
  <li><a href="#deterministic-accrual" id="toc-deterministic-accrual" class="nav-link" data-scroll-target="#deterministic-accrual"><span class="header-section-number">3.2.1</span> Deterministic Accrual</a></li>
  </ul></li>
  <li><a href="#drop-out-rates" id="toc-drop-out-rates" class="nav-link" data-scroll-target="#drop-out-rates"><span class="header-section-number">3.3</span> Drop-out Rates</a></li>
  </ul></li>
  <li><a href="#quantities-of-interest-qoi" id="toc-quantities-of-interest-qoi" class="nav-link" data-scroll-target="#quantities-of-interest-qoi"><span class="header-section-number">4</span> Quantities of Interest (QOI)</a>
  <ul>
  <li><a href="#posterior-probabilities" id="toc-posterior-probabilities" class="nav-link" data-scroll-target="#posterior-probabilities"><span class="header-section-number">4.1</span> Posterior Probabilities</a>
  <ul class="collapse">
  <li><a href="#notes-on-setting-deltas" id="toc-notes-on-setting-deltas" class="nav-link" data-scroll-target="#notes-on-setting-deltas"><span class="header-section-number">4.1.1</span> Notes on setting Deltas</a></li>
  <li><a href="#p-value-deltas" id="toc-p-value-deltas" class="nav-link" data-scroll-target="#p-value-deltas"><span class="header-section-number">4.1.2</span> P-value Delta’s</a></li>
  <li><a href="#p-value-comparisons-with-no-control-arm" id="toc-p-value-comparisons-with-no-control-arm" class="nav-link" data-scroll-target="#p-value-comparisons-with-no-control-arm"><span class="header-section-number">4.1.3</span> P-value Comparisons with No Control Arm</a></li>
  </ul></li>
  <li><a href="#predictive-probabilities" id="toc-predictive-probabilities" class="nav-link" data-scroll-target="#predictive-probabilities"><span class="header-section-number">4.2</span> Predictive Probabilities</a>
  <ul class="collapse">
  <li><a href="#bayesian-predictive-probabilities" id="toc-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#bayesian-predictive-probabilities"><span class="header-section-number">4.2.1</span> Bayesian predictive probabilities</a>
  <ul class="collapse">
  <li><a href="#current-trial-bayesian-predictive-probabilities" id="toc-current-trial-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#current-trial-bayesian-predictive-probabilities"><span class="header-section-number">4.2.1.1</span> Current Trial Bayesian Predictive Probabilities</a></li>
  <li><a href="#current-trial-bayesian-predictive-probabilities-time-to-event" id="toc-current-trial-bayesian-predictive-probabilities-time-to-event" class="nav-link" data-scroll-target="#current-trial-bayesian-predictive-probabilities-time-to-event"><span class="header-section-number">4.2.1.2</span> Current Trial Bayesian Predictive Probabilities – Time-to-Event</a></li>
  <li><a href="#future-trial-bayesian-predictive-probabilities" id="toc-future-trial-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#future-trial-bayesian-predictive-probabilities"><span class="header-section-number">4.2.1.3</span> Future Trial Bayesian Predictive Probabilities</a></li>
  </ul></li>
  <li><a href="#conditional-power" id="toc-conditional-power" class="nav-link" data-scroll-target="#conditional-power"><span class="header-section-number">4.2.2</span> Conditional Power</a>
  <ul class="collapse">
  <li><a href="#current-trial-conditional-power" id="toc-current-trial-conditional-power" class="nav-link" data-scroll-target="#current-trial-conditional-power"><span class="header-section-number">4.2.2.1</span> Current Trial Conditional Power</a></li>
  <li><a href="#future-trial-conditional-power" id="toc-future-trial-conditional-power" class="nav-link" data-scroll-target="#future-trial-conditional-power"><span class="header-section-number">4.2.2.2</span> Future Trial Conditional Power</a></li>
  <li><a href="#technical-aspects-of-conditional-power-calculations" id="toc-technical-aspects-of-conditional-power-calculations" class="nav-link" data-scroll-target="#technical-aspects-of-conditional-power-calculations"><span class="header-section-number">4.2.2.3</span> Technical Aspects of Conditional Power Calculations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#p-values" id="toc-p-values" class="nav-link" data-scroll-target="#p-values"><span class="header-section-number">4.3</span> P-values</a>
  <ul class="collapse">
  <li><a href="#p-values-when-there-is-no-control-arm" id="toc-p-values-when-there-is-no-control-arm" class="nav-link" data-scroll-target="#p-values-when-there-is-no-control-arm"><span class="header-section-number">4.3.1</span> P-values when there is no control arm</a></li>
  <li><a href="#fisher-exact-test" id="toc-fisher-exact-test" class="nav-link" data-scroll-target="#fisher-exact-test"><span class="header-section-number">4.3.2</span> Fisher-Exact Test</a></li>
  </ul></li>
  <li><a href="#target-doses" id="toc-target-doses" class="nav-link" data-scroll-target="#target-doses"><span class="header-section-number">4.4</span> Target Doses</a></li>
  <li><a href="#decision-quantities" id="toc-decision-quantities" class="nav-link" data-scroll-target="#decision-quantities"><span class="header-section-number">4.5</span> Decision Quantities</a></li>
  <li><a href="#standard-evaluation-variables" id="toc-standard-evaluation-variables" class="nav-link" data-scroll-target="#standard-evaluation-variables"><span class="header-section-number">4.6</span> Standard Evaluation Variables</a>
  <ul class="collapse">
  <li><a href="#the-direction-of-comparison-for-default-qois" id="toc-the-direction-of-comparison-for-default-qois" class="nav-link" data-scroll-target="#the-direction-of-comparison-for-default-qois"><span class="header-section-number">4.6.1</span> The direction of comparison for default QOIs</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#design-overview" id="toc-design-overview" class="nav-link" data-scroll-target="#design-overview"><span class="header-section-number">5</span> Design Overview</a>
  <ul>
  <li><a href="#evaluation-of-bayesian-posterior-estimates" id="toc-evaluation-of-bayesian-posterior-estimates" class="nav-link" data-scroll-target="#evaluation-of-bayesian-posterior-estimates"><span class="header-section-number">5.1</span> Evaluation of Bayesian Posterior Estimates</a></li>
  </ul></li>
  <li><a href="#dose-response" id="toc-dose-response" class="nav-link" data-scroll-target="#dose-response"><span class="header-section-number">6</span> Dose Response</a>
  <ul>
  <li><a href="#continuous-dichotomous-and-time-to-event" id="toc-continuous-dichotomous-and-time-to-event" class="nav-link" data-scroll-target="#continuous-dichotomous-and-time-to-event"><span class="header-section-number">6.1</span> Continuous, Dichotomous, and Time-To-Event</a></li>
  <li><a href="#descriptions-of-dose-response-models" id="toc-descriptions-of-dose-response-models" class="nav-link" data-scroll-target="#descriptions-of-dose-response-models"><span class="header-section-number">6.2</span> Descriptions of Dose Response Models</a>
  <ul class="collapse">
  <li><a href="#independent-dose-model" id="toc-independent-dose-model" class="nav-link" data-scroll-target="#independent-dose-model"><span class="header-section-number">6.2.1</span> Independent Dose Model</a></li>
  <li><a href="#independent-beta-binomial-model-dichotomous-only" id="toc-independent-beta-binomial-model-dichotomous-only" class="nav-link" data-scroll-target="#independent-beta-binomial-model-dichotomous-only"><span class="header-section-number">6.2.2</span> Independent Beta-Binomial Model (Dichotomous Only)</a></li>
  <li><a href="#simple-ndlm" id="toc-simple-ndlm" class="nav-link" data-scroll-target="#simple-ndlm"><span class="header-section-number">6.2.3</span> Simple NDLM</a></li>
  <li><a href="#monotonic-ndlm" id="toc-monotonic-ndlm" class="nav-link" data-scroll-target="#monotonic-ndlm"><span class="header-section-number">6.2.4</span> Monotonic NDLM</a></li>
  <li><a href="#second-order-ndlm" id="toc-second-order-ndlm" class="nav-link" data-scroll-target="#second-order-ndlm"><span class="header-section-number">6.2.5</span> Second Order NDLM</a></li>
  <li><a href="#parameter-logistic" id="toc-parameter-logistic" class="nav-link" data-scroll-target="#parameter-logistic"><span class="header-section-number">6.2.6</span> 3-Parameter Logistic</a></li>
  <li><a href="#hierarchical-logistic" id="toc-hierarchical-logistic" class="nav-link" data-scroll-target="#hierarchical-logistic"><span class="header-section-number">6.2.7</span> Hierarchical Logistic</a></li>
  <li><a href="#sigmoid-model" id="toc-sigmoid-model" class="nav-link" data-scroll-target="#sigmoid-model"><span class="header-section-number">6.2.8</span> Sigmoid Model</a></li>
  <li><a href="#u-shaped-model" id="toc-u-shaped-model" class="nav-link" data-scroll-target="#u-shaped-model"><span class="header-section-number">6.2.9</span> U-Shaped Model</a></li>
  <li><a href="#plateau-model" id="toc-plateau-model" class="nav-link" data-scroll-target="#plateau-model"><span class="header-section-number">6.2.10</span> Plateau Model</a></li>
  <li><a href="#parameter-exponential-logistic-dichotomous-only" id="toc-parameter-exponential-logistic-dichotomous-only" class="nav-link" data-scroll-target="#parameter-exponential-logistic-dichotomous-only"><span class="header-section-number">6.2.11</span> 3 Parameter Exponential Logistic (Dichotomous Only)</a></li>
  <li><a href="#hierarchical-model" id="toc-hierarchical-model" class="nav-link" data-scroll-target="#hierarchical-model"><span class="header-section-number">6.2.12</span> Hierarchical Model</a></li>
  <li><a href="#linear-model" id="toc-linear-model" class="nav-link" data-scroll-target="#linear-model"><span class="header-section-number">6.2.13</span> Linear Model</a></li>
  <li><a href="#hierarchical-linear-model" id="toc-hierarchical-linear-model" class="nav-link" data-scroll-target="#hierarchical-linear-model"><span class="header-section-number">6.2.14</span> Hierarchical Linear Model</a></li>
  </ul></li>
  <li><a href="#d-treatment-dose-response-models" id="toc-d-treatment-dose-response-models" class="nav-link" data-scroll-target="#d-treatment-dose-response-models"><span class="header-section-number">6.3</span> 2D Treatment Dose Response Models</a>
  <ul class="collapse">
  <li><a href="#d-continuous-factorial-model" id="toc-d-continuous-factorial-model" class="nav-link" data-scroll-target="#d-continuous-factorial-model"><span class="header-section-number">6.3.1</span> 2D Continuous Factorial Model</a></li>
  <li><a href="#d-discrete-factorial-model" id="toc-d-discrete-factorial-model" class="nav-link" data-scroll-target="#d-discrete-factorial-model"><span class="header-section-number">6.3.2</span> 2D Discrete Factorial Model</a></li>
  <li><a href="#d-ndlm" id="toc-d-ndlm" class="nav-link" data-scroll-target="#d-ndlm"><span class="header-section-number">6.3.3</span> 2D NDLM</a>
  <ul class="collapse">
  <li><a href="#the-base-model-with-control-included" id="toc-the-base-model-with-control-included" class="nav-link" data-scroll-target="#the-base-model-with-control-included"><span class="header-section-number">6.3.3.1</span> The Base Model, with Control Included</a></li>
  <li><a href="#fix-smoothing-ratio-for-row-factor-and-column-factor" id="toc-fix-smoothing-ratio-for-row-factor-and-column-factor" class="nav-link" data-scroll-target="#fix-smoothing-ratio-for-row-factor-and-column-factor"><span class="header-section-number">6.3.3.2</span> Fix smoothing ratio for row factor and column factor</a></li>
  <li><a href="#control-not-in-model-no-zero-level-doses" id="toc-control-not-in-model-no-zero-level-doses" class="nav-link" data-scroll-target="#control-not-in-model-no-zero-level-doses"><span class="header-section-number">6.3.3.3</span> Control not in model, no zero-level doses</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#baseline-adjusted-dose-response-models-continuous-only" id="toc-baseline-adjusted-dose-response-models-continuous-only" class="nav-link" data-scroll-target="#baseline-adjusted-dose-response-models-continuous-only"><span class="header-section-number">6.4</span> Baseline Adjusted Dose Response Models (Continuous Only)</a></li>
  <li><a href="#control-and-comparator-priors" id="toc-control-and-comparator-priors" class="nav-link" data-scroll-target="#control-and-comparator-priors"><span class="header-section-number">6.5</span> Control and Comparator Priors</a></li>
  <li><a href="#inverse-gamma-priors" id="toc-inverse-gamma-priors" class="nav-link" data-scroll-target="#inverse-gamma-priors"><span class="header-section-number">6.6</span> Inverse-gamma priors</a></li>
  <li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data"><span class="header-section-number">6.7</span> Handling Missing Data</a>
  <ul class="collapse">
  <li><a href="#time-to-event-missingness" id="toc-time-to-event-missingness" class="nav-link" data-scroll-target="#time-to-event-missingness"><span class="header-section-number">6.7.1</span> Time-to-Event Missingness</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#augmented-priors-historical-prior" id="toc-augmented-priors-historical-prior" class="nav-link" data-scroll-target="#augmented-priors-historical-prior"><span class="header-section-number">7</span> Augmented Priors (Historical Prior)</a>
  <ul>
  <li><a href="#setting-priors-for-hierarchical-model-hyper-parameters" id="toc-setting-priors-for-hierarchical-model-hyper-parameters" class="nav-link" data-scroll-target="#setting-priors-for-hierarchical-model-hyper-parameters"><span class="header-section-number">7.1</span> Setting Priors for Hierarchical Model Hyper Parameters</a></li>
  <li><a href="#bayesian-augmented-control-bac-example" id="toc-bayesian-augmented-control-bac-example" class="nav-link" data-scroll-target="#bayesian-augmented-control-bac-example"><span class="header-section-number">7.2</span> Bayesian Augmented Control (BAC) Example:</a></li>
  </ul></li>
  <li><a href="#frequentist-analysis" id="toc-frequentist-analysis" class="nav-link" data-scroll-target="#frequentist-analysis"><span class="header-section-number">8</span> Frequentist Analysis</a>
  <ul>
  <li><a href="#continuous-endpoints-1" id="toc-continuous-endpoints-1" class="nav-link" data-scroll-target="#continuous-endpoints-1"><span class="header-section-number">8.1</span> Continuous Endpoints</a></li>
  <li><a href="#dichotomous-endpoints-1" id="toc-dichotomous-endpoints-1" class="nav-link" data-scroll-target="#dichotomous-endpoints-1"><span class="header-section-number">8.2</span> Dichotomous Endpoints</a></li>
  <li><a href="#time-to-event-frequentist-analysis" id="toc-time-to-event-frequentist-analysis" class="nav-link" data-scroll-target="#time-to-event-frequentist-analysis"><span class="header-section-number">8.3</span> Time-to-Event Frequentist Analysis</a></li>
  </ul></li>
  <li><a href="#longitudinal-modeling" id="toc-longitudinal-modeling" class="nav-link" data-scroll-target="#longitudinal-modeling"><span class="header-section-number">9</span> Longitudinal Modeling</a>
  <ul>
  <li><a href="#multiple-imputation" id="toc-multiple-imputation" class="nav-link" data-scroll-target="#multiple-imputation"><span class="header-section-number">9.1</span> Multiple Imputation</a></li>
  <li><a href="#how-many-longitudinal-models" id="toc-how-many-longitudinal-models" class="nav-link" data-scroll-target="#how-many-longitudinal-models"><span class="header-section-number">9.2</span> How many longitudinal models?</a></li>
  <li><a href="#longitudinal-models-for-a-continuous-endpoint" id="toc-longitudinal-models-for-a-continuous-endpoint" class="nav-link" data-scroll-target="#longitudinal-models-for-a-continuous-endpoint"><span class="header-section-number">9.3</span> Longitudinal Models for a Continuous Endpoint</a>
  <ul class="collapse">
  <li><a href="#locf-last-observation-carried-forward" id="toc-locf-last-observation-carried-forward" class="nav-link" data-scroll-target="#locf-last-observation-carried-forward"><span class="header-section-number">9.3.1</span> LOCF (Last Observation Carried Forward)</a></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression"><span class="header-section-number">9.3.2</span> Linear Regression</a></li>
  <li><a href="#time-course-hierarchical" id="toc-time-course-hierarchical" class="nav-link" data-scroll-target="#time-course-hierarchical"><span class="header-section-number">9.3.3</span> Time Course Hierarchical</a></li>
  <li><a href="#kernel-density" id="toc-kernel-density" class="nav-link" data-scroll-target="#kernel-density"><span class="header-section-number">9.3.4</span> Kernel Density</a></li>
  <li><a href="#itp" id="toc-itp" class="nav-link" data-scroll-target="#itp"><span class="header-section-number">9.3.5</span> ITP</a></li>
  </ul></li>
  <li><a href="#longitudinal-models-for-a-dichotomous-endpoint" id="toc-longitudinal-models-for-a-dichotomous-endpoint" class="nav-link" data-scroll-target="#longitudinal-models-for-a-dichotomous-endpoint"><span class="header-section-number">9.4</span> Longitudinal Models for a Dichotomous Endpoint</a>
  <ul class="collapse">
  <li><a href="#locf-last-observation-carried-forward-1" id="toc-locf-last-observation-carried-forward-1" class="nav-link" data-scroll-target="#locf-last-observation-carried-forward-1"><span class="header-section-number">9.4.1</span> LOCF (Last Observation Carried Forward)</a></li>
  <li><a href="#beta-binomial" id="toc-beta-binomial" class="nav-link" data-scroll-target="#beta-binomial"><span class="header-section-number">9.4.2</span> Beta Binomial</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><span class="header-section-number">9.4.3</span> Logistic regression</a></li>
  <li><a href="#restricted-markov-model-absorbing-markov-chain" id="toc-restricted-markov-model-absorbing-markov-chain" class="nav-link" data-scroll-target="#restricted-markov-model-absorbing-markov-chain"><span class="header-section-number">9.4.4</span> Restricted Markov Model (Absorbing Markov Chain)</a></li>
  <li><a href="#dichotomous-endpoint-dichotomized-continuous-longitudinal-model" id="toc-dichotomous-endpoint-dichotomized-continuous-longitudinal-model" class="nav-link" data-scroll-target="#dichotomous-endpoint-dichotomized-continuous-longitudinal-model"><span class="header-section-number">9.4.5</span> Dichotomous Endpoint: Dichotomized Continuous Longitudinal Model</a></li>
  </ul></li>
  <li><a href="#time-to-event-predictor-models" id="toc-time-to-event-predictor-models" class="nav-link" data-scroll-target="#time-to-event-predictor-models"><span class="header-section-number">9.5</span> Time-to-Event Predictor Models</a>
  <ul class="collapse">
  <li><a href="#continuous-predictor" id="toc-continuous-predictor" class="nav-link" data-scroll-target="#continuous-predictor"><span class="header-section-number">9.5.0.1</span> Continuous Predictor</a></li>
  <li><a href="#dichotomous-predictor" id="toc-dichotomous-predictor" class="nav-link" data-scroll-target="#dichotomous-predictor"><span class="header-section-number">9.5.0.2</span> Dichotomous Predictor</a></li>
  <li><a href="#time-to-event-predictor" id="toc-time-to-event-predictor" class="nav-link" data-scroll-target="#time-to-event-predictor"><span class="header-section-number">9.5.0.3</span> Time to Event Predictor</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#allocation" id="toc-allocation" class="nav-link" data-scroll-target="#allocation"><span class="header-section-number">10</span> Allocation</a>
  <ul>
  <li><a href="#non-adaptive-designs" id="toc-non-adaptive-designs" class="nav-link" data-scroll-target="#non-adaptive-designs"><span class="header-section-number">10.1</span> Non-adaptive designs</a></li>
  <li><a href="#fixed-allocation" id="toc-fixed-allocation" class="nav-link" data-scroll-target="#fixed-allocation"><span class="header-section-number">10.2</span> Fixed Allocation</a></li>
  <li><a href="#arm-dropping" id="toc-arm-dropping" class="nav-link" data-scroll-target="#arm-dropping"><span class="header-section-number">10.3</span> Arm Dropping</a>
  <ul class="collapse">
  <li><a href="#randomization-ratio-and-blocking" id="toc-randomization-ratio-and-blocking" class="nav-link" data-scroll-target="#randomization-ratio-and-blocking"><span class="header-section-number">10.3.1</span> Randomization Ratio and Blocking</a></li>
  <li><a href="#arm-dropping-criteria" id="toc-arm-dropping-criteria" class="nav-link" data-scroll-target="#arm-dropping-criteria"><span class="header-section-number">10.3.2</span> Arm Dropping Criteria</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup"><span class="header-section-number">10.3.3</span> Setup</a>
  <ul class="collapse">
  <li><a href="#max-number-of-arms-that-can-be-dropped-during-the-study" id="toc-max-number-of-arms-that-can-be-dropped-during-the-study" class="nav-link" data-scroll-target="#max-number-of-arms-that-can-be-dropped-during-the-study"><span class="header-section-number">10.3.3.1</span> Max number of arms that can be dropped during the study</a></li>
  <li><a href="#prune-from-lowesthighest-dose" id="toc-prune-from-lowesthighest-dose" class="nav-link" data-scroll-target="#prune-from-lowesthighest-dose"><span class="header-section-number">10.3.3.2</span> Prune from lowest/highest dose</a></li>
  <li><a href="#upon-arm-drop" id="toc-upon-arm-drop" class="nav-link" data-scroll-target="#upon-arm-drop"><span class="header-section-number">10.3.3.3</span> Upon arm drop</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#adaptive-allocation" id="toc-adaptive-allocation" class="nav-link" data-scroll-target="#adaptive-allocation"><span class="header-section-number">10.4</span> Adaptive Allocation</a>
  <ul class="collapse">
  <li><a href="#adaptive-allocation-targets" id="toc-adaptive-allocation-targets" class="nav-link" data-scroll-target="#adaptive-allocation-targets"><span class="header-section-number">10.4.0.1</span> Adaptive Allocation Targets</a></li>
  <li><a href="#tips-tricks-and-intuition" id="toc-tips-tricks-and-intuition" class="nav-link" data-scroll-target="#tips-tricks-and-intuition"><span class="header-section-number">10.4.1</span> Tips, Tricks, and Intuition</a>
  <ul class="collapse">
  <li><a href="#weighting-for-probability-vs-information" id="toc-weighting-for-probability-vs-information" class="nav-link" data-scroll-target="#weighting-for-probability-vs-information"><span class="header-section-number">10.4.1.1</span> Weighting for Probability vs Information</a></li>
  <li><a href="#fixed-allocation-target" id="toc-fixed-allocation-target" class="nav-link" data-scroll-target="#fixed-allocation-target"><span class="header-section-number">10.4.1.2</span> Fixed Allocation Target</a></li>
  <li><a href="#non-fixed-control-adaptive-allocation" id="toc-non-fixed-control-adaptive-allocation" class="nav-link" data-scroll-target="#non-fixed-control-adaptive-allocation"><span class="header-section-number">10.4.1.3</span> Non-fixed Control Adaptive Allocation</a></li>
  <li><a href="#zero-out-allocation-probabilities" id="toc-zero-out-allocation-probabilities" class="nav-link" data-scroll-target="#zero-out-allocation-probabilities"><span class="header-section-number">10.4.1.4</span> Zero Out Allocation Probabilities</a></li>
  </ul></li>
  <li><a href="#adaptive-allocation-calculation-examples" id="toc-adaptive-allocation-calculation-examples" class="nav-link" data-scroll-target="#adaptive-allocation-calculation-examples"><span class="header-section-number">10.4.2</span> Adaptive Allocation Calculation Examples</a>
  <ul class="collapse">
  <li><a href="#simple-response-adaptive-randomization-example" id="toc-simple-response-adaptive-randomization-example" class="nav-link" data-scroll-target="#simple-response-adaptive-randomization-example"><span class="header-section-number">10.4.2.1</span> Simple Response Adaptive Randomization Example</a></li>
  <li><a href="#using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" id="toc-using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" class="nav-link" data-scroll-target="#using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms"><span class="header-section-number">10.4.2.2</span> Using Static Weighting Example: Ensuring a minimum allocation to all arms</a></li>
  <li><a href="#using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" id="toc-using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" class="nav-link" data-scroll-target="#using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose"><span class="header-section-number">10.4.2.3</span> Using Static Weighting Example: Ensuring a minimum allocation to top dose</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#deterministic-allocation" id="toc-deterministic-allocation" class="nav-link" data-scroll-target="#deterministic-allocation"><span class="header-section-number">10.5</span> Deterministic Allocation</a></li>
  <li><a href="#cohort-recruitment-fixed-allocation" id="toc-cohort-recruitment-fixed-allocation" class="nav-link" data-scroll-target="#cohort-recruitment-fixed-allocation"><span class="header-section-number">10.6</span> Cohort recruitment – fixed allocation</a></li>
  <li><a href="#cohort-recruitment-adaptive-allocation" id="toc-cohort-recruitment-adaptive-allocation" class="nav-link" data-scroll-target="#cohort-recruitment-adaptive-allocation"><span class="header-section-number">10.7</span> Cohort recruitment – adaptive allocation</a></li>
  <li><a href="#cohort-recruitment-allocate-to-best-dose" id="toc-cohort-recruitment-allocate-to-best-dose" class="nav-link" data-scroll-target="#cohort-recruitment-allocate-to-best-dose"><span class="header-section-number">10.8</span> Cohort recruitment – allocate to best dose</a></li>
  </ul></li>
  <li><a href="#interims" id="toc-interims" class="nav-link" data-scroll-target="#interims"><span class="header-section-number">11</span> Interims</a>
  <ul>
  <li><a href="#interim-analysis-triggers" id="toc-interim-analysis-triggers" class="nav-link" data-scroll-target="#interim-analysis-triggers"><span class="header-section-number">11.1</span> Interim Analysis Triggers</a>
  <ul class="collapse">
  <li><a href="#continuous-and-dichotomous-endpoint" id="toc-continuous-and-dichotomous-endpoint" class="nav-link" data-scroll-target="#continuous-and-dichotomous-endpoint"><span class="header-section-number">11.1.1</span> Continuous and Dichotomous Endpoint</a></li>
  <li><a href="#time-to-event-endpoint" id="toc-time-to-event-endpoint" class="nav-link" data-scroll-target="#time-to-event-endpoint"><span class="header-section-number">11.1.2</span> Time-to-Event Endpoint</a></li>
  </ul></li>
  <li><a href="#subject-follow-up-options" id="toc-subject-follow-up-options" class="nav-link" data-scroll-target="#subject-follow-up-options"><span class="header-section-number">11.2</span> Subject Follow-up Options</a></li>
  </ul></li>
  <li><a href="#successfutility-criteria" id="toc-successfutility-criteria" class="nav-link" data-scroll-target="#successfutility-criteria"><span class="header-section-number">12</span> Success/Futility Criteria</a>
  <ul>
  <li><a href="#final-evaluation" id="toc-final-evaluation" class="nav-link" data-scroll-target="#final-evaluation"><span class="header-section-number">12.1</span> Final Evaluation</a></li>
  <li><a href="#interim-analysis-criteria" id="toc-interim-analysis-criteria" class="nav-link" data-scroll-target="#interim-analysis-criteria"><span class="header-section-number">12.2</span> Interim Analysis Criteria</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Version 7.1</li><li class="breadcrumb-item">User Guides</li><li class="breadcrumb-item"><a href="../../../../documentation/v71/userguides/core/aa_coreOverview.html">FACTS Core Designs</a></li><li class="breadcrumb-item"><a href="../../../../documentation/v71/userguides/core/aa_coreOverview.html">Core Designs - Shared Features</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Core Designs - Shared Features</h1>
<p class="subtitle lead">All Endpoints: Quantities of Interest and Design options.</p>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p><img src="coreUGattachments/CoreUserGuide/media/image1.png" style="width:6.93268in;height:1.84409in" alt="facts_splash.png"></p>
<section id="introduction" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<section id="purpose-of-this-document" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="purpose-of-this-document"><span class="header-section-number">1.1</span> Purpose of this document</h2>
<p>This document describes how to use the ‘Quantities of Interest’ and ‘Design’ options that are common across the FACTS Core design engines. It is intended for all end users of the system.</p>
</section>
<section id="scope-of-this-document" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="scope-of-this-document"><span class="header-section-number">1.2</span> Scope of this document</h2>
<p>This document covers the design options that are common across the four FACTS Core Design Engines: Continuous, Dichotomous, Time-to-Event, and Multiple Endpoint. Design elements that are unique to a particular engine (primarily data simulation and simulation output) are covered in the endpoint specific Core Engine User Guide.</p>
<p>This document does not address the use of FACTS Enrichment Designs, Dose Escalation, or Platform Trials, which have separate User Guides.</p>
<p>The screenshots provided are specific to a particular installation and <a href="##" title="Screenshots from earlier versions of FACTS 6 are retained only where they are unchanged in FACTS 7.1">may not reflect the exact layout</a> of the information seen by any particular user. They were taken from FACTS V7 &amp; V6 installed on Windows 10 or 11. If FACTS is installed on different versions of Windows, or with different Windows ‘themes’ there will be some differences in appearance introduced by Windows. The contents of each tab, however, will still be consistent with the screenshots in this document.</p>
</section>
<section id="context-of-this-issue" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="context-of-this-issue"><span class="header-section-number">1.3</span> Context of this Issue</h2>
<p>This is the version of the user guide for inclusion with the FACTS 7.1 release.</p>
</section>
<section id="citing-facts" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="citing-facts"><span class="header-section-number">1.4</span> Citing FACTS</h2>
<p>If writing in and using Bibtex, if you wish to cite FACTS (thank you!), we suggest the following:</p>
<pre class="{verbatim}"><code>@techreport{FACTS71,
&nbsp;&nbsp;author = {{FACTS&nbsp;Development Team}},
&nbsp;&nbsp;title = {{FACTS}: Fixed and Adaptive Clinical Trial Simulator},
&nbsp;&nbsp;year&nbsp; = {2024},
&nbsp;&nbsp;month = {03},
&nbsp;&nbsp;number = {Version 7.1},
&nbsp;&nbsp;type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; = {Computer Software},
&nbsp;&nbsp;institution = {Berry Consultants LLC},
&nbsp;&nbsp;address = {Austin, TX},
&nbsp;&nbsp;note&nbsp;&nbsp; = {&lt;https://www.berryconsultants.com/software/facts/&gt;}
}</code></pre>
<p>This will result in a reference that, for example in the APA style, will look like the following:</p>
<pre class="{verbatim}"><code>FACTS Development Team (2024). FACTS: Fixed and adaptive clinical trial
simulator. Computer Software Version 7.1, Berry Consultants LLC, Austin, TX. &lt;https://www.berryconsultants.com/software/facts/&gt;.</code></pre>
</section>
</section>
<section id="facts-core-overview" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> FACTS Core Overview</h1>
<p>For an overview of the form entry and layout, see the User Guide for the Core Engine of the particular endpoint that you are using for your trial.</p>
<p>FACTS Core is for simulating trials where there are a number of related treatments being tested against a common control arm. Commonly, these different treatments will be different doses of the same drug and hence dose-response modelling is justifiable. If the treatments do not differ by dose but in some other way such as dosing frequency or treatment combination, then analysis can be by pairwise comparison with control, this is referred to as the ‘No model’ option.</p>
<p>FACTS provides numerous options for the statistical analysis, some of them straight forward, some of them quite novel, though all have been used in actual trials:</p>
<ul>
<li><p>The endpoint can be continuous, dichotomous or time to event.</p></li>
<li><p>As well as a control arm, the study arms can be compared with an active comparator.</p></li>
<li><p>With either a dichotomous or continuous endpoint, longitudinal models can used to impute the patient’s likely final outcome from early interim measures. This can be used when final endpoint data is missing due to subject drop-out or at interims for subjects who’ve not reached their final endpoint yet.</p></li>
<li><p>Estimation of the response on the control arm can be augmented using a hierarchical model to borrow from data from previous studies (This is known as Bayesian Augmented Control, BAC).</p></li>
<li><p>Interim analyses can be specified at fixed intervals by time, the number of subjects recruited or the number of events observed.</p></li>
<li><p>At interim analyses, options include:</p>
<ul>
<li><p>Choosing to stop the whole study for success or futility.</p></li>
<li><p>Dropping treatment arms</p></li>
<li><p>Adapting the randomization proportions to favor allocating to the doses that are most likely to be the desired target – which can be the study arm with the maximum response, the EDx, or minimum efficacious dose.</p></li>
</ul></li>
</ul>
</section>
<section id="simulating-virtual-subjects" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Simulating Virtual Subjects</h1>
<section id="subject-responses" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="subject-responses"><span class="header-section-number">3.1</span> Subject Responses</h2>
<p>The methods used to simulate subject responses vary by endpoint type. For each endpoint, the endpoint specific user guides provide information about simulating subject responses.</p>
<p>For simulating dichotomous responses see: <a href="##" title="Add correct link here.">FACTS Core Dichotomous User Guide</a></p>
<p>For simulating continuous responses see: <a href="##" title="Add correct link here.">FACTS Core Continuous User Guide</a></p>
<p>For simulating time to event responses see: <a href="##" title="Add correct link here.">FACTS Core Time-to-Event User Guide</a></p>
<p>For simulating multiple endpoint responses see the continuous or dichotomous user guide, depending on the type of endpoints used in the multiple endpoint study.</p>
</section>
<section id="accrual" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="accrual"><span class="header-section-number">3.2</span> Accrual</h2>
<p>The Accrual sub-tab provides an interface for specifying accrual profiles. Accrual profiles define the mean recruitment rate week by week during the course of the trial. Virtual subjects are simulated from a Poisson process in which the expected number of subjects per week is allowed to change week by week.</p>
<p>Accrual profiles are shown as a list on the left of the screen, as depicted below. These accrual profiles may be renamed by double-clicking on them and typing a new profile name. After creating a profile, the user must create at least one recruitment region. Early in the trial design process, detailed simulation of the expected accrual pattern is typically not necessary and a single region with a simple mean accrual rate is sufficient.</p>
<p>To model the expected accrual rates more precisely over the course of the trial, the user may specify multiple regions for each accrual profile and separately parameterize them. Regions are added via the table in the center of the screen (Figure 7‑1). Within this table, the user may modify:</p>
<ul>
<li><p>the peak mean weekly recruitment rate,</p></li>
<li><p>the start date (in weeks from the start of the trial) for this recruitment region,</p></li>
<li><p>whether the region will have a ramp up phase and if so when the ramp up will be complete (in weeks from the start of the trial).</p></li>
<li><p>Whether the region will have a ramp down, and if so when the ramp down start and when the ramp down will complete (in weeks from the start of the trial).</p></li>
</ul>
<p>Ramp up/ramp down define simple linear increase/decreases in mean recruitment rate from the start to the end of the ramp. Note that simulation of accrual is probabilistic, but ramp downs are defined in terms of time, so even if ramp downs are planned so that at the average accrual rate they will occur as the trial reaches cap, there is a risk in simulations when accrual has been slower than average, that ramp downs occur before the full sample size is reached. It is advisable to have at least one region that doesn’t ramp down to prevent simulations being unable to complete.</p>
<p>A graph of the recruitment rate of the highlighted region is shown as well. As the recruitment parameters are changed, the graph will update to show the time at which full accrual is reached. An accrual profile that does not reach full accrual is invalid and cannot be used to run simulations.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image2.png" style="width:5.44318in;height:4.13315in" alt="A screenshot of a social media post Description automatically generated"></p>
<p>In the screenshot above you can see the two step ramp up in accrual from two regions – each starting at different offsets into the trial.</p>
<p>Note that the accrual profile graph is only the mean expectation; actual accrual is simulated using exponential distributions for the intervals between subjects, derived from the mean accrual profile specified here. Thus some simulated trials will recruit more quickly than this and some more slowly.</p>
<p>There are commands to import and export region details from/to simple external XML files. When importing, the regions defined in the external file are <strong>added</strong> to the regions already defined, they don’t replace them.</p>
<p>This is an example of a very simple region file defining just one region:</p>
<pre class="{verbatim}"><code>&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;regions&gt;
&lt;region&gt;
&lt;name&gt;Region 1&lt;/name&gt;
&lt;rate&gt;5&lt;/rate&gt;
&lt;start&gt;0&lt;/start&gt;
&lt;ramp-up /&gt;
&lt;ramp-down /&gt;
&lt;/region&gt;
&lt;/regions&gt;</code></pre>
<section id="deterministic-accrual" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="deterministic-accrual"><span class="header-section-number">3.2.1</span> Deterministic Accrual</h3>
<p>If “Deterministic” accrual has been specified on the Study &gt; Study Info tab, then on the Accrual tab, rather that specifying an accrual profile from which subject recruitment times are simulated, the user loads a file of specific accrual dates for every subject.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image3.png" style="width:5.00179in;height:3.85875in"></p>
<p>The user specifies a “.dat” file to load that contains the <a href="##" title="This value is in weeks from FACTS 7.0 onwards, previously it was in days.">subject accrual dates in weeks</a> from the start of the trial.</p>
<p>The required file format is a text file with comma separate values. One row per subject, with 3 fields on each row:</p>
<ol type="1">
<li><p>the subject ID, (an integer)</p></li>
<li><p>the ID of the region where the subject was recruited (an integer)</p></li>
<li><p>and the subjects randomization date (in weeks from the start of the trial – this is a ‘real’ number allowing fractions of a week to be specified)</p></li>
</ol>
<p>The file must contain sufficient entries to allow the maximum number of subjects specified on the Study &gt; Study Info tab to be recruited.</p>
<p>After successfully loading a file, the FACTS GUI shows a plot of the resulting weekly accrual rate</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image4.png" style="width:5.00179in;height:3.85875in"></p>
</section>
</section>
<section id="drop-out-rates" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="drop-out-rates"><span class="header-section-number">3.3</span> Drop-out Rates</h2>
<p>For the continuous and dichotomous engines, and the multiple endpoint engine, the default dropout scenario is that no subjects drop out of the study before observing their final endpoint data. If dropouts are expected, the user can specify either the “Dropouts per Dose,” or “Dropouts per Dose per Visit.”</p>
<p>If “Dropouts per Dose” is selected, then each subject has a probability of not having an observable final endpoint value equal to the dropout rate of the dose that subject is randomized to. If each subject has multiple visits and “Dropouts per Dose” is selected, then the conditional probability of dropping out before each visit given that the subject had not dropped out up to the visit before rates are all equal. In other words, if the total dropout rate is <span class="math inline">\(\pi_D\)</span>, the probability of dropping out between visits <span class="math inline">\(i\)</span> and <span class="math inline">\(i+1\)</span> given that the subject had not dropped out at visit <span class="math inline">\(i\)</span> is <span class="math inline">\(1 - \left( 1 - \pi_{D} \right)^{\frac{1}{V}}\)</span> where <span class="math inline">\(V\)</span> is the total number of visits.</p>
<p>If “Dropouts per Dose per Visit” is selected, then each subject has a user specified probability of dropping out before a visit <span class="math inline">\(v\)</span> that is specified as the conditional probability of dropping out before visit <span class="math inline">\(v\)</span> given that that they had not dropped out by visit <span class="math inline">\(v-1\)</span>. This leads to a total dropout rate <span class="math inline">\(\pi_D\)</span> for a participant that is equal to:</p>
<p><span class="math display">\[\pi_{D} = 1 - \prod_{v = 0}^{V}{(1 - \pi_{v})}\]</span></p>
</section>
</section>
<section id="quantities-of-interest-qoi" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Quantities of Interest (QOI)</h1>
<p>The quantities of interest tab allows the user to specify the Bayesian posterior probabilities and frequentist p-values to be calculated and reported in the simulation results and available for use in early stopping decisions, trial adaptations and final evaluation.</p>
<p>There are 3 classes of QOI:</p>
<ol type="1">
<li><p>A probability calculated independently <strong>for each dose</strong>, there are 3 types of comparison:</p>
<ol type="1">
<li><p>The posterior probability that the estimate of the response of the subjects on that dose is better/worse than an absolute value or the estimate of response of the subjects on a reference dose, such as Control.</p></li>
<li><p>The predictive probability/conditional power of success (achieving frequentist statistical significance) in the current trial or a future trial comparing the estimate of response on the dose against that on the Control arm.</p></li>
<li><p>P-values for each dose comparing the estimate of response on that dose against that on the Control arm.</p></li>
</ol></li>
<li><p>Probabilities calculated across the doses for which dose is most likely to satisfy a specified <strong>target dose</strong> criteria. The target dose criteria can be to determine the dose with the maximum effect (QOI is called <span class="fake-code-block">Pr(Max)</span>), the minimum dose that achieves some known minimum effect (called <span class="fake-code-block">Pr(MED …)</span>), or that it is the minimum dose that achieves some percentago of the effect estimated for the most effective dose (called <span class="fake-code-block">Pr(EDq …)</span> where <span class="math inline">\(q\)</span> is the effect percentage).</p></li>
<li><p>A <strong>decision quantity</strong> – which is the value of either of the other types of QOIs at a specific dose level. The method of choosing the dose level that should be used for decision QOI is specified at the time of creating the decision QOI. As an example: a QOI may be created that calculates the Probability that each dose is superior to the control arm - <span class="fake-code-block">Pr(PBO)</span>. Additionally, a target QOI can be created that calculates the probability that each dose is the ED90 - <span class="fake-code-block">Pr(EDq relative to Control: Quantile=0.9)</span>. Then, a decision quantity could be created that is a scalar value representing the probability that the dose that is the most likely to be the ED90 is superior to control - <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d&gt;\theta_{Control}\)</span>); d=Greatest Pr(EDq relative to Control: Quantile=0.9)</span>. It is also easy to create a decision QOI that is simply the largest (or smallest) value of the dose specific QOI. An example of this would be the p-value of the dose with the smallest p-value.</p></li>
</ol>
<p>Trial decisions at interim analyses or the final analysis are made based on decision quantities, but adaptations like adaptive allocation can be based on posterior probabilities, predictive probabilities, and target probabilities.</p>
<p>Note that to creating a QOI for early stopping or final evaluation decisions will involve using 2 or 3 QOIs:</p>
<ol type="1">
<li><p>The probability to be tested e.g.&nbsp;the probability of being better than the Control by a clinically significant difference.</p></li>
<li><p>The target dose criteria for selecting the dose that is to be used in the test – e.g.&nbsp;the ED90. This step is not always necessary.</p></li>
<li><p>The decision quantity that combines 1 &amp; 2 – e.g.&nbsp;the probability that the ED90 is better than Control by a clinically significant difference.</p></li>
</ol>
<p>There are a number of pre-defined, default QOIs which simplifies the specification of the most commonly used decision quantities, and the importation of past FACTS designs. These are:</p>
<p><strong>Default Posterior Probabilities</strong></p>
<ul>
<li><p>The probability of being better than the control arm: <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d &gt; \theta_{Control}\)</span>)</span>, previously referred to as <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d – \theta_0\)</span>)</span>, <span class="fake-code-block">Pr(Pbo)</span> and <span class="fake-code-block">Prob. Beats Ctrl</span> in earlier versions of FACTS.</p></li>
<li><p>The probability of being better than the control arm by a clinically significant difference <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d - \theta_{Control} &gt; \delta^*\)</span>)</span>”, previously referred to as <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d – \theta_0 &gt;\)</span> CSD)</span>, <span class="fake-code-block">Pr(CSD)</span> and <span class="fake-code-block">Prob. Beats CSD</span> in earlier versions of FACTS. The value for the <span class="math inline">\(\delta^*\)</span> is the CSD, which is set in the “Standard Evaluation Variables” panel at the bottom of the QOI tab.</p></li>
</ul>
<p><strong>Default Predictive Probabilities</strong></p>
<ul>
<li>The probability of success in a future trial <span class="fake-code-block">Pr(Succ. Future Trial): N=<span class="math inline">\(N_{Future}\)</span>, <em>Sup/Noninf</em>, <span class="math inline">\(\alpha=\alpha^*\)</span>; <span class="math inline">\(\delta=\delta^*\)</span></span>, previously referred to as <span class="fake-code-block">Pr(S Phase III)</span> and <span class="fake-code-block">Prob. Stat Sig</span> in earlier versions of FACTS. The parameters for the future trial can be modified from the default by clicking on the QOI’s row in the table.</li>
</ul>
<p><strong>Default Target Doses</strong></p>
<ul>
<li><p>The probability for each dose that it is the dose with the maximum response, <span class="fake-code-block">Pr(Max)</span>, previously referred to as <span class="fake-code-block"><span class="math inline">\(d_{max}\)</span></span> and <span class="fake-code-block">Ppn Max</span> in earlier versions of FACTS. When used to select a dose in a decision quantity the label <span class="fake-code-block">p… <span class="math inline">\(d\)</span> = Greatest Pr(MAX)</span> is used.</p></li>
<li><p>The probability for each dose that it is the minimum dose that is better than Control by the specified CSD, <span class="fake-code-block">Pr(MED relative to Control: Delta = <span class="math inline">\(\delta^*\)</span></span>, previously referred to as <span class="fake-code-block">Ppn (MED)</span> in earlier versions of FACTS. The CSD used for comparison is specified in the Evaluation Variables panel at the bottom of the QOI tab. When used to select a dose in a decision quantity the label <span class="fake-code-block"><span class="math inline">\(d\)</span>= Greatest Pr(MED relative to <em>Control/Active Comparator</em>: Delta = <span class="math inline">\(delta^*\)</span>)</span> is used.</p></li>
<li><p>The minimum dose that gives a certain proportion of the maximum estimated response <span class="fake-code-block">Pr(EDq relative to Control: Quantile=<span class="math inline">\(Q\)</span>)</span>, previously referred to as <span class="fake-code-block">$d_{EDx}</span> and <span class="fake-code-block">Ppn(EDx)</span> in earlier versions of FACTS. The Effective Dose quantile to use can be modified by the clicking on QOI’s row in the table. When used to select a dose in a decision quantity <span class="fake-code-block">… <span class="math inline">\(d\)</span>=Greatest Pr(EDq relative to Control: Quantile=<span class="math inline">\(Q\)</span>)</span> is used.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image5.png" style="width:6.14271in;height:4.66432in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>In each panel for each type of quantity, existing quantities can be deleted by clicking on the <img src="coreUGattachments/CoreUserGuide/media/image6.png" style="width:0.32292in;height:0.23958in"> at the end of the corresponding row. Each quantity’s definition can be displayed and edited (only edited for the default QOIs) by clicking on the row displaying the quantity’s definition. A new quantity can be defined by clicking on the bottom row of the corresponding panel labelled “Add…”.</p>
<section id="posterior-probabilities" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="posterior-probabilities"><span class="header-section-number">4.1</span> Posterior Probabilities</h2>
<p>These are Bayesian quantities to be calculated at each interim and at the final analysis.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image7.png" style="width:3.59231in;height:2.61812in"></p>
<p>A Posterior Probability is specified as:</p>
<ul>
<li><p>Compare:</p>
<ul>
<li><p>Continuous: Means</p></li>
<li><p>Dichotomous: Rates or Log-odds</p></li>
<li><p>Time-to-Event: Hazard Ratio or Hazard Rates.</p></li>
</ul></li>
</ul>
<!-- -->
<ul>
<li><p>Condition: “&gt;” or “&lt;” a comparison value.</p></li>
<li><p>Relative to an absolute value or relative to the response on a <em>specific</em> dose.</p></li>
<li><p>The comparison can include a delta, which is the absolute value to be compared against if the comparison is absolute, or a value that the difference relative to the comparison arm is compared to.</p></li>
<li><p>The QOI will be given a “name” derived from these details and a short or Alternative name that will be used in the output files to allow easier access from other software, e.g.&nbsp;from within R.</p></li>
<li><p>If the endpoint is TTE and the design includes a predictor endpoint, then the definition of the QOI includes the specification of which endpoint it applies to.</p></li>
</ul>
<section id="notes-on-setting-deltas" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="notes-on-setting-deltas"><span class="header-section-number">4.1.1</span> Notes on setting Deltas</h3>
<p>In the three endpoints delta’s are defined as:</p>
<dl>
<dt>Continuous</dt>
<dd>
A CSD (Clinically Significant Difference) in the estimates of the mean response.
</dd>
<dt>Dichotomous</dt>
<dd>
A CSD in the estimate of the response rates if Rates is selected in the QOI, and of Odds Ratios
</dd>
<dt>Time-to-Event</dt>
<dd>
A CSHRD (Clinically Significant Hazard Ratio Difference) in the estimate of the Hazard Ratio
</dd>
</dl>
<p>A <em>standard</em> hypothesis test for demonstrating superiority to control uses a delta of 0. Testing for superiority with a non-zero delta is different, and the implications need to be <a href="##" title="Simulating its use in FACTS is a good way to achieve that understanding!">carefully understood</a>. Where the term CSD is used in this document, it should be taken to refer to CSHRD as well unless it is specifically stated otherwise.</p>
<p>When setting a target treatment difference from control for the study to beat, it is also common to require a degree of confidence that the target has been beaten. To achieve posterior probabilities of &gt;50% that the target has been beaten, the estimated mean difference will have to be <strong>greater</strong> than the target difference.</p>
<p>Thus, when setting a delta, we are setting up two hurdles the study drug must beat, first the delta and then on top of that an additional margin to give a &gt;50% confidence that the margin has been beaten. Thus, it is necessary to avoid setting the target delta too large. A common mistake is to set the delta to the ‘expected difference’ (the value that might have been used in a conventional sample size calculation). In scenarios where the simulated response is equal to the ‘expected difference’ and hence the CSD this will give probabilities of being better than control by the delta of 50% on average, regardless of the sample size.</p>
<p>It is inadvisable to require a posterior probability of 50% that the response is better than the Control by the delta margin as this turns the test into one that simply depends on whether the point estimate of the response is better.</p>
<p>It is inadvisable to require posterior probability of less than 50% for success, as such criteria have the undesirable characteristic that they can be met in circumstances where it can be seen that if further data was gathered consistent with what has already been seen, it would lead the threshold no longer being met! The posterior distribution would shrink so that there was no longer sufficient of the tail above the CSD.</p>
<p>It is better therefore to use a delta that is less than the expected difference that it is hoped to achieve, somewhat like having a non-inferiority margin around the target. So, when the design is simulated with a response at the expected difference the target will be clearly exceeded. A useful default value to use for a delta is half the ‘expected difference’. This usually yields “comprehensible” probability thresholds for both success and futility.</p>
<p>Using a delta has benefits however – simply being better than control but for very small difference can be established simply by having large sample sizes. Being better than control by a delta establishes some confidence that there is some patient benefit. Use of a delta is also useful if otherwise success thresholds “well out in the tail” (e.g.&nbsp;&gt; 0.99) are required such as the equivalent of an early look in a conservative Group Sequential design. Though the use of a delta does mean that there is a less direct equivalence to a p-value.</p>
</section>
<section id="p-value-deltas" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="p-value-deltas"><span class="header-section-number">4.1.2</span> P-value Delta’s</h3>
<p>Separately from the CSD/CSHRD delta, with a continuous or dichotomous endpoint (but not time-to-event), a frequentist super-superiority/non-inferiority delta can be specified.</p>
<p>These use the same selection of super-superiority/non-inferiority as the CSD</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image8.png" style="width:4.06126in;height:1.06908in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>Currently, unlike the CSD delta that is only applied to the default posterior probability QOI and MED target QOI, the p-value delta is applied to <strong>all</strong> the p-value QOIs and it cannot be overridden.</p>
<p>The value of the p-value delta is constrained to be 0 or positive. The ‘direction’ of the delta depends then on the direction of the endpoint (whether “higher/lower is better” or “a response is a positive/negative outcome”.</p>
<table class="table">
<caption>
<p>
Figure 8‑1: Accrual
</p>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>
</th>
<th>
Higher is better / Response is positive
</th>
<th>
Lower is better / Response is negative
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
Super-Superiority
</td>
<td>
Trt – Control &gt; delta
</td>
<td>
Trt – Control &lt; -delta
</td>
</tr>
<tr class="even">
<td>
Non-inferiority
</td>
<td>
Trt – Control &gt; -delta
</td>
<td>
Trt – Control &lt; delta
</td>
</tr>
</tbody>
</table>
<p>Figure 8‑1: Accrual</p>
</section>
<section id="p-value-comparisons-with-no-control-arm" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="p-value-comparisons-with-no-control-arm"><span class="header-section-number">4.1.3</span> P-value Comparisons with No Control Arm</h3>
<p>If no control arm is included p-values, with a continuous or dichotomous endpoint, the treatment response is compared to a fixed value. The fixed value is specified as “Frequentist <em>response/rate</em> to compare to for p-value QOIs:” in the Standard Evaluation Variables section at the bottom of the QOIs tab. It is not currently possible to compare different p-value QOIs to different fixed responses or rates.</p>
</section>
</section>
<section id="predictive-probabilities" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="predictive-probabilities"><span class="header-section-number">4.2</span> Predictive Probabilities</h2>
<p>There are two types of predictive probabilities –</p>
<ol type="1">
<li><p>Bayesian predictive probabilities, which are Bayesian predictions of frequentist outcomes and take into account the uncertainty around a set of parameters, and</p></li>
<li><p>Conditional Power, which aims to calculate the frequentist probability of success assuming a set of parameters to be true.</p></li>
</ol>
<p>The primary difference between the Bayesian predictive probabilities and the conditional power calculations is that the Bayesian predictive probabilities are calculated taking the variability around the estimated treatment effect into account, while the conditional power calculations assume that the observed test statistic of past data is the exact effect that future data will be generated from.</p>
<p>For both Bayesian predictive probabilities and conditional power, we differentiate two types, predicting the outcome in the current trial and predicting the outcome in a future trial.</p>
<section id="bayesian-predictive-probabilities" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="bayesian-predictive-probabilities"><span class="header-section-number">4.2.1</span> Bayesian predictive probabilities</h3>
<section id="current-trial-bayesian-predictive-probabilities" class="level4" data-number="4.2.1.1">
<h4 data-number="4.2.1.1" class="anchored" data-anchor-id="current-trial-bayesian-predictive-probabilities"><span class="header-section-number">4.2.1.1</span> Current Trial Bayesian Predictive Probabilities</h4>
<p>In the current trial, the outcome can be predicted under one of two assumptions:</p>
<ol type="1">
<li><p>That no new subjects are recruited, but all those who have been recruited are followed up until they are complete.</p></li>
<li><p>That the trial continues recruiting using the current allocation ratios until the trial maximum sample size is reached, and all subjects recruited are followed up until complete.</p></li>
</ol>
<p>Predictive probabilities currently can only predict outcomes based on p-values. Note that since p-values are only calculated as comparisons against a control arm, predictive probabilities of success in the current trial are only available if the current trial includes a control arm.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image9.png" style="width:2.64056in;height:2.61544in"></p>
<p>The user specifies how missingness is handled in the final analysis, the p-value test type – unadjusted, Bonferroni or <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett’s</a> and the (one sided) alpha level for the significance test. The QOI assumes that the specified default p-value delta is used in the final test.</p>
<p>The predictive probability of the current trial at the maximum sample size is only available:</p>
<ul>
<li>If the allocation is either fixed, or fixed with arm dropping, but not adaptive allocation.</li>
</ul>
<p>The predictive probability is calculated by simulating the remaining subjects, assuming their allocated at the current probabilities of allocation and simulating their final response based on the rate of response or (Normal) distribution of responses observed so far for each arm.</p>
<ul>
<li><p>Ignoring the possibility of the trial stopping or dropping an arm at a future interim</p></li>
<li><p>Ignoring the possibility of future subject drop-outs.</p></li>
</ul>
<p>There is one simulation of the remaining data per MCMC loop, potentially significantly increasing the time to perform the overall simulation of the trial.</p>
<p>If there is no data available on the arms involved in the Bayesian predictive probability calculation, FACTS will still perform the simulation of future subject outcomes based on posterior distribution. The posterior distribution for the arms with no available data will be the same as the user specified prior distribution.</p>
</section>
<section id="current-trial-bayesian-predictive-probabilities-time-to-event" class="level4" data-number="4.2.1.2">
<h4 data-number="4.2.1.2" class="anchored" data-anchor-id="current-trial-bayesian-predictive-probabilities-time-to-event"><span class="header-section-number">4.2.1.2</span> Current Trial Bayesian Predictive Probabilities – Time-to-Event</h4>
<p>Unlike the Continuous and Dichotomous endpoints, to predict the probability of success at full enrollment with a Time-to-Event endpoint, it is also necessary to simulate the accrual rate (and hence how many events might be observed).</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image10.png" style="width:2.94043in;height:2.92636in"></p>
<p>For TTE, for a Predictive Probability of Success at Full Enrollment, there are new parameters to determine how accrual is modeled. There are 3 models for accrual</p>
<ul>
<li><p>Fixed Rate, the parameters for this are:</p>
<ul>
<li>The fixed (mean) accrual rate per week to simulate.</li>
</ul></li>
<li><p>Estimated from the Last ‘W’ Weeks accrual data, using a Poisson distribution, with a Gamma prior. The parameters for this are</p>
<ul>
<li><p>The number of past weeks W to use the accrual data from.</p></li>
<li><p>The prior mean for the model of the accrual rate</p></li>
<li><p>The weight of the prior</p></li>
</ul></li>
<li><p>Estimated from all the accrual data from the start of the trial, using a Poisson distribution, with a Gamma prior, the parameters for this are:</p>
<ul>
<li><p>The prior mean for the model of the accrual rate</p></li>
<li><p>The weight of the prior</p></li>
</ul></li>
</ul>
</section>
<section id="future-trial-bayesian-predictive-probabilities" class="level4" data-number="4.2.1.3">
<h4 data-number="4.2.1.3" class="anchored" data-anchor-id="future-trial-bayesian-predictive-probabilities"><span class="header-section-number">4.2.1.3</span> Future Trial Bayesian Predictive Probabilities</h4>
<p>For predictive probabilities for a future trial, a predictive probability of success in a subsequent phase 3 trial is estimated during the current trial. The probability of success in phase 3 is calculated for each study arm, based on the specification of the phase 3 trial given here of:</p>
<ul>
<li><p>whether the aim is to show superiority or non-inferiority,</p></li>
<li><p>the sample size per arm,</p></li>
<li><p>the required one-sided alpha,</p></li>
<li><p>and the super-superiority margin or non-inferiority margin (if any).</p></li>
</ul>
<p>Given these criteria, FACTS calculates the predicted probability of success of the subsequent trial for that endpoint assuming the estimate of the response on that endpoint, integrated over the uncertainty in those estimates. The conventional expected power of the specified future trial is calculated for the treatment effect in each MCMC sample and then averaged. This predicted probability of success can then be used in the stopping criteria and final evaluation criteria for the current trial.</p>
<p>This QOI is an extension of the “probability of success in phase 3” in earlier versions of FACTS – the difference now is that multiple different possible future trials can be specified in different QOIs and used for different decisions.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image11.png" style="width:3.21594in;height:3.21594in"></p>
<p>This predictive probability has the following parameters that must be specified:</p>
<ul>
<li><p>Whether the future trial will be for Superiority or Non-inferiority.</p></li>
<li><p>The size of the future trial in terms of the number of subjects on each arm.</p></li>
<li><p>The (one sided) alpha level that will be used to determine the significance of the trial.</p></li>
<li><p>The Super-superiority margin (if any) or the non-inferiority margin. The default p-value delta is <strong>not</strong> used for this QOI it is specified as part of the QOI and can be different from the default.</p></li>
</ul>
<p>As with all QOIs, the future trial predictive probability QOI will be given an alternative shorter name that can be used when accessing the output files from other software such as R.</p>
<p>If there is no data available on the arms involved in the Bayesian predictive probability calculation, FACTS will still calculate the predictive probability of the future trial being a success based on the estimated posterior distribution. The posterior distribution for the arms with no available data will be the same as the user specified prior distribution.</p>
</section>
</section>
<section id="conditional-power" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="conditional-power"><span class="header-section-number">4.2.2</span> Conditional Power</h3>
<p>Conditional power is currently available for Continuous and Dichotomous endpoints in Core and Staged Designs.</p>
<p>When creating a Conditional Power QOI, the first specification that must be made is whether the conditional power should be calculated for the current trial or for a hypothetical future trial. The two selections are fundamentally different.</p>
<p>The Current Trial conditional power takes the information collected in the trial so far, and assumes that for the remainder of the current trial the data collected has an effect equal to the point estimate of the already collected data. The previously collected trial data is then combined with hypothetical future data and weighted based on the amount of information that has been and will be observed by the end of the trial. The result is the probability that the current trial will reject the null hypothesis at a provided alpha level under the assumption that the future patients are generated from a population having a treatment effect exactly equal to the past data’s test statistic.</p>
<p>The Future Trial conditional power also uses the information accrued in the trial so far to calculate the assumed treatment effect moving forward, but assumes that a new study would be started that does not use the data from the current trial in its analysis. The new study is assumed to be a 1:1 randomized study if there is a control arm, and a single arm study if no control, with a sample size per arm, objective, and alpha level specified at the time of QOI creation.</p>
<p>If a conditional power is ever calculated for an arm with no final response data or against a control arm with no final response data, the conditional power will be called missing (-9999 in FACTS).</p>
<section id="current-trial-conditional-power" class="level4" data-number="4.2.2.1">
<h4 data-number="4.2.2.1" class="anchored" data-anchor-id="current-trial-conditional-power"><span class="header-section-number">4.2.2.1</span> Current Trial Conditional Power</h4>
<p>When creating a current trial conditional power, the missingness strategy, multiplicity adjustment, final sample size, and alpha level for the significance test must be specified.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image12.png" style="width:2.61858in;height:2.61544in"></p>
<section id="handle-missingness-using" class="level5">
<h5 class="anchored" data-anchor-id="handle-missingness-using">Handle missingness using:</h5>
<p>Missingness handling for a continuous endpoint can be specified as:</p>
<ul>
<li><p><strong>Ignore:</strong> subjects that are known dropouts are not included in the current or final sample size, and are not used to estimate the treatment effect.</p></li>
<li><p><strong>Last Observation Carried Forward (LOCF):</strong> subjects that are known dropouts have their last observed endpoint value assumed to be their final endpoint. Subjects with no early observed data are ignored. Subjects that have data to carry forward are considered complete, and are used to estimate the current treatment effect.</p></li>
<li><p><strong>Baseline Observation Carried Forward (BOCF):</strong> subjects that are known dropouts have their baseline value assumed to be their final endpoint. They are included in the current information as complete subjects and are used to estimate the current treatment effect. BOCF is only available for the continuous endpoint and when simulating baseline for subjects.</p></li>
<li><p><strong>Failure:</strong> subjects that are known dropouts are assumed to have a negative outcome at their final visit. If responses are good, the subject is a non-response, and if responses are bad, the subject is a responder. Failure is only available for dichotomous endpoints.</p></li>
</ul>
</section>
<section id="test-type" class="level5">
<h5 class="anchored" data-anchor-id="test-type">Test Type</h5>
<p>The test type can either be Unadjusted or Bonferroni. An unadjusted test will always use the specified alpha level in the significance test. The Bonferroni adjustment will divide the specified alpha value by the number of non-control arms enrolling in the study in the enrolment period leading up to the current analysis time.</p>
</section>
<section id="sample-size" class="level5">
<h5 class="anchored" data-anchor-id="sample-size">Sample Size:</h5>
<p>The current trial conditional power can be calculated at two different future time points.</p>
<ol type="1">
<li><p><strong>Current Enrollment</strong>: That no new subjects are recruited, but all those who have been recruited are followed up until they are complete.</p></li>
<li><p><strong>Trial Maximum</strong>: That the trial would continue recruiting subjects using the current allocation ratios until the trial maximum sample size is reached, and all subjects recruited are followed up until they have the opportunity to complete.</p></li>
</ol>
</section>
<section id="one-sided-alpha" class="level5">
<h5 class="anchored" data-anchor-id="one-sided-alpha">One-sided Alpha</h5>
<p>The threshold that the current trial would have to be less than in order to be considered a success. The success/futility values specified in the design tab are not used in the conditional power calculation. This value may be adjusted by the “Test type:” input.</p>
</section>
<section id="super-superiority-non-inferiority-margin-for-p-value" class="level5">
<h5 class="anchored" data-anchor-id="super-superiority-non-inferiority-margin-for-p-value">Super-Superiority (Non-inferiority) margin for p-value:</h5>
<p>This value cannot be changed on the QOI pop-up. It’s instead modified at the bottom of the QOI page. The objective of the current trial cannot be different for each individual current trial conditional power QOIs.</p>
</section>
<section id="additional-notes" class="level5">
<h5 class="anchored" data-anchor-id="additional-notes">Additional Notes</h5>
<p>Currently, conditional power will always assume that there is no correction applied to combine the different p-values from the analysis timepoints, i.e.&nbsp;no combination test is used.</p>
<p>The conditional power of the current trial at the maximum sample size is only available if the allocation is either fixed, or fixed with arm dropping, but not adaptive allocation or deterministic allocation.</p>
<p>Conditional power for the current trial is calculated</p>
<ul>
<li><p>Ignoring the possibility of the trial stopping or dropping an arm at a future interim</p></li>
<li><p>Ignoring the possibility of future subject drop-outs.</p></li>
</ul>
</section>
</section>
<section id="future-trial-conditional-power" class="level4" data-number="4.2.2.2">
<h4 data-number="4.2.2.2" class="anchored" data-anchor-id="future-trial-conditional-power"><span class="header-section-number">4.2.2.2</span> Future Trial Conditional Power</h4>
<p>Conditional power of a future trial is reduced to a power calculation for a future trial, given the current frequentist estimates of treatment effect and standard deviation and a set of assumptions for the future trial, such as sample sizes, hypothesis to be tested, and significance levels to be used.</p>
<p>The test type of the future trial can be set to Superiority or Non-inferiority. If the superiority or non-inferiority margin is set to 0, then both types of tests simplify to traditional tests of superiority with no margin. If a non-zero margin is set, then the future trial must meet the success criteria indicated by the test type and the margin. The margin cannot be negative, but a super superiority test with a margin of -0.5 is equivalent to a non-inferiority test with a margin of 0.5.</p>
<p>The subjects per arm dictates how many subjects would be enrolled on each arm in the future study. If there is a control arm in the current trial, then the future trial is assumed to be randomized 1:1 between the active arm and the control. If there is no control arm in the current study, then the future trial is a single arm trial testing against the performance goal specified in the Freq. Comparison Response box in the QOI creation pop-up.</p>
<p>The One-sided Alpha is the significance level of the final analysis test of the future trial. The future trial is assumed to have 1 active arm, so there are no adjustments to the alpha level available.</p>
<p>The superiority margin or non-inferiority margin indicate the amount that the active arm must be better/not worse than the control arm by. If there is no control arm then this is the Freq Comparison response, which is the value that the active arms must be significantly better than in order to be declared a success. The frequentist margin for p-value QOIs on the QOI tab is not used for Future conditional power calculations – the future trial can have a different objective than the current trial.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image13.png" style="width:3.20399in;height:3.21594in"></p>
</section>
<section id="technical-aspects-of-conditional-power-calculations" class="level4" data-number="4.2.2.3">
<h4 data-number="4.2.2.3" class="anchored" data-anchor-id="technical-aspects-of-conditional-power-calculations"><span class="header-section-number">4.2.2.3</span> Technical Aspects of Conditional Power Calculations</h4>
<p>The conditional power calculations in FACTS are all calculated similarly to <a href="#jennisonturnbull" title="Jennison, C., &amp; Turnbull, B.W. (1999). Group Sequential Methods with Applications to Clinical Trials (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9780367805326">Jennison and Turnbull</a>.</p>
<p>For continuous endpoint conditional power calculations, the conditional power of the future trial is calculated using a pooled standard deviation from all arms. For dichotomous conditional power calculations, each arm has its own standard deviation based on the MLE estimate of its proportion. These decision result in the conditional power tests matching how standard p-value QOIs are calculated for continuous and dichotomous endpoints.</p>
<p>The following sections will provide formulae to calculate the conditional power in the case where there is a control arm. Simplifications for when the arm is being compared to a fixed value rather than a control arm are trivial: information fractions are only a function of the active arm standard deviation and the test statistic does not have a second sample mean subtracted from the active arm.</p>
<p>The value of <span class="math inline">\(\delta\)</span>, which can be a non-inferiority margin or a super superiority margin, is always positive coming out of FACTS. To make the math more concise we can define a couple of coefficients for the <span class="math inline">\(\delta\)</span> term that allow it to be used without re-writing formulas for different hypothesis test setups. If high values of the endpoint are good, then <span class="math inline">\(s_1 = 1\)</span>, and if low values of the endpoint are good, then <span class="math inline">\(s_1=−1\)</span>. If the specified <span class="math inline">\(\delta\)</span> is a non-inferiority margin, then <span class="math inline">\(s_2 = 1\)</span>, and if it’s a super superiority margin then <span class="math inline">\(s_2=-1\)</span>.</p>
<section id="continuous-conditional-power-for-the-current-trial" class="level5">
<h5 class="anchored" data-anchor-id="continuous-conditional-power-for-the-current-trial">Continuous Conditional Power for the Current Trial</h5>
<p>Let t be the interim index that the conditional power is being computed at, and T be the time of the analysis that the conditional power is being computed for. Then <span class="math inline">\(Z_k\)</span> is the test statistic of the data collected up to the current interim analysis in the study, <span class="math inline">\(I_k\)</span> is the information level at the time of the interim analysis, and <span class="math inline">\(I_K\)</span> is the information level at the end of the study that the conditional power is being calculated for.</p>
<p>Let arm 1 be the control and arm 2 be the active arm, <span class="math inline">\(\bar{x_{it}}\)</span> be the sample mean of arm <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, <span class="math inline">\(\widehat{\sigma_{i}^{2}}\)</span> be the sample variance of arm <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, <span class="math inline">\(n_{it}\)</span> be the number of subjects with complete known final data on arm <span class="math inline">\(i\)</span> at interim analysis <span class="math inline">\(t\)</span>, and <span class="math inline">\(n_{iT}\)</span> be the number of subjects with complete known final data on arm <span class="math inline">\(i\)</span> at the time that conditional power is being calculated for. The pooled variance estimate is <span class="math inline">\(\widehat{\sigma^{2}} = \sum_{d = 1}^{D}\widehat{\frac{\sigma_{d}^{2}}{n_{dt}}}\)</span> where D is the total number of arms in the study.</p>
<p>Then,</p>
<p><span class="math display">\[I_{t} = \left( \frac{\widehat{\sigma^{2}}}{n_{1t}} + \widehat{\frac{\sigma^{2}}{n_{2t}}} \right)^{-1}\]</span></p>
<p><span class="math display">\[I_{T} = \left( \frac{\widehat{\sigma^{2}}}{n_{1T}} + \widehat{\frac{\sigma^{2}}{n_{2T}}} \right)^{-1}\]</span></p>
<p><span class="math display">\[Z_{t} = \left( {\overline{x}}_{2t} - {\overline{x}}_{1t} + s_{1}s_{2}\delta \right)\sqrt{I_{t}}\]</span></p>
<p>where <span class="math inline">\(\delta\)</span> is the non-inferiority or super superiority margin.</p>
<p>Then for a one-sided alpha level of <span class="math inline">\(\alpha\)</span>, let <span class="math inline">\(Z_{1-\alpha}\)</span> be the critical value corresponding to <span class="math inline">\(\alpha\)</span>.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{Z_{t}\sqrt{I_{t}} - z_{1 - \alpha}\sqrt{I_{T}} + ({\overline{x}}_{2t} - {\overline{x}}_{1t} + s_{2}\delta)\left( I_{T} - I_{t} \right)}{\sqrt{I_{T} - I_{t}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{{- Z}_{t}\sqrt{I_{t}} - z_{1 - \alpha}\sqrt{I_{T}} - ({\overline{x}}_{2t} - {\overline{x}}_{1t} - s_{2}\delta)\left( I_{T} - I_{t} \right)}{\sqrt{I_{T} - I_{t}}} \right)\]</span></p>
</section>
<section id="calculation-of-continuous-conditional-power-for-a-future-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-continuous-conditional-power-for-a-future-trial">Calculation of Continuous Conditional Power for a Future Trial</h5>
<p>Most of the future trial conditional power calculation is the same as the above current trial conditional power. There are some simplifications.</p>
<p><span class="math inline">\({\overline{x}}_{it}\)</span> and <span class="math inline">\(\widehat{\sigma_{i}^{2}}\)</span> are the same as in the current conditional power calculation. <span class="math inline">\(I_t\)</span>, the weight of the current trial Z-score, is set to 0. <span class="math inline">\(I_T\)</span> is now the information at the end of the future trial, and is calculated as:</p>
<p><span class="math display">\[I_{T} = \left( \frac{\widehat{\sigma^{2}}}{n_{T}} + \widehat{\frac{\sigma^{2}}{n_{T}}} \right)^{- 1}\]</span></p>
<p>where <span class="math inline">\(n_T\)</span> is the sample size per arm in the future trial and again <span class="math inline">\(\widehat{\sigma^{2}}\)</span> is the pooled variance.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{- z_{1 - \alpha}\sqrt{I_{T}} + ({\overline{x}}_{2t} - {\overline{x}}_{1t} + s_{2}\delta)\left( I_{T} \right)}{\sqrt{I_{T}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{- z_{1 - \alpha}\sqrt{I_{T}} - ({\overline{x}}_{2t} - {\overline{x}}_{1t} - s_{2}\delta)\left( I_{T} \right)}{\sqrt{I_{T}}} \right)\]</span></p>
</section>
<section id="calculation-of-dichotomous-conditional-power-for-the-current-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-dichotomous-conditional-power-for-the-current-trial">Calculation of Dichotomous Conditional Power for the Current Trial</h5>
<p>The dichotomous conditional power calculations are similar in spirit to the continuous conditional power calculations. One substantial difference is in how the dichotomous conditional power tests handle a non-inferiority or super superiority margin, <span class="math inline">\(\delta\)</span>. The method of calculating an appropriate test statistic for a frequentist hypothesis test is not obvious when the null scenario has a non-zero <span class="math inline">\(\delta\)</span>.</p>
<p>When there is no margin, the estimate for each treatment is simply based on the observed response proportion&nbsp;<span class="math inline">\(\widehat{p_{i}}\)</span> for arm <span class="math inline">\(i\)</span>, and the test statistic for a comparison of the control arm, <span class="math inline">\(c\)</span>, with dose <span class="math inline">\(d\)</span> is the usual Wald test</p>
<p><span class="math display">\[Z_{d} = \frac{\widehat{p_{d}} - \widehat{p_{c}}}{\sqrt{\frac{\widehat{p_{d}}(1 - \widehat{p_{d}})}{n_{d}} + \frac{\widehat{p_{c}}(1 - \widehat{p_{c}})}{n_{c}}}}\]</span></p>
<p>When there is a margin, FACTS uses the Farrington-Manning Likelihood Score test statistic to estimate quantities <span class="math inline">\(\widetilde{p_{d}}\)</span> and <span class="math inline">\(\widetilde{p_{c}}\)</span> based on the MLEs of the arm proportions governed by the constraint that <span class="math inline">\(\widetilde{p_{d}} - \widetilde{p_{c}} = - s_{1}s_{2}\delta\)</span>. These constrained MLE estimates are used in the standard error of the test statistic. The FM test statistic is then,</p>
<p><span class="math display">\[Z_{FM,d} = \frac{\widehat{p_{d}} - \widehat{p_{c}} + s_{1}s_{2}\delta}{\sqrt{\frac{\widetilde{p_{d}}(1 - \widetilde{p_{d}})}{n_{d}} + \frac{\widetilde{p_{c}}(1 - \widetilde{p_{c}})}{n_{c}}}}\]</span></p>
<p>See the <a href="#pass" title="NCSS, LLC. Assurance for Non-Inferiority Tests for the Difference Between Two Proportions. In PASS Sample Size Software Documentation (pp. 289-1-289–31).">PASS documentation</a> or <a href="#sas" title="SAS Institute Inc. 2016. Base SAS® 9.4 Procedures Guide: Statistical Procedures, Sixth Edition. Cary, NC: SAS Institute Inc.">SAS documentation</a> for a complete description of the calculations that go into the FM test. In the SAS documentation, note that the FM test is the same as the Miettinen-Nurminen test without including the <span class="math inline">\(\frac{n}{n - 1}\)</span> variance correction. The FM test was used rather than the MN test because as <span class="math inline">\(\delta \rightarrow 0\)</span>, the FM test converges to the simple Wald test.</p>
<p>Once the test statistic has been resolved, the dichotomous conditional power for the current trial is calculated as follows. For calculating the conditional power for arm 2 compared to the control arm, called arm 1 without loss of generality, let <span class="math inline">\(I_t\)</span> be the current information amount and <span class="math inline">\(I_T\)</span> be the amount of information that the conditional power is being calculated for. Then,</p>
<p><span class="math display">\[I_{t} = \left( \frac{\widetilde{p_{1}}\left( 1 - \widetilde{p_{1}} \right)}{n_{1t}} + \frac{\widetilde{p_{2}}\left( 1 - \widetilde{p_{2}} \right)}{n_{2t}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[I_{T} = \left( \frac{\widetilde{p_{1}}\left( 1 - \widetilde{p_{1}} \right)}{n_{1T}} + \frac{\widetilde{p_{2}}\left( 1 - \widetilde{p_{2}} \right)}{n_{2T}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[Z_{t} = \left( \widehat{p_{2}} - \widehat{p_{1}} + s_{1}s_{2}\delta \right)*\sqrt{I_{t}}\]</span></p>
<p>where <span class="math inline">\(\delta\)</span> is the super superiority or non-inferiority margin, and <span class="math inline">\(n_{1t}\)</span> and <span class="math inline">\(n_{2t}\)</span> are current number of completers on the control and active arm, and <span class="math inline">\(n_{1T}\)</span> and <span class="math inline">\(n_{2T}\)</span> are the number of completers that will be on the control and active arm at time that the conditional power is being calculated for. Additionally, if there is no non-inferiority or super superiority margin <span class="math inline">\(\delta\)</span>, then all <span class="math inline">\(\widetilde{p_{*}}\)</span> values are equal to their corresponding <span class="math inline">\(\widehat{p_{*}}\)</span> values.</p>
<p>For a one-sided alpha level of <span class="math inline">\(\alpha\)</span>, let <span class="math inline">\(z_{1-\alpha}\)</span> be the critical value corresponding to <span class="math inline">\(\alpha\)</span>.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{Z_{t}\sqrt{I_{t}} - z_{1 - \alpha}\sqrt{I_{T}} + (\widehat{p_{2}} - \widehat{p_{1}} + s_{2}\delta)\left( I_{T} - I_{t} \right)}{\sqrt{I_{T} - I_{t}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{{- Z}_{t}\sqrt{I_{t}} - z_{1 - \alpha}\sqrt{I_{T}} - (\widehat{p_{2}} - \widehat{p_{1}} - s_{2}\delta)\left( I_{T} - I_{t} \right)}{\sqrt{I_{T} - I_{t}}} \right)\]</span></p>
</section>
<section id="calculation-of-dichotomous-conditional-power-for-a-future-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-dichotomous-conditional-power-for-a-future-trial">Calculation of Dichotomous Conditional Power for a Future Trial</h5>
<p>Most of the calculation quantities for the future trial conditional power are the same as the current trial conditional power. The only difference is that for the future trial conditional power we discard the influence of the current trial test statistic on the final analysis, so <span class="math inline">\(I_t=0\)</span>. Then the conditional power calculations become:</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{- z_{1 - \alpha}\sqrt{I_{T}} + (\widehat{p_{2}} - \widehat{p_{1}} + s_{2}\delta)\left( I_{T} \right)}{\sqrt{I_{T}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP_{T} = \Phi\left( \frac{- z_{1 - \alpha}\sqrt{I_{T}} - (\widehat{p_{2}} - \widehat{p_{1}} - s_{2}\delta)\left( I_{T} \right)}{\sqrt{I_{T}}} \right)\]</span></p>
</section>
</section>
</section>
</section>
<section id="p-values" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="p-values"><span class="header-section-number">4.3</span> P-values</h2>
<p>A p-value QOI simply allows the user to specify which test type to be used (unadjusted, Bonferroni, <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett’s</a>, or Trend Test), and how missing data is to be handled (ignored, LOCF, <a href="##" title="Only if continuous endpoint and baseline is being simulated.">BOCF</a>, and <a href="##" title="Dichotomous endpoint only.">missing is failure</a>). If a control arm is present, p-values are comparisons against the control arm. If there is no control arm present, p-value QOIs are comparisons against a fixed response or fixed rate that is specified at the bottom of the QOI tab (it cannot be set differently for separate QOIs).</p>
<p>Note that for dichotomous endpoints p-value are calculated using the Test of Proportions, this test statistic asymptotically approaches a normal distribution, and at least <a href="##" title="Sometimes this is said to be 10 and 10, or 15 and 15. Your rule of thumb can be based on your comfort level for allowing CLT to kick in.">5 success and 5 failures</a> should be observed for this to be reasonable.</p>
<p>The p-values are calculated including the default frequentist delta that has been specified at the bottom of the screen. The delta margin cannot be modified as part of the QOI, the value of the delta and nature of the test is the same for all the p-value QOIs.</p>
<p>In a TTE design with a predictor, the p-values are only calculated for the final event endpoint, not the predictors.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image14.png" style="width:3.08054in;height:1.89707in" alt="Graphical user interface, application Description automatically generated"></p>
<section id="p-values-when-there-is-no-control-arm" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="p-values-when-there-is-no-control-arm"><span class="header-section-number">4.3.1</span> P-values when there is no control arm</h3>
<p>If there is no control arm (not currently an option in Time-to-Event), the p-value delta is instead interpreted as the objective response or response rate to compare to. The option to set the trial type is also disabled (“Superiority” is selected and the “non-inferiority option is greyed out). For a non-inferiority trial comparing to an objective response or response rate simply use the objective rate minus the non-inferiority delta (if a higher response is better) or the objective rate plus the non-inferiority delta (if a lower response is better).</p>
<p>It is currently only possible to have one objective rate to compare against.</p>
<p>The same objective rate will be used for the target p-value test in the predictive probabilities.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image15.png" style="width:5.07319in;height:3.85221in" alt="Graphical user interface, text, application Description automatically generated"></p>
</section>
<section id="fisher-exact-test" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="fisher-exact-test"><span class="header-section-number">4.3.2</span> Fisher-Exact Test</h3>
<p>When specifying the QOIs for a dichotomous endpoint in a trial with a control arm, the bottom of the QOI tab allows the user to specify what statistical test to use when calculating p-values. Options are “Normal approximation” (default) and “Fisher exact test”. “Normal approximation” uses a t-test and should yield similar results to a Chi-Square test without continuity correction, while “Fisher exact test” uses an exact Fisher’s exact test for 2x2 tables.</p>
<p>If “Fisher exact test” is chosen as the test type, all p-value QOIs will use a Fisher’s exact test, except for future trial predictive probabilities, which will still use a t-test.</p>
<p>If “Fisher exact test” is chosen as the test type, only “Bonferroni” and “Unadjusted” are available as multiplicity corrections and any QOIs previously created using different multiplicity corrections will be deleted.</p>
<p>“Fisher exact test” is not available for non-inferiority comparisons.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image16.png" style="width:6.925in;height:5.07292in" alt="A screenshot of a computer Description automatically generated"></p>
</section>
</section>
<section id="target-doses" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="target-doses"><span class="header-section-number">4.4</span> Target Doses</h2>
<p>The target dose QOIs are Bayesian posterior probabilities based on MCMC sampling of how often each dose meets the specified target criteria. There are 3 types of target specifiable</p>
<ul>
<li><p>Max – the dose with the maximum response, this has no parameters to specify, so is available as a pre-defined default QOI.</p></li>
<li><p>MED – a Minimum Effective Dose, the lowest dose that has a response better than an absolute or relative target.</p></li>
<li><p>EDq – an effective dose, the dose that achieves a specified proportion (quantile <span class="math inline">\(q\)</span>) of the maximum improvement in response relative to an absolute value or the performance of a specific treatment arm.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image17.png" style="width:3.00783in;height:2.07488in"></p>
</section>
<section id="decision-quantities" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="decision-quantities"><span class="header-section-number">4.5</span> Decision Quantities</h2>
<p>The QOIs described so far have defined values to be calculated across all doses. For a Success/Futility decision to be made it is necessary to specify the treatment arm whose QOI value is to be used in comparison to the success and/or futility criteria. This selection can be done by specifying a specific arm, but normally it is specified by using a “Probability of being Target” selection criteria. A simple and common example is “The probability of the response being better than that of the Control of the Treatment arm with the maximum response”:</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image18.png" style="width:2.98863in;height:1.43143in"></p>
<p><img src="coreUGattachments/CoreUserGuide/media/image19.png" style="width:3.71051in;height:1.77718in"></p>
<p>A decision QOI consists of (1) a QOI that has been calculated for each dose, and (2) a method of choosing a dose to use the QOI value of. Choosing the dose can be done either by using a target Dose QOI like <span class="fake-code-block">Pr(Max)</span>, <span class="fake-code-block">Pr(EDq…)</span>, etc, by choosing the dose with the highest or lowest value of a QOI, or by explicitly choosing a dose level in advance.</p>
<p>As an example using a target QOI, you can imagine evaluating a decision QOI that is specified to choose the probability of being better than Control by 2 units <span class="fake-code-block">Pr(<span class="math inline">\(\theta_d - \theta_0 &gt; 2\)</span>)</span> based on the arm with the highest ED90 <span class="fake-code-block">EDq relative to control; Quantile 0.9</span>.</p>
<p>Instead of a Target Dose QOI, it is also possible to specify a specific dose, or to use the terms “Max probability over all doses” and “Min probability over all doses” which mean that the dose with the minimum or maximum value of the per dose QOI is used. This enables:</p>
<ul>
<li><p>Decisions QOIs testing specific doses, for example by defining a Posterior probability QOI that compares all doses against the lowest dose, and then a Decision QOI using that posterior probability with the highest dose selected as the target dose it is possible to based decisions on the posterior probability that the highest dose is better than the lowest dose.</p></li>
<li><p>A Decision QOI using “Max probability over all doses” allows a decision to be based on whether a probability or p-value is greater than a threshold at any dose, or less than a threshold at all doses.</p></li>
<li><p>A Decision QOI using “Min probability over all doses” allows a decision to be based on whether a probability or p-value is less than a threshold for any dose or greater than a threshold at all doses.</p></li>
</ul>
<p>There is one special case: if the QOI chosen is the Trend Test p-value, then because this is not actually a per-dose value, only one “Target dose” can be selected: “Overall Significance”.</p>
</section>
<section id="standard-evaluation-variables" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="standard-evaluation-variables"><span class="header-section-number">4.6</span> Standard Evaluation Variables</h2>
<p>These 2 parameters are used across some of the default QOIs and hence specified outside the normal QOI dialog boxes.</p>
<ul>
<li><p>The CSD value</p></li>
<li><p>and whether absolute or relative to the Control arm</p></li>
</ul>
<p>these are used in both the default “Pr(CSD)” and the “MED relative to Control” QOIs.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image20.png" style="width:6.925in;height:0.49375in"></p>
<p>Note that the CSD value here is designed to be usually entered as a positive value, as in earlier versions of FACTS. Its sign is automatically adjusted if “lower score means subject improvement” or if the trial is a non-inferiority trial.</p>
<p>These adjustments are <strong>not</strong> made for other user entered QOIs. The directions of comparison both for the definition of the probability to be calculated and the comparison of the resulting probability with a threshold are under the user’s control, as are whether delta’s are negative or positive. This allows the user to define QOIs in whatever fashion is natural to them and their team.</p>
<section id="the-direction-of-comparison-for-default-qois" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="the-direction-of-comparison-for-default-qois"><span class="header-section-number">4.6.1</span> The direction of comparison for default QOIs</h3>
<p>Note that as a result of being able to specify whether a higher or lower response represents improvement, and whether the aim is superiority or non-inferiority, the CSD or the NIM must always be a positive value. FACTS will automatically determine which direction is appropriate (e.g.&nbsp;if <strong><em>lower</em></strong> values are subject improvement, the engine will realize a CSD will need to be <strong><em>subtracted</em></strong> from the control score before comparing with the estimate of response on a treatment arm).</p>
</section>
</section>
</section>
<section id="design-overview" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Design Overview</h1>
<p>The FACTS core engine allows for the design and simulation of fixed and adaptive clinical trials, especially focused on, but not limited to, Bayesian designs with multiple active arms. Trials designed in the core engines are comprised of a number of elements:</p>
<ol type="1">
<li><p>The dose response model: the user must specify how the doses are related to eachother in the primary analysis, though there is a simple ‘no model’ option that estimates the mean treatment effect of each arm independently. A fixed trial uses the dose response model for the final Bayesian analysis of the data; an adaptive trial uses the same model both for the final analysis and at the interim updates.</p></li>
<li><p>The longitudinal (predictor) model: whether the trial is adaptive or fixed, the user may select to whether to use a longitudinal model (similarly, a predictor model in time to event). In a fixed trial the longitudinal model can be used to multiply impute final values for subjects that have dropped out. In an adaptive trial it is also used at the interim updates to multiply impute final values for subjects who have been recruited but do not yet have final values. In a fixed trial with no subject dropouts using a longitudinal model would have no effect on the outcome, analysis, or conduct of the trial.</p></li>
<li><p>Allocation rules: in a fixed trial the user just specifies the proportion of subjects to be recruited to each arm, and the same can be done in an adaptive trial (i.e.&nbsp;an adaptive trial does not have to adapt the allocation), but an adaptive trial has a range of options that the user can use to adapt how subjects are allocated to the different treatment arms as the trial progresses.</p></li>
<li><p>Early stopping rules: in an adaptive trial the user can select the criteria and specify the thresholds at which trial should be stopped at any interim where the conditions are satisfied. Early stopping is optional, and even in an adaptive design the user can opt to always recruit the maximum permitted number of subjects. In a fixed trial there are no interim analyses and hence no opportunity to stop early.</p></li>
<li><p>Final evaluation criteria: the same Bayesian evaluation criteria are available whether the trial is fixed or adaptive. The user selects which criteria to use and what thresholds will constitute success or failure. The success and failure criteria do not have to be complements of eachother, and any analysis that doesn’t completely satisfy either the success or futility criteria is called, “inconclusive.”</p></li>
<li><p>Frequentist analysis: frequentist p-values can be calculated comparing each dose to the control arm (or a fixed value if there is no control). P-values can be used as decision making quantities at interim updates or final analyses. p-value cannot benefit from the dose reponse models or longitudinal models, which are specific to the Bayesian model in FACTS.</p></li>
</ol>
<section id="evaluation-of-bayesian-posterior-estimates" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="evaluation-of-bayesian-posterior-estimates"><span class="header-section-number">5.1</span> Evaluation of Bayesian Posterior Estimates</h2>
<p>At every interim and final analysis there is a Bayesian model fit to the data observed up to that point in the trial. The Bayesian model contains a dose response model and, often, a longitudinal model. In the absence of a longitudinal model, the posterior is calculated as:</p>
<p><span class="math display">\[p(\omega|Y) \propto \prod_{i = 1}^{n}{p(y_{i}|\phi)p(\phi)}\]</span></p>
<p>where <span class="math inline">\(\phi\)</span> is the set of parameters of the selected response model, <span class="math inline">\(p(\phi)\)</span> is the prior for those parameters, <span class="math inline">\(y_i\)</span> is the final response for each subject and <span class="math inline">\(n\)</span> is the number of subjects with complete data.</p>
<p>With a longitudinal model, this becomes:</p>
<p><span class="math display">\[p(\omega|Y) \propto \prod_{i = 1}^{n}{p(y_{i}|\phi)p(\phi)\prod_{i = 1}^{n}{\prod_{j = 1}^{L}{p(y_{ij}|\psi)p(\psi)}}}\]</span></p>
<p>where <span class="math inline">\(\psi\)</span> is the set of parameters of the selected longitudinal model, <span class="math inline">\(p(\psi)\)</span> is the prior for those parameters, <span class="math inline">\(y_{ij}\)</span> is the response for each subject <span class="math inline">\(i\)</span> at each visit <span class="math inline">\(j\)</span> and <span class="math inline">\(L\)</span> is the number of visits.</p>
<p>The posterior is evaluated using <a href="##" title="Markov Chain Monte Carlo">MCMC</a> with individual parameters updated by Metropolis Hastings (or Gibbs sampling where possible), using only the <span class="math inline">\(y_i\)</span> and <span class="math inline">\(y_{ij}\)</span> data available at the time of the update.</p>
</section>
</section>
<section id="dose-response" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Dose Response</h1>
<p>Dose response models in FACTS may be more accurately called final endpoint models. They create and model a relationship across the doses specified in the Treatment Arms tab. Often, but not always, the dose strength, called “Effective Dose Strength” in the Study &gt; Treatment Arms tab of FACTS, is used in the dose response models to determine the order of doses, and which doses are more related to others.</p>
<p>The dose response models can be simple, and model the doses largely independently, as is done with the Independent Dose Model or the Independent Beta Binomial Model (dichotomous only). They can have logistic style models with interpretable parameters, like the 3-parameter logistic or the <span class="math inline">\(E_{max}\)</span> model (called Sigmoidal in FACTS). The dose response model can also be a model that creates a smooth, spline like, model over the doses using a normal dynamic linear model (NDLM), a monotonic NDLM, or a 2nd order NDLM.</p>
<p>For all endpoints, we model the response at each dose, d, in terms of <span class="math inline">\(\theta_d\)</span> on a continuous scale, allowing a consistent and rich range of dose response models to be used for all endpoint types. Transformations (see below) of the dichotomous and time-to-event responses are used to achieve this.</p>
<section id="continuous-dichotomous-and-time-to-event" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="continuous-dichotomous-and-time-to-event"><span class="header-section-number">6.1</span> Continuous, Dichotomous, and Time-To-Event</h2>
<p>With the exception of two dose response models specific to a dichotomous endpoint, the same dose response modeling facilities are available for all endpoints.</p>
<p>Let there be D total doses including the control arm if it exists. For any endpoint, the estimate of dose response model is called <span class="math inline">\(\theta_d\)</span> for a dose <span class="math inline">\(d \in \{1, \ldots , D\}\)</span>.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Continuous</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Dichotomous</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Time-To-Event</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>In the continuous dose response models the individual response or change from baseline (if it is being used) <span class="math inline">\(Y_i\)</span> of the <span class="math inline">\(i^{th}\)</span> subject allocated to dose <span class="math inline">\(d_i\)</span> is modeled: <span class="math display">\[
Y_i \sim \text{N}(\theta_{d_i}, \sigma^2)
\]</span> The variance <span class="math inline">\(\sigma^2\)</span> has an inverse-gamma prior. For a description in how FACTS elicits parameterizations for the Inverse Gamma distribution, <a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">see here</a>.</p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>In the dichotomous case the final endpoint of the <span class="math inline">\(i^{th}\)</span> subject who has been allocated to dose <span class="math inline">\(d_i\)</span> is modeled:</p>
<p><span class="math display">\[ Y_i \sim \text{Bernoulli}(P_{d_i}) \]</span> where <span class="math inline">\(P_{d_i}\)</span> is the probability of response for a subject on dose <span class="math inline">\(d_i\)</span>. The probability <span class="math inline">\(P_d\)</span> is modeled on the logit scale, so <span class="math display">\[P_{d} = \frac{e^{\theta_{d}}}{1 + e^{\theta_{d}}},\]</span> and <span class="math inline">\(\theta_d\)</span> is the log-odds ratio: <span class="math display">\[\theta_{d} = ln\left( \frac{P_{d}}{1 - P_{d}} \right)\]</span>,</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>In the time-to-event case, the time to a subject’s response, <span class="math inline">\(Y_i\)</span> is modeled as piece-wise exponentially distributed with hazard rates, <span class="math inline">\(\lambda_s\)</span>, for pieces <span class="math inline">\(s \in \{1,\ldots,S\}\)</span>. So,</p>
<p><span class="math display">\[ Y_i \sim \text{PWExp}(\{\lambda_1,\ldots,\lambda_S\})\]</span></p>
<p>for a subject on the control arm, and</p>
<p><span class="math display">\[ Y_i \sim \text{PWExp}(\{\lambda_1 e^{\theta_d},\ldots,\lambda_S e^{\theta_d}\})\]</span></p>
<p>for non-control doses. Then, <span class="math inline">\(\theta_d\)</span> is the log-hazard ratio <span class="math inline">\(\left( \ln\left( \frac{\lambda_{s}e^{\theta_{d}}}{\lambda_{s}} \right) = \ln\left( e^{\theta_{d}} \right) = \theta_{d} \right)\)</span> averaged over the observation time segments. This formulation implies a proportional treatment effect across the pieces of the piece-wise exponential.</p>
</div>
</div>
</div>
<p>Each dose response model is parameterized in terms of <span class="math inline">\(\theta_d\)</span>, but each endpoint models this parameter on a different scale. The dichotomous dose response models are on the log-odds scale, and the time-to-event endpoint models are on the log hazard ratio. When specifying a prior distribution for a continuous endpoint dose response model the expected data mean and variance determine which priors should be considered non-informative. When estimating a probability in the dichotomous case, using a prior with standard deviation above, say, 10 leads to a diffuse distribution on the log-odds scale, but results in a prior distribution on the probability scale that is heavily peaked at 0 and 1. This can lead to undesirable model results and decisions being made in small sample size situations, and numerical instability in extreme cases. Similarly on the time-to-event scale, the prior put on the log-hazard ratio <span class="math inline">\(\theta_d\)</span> is exponentiated before being multiplied by the hazard rate, so diffuse priors on the log-hazard can have unexpected modeled results. Again, time-to-event <span class="math inline">\(\theta_d\)</span> priors that have standard deviations less than about 10 are generally acceptably diffuse for most situations while avoiding edge case curiosities.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image21.png" style="width:2.07519in;height:2.68327in"></p>
</section>
<section id="descriptions-of-dose-response-models" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="descriptions-of-dose-response-models"><span class="header-section-number">6.2</span> Descriptions of Dose Response Models</h2>
<p>The Dose Response section of the Design tab allows the user to specify how to analyze the relationship between dose/treatment arm and the final response and hence estimate the values <span class="math inline">\(\theta_d\)</span>. The interpretation of <span class="math inline">\(\theta_d\)</span> depends on the nature of the endpoint:</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">Continuous</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Dichotomous</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-3" role="tab" aria-controls="tabset-2-3" aria-selected="false">Time-To-Event</a></li></ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<p>Where the response is continuous, <span class="math inline">\(\theta_d\)</span> is the estimate of the mean response/change from baseline on treatment arm <span class="math inline">\(d\)</span>, and the common inter-subject variance of the response <span class="math inline">\(\sigma^2\)</span>, is also estimated.</p>
<p>The response on the control arm, <span class="math inline">\(\theta_0\)</span>, is estimated either in the dose response model or modeled separately.</p>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<p>Where the response is dichotomous, <span class="math inline">\(\theta_d\)</span> is the estimate of the log-odds of the probability of observing a response on the treatment arm <span class="math inline">\(d\)</span>.</p>
<p>The response on the control arm, <span class="math inline">\(\theta_0\)</span>, is estimated either in the dose response model or modeled separately.</p>
</div>
<div id="tabset-2-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-3-tab">
<p>Where the response is time-to-event, <span class="math inline">\(\theta_d\)</span> is the estimate of the log hazard ratio compared to the control arm on the treatment arm <span class="math inline">\(d\)</span>.</p>
<p>When the primary endpoint is time-to-event, the response rate on the control arm, <span class="math inline">\(\lambda\)</span>, is estimated and <span class="math inline">\(\theta_d\)</span> for <span class="math inline">\(d\in \{1,2,\ldots,D\}\)</span> is the log hazard of the response rate of each treatment arm compared to the control arm, so <span class="math inline">\(\theta_0\equiv 0\)</span>.</p>
</div>
</div>
</div>
<p>Some, but not all, of the dose response models use the effective dose strength, <span class="math inline">\(\nu_d\)</span>, to model the dose response <span class="math inline">\(\theta_d\)</span>. The effective dose strength is specified on the Study &gt; Treatment Arms tab. It is always fixed at 0 for the control arm (<span class="math inline">\(\nu_0\equiv 0\)</span>).</p>
<section id="independent-dose-model" class="level3" data-number="6.2.1">
<h3 data-number="6.2.1" class="anchored" data-anchor-id="independent-dose-model"><span class="header-section-number">6.2.1</span> Independent Dose Model</h3>
<p>The “Independent Dose Model” providing a simple pair-wise comparison between the study drug arms and the control arm and/or the active comparator arm. The doses are modelled as independent and normally distributed with a prior of:</p>
<p><span class="math display">\[\theta_d \sim \text{N}(\mu_d, \nu_d^2)\]</span></p>
<p>Where <span class="math inline">\(\mu_d\)</span> and <span class="math inline">\(\nu_d^2\)</span> are specified in FACTS and can either be the same or vary across arms.</p>
<p>This model is useful:</p>
<ul>
<li><p>When there is only one or two experimental arms</p></li>
<li><p>When the study drug arms don’t differ by dose but in other ways, so there is no ordered sequence of treatments – e.g.&nbsp;each arm is the study drug in combination with a different additional drug.</p></li>
<li><p>For simulating simple trial designs</p></li>
<li><p>For simulating a ‘conventional’ or ‘strawman’ design to compare more complex designs against</p></li>
</ul>
<p>Otherwise for trials with multiple related arms that differ by dose, it is usually more efficient to use a dose-response model.</p>
</section>
<section id="independent-beta-binomial-model-dichotomous-only" class="level3" data-number="6.2.2">
<h3 data-number="6.2.2" class="anchored" data-anchor-id="independent-beta-binomial-model-dichotomous-only"><span class="header-section-number">6.2.2</span> Independent Beta-Binomial Model (Dichotomous Only)</h3>
<p>This is a “no model” option similar to the above, but only available for the Dichotomous endpoint. Unlike any other dose response model, this model uses the beta distribution to model the probability of response directly rather than fitting a model to the log-odds of the probability.</p>
<p>The final endpoint response <span class="math inline">\(Y_i\)</span> is modeled as:</p>
<p><span class="math display">\[Y_i \sim \text{Bernoulli}(P_d)\]</span> where <span class="math inline">\(P_d\)</span> is the probability that a patient is a response at the final endpoint for subjects randomized to dose <span class="math inline">\(d\)</span>. With posterior</p>
<p><span class="math display">\[P_d \sim \text{Beta}(\alpha_d + \text{responders}_d, \beta_d + \text{non_responders}_d)\]</span></p>
<p>Where <span class="math inline">\(\alpha_d\)</span>, <span class="math inline">\(\beta_d\)</span> are the priors for the arm <span class="math inline">\(d\)</span>, <span class="math inline">\(\text{responders}_d\)</span> is the number of responders on arm <span class="math inline">\(d\)</span> and <span class="math inline">\(\text{non_responders}_d\)</span> is the number of non-responders on arm <span class="math inline">\(d\)</span>.</p>
<p>This model has the advantages of an easier to understand prior, and better estimation of <span class="math inline">\(P_d\)</span> when the number of responders and non-responders is small (either is &lt; 5) compared to the log-odds model. As it’s a independent dose model, it is well suited to analyzing single arm, two arm or three arm trials, or trials where the experimental arms are unrelated, and so there is no basis on which to borrow information between them. With trials with multiple arms of the same treatment at different doses it is usually more advantageous to fit a dose response model.</p>
</section>
<section id="simple-ndlm" class="level3" data-number="6.2.3">
<h3 data-number="6.2.3" class="anchored" data-anchor-id="simple-ndlm"><span class="header-section-number">6.2.3</span> Simple NDLM</h3>
<p>The Normal Dynamic Linear Model (NDLM) estimates the final endpoint as a smoothed curve across doses included in the model. Doses are tied directly to their nearest neighbor, and the prior expectation for a dose is that it is equal to its neighboring doses, tending to a constant dose response across doses in the absence of data. The model is defined as follows:</p>
<p>Let doses <span class="math inline">\(d=d', \ldots, D\)</span> be doses in the dose response model and <span class="math inline">\(\theta_d\)</span> be the estimated dose response for dose <span class="math inline">\(d\)</span>. The initial dose <span class="math inline">\(d'=1\)</span> if there is no control or control is included in the dose response model, and <span class="math inline">\(d'=2\)</span> if the control arm is modeled separately.</p>
<p>The dose response of the first dose, <span class="math inline">\(d'\)</span>, has a prior of:</p>
<p><span class="math display">\[\theta_{d'} \sim N\left(\mu_{d'},\tau^2_{d'}\right)\]</span></p>
<p>where <span class="math inline">\(\mu_{d'}\)</span> and <span class="math inline">\(\tau_{d'}^2\)</span> are specified directly in FACTS. Subsequent dose response estimates <span class="math inline">\(\theta_{d'+1}, \ldots, \theta_D\)</span> have priors centered at the previous dose response with variances based on the distance between the dose <span class="math inline">\(d\)</span> strength and the dose <span class="math inline">\(d-1\)</span> strength. Specifically,</p>
<p><span class="math display">\[\theta_d \sim N\left(\theta_{d-1},\tau^2_{d-1}\right) \text{ for } d=d'+1, \ldots, D\]</span></p>
<p>where for dose strengths <span class="math inline">\(\nu_d\)</span> and <span class="math inline">\(\nu_{d-1}\)</span>, <span class="math inline">\(\tau_{d-1}^2\)</span> is defined as <span class="math display">\[\tau^2_{d-1}=\tau^2\left(\nu_d-\nu_{d-1}\right)\]</span></p>
<p>The prior distribution for the “drift” parameter, which controls the amount of smoothing is:</p>
<p><span class="math display">\[\tau^{2}\sim IG\left( \frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
<p>where <span class="math inline">\(\tau_\mu\)</span> and <span class="math inline">\(\tau_n\)</span> are specified in the Dose Response tab in FACTS under Model Parameters. <a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">See here</a> for help with specifying an inverse gamma distribution with center and weight.</p>
<p>In the continuous case the residual error around the estimated dose response is</p>
<p><span class="math display">\[\sigma^{2}\sim IG\left( \frac{\sigma_{n}}{2},\frac{\sigma_{\mu}^{2}\sigma_{n}}{2} \right)\]</span></p>
<p>where <span class="math inline">\(\sigma_\mu\)</span> and <span class="math inline">\(\sigma_n\)</span> are specified on the Dose Response tab in FACTS under Error Parameters.</p>
<p>The Simple NDLM is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Simple NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.</p>
<p>In a ‘null’ scenario where the response on all the doses is the same as control, the simple NDLM reduces type-1 error. The estimate of <span class="math inline">\(\tau^2\)</span> tends towards zero and the estimate of the dose response tends to a flat line. The smoothing of the estimates of the response reduces the random fluctuations in the estimates from dose to dose and is a very effective counter to the problem of type-1 error inflation due to the multiplicity of doses being tested. A small prior for the mean value of <span class="math inline">\(\tau\)</span> will accentuate this effect. The price to be paid for this benefit is a tendency to underestimate large changes in response or where there is a peak in the response. This over-smoothing can reduce power. A prior for the mean of <span class="math inline">\(\tau\)</span> centered at large values will minimize over-smoothing, and a very large prior would simply remove any smoothing effect at all. A standard prior for the mean of <span class="math inline">\(\tau\)</span> would be the expected average change in response from dose to dose, scaled to take into account the differences in the specified effective dose strengths.</p>
<p>Usually, the choice of prior for <span class="math inline">\(\tau^2\)</span> is tuned based on simulation results, trading off reducing type-1 error in the null case against loss of power and reduced estimate of maximum response in the effective scenario with the largest jump in response or steepest peak.</p>
<p><strong>Aside</strong>: When using the NDLM model or any of its alternatives (2<span class="math inline">\(^{nd}\)</span> order or Monotonic NDLM), and including doses in a design that receive no subject allocation (ie. Allocation ratio set to 0), some important characteristics of the model should be considered in the interpretation of results. First, the NDLM model “borrows” information from neighboring doses, and therefore including unallocated intermediate doses will increase uncertainty in the fitted response. Information must “pass through” these intermediate doses, and uncertainty should be expected to increase as the number of intermediate unallocated doses between two allocated doses increases. Secondly, the NDLM model estimates the response at unallocated doses, but without subject data at these doses the uncertainty in the estimate can be considerably larger than doses with subject data. This high degree of uncertainty can lead to a vestigial probability that an unallocated dose is the target dose (<span class="fake-code-block">Pr(EDq)</span>, <span class="fake-code-block">Pr(MED)</span>, <span class="fake-code-block">Pr(Max)</span>) even though the mean response estimate and probabilities at neighboring doses with subject data would not suggest this to be the case.</p>
</section>
<section id="monotonic-ndlm" class="level3" data-number="6.2.4">
<h3 data-number="6.2.4" class="anchored" data-anchor-id="monotonic-ndlm"><span class="header-section-number">6.2.4</span> Monotonic NDLM</h3>
<p>The Monotonic NDLM endpoint model is similar to the NDLM in the sense that it smooths dose response estimates using neighboring doses, but is constrained to be either monotonically increasing or monotonically decreasing across doses. The direction of monotonicity depends on the value specified in the “Monotonic:” selection in the Model Parameters section of the Monotonic NDLM Dose Response page.</p>
<p>The use of this model is generally limited to endpoints where a strong presumption of increasing/decreasing response with dose is reasonable – such as a biomarker or a toxicity endpoint.</p>
<p>Let doses <span class="math inline">\(d = d', \ldots, D\)</span> be doses in the dose response model and <span class="math inline">\(\theta_d\)</span> be the estimated dose response for dose <span class="math inline">\(d\)</span>. The initial dose <span class="math inline">\(d'=1\)</span> if there is no control or control is included in the dose response model, and <span class="math inline">\(d'=2\)</span> if the control arm is modeled separately. The following model is the monotonically positive NDLM:</p>
<p><span class="math display">\[\theta_{d'} \sim N\left(\mu_{d'},\tau^2_{d'}\right)\]</span></p>
<p>and</p>
<p><span class="math display">\[\theta_d \sim N^+\left(\theta_{d-1},\tau^2_{d-1}\right) \mbox{ for } d = d', \ldots, D,\]</span> where <span class="math inline">\(\tau_{d-1}^2\)</span> is defined as in the NDLM, and <span class="math inline">\(X \sim \text{N}^+(\mu, \sigma^2)\)</span> refers to a positive truncated normal distribution with density function:</p>
<p><span class="math display">\[f_{X}(x) = \frac{1 - \Phi\left( - \frac{\mu}{\sigma} \right)}{\sqrt{2\pi}\sigma}\exp\left\{ - \frac{1}{2\sigma^{2}}(x - \mu)^{2} \right\} \text{ for } x&gt;0\]</span></p>
<p>The result of this dose-response model is that the curve is monotonically increasing, in that <span class="math inline">\(\theta_d&gt;\theta_{d-1}\)</span>.</p>
<p>The monotonically decreasing NDLM is similar except: <span class="math display">\[\theta_d \sim N^-\left(\theta_{d-1},\tau^2_{d-1}\right) \mbox{ for } d = d', \ldots, D,\]</span></p>
<p>where <span class="math inline">\(X \sim \text{N}^-(\mu, \sigma^2)\)</span> refers to a negative truncated normal distribution:</p>
<p><span class="math display">\[f_{X}(x) = \frac{\Phi\left( - \frac{\mu}{\sigma} \right)}{\sqrt{2\pi}\sigma}\exp\left\{ - \frac{1}{2\sigma^{2}}(x - \mu)^{2} \right\} \text{ for } x&lt;0\]</span></p>
<p>The result of this dose-response model is that the curve is monotonically decreasing, in that <span class="math inline">\(\theta_d&lt;\theta_{d-1}\)</span>.</p>
</section>
<section id="second-order-ndlm" class="level3" data-number="6.2.5">
<h3 data-number="6.2.5" class="anchored" data-anchor-id="second-order-ndlm"><span class="header-section-number">6.2.5</span> Second Order NDLM</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The second order NDLM described in this section is the version utilized in FACTS version 4.0 and later. The model labelled “Second Order NDLM” in versions before 4.0 is was maintained as the model labelled “Legacy 2nd Order NDLM” until the release of FACTS 7.1, at which time it was removed.</p>
</div>
</div>
<p>The second order NDLM serves as a “smoother” similar to the NDLM, however it tends to smooth toward a linear fit with a slope (the NDLM itself tends to shrink each dose’s fit toward its neighbors, while the second order NDLM prefers any trend in the neighbors).</p>
<p>Let doses <span class="math inline">\(d=d', \ldots, D\)</span> be doses in the dose response model and <span class="math inline">\(\theta_d\)</span> be the estimated dose response for dose <span class="math inline">\(d\)</span>. The initial dose <span class="math inline">\(d'=1\)</span> if there is no control arm or control is included in the dose response model, and <span class="math inline">\(d'=2\)</span> if the control arm is modelled separately. The initial dose <span class="math inline">\(d'\)</span> is modeled:</p>
<p><span class="math display">\[\theta_{d'} \sim N\left(\mu_{0},\tau^2_{0}\right)\]</span></p>
<p>where <span class="math inline">\(\mu_0\)</span> and <span class="math inline">\(\tau_0^2\)</span> are specified directly in FACTS.</p>
<p>In the case of a time-to-event endpoint, the initial dose <span class="math inline">\(d'\)</span> is the control arm, and has a <span class="math inline">\(\theta_{d'}= 0\)</span> by definition, so no prior distribution is needed.</p>
<p>The prior distribution for the dose response for the dose directly after the initial dose is specified on the difference between the <span class="math inline">\(d'\)</span> and <span class="math inline">\(d'+1\)</span> level doses:</p>
<p><em>{d’+1} - </em>{d’} N(<em>{1},^2</em>{1})</p>
<p>Successive doses are then modeled based on differences in slope between the dose and the two doses below them. Let:</p>
<p><span class="math display">\[\theta_{d} = \theta_{d - 1} + \Delta_{d}\zeta_{d} + \frac{\Delta_{d}}{\Delta_{d - 1}}\left( \theta_{d - 1} - \theta_{d - 2} \right)\]</span></p>
<p>for doses <span class="math inline">\(d=d'+2,\ldots,D\)</span>, where <span class="math inline">\(\Delta_d=\nu_d-\nu_{d-1}\)</span> and <span class="math inline">\(\Delta_{d-1}=\nu_{d-1}-\nu_{d-2}\)</span>. The priors for the dose response smoothing terms <span class="math inline">\(\zeta_d\)</span> are:</p>
<p><span class="math display">\[\zeta_d \sim \text{N}(0, \tau_2^2)\]</span> The smoothing is determined by the parameter <span class="math inline">\(\tau_2\)</span>. Small values of <span class="math inline">\(\tau_2\)</span> lead to more smoothing, while large values of <span class="math inline">\(\tau_2\)</span> lead to little information sharing between doses (above dose 1). Note that “small” and “large” is dependent on the scale of the doses. The prior on the smoothing parameter is:</p>
<p><span class="math display">\[\tau_{2}^{2}\sim \text{IG}\left(\frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
<p>where <span class="math inline">\(\tau_\mu\)</span> is a central value for <span class="math inline">\(\tau_2\)</span>, and <span class="math inline">\(\tau_n\)</span> is the prior weight. <a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">See here</a> for help with specifying an inverse gamma distribution with center and weight.</p>
<p>Note that that in this formulation, <span class="math inline">\(\tau_2^2\)</span> can be thought of as the deviation from linearity. The linear scaling of deviations thus leads to a conditional variance that scales as the square of the dose difference:</p>
<p><span class="math display">\[\text{Var}[\theta_d \mid \theta_{d-1}, \theta_{d-2}]=\tau_2^2\cdot (\nu_d-\nu_{d-1})^2\]</span></p>
<p>The second order NDLM, like the simple NDLM, is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Second Order NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.</p>
<p>In a ‘null’ scenario where the response on all the doses is the same as control the Second Order NDLM, like the Simple NDLM, tends to reduce type-1 error. As the estimate of <span class="math inline">\(\tau^2\)</span> tends to zero the estimate of the dose response tends to a line (with non-zero slope if appropriate).</p>
<p>The second order NDLM has more power than the Simple NDLM when the dose response is smooth, but will tend to shrink estimates to the control by more than the Simple NDLM if there are marked peaks or steps in the response. Because it borrows from two neighboring doses, it is better at estimating a response for a dose where there is no data than the simple NDLM can, and can be used with burn-in’s where not all doses have been allocated to, but doesn’t cope well if there are consecutive doses where there is no data.</p>
<p>However, unlike the simple NDLMs where the variance structure is preserved if doses are added to or dropped from the design, this is not true for the 2<sup>nd</sup> order NLDM. Thus, if using the 2<sup>nd</sup> order NDLM and the doses that are available to the model are changed, then the parameters for the prior for <span class="math inline">\(\tau_2^2\)</span> may need to be re-visited.</p>
<p>The simple NDLM is likely to be preferred where there are fewer doses (4-5), and the second order NDLM is often preferred when there are 7 or more (it will depend on the expected smoothness of the response – the smoother it is the more useful the second order NDLM will be).</p>
<p>As with the simple NDLM, the choice of prior for <span class="math inline">\(\tau_2^2\)</span> can be tuned based on simulation results: balancing having a smaller prior that limits type-1 error in the null case, against having a larger prior that yields more power and better estimate of maximum response in the effective scenarios with the large jumps in response or pronounced peaks.</p>
</section>
<section id="parameter-logistic" class="level3" data-number="6.2.6">
<h3 data-number="6.2.6" class="anchored" data-anchor-id="parameter-logistic"><span class="header-section-number">6.2.6</span> 3-Parameter Logistic</h3>
<p>The 3-parameter logistic dose response model estimates efficacy as a smooth curve using an intuitive parameterization. The dose response for a dose <span class="math inline">\(d\)</span> with effective dose strength <span class="math inline">\(\nu_d\)</span> is:</p>
<p><span class="math display">\[\theta_{d} = a_{1} + \frac{a_{2}v_{d}}{v_{d} + a_{3}}\]</span></p>
<p>Where the <span class="math inline">\(a\)</span> parameters have the following description:</p>
<dl>
<dt><span class="math inline">\(a_1\)</span></dt>
<dd>
the estimated dose response for a dose of strength 0
</dd>
<dt><span class="math inline">\(a_2\)</span></dt>
<dd>
the estimated change in dose response for a dose with strength ∞ when compared to a dose of strength 0.
</dd>
<dt><span class="math inline">\(a_3\)</span></dt>
<dd>
the estimated ED50, the dose that has 50% of the dose response maximum (<span class="math inline">\(a_2\)</span>)
</dd>
</dl>
<p>The shape of the 3-parameter logistic curve can vary wildly based on the parameter values, but always starts at <span class="math inline">\(a_1\)</span> at dose strength 0 and monotonically increases to <span class="math inline">\(a_1+a_2\)</span> as the effective dose strength goes to infinity.</p>
<p>The following independent prior distributions are assumed:</p>
<p><span class="math display">\[a_1\sim \text{N}(\Lambda_1, \lambda_1^2)\]</span> <span class="math display">\[a_2\sim \text{N}(\Lambda_2, \lambda_2^2)\]</span> <span class="math display">\[a_3\sim \text{N}^+(\Lambda_3, \lambda_3^2)\]</span></p>
<p>In the continuous case, the prior distribution for the error term in the 3-Parameter Logistic is Inverse Gamma:</p>
<p><span class="math display">\[\sigma^{2}\sim IG\left( \frac{\sigma_{n}}{2},\frac{\sigma_{\mu}^{2}\sigma_{n}}{2} \right)\]</span></p>
<p>An advantage of the 3-Parameter Logistic model is that it is has a small number of parameters that have defined, intuitive interpretations. Since there are few parameters it’s generally easy to estimate the parameters even on small amounts of data. Because of the limited flexibility of the logistic curve, the 3-parameter logistic model should only be used when there is evidence that it is appropriate. See the <a href="#hierlog">Hierarchical Logistic</a> and <a href="#sigmoid">Sigmoid</a> (E<sub>max</sub>) models for dose response models with a similar pattern, but slightly more flexibility in shape.</p>
<p><a name="hierlog"></a></p><a name="hierlog">
</a></section><a name="hierlog">
</a><section id="hierarchical-logistic" class="level3" data-number="6.2.7"><a name="hierlog">
<h3 data-number="6.2.7" class="anchored" data-anchor-id="hierarchical-logistic"><span class="header-section-number">6.2.7</span> Hierarchical Logistic</h3>
</a><p><a name="hierlog">The </a><a href="##" title="Scott Berry's favorite dose response model.">hierarchical logistic model</a> is an extension of the 3-parameter logistic with the form:</p>
<p><span class="math display">\[\theta_{d} = a_{1} + \frac{a_{2}v_{d}}{v_{d} + a_{3}} + \zeta_{d}\]</span></p>
<p>where <span class="math inline">\(\zeta_d\)</span> is a random intercept term that modifies <span class="math inline">\(a_1\)</span> differently for each dose under the constraint that all <span class="math inline">\(\zeta_d\)</span> must sum to 0.</p>
<p>The additional term <span class="math inline">\(\zeta_d\)</span> is a per dose ‘off-curve’ effect. It allows for a secondary non-parametric dose effect over and above the logistic model. It has been used in circumstances in which there is actually some falling away of effect at the highest dose. This is an example mean fit from 100 simulations. The model fit and error bars are in green, and the true dose responses are shown by the black line.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image22.png" style="width:2.97677in;height:2.6604in"></p>
<p><span class="math inline">\(\zeta_d\)</span> is modelled as:</p>
<p><span class="math display">\[\zeta_d \sim \text{N}(0, a_4^2)\]</span></p>
<p>conditioned that</p>
<p><span class="math display">\[\sum_{d}^{}\zeta_{d} = 0\]</span></p>
<p>And <span class="math inline">\(a_4^2\)</span> has an inverse gamma prior:</p>
<p><span class="math display">\[a_{4}^{2}\sim IG\left( \frac{\Lambda_{n}}{2},\frac{\Lambda_{\mu}^{2}\Lambda_{n}}{2} \right)\]</span></p>
<p>The following independent prior distributions are assumed:</p>
<p><span class="math display">\[a_1\sim \text{N}(\Lambda_1, \lambda_1^2)\]</span> <span class="math display">\[a_2\sim \text{N}(\Lambda_2, \lambda_2^2)\]</span> <span class="math display">\[a_3\sim \text{N}^+(\Lambda_3, \lambda_3^2)\]</span></p>
<p>A typical recommended value for the center of the prior distribution of <span class="math inline">\(\alpha_4\)</span> is the largest expected likely deviation in true response from the underlying logistic with a weight of 1. The effect of this prior is then checked through simulation of a range of plausible dose response profiles, with a range of designs to check the sensitivity of the final estimate of response to this prior. Additionally, <a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">see here</a> for help with specifying an inverse gamma distribution with center and weight.</p>
<p>In this model, compared to the ‘plain’ 3-parameter logistic above, it is important that the true ED50 lies within the expected dose range, and that the prior for the ED50, <span class="math inline">\(a_3\)</span>, has the majority of its probability mass in the available dose range. For example, if the range of the effective dose strengths is from 0 to <span class="math inline">\(\nu_D\)</span> then a typical ‘weakly informative’ prior for <span class="math inline">\(a_3\)</span> would be:</p>
<p><span class="math display">\[a_{3}\sim N^{+}\left( \frac{\nu_{D}}{2},\left( \frac{\nu_{D}}{2} \right)^{2} \right)\]</span></p>
<p>Using a weaker prior, such as <span class="math inline">\(\text{N}^+(\nu_D, \nu_D^2)\)</span> leads to a more linear fit. With just this change to the prior for <span class="math inline">\(a_3\)</span> the average of the estimated of the mean response changes from the graph above to:</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image23.png" style="width:2.9739in;height:3.15818in"></p>
<p><a name="sigmoid"></a></p><a name="sigmoid">
</a></section><a name="sigmoid">
<section id="sigmoid-model" class="level3" data-number="6.2.8">
<h3 data-number="6.2.8" class="anchored" data-anchor-id="sigmoid-model"><span class="header-section-number">6.2.8</span> Sigmoid Model</h3>
<p>A sigmoid model (<em>E</em><sub>max</sub> model) provides a coherent parameterization of the dose response trend similar to the 3-parameter logistic, but with one extra shape parameter, <span class="math inline">\(a_4\)</span>.</p>
<p>The model formula is:</p>
<p><span class="math display">\[\theta_{d} = a_{1} + \frac{(a_{2} - a_{1})v_{d}^{a_{4}}}{{a_{3}}^{a_{4}} + v_{d}^{a_{4}}}\]</span></p>
<p>The interpretation of the four parameters is:</p>
<dl>
<dt><span class="math inline">\(a_1\)</span></dt>
<dd>
the estimated dose response for a dose of strength 0
</dd>
<dt><span class="math inline">\(a_2\)</span></dt>
<dd>
the estimated dose response for a dose of strength <span class="math inline">\(\infty\)</span> (slight difference from Logistic models)
</dd>
<dt><span class="math inline">\(a_3\)</span></dt>
<dd>
the estimated ED50, the dose that has 50% of the dose response maximum attainable effect (<span class="math inline">\(a_2-a_1\)</span>)
</dd>
<dt><span class="math inline">\(a_4\)</span></dt>
<dd>
controls the slope of the dose response model at the ED50. A larger value of <span class="math inline">\(a_4\)</span> corresponds to a steeper slope. A value of <span class="math inline">\(a_4=1\)</span> makes the Sigmoid model equivalent to a Three Parameter Logistic model with <span class="math inline">\(a_2\)</span> equal to <span class="math inline">\(a_1 + a_2\)</span> from the Sigmoid model. A value of <span class="math inline">\(a_4\)</span> approaching 0 corresponds to a dose response model that is nearly flat at <span class="math inline">\(\frac{a_{1} + a_{2}}{2}\)</span>. By differentiation, it can be seen that the slope where the effective dose <span class="math inline">\(\nu_d=a_3\)</span> is <span class="math inline">\((a_{2} - a_{1})\frac{a_{4}}{4a_{3}}\)</span>.
</dd>
</dl>
<p>The following independent prior distributions are assumed:</p>
<p><span class="math display">\[a_1\sim \text{N}(\Lambda_1, \lambda_1^2)\]</span> <span class="math display">\[a_2\sim \text{N}(\Lambda_2, \lambda_2^2)\]</span> <span class="math display">\[a_3\sim \text{N}^+(\Lambda_3, \lambda_3^2)\]</span> <span class="math display">\[a_3\sim \text{N}^+(\Lambda_4, \lambda_4^2)\]</span></p>
<p>The advantage of this model is that it is considerably more flexible than the logistic, but still more efficient to estimate than an NDLM. This model (if applicable) is ideal if the target is an Effective Dose (ED) such as an ED90. Estimating an ED requires estimating the response on control, the maximum response, and the gradient which is requires a lot of data to do well if using no model or a smoothing model such as one of the NDLMs. With the 4-parameter Sigmoid model (or 3-parameter logistic – but that has a more limited applicability due to being significantly less flexible in shape), it’s usually not an issue to estimate the EDx well.</p>
<p>The caveats to using this model are:</p>
<ul>
<li><p>Whilst being much more flexible than the logistic, it still has model assumptions, in particular monotonicity, that must be met for this to be a reasonable model to be used.</p></li>
<li><p>The curve is only well estimated if the true ED50 lies within the doses tested.</p></li>
<li><p>Like the hierarchical logistic model above, the prior for <span class="math inline">\(a_3\)</span> should be weakly informative, with the majority of its probability mass in the available dose range. So similarly, if the range of the effective dose strengths is from 0 to <span class="math inline">\(\nu_D\)</span> then a typical ‘weakly informative’ prior for <span class="math inline">\(a_3\)</span> would be: <span class="math display">\[a_3 \sim N^{+}\left( \frac{\nu_{D}}{2},\left( \frac{\nu_{D}}{2} \right)^{2} \right)\]</span></p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image24.png" style="width:3.384in;height:2.12987in"></p>
</section>
<section id="u-shaped-model" class="level3" data-number="6.2.9">
<h3 data-number="6.2.9" class="anchored" data-anchor-id="u-shaped-model"><span class="header-section-number">6.2.9</span> U-Shaped Model</h3>
<p>The U-shaped model when the allows for an initial increase (decrease) in the dose response with dose, followed by a leveling out of the mean, then a decrease (increase). Whether the U-Shaped model increases then decreases or decreases then increases is specified by the user on the Dose Response tab. An example curve for this model is given in the figure below.</p>
<p>The dose-response curve can be characterized in four different regions of doses. For the first region, which contains the lowest doses, <span class="math inline">\(0&lt;\nu_d&lt;p_{min}\)</span>, the dose-response curve is increasing (decreasing):</p>
<p><span class="math display">\[\theta_{d} = \theta_{0} + S \cdot \delta \cdot \left( \frac{\nu_{d}}{p_{\min}} \right)^{\alpha}\]</span></p>
<p>The next region is the plateau, where the dose-response curve is constant. For <span class="math inline">\(p_{min} &lt; \nu_d &lt; p_{min}+p_{width}\)</span>: <span class="math display">\[\theta_d=\theta_0 + S\cdot\delta\]</span> For the third region, the dose-response curve is decreasing (increasing). For <span class="math inline">\(p_{min}+p_{width} &lt; \nu_d &lt; p_{min}+p_{width} + w_{width}\)</span>,</p>
<p><span class="math display">\[\theta_{d} = \theta_{0} + S \cdot \delta \cdot \left( 1 - \frac{\nu_{d} - \left( p_{\min} + p_{width} \right)}{w_{width}} \right)^{\beta}\]</span></p>
<p>For the final region, the dose-response curve is again constant, at the same level as the zero-dose. For <span class="math inline">\(\nu_d &gt; p_{min}+p_{width} + w_{width}\)</span>, <span class="math display">\[\theta_d = \theta_0\]</span></p>
<p>The parameters of the model are described below:</p>
<ol type="1">
<li><p><span class="math inline">\(S\)</span> is <span class="math inline">\(1\)</span> or <span class="math inline">\(-1\)</span>, as determined by the Model is increasing/decreasing radio buttons. <span class="math inline">\(S=1\)</span> if Model is Increasing is selected, indicating that the model starts increasing at low doses.</p></li>
<li><p><span class="math inline">\(\theta_0\)</span> represents the zero-strength dose response. Its prior is: <span class="math display">\[\theta_0 \sim \text{N}(\mu_0, \sigma_0^2)\]</span></p></li>
<li><p><span class="math inline">\(\delta\)</span> represents the maximal change in response from the zero-strength dose. It is restricted to be positive, and has a prior of: <span class="math display">\[\delta \sim \text{N}^+(\mu_\delta, \sigma_\delta^2)\]</span></p></li>
<li><p><span class="math inline">\(p_{min}\)</span> represents the lowest dose at which the maximal change in response from the zero-strength is achieved. It is restricted to be positive, and has a prior of: <span class="math display">\[p_{min} \sim \text{N}^+(\mu_{min}, \sigma_{min}^2)\]</span></p></li>
<li><p><span class="math inline">\(p_{width}\)</span> represents the width of the plateau – the region where all doses achieve maximal change in response from the zero-strength dose. It is restricted to be positive, and has a prior of: <span class="math display">\[p_{width} ~ \sim \text{N}^+(\mu_{width}, \sigma_{width}^2)\]</span></p></li>
<li><p><span class="math inline">\(w_{width}\)</span> represents the width of the region for doses beyond the plateau, where response is returning to the zero-strength dose level. It is restricted to be positive, and has a prior of: <span class="math display">\[w_{width} ~ \sim \text{N}^+(\mu_{w}, \sigma_{w}^2)\]</span></p></li>
<li><p><span class="math inline">\(\alpha\)</span> determines the rate of change of the dose response curve for doses below the plateau. Values less than <span class="math inline">\(1\)</span> indicate a rapid initial change from baseline, with slower change as the plateau is reached. Values greater than <span class="math inline">\(1\)</span> indicate a slow initial change from baseline, with more rapid change as the plateau is reached. To help avoid identifiability issues, <span class="math inline">\(\alpha\)</span> is restricted to be between <span class="math inline">\(10^{-1}\)</span> and <span class="math inline">\(10^{1}\)</span>. <span class="math inline">\(\alpha\)</span>’s prior is: <span class="math display">\[\alpha \sim \text{LN}^*(\mu_\alpha, \sigma_\alpha^2)\]</span> where <span class="math inline">\(\text{LN}^*()\)</span> represents the lognormal distribution with truncation constraints at <span class="math inline">\(10^{-1}\)</span> and <span class="math inline">\(10^{1}\)</span>.</p></li>
<li><p><span class="math inline">\(\beta\)</span> determines the rate of change of the dose response curve for doses beyond the plateau. Values less than <span class="math inline">\(1\)</span> indicate a slow initial change from the plateau level, with more rapid change subsequently. Values greater than <span class="math inline">\(1\)</span> indicate a rapid initial change from the plateau level, with slower change subsequently. To help avoid identifiability issues, <span class="math inline">\(\beta\)</span> is restricted to be between <span class="math inline">\(10^{-1}\)</span> and <span class="math inline">\(10^{1}\)</span>. The prior on <span class="math inline">\(\beta\)</span> is: <span class="math display">\[\beta \sim \text{LN}^*(\mu_\beta, \sigma_\beta^2)\]</span></p></li>
</ol>
<p>The U-shaped model has seven free parameters, and thus it is inadvisable to use such a model for dose-finding trial designs that contain only a few dose levels. When a small number of doses are available, it may help to constrain the values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> by utilizing small standard deviations in the priors.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image25.emf" style="width:4.63571in;height:4.63571in"></p>
</section>
<section id="plateau-model" class="level3" data-number="6.2.10">
<h3 data-number="6.2.10" class="anchored" data-anchor-id="plateau-model"><span class="header-section-number">6.2.10</span> Plateau Model</h3>
<p>The plateau model is a special case of the U-shaped model, in which <span class="math inline">\(p_{width}=\infty\)</span>. That is, there is no return to baseline for high doses. This model eliminates three parameters from the U-Shaped model, since <span class="math inline">\(p_{width}\)</span>, <span class="math inline">\(w_{width}\)</span>, and <span class="math inline">\(\beta\)</span> are not used. See the figure below to see an example dose response model for the plateau model that mimics the beginning of the U-Shaped model above.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image26.emf" style="width:4.70513in;height:4.70714in"></p>
</section>
<section id="parameter-exponential-logistic-dichotomous-only" class="level3" data-number="6.2.11">
<h3 data-number="6.2.11" class="anchored" data-anchor-id="parameter-exponential-logistic-dichotomous-only"><span class="header-section-number">6.2.11</span> 3 Parameter Exponential Logistic (Dichotomous Only)</h3>
<p>The 3-parameter exponential logistic model has the following structure:</p>
<p><span class="math display">\[\theta_d = a_1 + a_2 \nu_d^{a_3}\]</span></p>
<p>Where <span class="math inline">\(\nu_d\)</span> is the effective dose strength of dose <span class="math inline">\(d\)</span>. This is a logistic model for the dichotomous endpoint because <span class="math inline">\(\theta_d\)</span> is the log odds ratio of the probability of the response, <span class="math inline">\(P_d\)</span> at dose <span class="math inline">\(d\)</span>.</p>
<p>The exponent parameter <span class="math inline">\(\alpha_3\)</span> allows the change in slope at the lower end of the curve to be asymmetric in comparison to the change in curve at the upper end of the curve.</p>
<p>The priors for the parameters are:</p>
<p><span class="math display">\[a_1\sim \text{N}(\Lambda_1, \lambda_1^2)\]</span> <span class="math display">\[a_2\sim \text{N}(\Lambda_2, \lambda_2^2)\]</span> <span class="math display">\[a_3\sim \text{N}^+(\Lambda_3, \lambda_3^2)\]</span> The interpretations of the parameters defining this model are:</p>
<dl>
<dt><span class="math inline">\(a_1\)</span></dt>
<dd>
the dose response for a dose with strength 0
</dd>
<dt><span class="math inline">\(a_2\)</span></dt>
<dd>
the slope associated with the exponentiated dose strength
</dd>
<dt><span class="math inline">\(a_3\)</span></dt>
<dd>
a shape parameter modifying the effective dose strength through exponentiation.
</dd>
</dl>
<p>The figure below shows an example of two different 3-parameter exponential logistic model fits. Notably, the fit shown in green has an <span class="math inline">\(a_3\)</span> parameter greater than <span class="math inline">\(1\)</span>, which leads to faster increases of the response rate model as the effective dose strength increases.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image27.png" style="width:3.424in;height:2.28267in"></p>
</section>
</a><section id="hierarchical-model" class="level3" data-number="6.2.12"><a name="sigmoid">
<h3 data-number="6.2.12" class="anchored" data-anchor-id="hierarchical-model"><span class="header-section-number">6.2.12</span> Hierarchical Model</h3>
<p>Like the Independent Dose Model, the hierarchical model treats the arms as if they are an unordered set of treatments, but unlike the Independent Dose Model the Hierarchical Model shares information between doses included in the model. The hierarchical model is a way of encouraging the estimates of arm responses to be similar, and the degree of this encouragement can be controlled using parameters of the prior distribution. The hierarchical model assumes that the arm parameters are drawn from the same normal distribution:</p>
<p><span class="math display">\[\theta_d \sim \text{N}(\mu, \tau^2)\]</span></p>
<p>Where <span class="math inline">\(d\)</span> is the set of doses included in the model. The prior distributions for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau^2\)</span> are</p>
<p><span class="math inline">\(\mu \sim \text{N}(\Lambda_\mu, \lambda_\mu^2)\)</span></p>
<p>and</p>
<p><span class="math display">\[\tau^{2}\sim \text{IG}\left(\frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
</a><p><a name="sigmoid">where <span class="math inline">\(\tau_\mu\)</span> is a central value for <span class="math inline">\(\tau\)</span>, and <span class="math inline">\(\tau_n\)</span> is the prior weight. <span class="math inline">\(\tau^2\)</span> governs the amount of information shared between doses in the model. The estimates of the dose parameters can be encouraged to be close together by choosing a small value for <span class="math inline">\(\tau_\mu\)</span> and a large value for <span class="math inline">\(\tau_n\)</span>. </a><a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">See here</a> for a tool to help understand the inverse gamma distribution specified by center and weight parameters.</p>
<p>The control arm can be included in the hierarchical model if it is desired to encourage the experimental arms to be similar to the control arm, or excluded from it if the experimental arms are encouraged to be similar to each other but not necessarily to the control arm. This is not true with time-to-event data, when the control arm can only be excluded from the hierarchical model.</p>
</section>
<section id="linear-model" class="level3" data-number="6.2.13">
<h3 data-number="6.2.13" class="anchored" data-anchor-id="linear-model"><span class="header-section-number">6.2.13</span> Linear Model</h3>
<p>The linear model uses a strong assumption of exact linearity between the responses and the dose strengths. (For dichotomous models, the linearity is on the log-odds scale, and the linearity is on the log hazard ratio scale for TTE models.) The model is</p>
<p><span class="math display">\[\theta_d=\alpha+\beta\nu_d\]</span> for all doses <span class="math inline">\(d\)</span> in the model. Both <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are given normal prior distributions:</p>
<p><span class="math display">\[\alpha \sim \text{N}(\Lambda_\alpha, \lambda_\alpha^2)\]</span> <span class="math display">\[\beta \sim \text{N}(\Lambda_\beta, \lambda_\beta^2)\]</span></p>
<p>The linear model is appropriate when there is strong scientific knowledge that the shape of the response curve should be linear as a function of dose strength. Note that if an arm has a dose strength between two other arms in the model, its response will always be estimated to be between the responses of those two arms. As a result, the linear model may not be appropriate in combination with certain decision quantities such as <span class="fake-code-block">Pr(Max)</span>, because some doses are guaranteed to have probability zero of being the best arm. If the control arm is included in the linear model and it has the smallest dose value, then all experimental arms will always have exactly the same probability of being better than control.</p>
<p>We recommend creating scenarios where the true parameters deviate from linearity and simulating them to test the robustness of a design based on the linear model.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>For dichotomous models, the linear model replaces the 2-parameter logistic model available in FACTS versions before 6.4. The two models are identical.</p>
</div>
</div>
</section>
<section id="hierarchical-linear-model" class="level3" data-number="6.2.14">
<h3 data-number="6.2.14" class="anchored" data-anchor-id="hierarchical-linear-model"><span class="header-section-number">6.2.14</span> Hierarchical Linear Model</h3>
<p>A more flexible version of the linear model is the hierarchical linear model. This model encourages the arm responses to have a linear-like shape, but also includes a term allowing parameters to deviate from linearity when appropriate. The arm parameters satisfy the relationship</p>
<p><span class="math display">\[\theta_d = \alpha + \beta \nu_d + \zeta_d\]</span> where the <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> parameters are as in the linear model, with prior distributions</p>
<p><span class="math display">\[\alpha \sim \text{N}(\Lambda_\alpha, \lambda_\alpha^2)\]</span> <span class="math display">\[\beta \sim \text{N}(\Lambda_\beta, \lambda_\beta^2)\]</span> and the <span class="math inline">\(\zeta_d\)</span> parameters are the deviations from linearity. These deviations are assumed to have a normal distribution constrained so that their average value is zero:</p>
<p><span class="math display">\[\zeta_d \sim \text{N}(0, \tau^2) \text{ with } \sum_d\zeta_d=0.\]</span></p>
<p>The prior distribution for <span class="math inline">\(\tau^2\)</span> is</p>
<p><span class="math display">\[\tau^{2}\sim\text{IG}\left(\frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
<p>If <span class="math inline">\(\tau^2\)</span> is small, which can be encouraged by choosing <span class="math inline">\(\tau_\mu\)</span> to be small and <span class="math inline">\(\tau_n\)</span> to be large, then the dose parameter estimates will lie close to a line. <a href="../../../../concepts/facts/InverseGammaDistribution.html" title="Widget for assessing how the center and weight parameters in FACTS impact the inverse gamma distribution.">See here</a> for help understanding FACTS’s parameterization of the inverse gamma distribution.</p>
<p>The hierarchical linear model is a good choice when, for example, one expects a linear relationship between the dose strengths and the response but one is not prepared to assume exact linearity. It can also be a good way of encouraging, but not requiring, monotonicity in the response.</p>
</section>
</section>
<section id="d-treatment-dose-response-models" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="d-treatment-dose-response-models"><span class="header-section-number">6.3</span> 2D Treatment Dose Response Models</h2>
<p>If on the Study &gt; Treatment Arms tab, the “Use 2D treatment arm model” option has been checked, the user may either use any of the 1D Dose Response options described above, or may use a dose response model specifically modelling the two dosing dimensions.</p>
<p>If using one of the 1D dose response models, the effective dose strength <span class="math inline">\(\nu_d\)</span> is as specified by the user on the “Select doses to be used in the trial” tab. These calculated dose levels are forced to be distinct values, and this results in a 1D ordering of the combinations.</p>
<p>There are also three 2D Dose Response models that can be used:</p>
<ol type="1">
<li><p>2D Continuous Factorial Model</p></li>
<li><p>2D Discrete Factorial model</p></li>
<li><p>2D NDLM</p></li>
</ol>
<p>These are described in the next sections.</p>
<p>The 2D dose response models work with a slightly different notation to accommodate that treatments are defined as the combination of two factors. Rather than <span class="math inline">\(\theta_i\)</span> being the estimated mean of the dose response estimate for dose <span class="math inline">\(i\)</span>, the estimated dose response for the treatment created from row factor level <span class="math inline">\(r\)</span> and column factor level <span class="math inline">\(c\)</span> is denoted <span class="math inline">\(\theta_{rc}\)</span>. <span class="math inline">\(Y_{rc}\)</span> denotes the mean of the observed data in the cell.</p>
<p>In the continuous case, the likelihood for the data is,</p>
<p><span class="math display">\[Y_{rc} \sim \text{N}(\theta_{rc}, \sigma^2)\]</span> <span class="math display">\[\sigma^{2}\sim\text{IG}\left(\frac{\sigma_{n}}{2},\frac{\sigma_{\mu}^{2}\sigma_{n}}{2} \right)\]</span></p>
<p>Where the form of <span class="math inline">\(\theta_{rc}\)</span> varies based on dose response model selection.</p>
<p>Similarly, in the dichotomous case,</p>
<p><span class="math display">\[Y_{rc} \sim \text{Bernoulli}(P_{rc})\]</span> <span class="math display">\[P_{rc} = \frac{e^{\theta_{rc}}}{1 + e^{\theta_{rc}}}\]</span></p>
<section id="d-continuous-factorial-model" class="level3" data-number="6.3.1">
<h3 data-number="6.3.1" class="anchored" data-anchor-id="d-continuous-factorial-model"><span class="header-section-number">6.3.1</span> 2D Continuous Factorial Model</h3>
<p>The 2D Continuous Factorial Model fits a regression on the dose response that uses the numeric dose strength as a continuous valued covariate. The dose response (with <span class="math inline">\(\eta_r\)</span> and <span class="math inline">\(\zeta_c\)</span> denoting dose strength of the row level and column level, respectively) is modeled as:</p>
<p><span class="math display">\[\theta_{rc} = \alpha_0 + \alpha_1 \zeta_c + \alpha_2 \eta_r + \alpha_3\zeta_c \eta_r\]</span> With priors</p>
<p><span class="math display">\[\alpha_0 \sim \text{N}(\mu_0, \sigma_0^2)\]</span> <span class="math display">\[\alpha_1 \sim \text{N}(\mu_1, \sigma_1^2)\]</span> <span class="math display">\[\alpha_2 \sim \text{N}(\mu_2, \sigma_2^2)\]</span> <span class="math display">\[\alpha_3 \sim \text{N}(\mu_3, \sigma_3^2)\]</span></p>
<p>Then, <span class="math inline">\(\alpha_0\)</span> is the response at the control combination, <span class="math inline">\(\alpha_1\)</span> is the linear coefficient of the response to the column factor strengths <span class="math inline">\(\zeta_c\)</span>, and <span class="math inline">\(\alpha_2\)</span> is the linear coefficient of the response to the row factor strengths <span class="math inline">\(\eta_r\)</span>.</p>
<p>The user has the option to simplify the model and exclude the interaction term <span class="math inline">\(\alpha_3\)</span>, which is the coefficient of the product of the two factor strengths.</p>
<p>Note that despite being called “continuous” this dose response model applies to all endpoints. It’s called continuous because the coefficients act on the dose strengths as continuous measures of strength.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image29.png" style="width:5.50007in;height:4.17635in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
<section id="d-discrete-factorial-model" class="level3" data-number="6.3.2">
<h3 data-number="6.3.2" class="anchored" data-anchor-id="d-discrete-factorial-model"><span class="header-section-number">6.3.2</span> 2D Discrete Factorial Model</h3>
<p>The 2D Discrete Factorial Model fits a regression on the dose response that uses the dose strength as a factor covariate rather than a numeric dose strength. Each dose is an independent level within each row or column factor, so any dose is equidistant from all other doses</p>
<p><span class="math display">\[\theta_{rc} = \alpha + \gamma_r + \beta_c\]</span></p>
<p>With priors</p>
<p><span class="math display">\[\alpha \sim \text{N}(\mu_\alpha, \sigma_\alpha^2)\]</span></p>
<p><span class="math display">\[\beta_c \sim \text{N}(\mu_{\beta_c}, \sigma_{\beta_c}^2)\]</span> <span class="math display">\[\gamma_r \sim \text{N}(\mu_{\gamma_r}, \sigma_{\gamma_r}^2)\]</span></p>
<p>The parameters associated with lowest level of each factor, <span class="math inline">\(\gamma_0\)</span> and <span class="math inline">\(\beta_0\)</span>, are constrained to be <span class="math inline">\(0\)</span>.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image30.png" style="width:5.51472in;height:4.35172in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
<section id="d-ndlm" class="level3" data-number="6.3.3">
<h3 data-number="6.3.3" class="anchored" data-anchor-id="d-ndlm"><span class="header-section-number">6.3.3</span> 2D NDLM</h3>
<p>The 2-D NDLM Model takes the idea of smoothing across doses that was used in the standard NDLM model, but smooths across row factors and column factors separately.</p>
<section id="the-base-model-with-control-included" class="level4" data-number="6.3.3.1">
<h4 data-number="6.3.3.1" class="anchored" data-anchor-id="the-base-model-with-control-included"><span class="header-section-number">6.3.3.1</span> The Base Model, with Control Included</h4>
<p>The treatment effect for the combination of level <span class="math inline">\(r\)</span> in the row factor and level <span class="math inline">\(c\)</span> in the column factor is denoted as <span class="math inline">\(\theta_{rc}\)</span>, and <span class="math inline">\(Y_{rc}\)</span> is the observed data in that cell. The borrowing parameters are denoted as <span class="math inline">\(\phi\)</span> for the row factor smoothing, and <span class="math inline">\(\tau\)</span> for the column factor smoothing. The dose strengths are denoted as <span class="math inline">\(\nu_r\)</span> for the row factors, and <span class="math inline">\(\omega_c\)</span> for the column factors. Let <span class="math inline">\(\Delta \nu_r = \nu_r - \nu_{r-1}\)</span> and <span class="math inline">\(\Delta \omega_c = \omega_c - \omega_{c-1}\)</span> (for <span class="math inline">\(r&gt;0\)</span> and <span class="math inline">\(c&gt;0\)</span>). For notational convenience at the grid edge, let <span class="math inline">\(\theta_{-1, c} = 0\)</span>, <span class="math inline">\(\theta_{r,-1}\)</span>, <span class="math inline">\(\Delta\nu_0\equiv\infty\)</span>, and <span class="math inline">\(\Delta\omega_0\equiv\infty\)</span>.</p>
<p>The 2-D NDLM Model <strong><em>with control included in the model</em></strong> can then be specified as:</p>
<p><span class="math display">\[\theta_{0,0} \sim \text{N}(\mu_0, \tau_0^2)\]</span> <span class="math display">\[\theta_{rc} \sim \text{N}(\mu_{rc}, \tau_{rc}^2)\]</span> where</p>
<p><span class="math display">\[\tau_{rc}^{2} = \left( \frac{1}{\mathrm{\Delta}\nu_{r}\phi^{2}} + \frac{1}{\mathrm{\Delta}\omega_{c}\tau^{2}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[\mu_{rc} = \tau_{rc}^{2}\left( \frac{\theta_{r - 1,c}}{\mathrm{\Delta}\nu_{r}\phi^{2}} + \frac{\theta_{r,c - 1}}{\mathrm{\Delta}\omega_{c}\tau^{2}} \right)\]</span></p>
<p>with priors</p>
<p><span class="math display">\[\tau^{2}\sim\text{IG}\left( \frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
<p><span class="math display">\[\phi^{2}\sim\text{IG}\left( \frac{\phi_{n}}{2},\frac{\phi_{\mu}^{2}\phi_{n}}{2} \right)\]</span></p>
<p>Note: that not all combinations of <span class="math inline">\(r\)</span> and <span class="math inline">\(c\)</span> will have data associated with them. However, FACTS will still evaluate the prior at all combinations. Thus, in the situation depicted below where the grayed-out point indicates a treatment combination with no allocation, <span class="math inline">\(\theta_{1,2}\)</span> is not modeled conditioned only on <span class="math inline">\(\theta_{1,1}\)</span>. <span class="math inline">\(\theta_{0,1}\)</span> also informs on <span class="math inline">\(\theta_{1,2}\)</span> via <span class="math inline">\(\theta_{0,2}\)</span>.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image31.png" style="width:2.1in;height:2.1in" alt="Calendar Description automatically generated"></p>
</section>
<section id="fix-smoothing-ratio-for-row-factor-and-column-factor" class="level4" data-number="6.3.3.2">
<h4 data-number="6.3.3.2" class="anchored" data-anchor-id="fix-smoothing-ratio-for-row-factor-and-column-factor"><span class="header-section-number">6.3.3.2</span> Fix smoothing ratio for row factor and column factor</h4>
<p>Optionally, the user might want to specify the row factor borrowing as a function of the column factor borrowing:</p>
<p><span class="math display">\[\phi\equiv k \cdot \tau\]</span> where <span class="math inline">\(k\)</span> is a user-specified constant. This can be performed by selecting “Fixed smoothing ratio” in the <span class="math inline">\(\phi^2\)</span> prior specification area.</p>
</section>
<section id="control-not-in-model-no-zero-level-doses" class="level4" data-number="6.3.3.3">
<h4 data-number="6.3.3.3" class="anchored" data-anchor-id="control-not-in-model-no-zero-level-doses"><span class="header-section-number">6.3.3.3</span> Control not in model, no zero-level doses</h4>
<p>If neither treatment arm allows zero-level doses (e.g.&nbsp;like one would expect if the column factor represented doses and the row factor represented frequency), then a prior for the lowest dose would instead be needed as input from the GUI:</p>
<p><span class="math display">\[\theta_{1,1} \sim \text{N}(\mu_1, \tau_1^2)\]</span></p>
<p><img src="coreUGattachments/CoreUserGuide/media/image32.png" style="width:5.47053in;height:4.31685in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
</section>
</section>
<section id="baseline-adjusted-dose-response-models-continuous-only" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="baseline-adjusted-dose-response-models-continuous-only"><span class="header-section-number">6.4</span> Baseline Adjusted Dose Response Models (Continuous Only)</h2>
<p>If a baseline endpoint is simulated, the user has the option of adding a linear covariate effect to the dose response model. If the chosen dose response model states that for dose <span class="math inline">\(d\)</span>, <span class="math display">\[Y\sim \text{N}(\theta_d, \sigma^2)\]</span>, then the distribution including the baseline adjustment term is <span class="math display">\[Y\sim \text{N}(\theta_d+\beta Z, \sigma^2)\]</span>. where <span class="math inline">\(Z\)</span> is the standardized baseline value <span class="math inline">\(\left(Z=\frac{X-\bar X}{s_x}\right)\)</span>, and <span class="math inline">\(\beta\)</span> is an estimated parameter that is distinct from any parameter called <span class="math inline">\(\beta\)</span> within the dose response model.</p>
<p>The baseline adjustment model uses a normal prior for <span class="math inline">\(\beta\)</span> for which the user enters a mean and standard deviation.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Technical Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The VSR based simulation of baseline is more general than the model adjustment for baseline (this is to allow baseline to be incorporated in a number of different ways). This means that the parameters entered in the VSR (for example the <span class="math inline">\(\beta\)</span> parameter) will not always match the corresponding parameter estimated in the dose response model.</p>
<p>As a simple example, suppose we enter into the VSR response <span class="math inline">\(Y\sim \text{N}(\mu_Y, \sigma_Y^2)\)</span>, baseline <span class="math inline">\(X\sim \text{N}(\mu_X, \sigma_X^2)\)</span>, and use the baseline adjustment (<span class="math inline">\(c\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(\beta_{VSR}\)</span> are user inputs) so the actual simulated response <span class="math inline">\(Y\)</span> is <span class="math inline">\(Y^{'} = Y + \beta_{VSR}\frac{X - c}{s}\)</span>.</p>
<p>If the values of <span class="math inline">\(c\)</span> and <span class="math inline">\(s\)</span> used in the baseline adjustment are the same as the mean <span class="math inline">\(\mu_X\)</span> and standard deviation <span class="math inline">\(\sigma_X\)</span> of the simulated baseline, then the <span class="math inline">\(\beta_{VSR}\)</span> will converge to the estimated <span class="math inline">\(\beta\)</span> parameter as the sample size of the study increases. If <span class="math inline">\(c\ne\mu_X\)</span> or <span class="math inline">\(s\ne\sigma_X\)</span>, then the estimated <span class="math inline">\(\beta\)</span> will not converge to the <span class="math inline">\(\beta_{VSR}\)</span> used in data simulation. Additionally, if the baseline values are simulated from a truncated normal distribution, then the estimated <span class="math inline">\(\beta\)</span> will not converge to <span class="math inline">\(\beta_{VSR}\)</span>.</p>
</div>
</div>
</section>
<section id="control-and-comparator-priors" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="control-and-comparator-priors"><span class="header-section-number">6.5</span> Control and Comparator Priors</h2>
<p>For <a href="##" title="All continuous and dichotomous models except the U-shaped and Plateau models.">most</a> dose response models the control arm can be modeled either as part of the dose response model or separately. If it is modeled separately, it may have a simple user specified Normal prior or a “historical” prior. A historical prior in FACTS is a hierarchical prior that models the response on control as coming from a distribution that also contains trial outcomes from external historical studies.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image33.png" style="width:5.7284in;height:4.23754in"></p>
<p>The active comparator is always modeled separately, and as with a control arm modeled separately, it can be modeled with a user specified Normal prior or a “historical” prior.</p>
<p>When a user specified Normal prior is used, the user specifies the mean and standard deviation of the prior normal distribution for <span class="math inline">\(\theta_0\)</span>. This is useful if the control response is not thought to be consistent with the model being used to model the study doses – for instance if using an NDLM and there might be a sharp step in response from control to the lowest dose.</p>
<p>If “historical” prior is selected for either the control arm or an Active Comparator arm, an “Augmented Priors” tab is created.</p>
</section>
<section id="inverse-gamma-priors" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="inverse-gamma-priors"><span class="header-section-number">6.6</span> Inverse-gamma priors</h2>
<p>FACTS uses inverse-gamma priors for parameters of variance – these are conjugate and allow efficient computation and avoid problems of convergence. <a href="#gelman" title="Prior distributions for variance parameters in hierarchical models, Andrew Gelman, Bayesian Analysis 2006, 1, Number 3 pp 515-533.">Andrew Gelman’s 2006 paper</a> however notes a potential problem with this model, the problem is specifically</p>
<ul>
<li><p>When updating the estimate of the variance of a hierarchical model parameter there will be typically relative few actual data observations (e.g.&nbsp;relatively few historic studies for estimating the variance of the hyper parameter in a Bayesian Augmented Control model for the response on a control arm, and relatively few observations of the change in response from one dose to the next when using an NDLM dose-response model).</p></li>
<li><p>The conventional ‘non-informative’ gamma-prior of IG(0.001, 0.001) has an effect when the observed variance is small, of over-shrinking the posterior estimate of variance.</p></li>
</ul>
<p>In FACTS this possibility arises in the dose response models in the context of priors for the <span class="math inline">\(\tau\)</span> parameter for the NDLM models and the <span class="math inline">\(a_4\)</span> parameter for the hierarchical logistic dose response model, where the number of observations is the number of doses or dose intervals.</p>
<p>To avoid the problem reported by Gelman we recommend using a weakly informative prior. Using the settings that control how the inverse-gamma distribution is parameterized (Settings &gt; Options &gt; Gamma Distribution Parameters), use the ‘center and weight’ options and use a weight of 1, with a ‘reasonable’ expectation for the upper limit difference in the values being modeled entered as the center for the SD. The inverse gamma distribution is the prior of the variance, so the center parameter being specified is more correctly an expectation of the square root of the mean of the variance.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Help with Inverse Gamma specification
</div>
</div>
<div class="callout-body-container callout-body">
<p>We have created a tool that can help visualize the inverse gamma distribution and relate the center/weight parameterization, which FACTS uses by default, to the alpha/beta parameterization that is common.</p>
<p><a href="../../../../concepts/facts/InverseGammaDistribution.html">See here.</a></p>
</div>
</div>
<p>This ‘reasonable’ upper limit for the difference is a value that a clinical team will usually have an intuition about: for the largest change in mean response from one dose to another for instance, it is (often)[## “If the trial has doses that are more closely spaced than usual, a smaller figure can be used.”] reasonable to assume that the upper limit for the expected change in response from one dose to the next is the ‘expected difference in effect size’ that might have been used to power the trial in a conventional setting.</p>
<p>In the dose response setting the smoothing parameters like <span class="math inline">\(\tau\)</span> in the NDLM are nuisance parameters in the sense that they are necessary to estimate in order to get appropriate estimates of the dose response values, but are rarely of inferential interest on their own. This can ease some of the undue burden of setting a prior on <span class="math inline">\(\tau\)</span>. If it <a href="##" title="This is subjective. The Per Sim: Response and Subject Alloc plot in FACTS can help assess this fit.">gives estimates of the dose responses that look like they should</a>, then it is generally good enough.</p>
</section>
<section id="handling-missing-data" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="handling-missing-data"><span class="header-section-number">6.7</span> Handling Missing Data</h2>
<p>FACTS allows a “pre-processing” step before fitting the dose response model that helps with handling of data that is missing due to dropouts. If a subject has incomplete data due to a dropout, the user may specify all dropouts have their unknown final endpoint treated as known with the following options:</p>
<ol type="1">
<li><p>BOCF (continuous only, requires baseline be simulated) – All dropouts are assumed to have a final endpoint equal to their observed baseline value.</p></li>
<li><p>LOCF (continuous or dichotomous, requires longitudinal data be present) – All dropouts are assumed to have a final endpoint equal to their last observed visit value. If no post-baseline visits are available, but the subject has a baseline visit value, then the baseline values is carried forward to their final endpoint.</p></li>
<li><p>Missing is failure (dichotomous only) – All dropouts are assumed to be failures (which may be coded as 0 or 1 depending on whether a response is considered a success).</p></li>
</ol>
<p>Subjects who are imputed in this pre-processing step have final endpoint values known and used for the purposes of estimating the dose response curve. However, these pre-processed final endpoint values are not used in the updating on the longitudinal model, which is based only on observed visit data.</p>
<p>If the user does not specify one of the dropout imputation methods specified above, the dropout subjects and incomplete subjects (subjects who have not reached their final endpoint but are still continuing in the study) will have their final endpoints multiply imputed using Bayesian Multiple Imputation, described in the <a href="#longitudinalModeling">Longitudinal Modeling</a> section.</p>
<p>Generally, patients with “no data” do not affect the posterior distribution, and thus are omitted from the analysis. However, one must take into account a subject can have no visit data but still have “data” based on these dropout imputation methods. For example, if one selects “missing as failure” and a patient drops out before any visit data is recorded, then the subject still supplies information through the dropout imputation (similarly for BOCF). However, if LOCF is selected and no visit data is available, there remains no information on the subject to be used for the LOCF dropout imputation, and thus these subjects are omitted from the analysis. All subjects are included if they either 1) have some visit data available, or 2) are dropouts before visit 1 with sufficient information to impute their final endpoint with this pre-processing step.</p>
<section id="time-to-event-missingness" class="level3" data-number="6.7.1">
<h3 data-number="6.7.1" class="anchored" data-anchor-id="time-to-event-missingness"><span class="header-section-number">6.7.1</span> Time-to-Event Missingness</h3>
<p>For a time-to-event endpoint, as is the convention in this endpoint, subjects are observed up to the time they have an event (or the end of follow up), so no subject drops out after having had an event. Subjects that do drop-out are included in the analysis as not having had an event up to the last observation of the subject.</p>
</section>
</section>
</section>
<section id="augmented-priors-historical-prior" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Augmented Priors (Historical Prior)</h1>
<p>If a Bayesian Augmentation is used for either the Control or Active Comparator arm then the user specifies:</p>
<ul>
<li><p>The sufficient statistics to be included from each historic study, these are:</p>
<ul>
<li><p>Continuous: the mean response and the SD of the response of the control or active comparator arm and the number of subjects observed.</p></li>
<li><p>Dichotomous: the observed number of responders and the number of subjects observed in the study.</p></li>
<li><p>Time-to-Event: the number of events and the amount of exposure within each bin in the piecewise model.</p></li>
</ul></li>
</ul>
<p>The information from the historical studies can be ‘down-weighted’ by decreasing the effective information in the sample size. For continuous, this can be done by decreasing the sample size by a percentage. For dichotomous, both the number of responders and the number of subjects would be decreased by a percentage. For time-to-event, multiplying the number of events and the exposure by the same fraction will reduce the information in the study without changing the reported hazard rate.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image34.png" style="width:6.5in;height:4.62723in"></p>
<p>The hierarchical models for the control or active comparator rates are very similar across the endpoints. They are briefly described below.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">Continuous Endpoints</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Dichotomous Endpoints</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-3" role="tab" aria-controls="tabset-3-3" aria-selected="false">Time-to-Event Endpoints</a></li></ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><span class="math display">\[\theta_{0t} \sim \text{N}(\mu_0, \tau_0^2) \text{ for } \tau=0,1,2,\ldots,T\]</span> where <span class="math inline">\(\theta_{0t}\)</span> is the mean for the control arm in trial <span class="math inline">\(t\)</span> (<span class="math inline">\(t=0\)</span> for the current trial and <span class="math inline">\(t=1,2,\ldots,T\)</span> for previous trials). A user needs to specify appropriate priors for the hyper-parameters:</p>
<p><span class="math display">\[\mu_0 \sim \text{N}(m_0, \sigma_0^2)\]</span> <span class="math display">\[\tau_0^2 \sim \text{IG}(a_0, b_0)\]</span></p>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><span class="math display">\[\theta_{0t} \sim \text{N}(\mu_0, \tau_0^2) \text{ for } \tau=0,1,2,\ldots,T\]</span> where <span class="math inline">\(\theta_{0t}\)</span> is the log-odds for the control arm in trial <span class="math inline">\(t\)</span> (<span class="math inline">\(t=0\)</span> for the current trial; <span class="math inline">\(t=1,2,\ldots,T\)</span> for previous trials). A user needs to specify appropriate priors for the hyper-parameters:</p>
<p><span class="math display">\[\mu_0 \sim \text{N}(m_0, \sigma_0^2)\]</span> <span class="math display">\[\tau_0^2 \sim \text{IG}(a_0, b_0)\]</span></p>
<p>The prior distributions for the hyper-parameters of the hierarchical model. The hyper-parameters are the mean and standard deviation of Normal distribution for the log hazard ratios of the event rates of the historical studies and the current study.</p>
</div>
<div id="tabset-3-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-3-tab">
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><span class="math display">\[\lambda_{st}=\lambda_s \exp(\gamma_t) \text{ for } t=0,1,2,\ldots,T\]</span> where <span class="math inline">\(\lambda_{st}\)</span> is the hazard rate for the control arm in segment <span class="math inline">\(s\)</span> (<span class="math inline">\(s=1,2,\ldots,S\)</span>) for previous trial <span class="math inline">\(t\)</span> (<span class="math inline">\(t=1,2,\ldots,T\)</span>) and <span class="math inline">\(\lambda_{s0}\)</span> is the hazard rate for the current control arm in segment <span class="math inline">\(s\)</span>; <span class="math inline">\(\lambda_s\)</span> is a base hazard for segment <span class="math inline">\(s\)</span>; and <span class="math inline">\(\gamma_t\)</span> is the log hazard ratio between that base rate and the <span class="math inline">\(\lambda_{st}\)</span> values.</p>
<p>The following hierarchical model is used</p>
<p><span class="math display">\[\gamma_t \sim \text{N}(\mu_\gamma, \tau_\gamma^2) \text{ for } t=0,1,2,\ldots,T\]</span> Users specify priors for the hyper-parameters:</p>
<p><span class="math display">\[\mu_\gamma \sim \text{N}(m_\gamma, t_\gamma^2)\]</span> <span class="math display">\[\tau^2 \sim \text{IG}(a_\gamma, b_\gamma)\]</span></p>
<p>The formulation above is not identifiable as changes in <span class="math inline">\(\lambda_s\)</span> can be compensated for by changes in the <span class="math inline">\(\gamma_t\)</span> values (thus, one can use different combination of <span class="math inline">\(\lambda_s\)</span> and <span class="math inline">\(\gamma_t\)</span> but acquire the same set of values <span class="math inline">\(\lambda_{st}\)</span> and thus the same likelihood. To avoid this difficulty, we use the above formulation but fix <span class="math inline">\(\gamma_0 = 0\)</span>. In addition to preserving the identifiability of the structure, this constraint allows <span class="math inline">\(\lambda_s\)</span> to have the interpretation of being the hazard rate for the current control arm, and thus the prior on <span class="math inline">\(\lambda_s\)</span> from the main dose response may be used as the prior for <span class="math inline">\(\lambda_s\)</span>.</p>
</div>
</div>
</div>
<section id="setting-priors-for-hierarchical-model-hyper-parameters" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="setting-priors-for-hierarchical-model-hyper-parameters"><span class="header-section-number">7.1</span> Setting Priors for Hierarchical Model Hyper Parameters</h2>
<p>Unless the intent is to add information that is not included in the historic studies, the hyper parameters can and should be set so that they are ‘weak’ priors, centered on the expected values.</p>
<p>In this case the following would be reasonable:</p>
<ul>
<li><p>Set the prior mean value for Mu as the mean of the mean responses on the control arm in the historic studies</p></li>
<li><p>Set the prior SD for Mu equal to the average SD of response divided by the square root of the number of studies.</p></li>
<li><p>Set the center for tau to the same value as the prior SD for Mu.</p></li>
<li><p>Set the weight for tau to be &lt; 1.</p></li>
</ul>
<p>One can traverse the spectrum from ‘complete pooling of data’ to ‘completely separate analyses’ through the prior for tau. If the weight of the prior for tau is small (relative to the number of studies), then (unless set to a very extreme value) the mean of the prior for tau will have little impact and the degree of borrowing will depend on the observed data.</p>
<p>To give some prior preference towards pooling or separate analysis the <strong>weight</strong> for tau has to be large (relative to the number of historic studies) – to have a design that is like pooling all the historic studies the mean for tau needs to be small (say 10% or less of the value suggested above). For there to be no borrowing from the historic studies the value for tau needs to be large (say 10x or more the value suggested above).</p>
<p>The best way to understand the impact of the priors is try different values and run simulations.</p>
</section>
<section id="bayesian-augmented-control-bac-example" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="bayesian-augmented-control-bac-example"><span class="header-section-number">7.2</span> Bayesian Augmented Control (BAC) Example:</h2>
<p>It is easiest to study the impact of BAC in a simplified version of the trial being designed, for example use a 2 arm fixed design with ‘no model’, no adaptation, no longitudinal modeling, etc.</p>
<p>For instance, in a continuous setting with an expected sample size of 50 on control, a mean response of 5 and an SD in the response of 2, looking at the effect of having 4 prior, similarly sized studies:</p>
<table class="table">
<caption>
<p>
External Study Sufficient Statistics
</p>
</caption>
<colgroup>
<col style="width: 24%">
<col style="width: 22%">
<col style="width: 30%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>
</th>
<th>
Number of subjects
</th>
<th>
Mean Response
</th>
<th>
SD of Response
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
Study 1
</td>
<td>
50
</td>
<td>
4.76
</td>
<td>
2
</td>
</tr>
<tr class="even">
<td>
Study 2
</td>
<td>
50
</td>
<td>
4.93
</td>
<td>
2
</td>
</tr>
<tr class="odd">
<td>
Study 3
</td>
<td>
50
</td>
<td>
5.07
</td>
<td>
2
</td>
</tr>
<tr class="even">
<td>
Study 4
</td>
<td>
50
</td>
<td>
5.24
</td>
<td>
2
</td>
</tr>
</tbody>
</table>
<p>For simplicity we have just varied the means of the studies – they are all consistent with a normally distributed estimate, with mean of 5 and a standard error of <span class="math inline">\(\frac{2}{\sqrt{50}}\)</span>.</p>
<p>By simulating a fixed trial with a sample size of 100 and fixed 1:1 allocation between control and a study arm we can easily observe the effects of a BAC on the control arm. Creating 6 VSR profiles with sigma = 2, and the same mean response for control and the study arm in each profile of: 4.53, 4.76, 5.07, 5.24 and 5.47 we can look at the bias of the final estimate and the shrinkage in the SD of the estimate that could be brought about by using BAC:</p>
<table class="table">
<caption>
<p>
Quick simulation study of how the hierarchical model for BAC effects estimates of the control rate under different true control rate scenarios.
</p>
</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>
True Mean
</th>
<th>
Raw mean
</th>
<th>
Raw SD
</th>
<th>
Estimate inc BAC
</th>
<th>
SD inc BAC
</th>
<th>
Bias
</th>
<th>
Effective additional Subjects
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
4.53
</td>
<td>
4.55
</td>
<td>
0.28
</td>
<td>
4.64
</td>
<td>
0.255
</td>
<td>
2.1%
</td>
<td>
11.1
</td>
</tr>
<tr class="even">
<td>
4.76
</td>
<td>
4.78
</td>
<td>
0.28
</td>
<td>
4.83
</td>
<td>
0.250
</td>
<td>
1.0%
</td>
<td>
13.5
</td>
</tr>
<tr class="odd">
<td>
4.93
</td>
<td>
4.95
</td>
<td>
0.28
</td>
<td>
4.96
</td>
<td>
0.248
</td>
<td>
0.2%
</td>
<td>
14.3
</td>
</tr>
<tr class="even">
<td>
5.07
</td>
<td>
5.09
</td>
<td>
0.28
</td>
<td>
5.07
</td>
<td>
0.248
</td>
<td>
-0.4%
</td>
<td>
14.2
</td>
</tr>
<tr class="odd">
<td>
5.24
</td>
<td>
5.26
</td>
<td>
0.28
</td>
<td>
5.20
</td>
<td>
0.250
</td>
<td>
-1.1%
</td>
<td>
13.2
</td>
</tr>
<tr class="even">
<td>
5.46
</td>
<td>
5.49
</td>
<td>
0.28
</td>
<td>
5.38
</td>
<td>
0.255
</td>
<td>
-1.9%
</td>
<td>
10.7
</td>
</tr>
</tbody>
</table>
<p>Note it is important to use the column “SD Mean resp 1” from the simulations file to see the SD of the estimate and not use the SD of the estimates in the summary table.</p>
<p>The small shrinkage in the SD is more impressive when viewed in terms of how many additional subjects would have to be recruited to achieve the same shrinkage in the raw estimate. These are useful savings for small additional bias.</p>
<p>The “effective additional subjects” was calculated: <span class="math display">\[\left( \frac{\text{True sigma}}{\text{AVG(SD Mean resp)}} \right)^{2} - \left( \frac{\text{True sigma}}{\text{AVG(SE Mean Raw Response)}} \right)^{2}\]</span> where in this example <span class="math inline">\(\text{True sigma}\)</span> was 2.</p>
</section>
</section>
<section id="frequentist-analysis" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Frequentist Analysis</h1>
<p>On the Frequentist Analysis tab the user can specify that some standard frequentist analyses be performed at trial analyses. The frequentist analysis tab is completely separate from, and independent of, any p-value QOIs that have been defined. The analyses specified on this tab cannot be used for simulated trial decisions - they are for storing in output only.</p>
<p>Each specified analysis can be conducted using a variety of ways of handling missingness. Select all ways of handling missingness that are desired:</p>
<ul>
<li><p>Missing data replaced by last observation carried forward (LOCF)</p></li>
<li><p>Missing data replaced by baseline observation carried forward (BOCF). This is only available if the endpoint is continuous and Baseline is being simulated.</p></li>
<li><p>Missing data is ignored (a “per-protocol” analysis).</p></li>
<li><p>Missing data is treated as a failure. This is only available if the endpoint is dichotomous.</p></li>
</ul>
<p>If the trial has interim analyses, then for the simulations for which frequentist weeks files are to be output (specified on the Simulation tab) the standard frequentist analyses will be performed. If the trial has p-values QOIs, those QOIs are calculated every interim in all simulations.</p>
<p>Having the frequentist analysis include <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett’s</a> adjusted p-values is a separate option (that applies to all the analysis type requested) because of the significant run-time overhead this can entail. <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett’s</a> adjustment is available for continuous and dichotomous frequentist analyses.</p>
<p>The frequentist analysis tabs for the continuous and dichotomous engines also have trend tests, and allow the user to specify contrast coefficients to conduct those tests.</p>
<p>Note that the reported frequentist estimates of the treatment effect take the specified direction of response on the Study tab (whether a response indicates subject improving or worsening) into account. They are adjusted so that a treatment that is estimated to be better than the control always has a positive treatment effect.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image35.png" style="width:4.51964in;height:3.24521in"></p>
<section id="continuous-endpoints-1" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="continuous-endpoints-1"><span class="header-section-number">8.1</span> Continuous Endpoints</h2>
<p>At the end of each simulated trial the following frequentist values will be calculated for each missingness handling method checked:</p>
<ol type="1">
<li><p>Using unadjusted dose-placebo comparisons based on a two-sample t-test calculate the:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>(p-value)[## “1-sided p-value is reported in all the frequentist results. This is done in order to be consistent with comparisons with 1-sided α-values elsewhere.”],</p></li>
<li><p>confidence interval for the mean difference,</p></li>
<li><p>for each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were) .</p></li>
</ol></li>
<li><p>If selected, using <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett</a>-adjusted dose-placebo comparisons based on a two-sample t-test calculate the:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>confidence interval for the mean difference</p></li>
<li><p>for each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were) .</p></li>
</ol></li>
<li><p>Using the general trend test calculate the t-test statistic and p-value using user supplied contrast coefficients.</p></li>
</ol>
<p>If neither placebo nor an active comparator are simulated, a difference from 0 is assessed for each dose arm and <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett</a>-adjusted calculations are not carried out.</p>
<p>If high values of the endpoint are good, P-values are calculated using a one-sided t-test testing <span class="math display">\[H_0: \mu_T &lt; \mu_C\]</span> against <span class="math display">\[H_1: \mu_T \ge \mu_C\]</span> with <span class="math inline">\(\mu_T\)</span> being the true treatment response mean and <span class="math inline">\(\mu_C\)</span> being the true control response mean. If low values of the endpoint are good, then the signs of the hypotheses are flipped.</p>
</section>
<section id="dichotomous-endpoints-1" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="dichotomous-endpoints-1"><span class="header-section-number">8.2</span> Dichotomous Endpoints</h2>
<p>At the end of each simulated trial the following frequentist values will be calculated for each missingness handling method checked:</p>
<ol type="1">
<li><p>Using the methodology described by <a href="#agresti" title="Agresti, A. 2002. Categorical Data Analysis. Second Edition. Wiley.">Agresti</a>, <a href="#mee" title="Mee, R. W. 1984. Confidence bounds for the difference between two probabilities. Biometrics. 40, 1175-1176.">Mee</a> and <a href="#nurminem" title="Nurminen, M. 1986. Confidence intervals for the ratio and difference of two binomial proportions. Biometrics. 42, 675-676.">Nurminem</a> for comparing the difference of proportions:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>95% confidence interval for the difference in proportions,</p></li>
<li><p>marginal probabilities of significance.</p></li>
</ol></li>
<li><p>If checked, using <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett</a>-adjusted dose-placebo comparisons for comparing the difference of proportions:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>95% confidence interval for the difference in proportions,</p></li>
<li><p>marginal probabilities of significance.</p></li>
</ol></li>
<li><p>Using the general trend test calculate the t-test statistic and p-value using user supplied contrast coefficients.</p></li>
</ol>
<p>P-values are calculated by user choice either using a normal approximation (see previous section on p-value calculations for continuous endpoints) or a Fisher’s exact test, which is a conservative test to test the null hypothesis that the outcome is independent of the treatment assignment. For the normality approximation to have good asymptotic coverage, the expected number of successes and failures under the null hypothesis should be greater or equal to 5 for both groups. In cases where this is not guaranteed, Fisher’s exact test is recommended when strict type 1 error control is required.</p>
<p>If neither placebo nor active comparator are specified, a difference from 0 is assessed for each dose arm and <a href="#dunnett" title="Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.">Dunnett</a>-adjusted calculations are not carried out.</p>
</section>
<section id="time-to-event-frequentist-analysis" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="time-to-event-frequentist-analysis"><span class="header-section-number">8.3</span> Time-to-Event Frequentist Analysis</h2>
<p>For each simulated trial, the following frequentist analyses will be performed:</p>
<ol type="1">
<li><p>Dose-placebo comparisons based on log-rank test and the Cox proportional hazards model. Summaries include:</p>
<ol type="1">
<li><p>The log-rank and Wilcoxon test statistics and the corresponding p-values,</p></li>
<li><p>Estimated hazard ratio and its confidence interval from Cox model,</p></li>
<li><p>For each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were, based on the hazard ratio inference from the Cox model).</p></li>
</ol></li>
<li><p>Median survival times based on the Kaplan-Meier method.</p></li>
<li><p>For the predictor, descriptive statistics are computes – a 7 number summary for a continuous predictor, percentages for the dichotomous predictor, and median time, average hazard, and a cox model with predictor as covariate are computed for a time to event predictor.</p></li>
</ol>
<p>The following variations for adjusting the alpha level for multiple comparisons should be available using the user-specified 1-sided alpha: unadjusted, and Bonferonni adjusted.</p>
<p><a name="longitudinalModeling"></a></p><a name="longitudinalModeling">
</a></section><a name="longitudinalModeling">
</a></section><a name="longitudinalModeling">
</a><section id="longitudinal-modeling" class="level1" data-number="9"><a name="longitudinalModeling">
<h1 data-number="9"><span class="header-section-number">9</span> Longitudinal Modeling</h1>
<p>The continuous and dichotomous endpoints provide the ability to use longitudinal models to utilize data from incomplete subject’s observed early endpoint values. These subjects may be those that have dropped out, or subjects at an interim that have not had the opportunity to complete their follow-up.</p>
<p>To perform any longitudinal modeling, ‘Use longitudinal modeling’ must be checked on the Study &gt; Study Info tab, and the subject visit schedule must be defined.</p>
<p>To include dropouts in the longitudinal analysis, on the Design &gt; Dose Response tab select “Bayesian multiple imputation from post baseline.”</p>
</a><section id="multiple-imputation" class="level2" data-number="9.1"><a name="longitudinalModeling">
<h2 data-number="9.1" class="anchored" data-anchor-id="multiple-imputation"><span class="header-section-number">9.1</span> Multiple Imputation</h2>
<p>Unless a deterministic method is used such as LOCF or BOCF, longitudinal models inform the dose response estimates by using the longitudinal model to stochastically impute subjects’ final endpoint data when it’s not been directly observed.</p>
<p>First, data from subjects with both intermediate and final observations is used to estimate the parameters of whatever longitudinal imputation model has been selected.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image36.png" style="width:3.33848in;height:1.92in"></p>
<p>Subjects with missing final data have final data sampled from the posterior distribution of the longitudinal model given the subjects most recent intermediate visit (or in some models, all their available intermediate visit data). Subjects with no final or intermediate data have final data sampled from the posterior distribution of the dose response model given the dose arm the subject was allocated to.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image37.png" style="width:3.336in;height:1.91857in"></p>
<p>Once every randomized subject has either a real known final endpoint or an imputed final endpoint, the dose response model is re-estimated using that <em>complete</em> dataset.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image38.png" style="width:3.352in;height:2.10985in"></p>
</a><p><a name="longitudinalModeling">This impute-then-fit-dose-response process is built into the MCMC estimation sampling loop. Each time we draw a new set of parameters from the longitudinal model they are used to impute the final endpoint of incomplete subjects. These subjects then inform the dose response model. Then we get a new sample from the longitudinal model and so on. The longitudinal models, with </a><a href="##" title="The ITP model uses the current state of the dose response models in its imputation.">one exception</a>, are not conditioned on the dose response models.</p>
<p>The missing final endpoint values are imputed with the uncertainty in the longitudinal model, and, as a result, the dose response model is estimated including both the uncertainty in the longitudinal model and the usual uncertainty in its parameters.</p>
<p>Above, it says “fit the dose response model,” as a step in the iterative process. The idea is that once you create a dataset through imputation you should update the dose response model MCMC chain until it converges. By default only 1 step is taken on the dose response model MCMC chain. It is safer, especially if doing a real analysis, to allow the dose response model parameter chains to converge slightly before imputing the missing data again. This can be done on the MCMC settings control on the Simulation tab and setting the “Samples per Imputation” parameter. As a rough guide, if it at some early interims &gt; 5% of the data being analyzed will be imputed, a value in the range 2 to 10 is recommended to avoid underestimating the uncertainty. A higher number should be used the greater the proportion of imputed data.</p>
<p>A similar procedure is used when imputing event times based on a predictor endpoint in FACTS Core Time-to-Event.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Computational Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>FACTS is not fitting a joint Bayesian model of the longitudinal and dose response models. This would require a full MCMC fit of one model for every MCMC step of the other. Thus, if taking 2,500 samples, we would require a total of 2,500<sup>2</sup> samples. This would make running simulations with longitudinal model prohibitively expensive.</p>
</div>
</div>
</section>
<section id="how-many-longitudinal-models" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="how-many-longitudinal-models"><span class="header-section-number">9.2</span> How many longitudinal models?</h2>
<p>When specifying a longitudinal model in FACTS, the user must clarify whether the longitudinal model is shared across all doses, or if different arms are to estimate different functions connecting early endpoints to the final endpoint.</p>
<p>The options that may be selected for the number of model instances are:</p>
<ul>
<li><p>“Single model for all arms” – just one set of longitudinal parameters is estimated using all the subject data regardless of their treatment.</p></li>
<li><p>“Model control separately” – two sets of longitudinal parameters are estimated, one using data from just those subjects on the control arm, and the other using all the subject data from all the other arms.</p></li>
<li><p>“Model comparator separately” (only available if there is an active comparator arm) - two sets of longitudinal parameters are estimated, one using data from just those subjects on the active comparator arm, and the other using all the subject data from all the other arms (control and active treatments).</p></li>
<li><p>“Model control and comparator separately” (only available if there is an active comparator arm) - three sets of longitudinal parameters are estimated, one using data from just those subjects on the active comparator arm, one using data from just those subjects on the control arm, and the third using all the subject data from all the other arms.</p></li>
<li><p>“Model all arms separately” – a set of longitudinal parameters is independently estimated separately for each arm, each set estimated just using the data available from the subjects on that arm.</p></li>
</ul>
<p>The fewer models used, the more data is pooled, the more precisely the model parameters can be estimated, and the more informative the intermediate data can be. Pooling data assumes that subjects in different groups have the same longitudinal profile, although they may still have different magnitude or probability of response (estimated by Dose Response Model).</p>
<p>If the response profile could be different on different treatment arms – for example, if subjects on control recover constantly over time, but those on an effective dose of the study drug recover very quickly early on, and more gradually later in their follow-up - a longitudinal model based on pooled data would tend to over-estimate the final endpoint of subjects on an effective dose of the study drug when only their early data was available. In a case like that, it would be better to use separate models. If the rapid early response was likely on all study drug treatment arms, then possibly use “model control separately.” If, however, the rapid response will only be seen on some study drug arms then use “model all arms separately”.</p>
<p>In addition to declaring how many longitudinal models should be estimated, when there is more than one model instance the user must declare if the prior distributions should be specified differently across each model instance or not. The options that may be selected for prior specification (for all LMs but linear regression) are:</p>
<ol type="1">
<li>Same priors across all model instances</li>
</ol>
<ul>
<li>Each instance of the model has identical prior distributions on its parameters. Estimation is still performed independently on each model instance.</li>
</ul>
<ol start="2" type="1">
<li>Specify priors per model instance</li>
</ol>
<ul>
<li>Each instance of the model has its own priors that may vary across instances.</li>
</ul>
<p>The linear regression longitudinal model has a different parameter set estimated for each visit, so its prior specification rules are slightly different. See the linear regression section below for specifics about prior specification specific to this model.</p>
</section>
<section id="longitudinal-models-for-a-continuous-endpoint" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="longitudinal-models-for-a-continuous-endpoint"><span class="header-section-number">9.3</span> Longitudinal Models for a Continuous Endpoint</h2>
<section id="locf-last-observation-carried-forward" class="level3" data-number="9.3.1">
<h3 data-number="9.3.1" class="anchored" data-anchor-id="locf-last-observation-carried-forward"><span class="header-section-number">9.3.1</span> LOCF (Last Observation Carried Forward)</h3>
<p>The simplest possible longitudinal model. If {<span class="math inline">\(y_{it}\)</span>} is the set of observed responses from early visits, and <span class="math inline">\(y_{i t_m}\)</span> is the last observed value of <span class="math inline">\(y_{i t}\)</span>, then the LOCF model for the final endpoint <span class="math inline">\(Y_i\)</span> is</p>
<p><span class="math display">\[Y_i\mid \{y_{it}\} = y_{it_m}\]</span></p>
<p>In the continuous engine <span class="math inline">\(t_m\)</span> can be any earlier observed visit including the baseline value.</p>
</section>
<section id="linear-regression" class="level3" data-number="9.3.2">
<h3 data-number="9.3.2" class="anchored" data-anchor-id="linear-regression"><span class="header-section-number">9.3.2</span> Linear Regression</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Shiny App
</div>
</div>
<div class="callout-body-container callout-body">
<p>The following shiny application for a tool that helps visualize and set priors for the linear regression longitudinal model.</p>
<p><a href="../../../../concepts/facts/LinearRegressionLMPriors.html">See here.</a></p>
</div>
</div>
<p>The linear regression model fits a simple linear model from the data at each visit with the final visit</p>
<p><span class="math display">\[Y_i \mid y_{it} \sim \alpha_t + \beta_t y_{it} + \text{N}(0,\lambda_t^2)\]</span></p>
<p>The parameter <span class="math inline">\(\alpha_t\)</span> is the intercept of the model for visit t, and the parameter <span class="math inline">\(\beta_t\)</span> is a multiplicative modifier (slope) of the response observed longitudinal at visit <span class="math inline">\(t\)</span> to adjust the prediction of the final endpoint.</p>
<p>Imputation of the final endpoint value for a subject using the linear regression longitudinal model is based on only the latest observed visit’s endpoint value.</p>
<p>The default setting of “Same priors across all model instances and visits,” implies that each parameter <span class="math inline">\(\alpha\)</span>, <em>β</em>, and <em>λ</em> have the same prior for all <em>t</em>. Estimation of those parameters is still done independently for each model instance. The one prior across all model instance are formulated as:</p>
<p><span class="math display">\[\alpha_t \sim \text{N}(\alpha_\mu, \alpha_\sigma^2)\]</span> <span class="math display">\[\beta_t \sim \text{N}(\beta_\mu, \beta_\sigma^2)\]</span> <span class="math display">\[\lambda_{t}^{2} \sim \text{IG}\left( \frac{\lambda_{n}}{2},\frac{\lambda_{\mu}^{2}\lambda_{n}}{2} \right)\]</span></p>
<p>The above prior formulation may not be desirable if specifying priors that are not extremely diffuse – especially on the <span class="math inline">\(\beta\)</span> parameters. Instead, selecting “Specify priors per visit across all model instances,” will share the prior specification across all instances of the model, but allows for different priors to be put on the parameters associated with each visit. The user inputted prior parameters are now subscripted with <span class="math inline">\(t\)</span> to denote the visit they correspond to. These priors apply to all model instances:</p>
<p><span class="math display">\[\alpha_t \sim \text{N}(\alpha_{\mu_t}, \alpha_{\sigma_t}^2)\]</span> <span class="math display">\[\beta_t \sim \text{N}(\beta_{\mu_t}, \beta_{\sigma_t}^2)\]</span> <span class="math display">\[\lambda_{t}^{2} \sim \text{IG}\left( \frac{\lambda_{n_t}}{2},\frac{\lambda_{\mu_t}^{2}\lambda_{n_t}}{2} \right)\]</span></p>
<p>It is also possible to specify priors “Per model instance and visit,” in which every visit has separate priors, and those differing priors vary across model instances. This is the most flexible prior specification method. The user inputted prior parameters are now subscripted by both <em>t</em> for visit and <em>i</em> for model instance.</p>
<p><span class="math display">\[\alpha_{ti} \sim \text{N}(\alpha_{\mu_{ti}}, \alpha_{\sigma_{ti}}^2)\]</span> <span class="math display">\[\beta_{ti} \sim \text{N}(\beta_{\mu_{ti}}, \beta_{\sigma_{ti}}^2)\]</span> <span class="math display">\[\lambda_{ti}^{2} \sim \text{IG}\left( \frac{\lambda_{n_{ti}}}{2},\frac{\lambda_{\mu_{ti}}^{2}\lambda_{n_{ti}}}{2} \right)\]</span></p>
<p>A potential starting place for non-informative prior values would be</p>
<dl>
<dt><span class="math inline">\(\alpha\)</span></dt>
<dd>
mean of 0, SD <span class="math inline">\(\ge\)</span> largest expected response
</dd>
<dt><span class="math inline">\(\beta\)</span></dt>
<dd>
mean of either 0 or <span class="math inline">\(\frac{\text{final visit time}}{\text{early visit time}}\)</span>, SD <span class="math inline">\(\ge\)</span> largest expected ratio of final visit to first visit
</dd>
<dt><span class="math inline">\(\lambda\)</span></dt>
<dd>
mean of expected SD of the endpoint (‘sigma’), weight of 1. The variability of the prediction from the longitudinal model (based on an observed intermediate response) should be less than that based solely on the treatment allocation, thus this is a weakly pessimistic prior on the effectiveness of the longitudinal model that should be quickly overwhelmed by the data.
</dd>
</dl>
<p>This model is easy to understand and can be used even if there is only one visit, but doesn’t get more powerful if there are more visits. Its power will depend on the degree of correlation between the intermediate visit response and the final response.</p>
</section>
<section id="time-course-hierarchical" class="level3" data-number="9.3.3">
<h3 data-number="9.3.3" class="anchored" data-anchor-id="time-course-hierarchical"><span class="header-section-number">9.3.3</span> Time Course Hierarchical</h3>
<p>The Time Course Hierarchical models the relationship between subjects’ early responses and their final response. It incorporates a per-subject offset from the mean response and a scaling factor from each visit to the final endpoint, but with no model of the change from visit-to-visit.</p>
<p>The response at the <span class="math inline">\(t_{th}\)</span> visit for the <span class="math inline">\(i^{th}\)</span> subject, having been randomized to the <span class="math inline">\(d^{th}\)</span> dose is modeled as:</p>
<p><span class="math display">\[y_{it} \sim e^{\alpha_t}(\theta_d + \delta_i) + \text{N}(0, \lambda_t^2)\]</span></p>
<p>The imputed final response (visit <span class="math inline">\(T\)</span>$) for the <span class="math inline">\(i^{th}\)</span> subject, having been randomized to the <span class="math inline">\(d^{th}\)</span> dose is modeled as:</p>
<p><span class="math display">\[Y_{iT} \sim \theta_d + \delta_i + \text{N}(0, \lambda_T^2)\]</span></p>
<p>(i.e.&nbsp;<span class="math inline">\(\alpha_T\)</span> is 0).</p>
<p>The model parameters can be interpreted as follows:</p>
<dl>
<dt><span class="math inline">\(\theta_d\)</span></dt>
<dd>
the estimated mean response at the final visit in dose <span class="math inline">\(d\)</span> from the dose response model.
</dd>
<dt><span class="math inline">\(\delta_i\)</span></dt>
<dd>
the estimated patient level random effect around the mean final response (<span class="math inline">\(\theta_d\)</span>) for the dose <span class="math inline">\(d\)</span> that patient <span class="math inline">\(i\)</span> is randomized to.
</dd>
<dt><span class="math inline">\(\alpha_t\)</span></dt>
<dd>
a scaling parameter that determines the proportion of the final response that is observable at visit <span class="math inline">\(t\)</span>. A value of <span class="math inline">\(\alpha_t=0\)</span> indicates that the expected value of early visit <span class="math inline">\(t\)</span> is equal to the estimated final visit mean <span class="math inline">\(\theta_d\)</span>. A value of <span class="math inline">\(\alpha_t= −0.69315\)</span> indicates that the expected value of early visit <span class="math inline">\(t\)</span> is 50% of the estimated final visit mean <span class="math inline">\(\theta_d\)</span>.
</dd>
<dt><span class="math inline">\(\lambda_t^2\)</span></dt>
<dd>
the variance of the endpoint around the estimated mean response at visit <span class="math inline">\(t\)</span>.
</dd>
</dl>
<p>The prior for <span class="math inline">\(\alpha_t\)</span> is a normal distribution with a user specified the mean and standard deviation:</p>
<p><span class="math display">\[\alpha_t \sim \text{N}(\alpha_\mu, \alpha_\sigma^2)\]</span></p>
<p>The prior for the <span class="math inline">\(\delta_i\)</span> terms is a normal distribution with a mean of 0 and variance <em>τ</em><sup>2</sup>.</p>
<p><span class="math display">\[\delta_i \sim \text{N}(0, \tau^2)\]</span></p>
<p><span class="math inline">\(\tau^2\)</span> is estimated as part of the longitudinal model, and has an inverse gamma prior distribution with prior central value <span class="math inline">\(\tau_\mu\)</span> and weight (in terms of “equivalent number of observations”) <span class="math inline">\(\tau_n\)</span>:</p>
<p><span class="math display">\[\tau^{2} \sim \text{IG}\left( \frac{\tau_{n}}{2},\\\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span></p>
<p>The prior for the <span class="math inline">\(\lambda_t^2\)</span> terms is an inverse gamma distribution with prior central value <span class="math inline">\(\lambda_\mu\)</span> and weight (in terms of “equivalent number of observations”) <span class="math inline">\(\lambda_n\)</span>:</p>
<p><span class="math display">\[\lambda_{t}^{2}\sim\text{IG}\left( \frac{\lambda_{n}}{2},\frac{\lambda_{\mu}^{2}\lambda_{n}}{2} \right)\]</span></p>
<p>A reasonable starting place for prior values would be</p>
<dl>
<dt><span class="math inline">\(\alpha_t\)</span></dt>
<dd>
mean of -2, SD of 2, … so the prior ~70% interval for <span class="math inline">\(\alpha_t\)</span> is between -4 and 0 (+/1 1 SD) and thus the prior 70% interval for <span class="math inline">\(e^{\alpha_t}\)</span> to be between 0.02 and 1.
</dd>
<dt><span class="math inline">\(\tau\)</span></dt>
<dd>
mean set to the expected SD of the endpoint (‘sigma’), with a weight of 1.
</dd>
<dt><span class="math inline">\(\lambda_t\)</span></dt>
<dd>
mean set to the expected SD of the endpoint (‘sigma’), with weight of 1.
</dd>
</dl>
<p>We would expect <span class="math inline">\(\tau^2 + \lambda^2 \approx \sigma^2\)</span>, thus to specify a prior mean of <span class="math inline">\(\sigma\)</span> for each with a weight of 1 is a weakly pessimistic prior that should be quickly overwhelmed by the data.</p>
<p>This model is useful if there is thought to be a significant per-subject component to the response that should be manifest at the intermediate visits, and sufficient visits for the per-subject component to be estimated.</p>
</section>
<section id="kernel-density" class="level3" data-number="9.3.4">
<h3 data-number="9.3.4" class="anchored" data-anchor-id="kernel-density"><span class="header-section-number">9.3.4</span> Kernel Density</h3>
<p>The Kernel Density Model longitudinal model is a non-parametric re-sampling approach that is ideal for circumstances where the relationship between the interim time and the final endpoint is not known or not canonical.</p>
<p>The procedure is as follows. Assume an interim value for patient <span class="math inline">\(i\)</span> at time <span class="math inline">\(t\)</span>, <span class="math inline">\(Y_{it}\)</span>. Patient <span class="math inline">\(i\)</span> does not have an observed final endpoint at time <span class="math inline">\(T\)</span>, so one is to be imputed. Let <span class="math inline">\((X_{1t},X_{1T}), \ldots, (X_{nt}, X_{nT})\)</span> be the set of values for the previous subjects for whom there exists an interim value <span class="math inline">\(X_{*t}\)</span> and final value <span class="math inline">\(X_{*T}\)</span>.</p>
<p>To impute a value of <span class="math inline">\(Y_{iT}\)</span> given <span class="math inline">\(Y_{it}\)</span>, a pair <span class="math inline">\((X_{kt},X_{kT})\)</span> is selected with probability based on the pair’s time <span class="math inline">\(t\)</span> visit response’s proximity to the observed <span class="math inline">\(Y_{it}\)</span>:</p>
<p><span class="math display">\[\Pr\left(\text{Selecting}\left( X_{kt},\\X_{kT} \right) \right) = \frac{\exp\left( - \frac{1}{2h_{X_{t}}^{2}}\left( Y_{it} - X_{kt} \right)^{2} \right)}{\sum_{k = 1}^{n}{\exp\left( - \frac{1}{2h_{X_{t}}^{2}}\left( Y_{it} - X_{kt} \right)^{2} \right)}}\]</span></p>
<p>Then, a value of <span class="math inline">\(Y_{iT}\)</span> is imputed from the following distribution, which uses the selected pair’s final endpoint response <span class="math inline">\(X_{kT}\)</span>:</p>
<p><span class="math display">\[Y_{iT} \sim \text{N}(X_{kT}, h_{X_T}^2)\]</span></p>
<p>The bandwidths <span class="math inline">\(h_{X_t}\)</span> and <span class="math inline">\(h_{X_T}\)</span> are selected based on the criterion given by Scott (1992). That is,</p>
<p><span class="math display">\[h_{X_{j}} = \sigma_{X_{j}} \left( 1 - \rho^{2} \right)^{\frac{5}{12}} \left( 1 + \frac{\rho^{2}}{2} \right)^{- \frac{1}{6}}{\\n}^{- \frac{1}{6}}\text{   for } j = t \text{ and } T\]</span></p>
<p>where <span class="math inline">\(\sigma_{X_j}\)</span> is the standard deviation of the observed responses at time <span class="math inline">\(j\)</span>, <span class="math inline">\(n\)</span> is the number of pairs <span class="math inline">\((X_{*t},X_{*T})\)</span> that were chosen between, and <span class="math inline">\(\rho\)</span> is the correlation coefficient between <span class="math inline">\(X_t\)</span> and <span class="math inline">\(X_T\)</span> in the pairs <span class="math inline">\((X_{1t},X_{1T}), \ldots, (X_{nt}, X_{nT})\)</span>.</p>
<p>The Kernel Density model does not take prior distributions as input. So long as each early visit has more subjects with an observed early response and final response than the value entered in “Minimum number of participants with an early visit and final visit needed to estimate kernel bandwidths for that early visit:” then this algorithm runs without regard for user input.</p>
<p>If any visit has fewer subjects with early data and final data than the specified minimum number of participants, then instead of calculating the values of <span class="math inline">\(h_{X_t}\)</span> or <span class="math inline">\(h_{X_T}\)</span> the input values of “Fixed kernel bandwidth <span class="math inline">\(h_x\)</span>:” and “Fixed kernel bandwidth <span class="math inline">\(h_y\)</span>:” are used.</p>
<p>For <span class="math inline">\(h_x\)</span> and <span class="math inline">\(h_y\)</span>, possible starting values are the expected SD of the endpoint (‘sigma’). The default value for the minimum number of subjects with complete early and final visits is 6, but this value can be set to anything greater than 0 that the user desires.</p>
<p>The Kernel Density model is effective and flexible with no model assumptions, but its computational overhead is large. Simulations may take <span class="math inline">\(\sim 10\)</span> times longer to run, and having no prior model there has to be ‘in trial’ data before it can come into play.</p>
</section>
<section id="itp" class="level3" data-number="9.3.5">
<h3 data-number="9.3.5" class="anchored" data-anchor-id="itp"><span class="header-section-number">9.3.5</span> ITP</h3>
<p>The ITP (Integrated Two-component Prediction) model fits an observation for patient <span class="math inline">\(i\)</span> on dose <span class="math inline">\(d\)</span> at visit <span class="math inline">\(t\)</span> as:</p>
<p><span class="math display">\[y_{idt} = \left( \theta_{d} + s_{id} + \epsilon_{idt} \right)\left( \frac{1 - \text{exp}\left( kx_{idt} \right)}{1 - \text{exp}(kX)} \right)\]</span></p>
<p>where <span class="math display">\[\epsilon_{idt} \sim \text{N}(0, \lamnbda^2)\]</span> <span class="math display">\[\s_{id} \sim \text{N}(0, \tau^2)\]</span></p>
<p>and <span class="math inline">\(\theta_d\)</span> is the mean estimate of the final endpoint for dose d using all complete and partial data and assuming an independent dose response model on the doses. <span class="math inline">\(s_{id}\)</span> is a subject specific random effect, <span class="math inline">\(k\)</span> is a shape parameter, <span class="math inline">\(x_{idt}\)</span> is the time <span class="math inline">\(y_{idt}\)</span> is observed, <span class="math inline">\(X\)</span> is the time to final endpoint, and each <span class="math inline">\(\epsilon_{idt}\)</span> is a residual error.</p>
<p>The ITP model is similar to the Time Course Hierarchical above in that both models estimate subject specific component of the response. The biggest difference between the two is that in the ITP models the response changes over time as a parametric function based on the parameter <span class="math inline">\(k\)</span>, rather than having a separately estimated <span class="math inline">\(e^{\alpha_t}\)</span> for each visit.</p>
<p>The shape parameter <span class="math inline">\(k\)</span> determines the rate at which the final endpoint’s eventual effect is observed during a subject’s follow-up. A value of <span class="math inline">\(k=0\)</span> indicates that the proportion of effect observed moves linearly with time. A value of <span class="math inline">\(k&lt;0\)</span> means that the eventual final effect is observed earlier in follow-up and plateaus off as time moves towards the final endpoint. A value of <span class="math inline">\(k&gt;0\)</span> indicates that less of the total final endpoint effect is observed early in follow up, but as time approaches the final endpoint time the proportion of the effect observed increases rapidly. Values of <span class="math inline">\(k\)</span> less than 0 tend to be more common than values of <span class="math inline">\(k\)</span> greater than 0. See the figure below for a visualization of the different response-over-time curves that can be estimated with the ITP model.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image39.png" style="width:3.26636in;height:2.104in"></p>
<p>The priors for the parameters in the ITP model are: <span class="math display">\[k \sim \text{N}(\mu_k, \sigma_k^2)\]</span> <span class="math display">\[\theta_d \sim \text{N}(\mu_{\theta_d}, \sigma_{\theta_d}^2)\]</span> <span class="math display">\[\tau^2 \sim \text{IG}\left( \frac{\tau_{n}}{2},\frac{\tau_{\mu}^{2}\tau_{n}}{2} \right)\]</span> <span class="math display">\[\lambda^2 \sim \text{IG}\left( \frac{\lambda_{n}}{2},\frac{\lambda_{\mu}^{2}\lambda_{n}}{2} \right)\]</span></p>
<p>A reasonable starting place for prior values would be:</p>
<dl>
<dt><span class="math inline">\(\theta_d\)</span></dt>
<dd>
mean of the expected mean improvement from baseline on the Control arm, with SD greater than or equal to the expected treatment effect size.
</dd>
<dt><span class="math inline">\(k\)</span></dt>
<dd>
a mean of 0 and SD of 2, if subject improvement is expected to be rapid and then diminishing, the prior mean might be -0.5 or -1, if subject improvement is expected to be initially slow or non-existent then increasing, the prior mean might be 0.5 or 1.
</dd>
<dt><span class="math inline">\(\tau\)</span></dt>
<dd>
mean set to the expected SD of the endpoint (“sigma”), with a weight of 1.
</dd>
<dt><span class="math inline">\(\lambda\)</span></dt>
<dd>
mean set to the expected SD of the endpoint (“sigma”), with a weight of 1.
</dd>
</dl>
<p>The ITP model implies that the variance of the observations shrinks towards 0 with the mean (so early visits have reduced expected responses and variances). The ITP model may result in biased estimates of <span class="math inline">\(\theta_d\)</span> and/or the variance terms <span class="math inline">\(\tau^2\)</span> and <span class="math inline">\(\lambda^2\)</span> if the mean-variance relationship assumed by the ITP model is not present in the observed data. If the model assumptions are correct this can be a very effective longitudinal model.</p>
</section>
</section>
<section id="longitudinal-models-for-a-dichotomous-endpoint" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="longitudinal-models-for-a-dichotomous-endpoint"><span class="header-section-number">9.4</span> Longitudinal Models for a Dichotomous Endpoint</h2>
<section id="locf-last-observation-carried-forward-1" class="level3" data-number="9.4.1">
<h3 data-number="9.4.1" class="anchored" data-anchor-id="locf-last-observation-carried-forward-1"><span class="header-section-number">9.4.1</span> LOCF (Last Observation Carried Forward)</h3>
<p>The simplest possible longitudinal model. If {<span class="math inline">\(y_{it}\)</span>} is the set of observed responses from early visits, and <span class="math inline">\(y_{i t_m}\)</span> is the last observed value of <span class="math inline">\(y_{it}\)</span>, then the LOCF model for the final endpoint <span class="math inline">\(Y_i\)</span> is</p>
<p><span class="math display">\[Y_i \mid \{y_{it}} = y_{i t_m}\]</span></p>
</section>
<section id="beta-binomial" class="level3" data-number="9.4.2">
<h3 data-number="9.4.2" class="anchored" data-anchor-id="beta-binomial"><span class="header-section-number">9.4.2</span> Beta Binomial</h3>
<p>The Beta Binomial longitudinal model imputes a patient’s final endpoint given their most recent observed response.</p>
<p>The final endpoint response <span class="math inline">\(Y_i\)</span> is modeled as:</p>
<p><span class="math display">\[Y_i \sim \text{Bernoulli}(\pi_{t y_{it}})\]</span></p>
<p>where <span class="math inline">\(\pi_{t y_{it}}\)</span> is the probability that a patient is a response at the final endpoint given its early observed endpoint at time <span class="math inline">\(t\)</span> is <span class="math inline">\(y_{it}\)</span>,</p>
<p><span class="math display">\[\pi_{t y_{it}} = \Pr(Y_i = 1 \mid y_{it}) \sim \text{Beta}(\alpha_{t {y_it}}, \beta_{t y_{it}})\]</span></p>
<p>We use the set cardinality operator <span class="math inline">\(\mid \ldots \mid\)</span> to obtain the posterior distributions of <span class="math inline">\(\alpha_t\)</span> and <span class="math inline">\(\beta_t\)</span> as:</p>
<p><span class="math display">\[\alpha_{t0} = \alpha_{\mu 0} + \left| Y_i = 1, y_{it} = 0 \right| \]</span> <span class="math display">\[\alpha_{t1} = \alpha_{\mu 1} + \left| Y_i = 0, y_{it} = 0 \right| \]</span> <span class="math display">\[\beta_{t0} = \beta_{\mu 0} + \left| Y_i = 1, y_{it} = 1 \right| \]</span> <span class="math display">\[\beta_{t1} = \beta_{\mu 1} + \left| Y_i = 0, y_{it} = 1 \right| \]</span></p>
<p>i.e.&nbsp;a prior value <span class="math inline">\((\alpha_{\mu 0}, \alpha_{\mu 1}, \beta_{\mu 0}, \beta_{\mu 1})\)</span> plus the number of subjects for which the final response is known to be 1 for <span class="math inline">\(\alpha_{tx}\)</span> (or 0 for <span class="math inline">\(\beta_{tx}\)</span>) and the response at time <span class="math inline">\(t\)</span> is <span class="math inline">\(x\)</span>.</p>
<p>The <span class="math inline">\(\alpha_{tx}\)</span> and <span class="math inline">\(\beta_{tx}\)</span> parameters are independently estimated using only patients in their model instance, and may or not have identical priors <span class="math inline">\(\alpha_{\mu *}\)</span> and <span class="math inline">\(\beta_{\mu *}\)</span> depending on the Model Priors selection in FACTS. A common non-informative prior for the <span class="math inline">\(\pi_{t0}\)</span> and <span class="math inline">\(\pi_{t1}\)</span> parameters is <span class="math inline">\(\text{Beta}(1,1)\)</span>.</p>
</section>
<section id="logistic-regression" class="level3" data-number="9.4.3">
<h3 data-number="9.4.3" class="anchored" data-anchor-id="logistic-regression"><span class="header-section-number">9.4.3</span> Logistic regression</h3>
<p>The Logistic regression longitudinal model works similarly to the Beta Binomial imputation model. The difference is in the method of modeling the probability of a transition from an interim visit to the final visit <span class="math inline">\(\Pr(Y_i = 1 \mid y_{it})\)</span>. Like the Beta Binomial model, the logistic regression model imputes a patient’s final endpoint given their most recent observed response.</p>
<p>The final endpoint response <span class="math inline">\(Y_i\)</span> is modeled as:</p>
<p><span class="math display">\[Y_i \sim \text{Bernoulli}(\pi_{t y_{it}})\]</span></p>
<p>where <span class="math inline">\(\pi_{t y_{it}}\)</span> is the probability of a response at the final endpoint time given that its early observed endpoint at time <span class="math inline">\(t\)</span>$ is <span class="math inline">\(y_{it}\)</span>. Then, we define the parameter</p>
<p><span class="math display">\[\theta_{ty_{it}} = \text{logit}\left( \pi_{ty_{it}} \right) = \log\left( \frac{\pi_{ty_{it}}}{1 - \pi_{ty_{it}}} \right)\]</span>.</p>
<p>The priors on <span class="math inline">\(\theta_{t0}\)</span> and <span class="math inline">\(\theta{t1}\)</span> are:</p>
<p><span class="math display">\[\theta_{t0} \sim \text{N}(\mu_0, \sigma_0^2)\]</span> <span class="math display">\[\theta_{t1} \sim \text{N}(\mu_1, \sigma_1^2)\]</span></p>
<p>The model computes the posterior distribution of <span class="math inline">\(\theta_{t0}\)</span> and <span class="math inline">\(\theta_{t1}\)</span> using all patients on arms belonging to the model instance that have observed endpoint values at time <span class="math inline">\(t\)</span> and the final endpoint time <span class="math inline">\(T\)</span>.</p>
<p>The priors on <span class="math inline">\(\theta_{t0}\)</span> and <span class="math inline">\(\theta_{t1}\)</span> may be shared across model instances and/or visits depending on the selection made in the Model Priors section of the FACTS Logistic regression Longitudinal model page.</p>
<p>A possible starting place for non-informative priors in this model would be: <span class="math inline">\(\mu=0\)</span>,&nbsp;<span class="math inline">\(\sigma=2\)</span>. A weakly informative set of priors that an early response makes a final response more likely could be <span class="math display">\[\theta_{t0} \sim \text{N}(-.75, 1.25^2)\]</span> and <span class="math display">\[\theta_{t1} \sim \text{N}(0.75, 1.25^2)\]</span></p>
</section>
<section id="restricted-markov-model-absorbing-markov-chain" class="level3" data-number="9.4.4">
<h3 data-number="9.4.4" class="anchored" data-anchor-id="restricted-markov-model-absorbing-markov-chain"><span class="header-section-number">9.4.4</span> Restricted Markov Model (Absorbing Markov Chain)</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Using the Restricted Markov Model
</div>
</div>
<div class="callout-body-container callout-body">
<p>The restricted markov model is special in the sense that it can be used if and only if the “Use longitudinal modeling” check box is checked, the “Enable Special Longitudinal Options” check box is checked, and “Use restriced Markov model” is selected. When these conditions are met the Virtual Subject Response tab changes and the Design &gt; Longitudinal tab only has the Restricted Markov option.</p>
</div>
</div>
<p>The Absorbing Markov Chain model assumes that at each visit a subject is in one of three states – responder (1), stable (S), or failure (0). The responder and failure states are absorbing, meaning that once a patient has entered one of those states they must remain in that state for the remainder of the visits. Patients in the stable state may move to a responder or a failure in subsequent visits.</p>
<p>Unlike most other longitudinal models in FACTS, the Restricted Markov Model estimates the probability of a result at a visit based on the visit right before it, rather than predicting directly to the final endpoint from the early visit.</p>
<p><span class="math display">\[\Pr(y_{it} = n \mid y_{i, t-1} = S) \sim \text{Dirichlet}(\{\alpha_{0,t}, \alpha_{1,t}\, \alpha_{S,t}\}) \text{ for } t\ge 2\]</span></p>
<p>Where n can be 0, 1, or S, denoting the probability of going to the Fail state, the Responder state, or the Stable state at visit <span class="math inline">\(t\)</span> from the Stable state at visit <span class="math inline">\(t-1\)</span>. <span class="math inline">\(t\)</span> must be greater than or equal to <span class="math inline">\(2\)</span>, because we do not impute the first visit – a subject missing visit 1 and all visits after does not contribute to the longitudinal model or dose response model.</p>
<p>The priors for the <span class="math inline">\(\alpha\)</span> parameters are specified in terms of the prior number of transitions from Stable at <span class="math inline">\(t-1\)</span> to each different state at time <span class="math inline">\(t\)</span>. For example, if the prior value for the parameter <span class="math inline">\(\alpha_{1,3}\)</span> is <span class="math inline">\(2\)</span>, we are putting apriori information into the Dirichlet distribution suggesting that <span class="math inline">\(2\)</span> patients transitioned from Stable at visit 2 to Responders at visit 3. Specified priors can either be common or different across model instances based on user specification.</p>
<p>The parameters defining the posterior distribution of the state probabilities are available in closed form as:</p>
<p><span class="math display">\[\alpha_{0,t} = \gamma_{0,t} + \left|y_{it}=0, y_{i, t-1} = S\right|\]</span> <span class="math display">\[\alpha_{S,t} = \gamma_{S,t} + \left|y_{it}=S, y_{i, t-1} = S\right|\]</span> <span class="math display">\[\alpha_{1,t} = \gamma_{1,t} + \left|y_{it}=1, y_{i, t-1} = S\right|\]</span></p>
<p>To create a dichotomous endpoint, the user specifies in the <code>Study &gt; Study Info &gt; Design Options</code> section whether patients remaining in a stable state at the final visit should be dichotomized as responders or failures.</p>
</section>
<section id="dichotomous-endpoint-dichotomized-continuous-longitudinal-model" class="level3" data-number="9.4.5">
<h3 data-number="9.4.5" class="anchored" data-anchor-id="dichotomous-endpoint-dichotomized-continuous-longitudinal-model"><span class="header-section-number">9.4.5</span> Dichotomous Endpoint: Dichotomized Continuous Longitudinal Model</h3>
<p>The user may select (on the Study tab) to assume that the dichotomous final endpoint is generated by observing continuous longitudinal data and then dichotomizing the final endpoint based on whether it is greater than or less than a provided threshold. If the user selects this option, then they may select any of the continuous longitudinal models specified in the <a href="../../../../documentation/v71/userguides/core/longitudinalmodels/continuous.html">Continuous Longitudinal Models section</a>. The engine will impute incomplete subjects according to the continuous model, resulting in a continuous imputed final endpoint. The imputed dichotomous final endpoint is then simply the dichotomized version of the continuous imputation.</p>
<p>All priors and methods are identical to the continuous longitudinal models mentioned above.</p>
</section>
</section>
<section id="time-to-event-predictor-models" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="time-to-event-predictor-models"><span class="header-section-number">9.5</span> Time-to-Event Predictor Models</h2>
<p>For all predictors (<span class="math inline">\(Z\)</span>) for time-to-event endpoints, the engine estimates both a marginal distribution (normal mean and variance for continuous, probability of response for dichotomous, and a piecewise exponential hazard model for time to event predictors) and a working model relating the predictor to the final endpoint. The marginal distribution is used to impute predictors for subjects lacking an observed predictor value and may also be used for stopping (see section on stopping). The working model is used to impute final endpoints for subjects lacking a final endpoint. For subject missing both a predictor and final endpoint, the predictor is imputed first from its marginal distribution, and then the final endpoint is imputed conditionally on the predictor <span class="math inline">\(Z\)</span>.</p>
<section id="continuous-predictor" class="level4" data-number="9.5.0.1">
<h4 data-number="9.5.0.1" class="anchored" data-anchor-id="continuous-predictor"><span class="header-section-number">9.5.0.1</span> Continuous Predictor</h4>
<p>Within each dose (including control and active comparator), the marginal distribution of <span class="math inline">\(Z\)</span> is a normal distribution with mean <span class="math inline">\(\theta_{Zd}\)</span> and standard deviation <span class="math inline">\(\sigma_Z\)</span>. The standard deviation is common across the doses, but the means <span class="math inline">\(\theta_{Zd}\)</span> are allowed to vary across the same range of dose response models as the final endpoint (NDLM, Logistic, etc.). The prior specification for these predictor dose response models is identical in structure to the final endpoint, although the user selects a separate set of parameter values. The dose response for the predictor does not need to match the dose response for the final endpoint.</p>
<p>The working model assumes the final event time T is related to the predictor <span class="math inline">\(Z\)</span> by assuming <span class="math inline">\(T\mid Z \sim \text{Exp}(\lambda_d e^{\beta Z})\)</span>, where <span class="math inline">\(\lambda_d\)</span> varies by dose and has separate priors <span class="math inline">\(\lambda_d \sim \text{Gamma}(\alpha_d, \beta_d)\)</span> for each dose. The coefficient in the exponent <span class="math inline">\(\beta\)</span> (no subscript) is constant across doses with prior <span class="math inline">\(\beta \sim \text{N}(m, s)\)</span>.&nbsp;</p>
</section>
<section id="dichotomous-predictor" class="level4" data-number="9.5.0.2">
<h4 data-number="9.5.0.2" class="anchored" data-anchor-id="dichotomous-predictor"><span class="header-section-number">9.5.0.2</span> Dichotomous Predictor</h4>
<p>A dichotomous predictor is handled similarly to a continuous predictor, with a marginal distribution having a predictor dose response model. However, in this case the predictor dose response relates the log-odds rather than the probability of response itself. The working model for dichotomous is identical to the working model for a continuous predictor, with <span class="math display">\[T\mid Z \sim \text{Exp}(\lambda_d e^{\beta Z})\]</span>. In this situation the working model is simpler to understand, as <span class="math display">\[T\mid (Z=0) \sim \Exp(\lambda_d)\]</span> and <span class="math display">\[T \mid (Z=1) \sim \text{Exp}(\lambda_{d\beta})\]</span>.</p>
</section>
<section id="time-to-event-predictor" class="level4" data-number="9.5.0.3">
<h4 data-number="9.5.0.3" class="anchored" data-anchor-id="time-to-event-predictor"><span class="header-section-number">9.5.0.3</span> Time to Event Predictor</h4>
<p>The time to event predictor is qualitatively different than the continuous or dichotomous predictors. Instead of the predictor adjusting the hazard, the time to event predictor is viewed as an offset. The final endpoint is viewed as a sum of a predictor time <span class="math inline">\(Z_1\)</span> and a post-predictor time <span class="math inline">\(Z_2\)</span>, where <span class="math inline">\(Z_1\)</span> and <span class="math inline">\(Z_2\)</span> are independent random variables and the final endpoint is thus <span class="math inline">\(Z_1 + Z_2\)</span>.</p>
<p>For the working model, <span class="math inline">\(Z_1 \sim \text{PWExp}(\lambda_{1s}*\theta_{1d})\)</span> and <span class="math inline">\(Z_2 \sim \text{Exp}(\lambda_{2d})\)</span>, with priors <span class="math inline">\(\theta_{1s} \sim \text{Gamma}(\alpha_{1s}, \beta_{1s})\)</span>, <span class="math inline">\(\theta_{2d} \sim \text{Gamma}(\alpha_{2d}, \beta_{2d})\)</span> (with <span class="math inline">\(Z_1\)</span>’s control hazard model potentially being piecewise exponential). For imputation, a subject missing both the biomarker and final endpoint times has both <span class="math inline">\(Z_1\)</span> and <span class="math inline">\(Z_2\)</span> imputed, with the final endpoint imputed as the sum. For a subject with a predictor time but no final endpoint, <span class="math inline">\(Z_2\)</span> is imputed and added to the observed predictor time to impute the final endpoint.</p>
</section>
</section>
</section>
<section id="allocation" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Allocation</h1>
<p>The options on allocation tab depend on whether an adaptive or non-adaptive design has been selected on the ‘Study &gt; Study Info’ tab, and if adaptive whether subjects are recruited sequentially or in cohorts.</p>
<p>If the design is non-adaptive then the only allocation option is blocked with fixed allocation ratios.</p>
<p>If the design is adaptive with Continuous or Deterministic recruitment, then there are 4 allocation options.</p>
<ul>
<li><p>Fixed allocation – Subjects are randomized in blocks with fixed allocation ratios that do not change at interim analyses. This allocation strategy can still be useful in an adaptive design when paired with early stopping.</p></li>
<li><p>Arm dropping – which uses fixed allocation combined with the ability to drop under-performing treatment arms at any interim.</p></li>
<li><p>Adaptive Allocation - dose response adaptive allocation. At every interim the randomization probabilities are modified based on the specified adaptive allocation targets.</p></li>
<li><p>Deterministic Allocation – subjects are assigned treatments in an order specified in an external file that is imported into FACTS. This can be used to create a flexible randomization scheme in non-standard simulation scenarios.</p></li>
</ul>
<p>If the design is adaptive with cohort recruitment then there are 3 allocation options, all of which can be combined with early stopping:</p>
<ul>
<li><p>Fixed allocation – subjects are block allocated to treatments. The block distribution can be specified differently for the first cohort and the subsequent cohorts.</p></li>
<li><p>Adaptive Allocation - dose response adaptive allocation, in which at every interim the randomization probabilities are modified based on the provided adaptive allocation targets.</p></li>
<li><p>Adaptive Allocation – “best dose selection” after every interim the randomization for the next cohort is between the control and the dose that best meets the ‘target’ dose criteria.</p></li>
</ul>
<p>The details of specifying each type of adaptive design are described below, in each case specifying the “Interim Frequency” is the same, and this facility is described in subsection: 10</p>
<section id="non-adaptive-designs" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="non-adaptive-designs"><span class="header-section-number">10.1</span> Non-adaptive designs</h2>
<p>If the design is non-adaptive, then on this tab the user simply specifies the fixed allocation ratio to use between all the treatment arms for the duration of the study. The allocation is implemented using a blocking scheme – the block size is the sum of the allocation ratios entered and each arm is given the number of slots in the block corresponding to its allocation ratio. Consequently, the values entered must be integers.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image40.png" style="width:4.26584in;height:2.38513in"></p>
</section>
<section id="fixed-allocation" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="fixed-allocation"><span class="header-section-number">10.2</span> Fixed Allocation</h2>
<p>If allocation is to be fixed, then on this tab the fixed allocation ratios and block size are specified. For each arm in the study allocation ratios are entered as for fixed designs, and allocation uses a block size that is the sum of the ratios. Fixed allocation works identically to the non-adaptive design randomization. The difference is that this Fixed allocation can be performed concurrently with interim analyses being performed.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image41.png" style="width:4.17452in;height:2.8332in"></p>
</section>
<section id="arm-dropping" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="arm-dropping"><span class="header-section-number">10.3</span> Arm Dropping</h2>
<p>Adaptive arm dropping trials allow accruing data to inform the adaptive design that an arm, or a set of arms, can be dropped, meaning they no longer have subjects randomized to them. FACTS Core supports designs in which some number of arms that are clearly ineffective can be dropped. Designs where at an interim one or more arms are selected to be continued and all other arms are dropped can be simulated using FACTS Staged Designs.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image42.png" style="width:6.925in;height:4.92978in"></p>
<section id="randomization-ratio-and-blocking" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="randomization-ratio-and-blocking"><span class="header-section-number">10.3.1</span> Randomization Ratio and Blocking</h3>
<p>In the Randomization Ratio and Blocking section of the Allocation tab the user inputs the components of randomization blocks that enroll from the onset of the study and until any arm is dropped. These blocks work like the Fixed Allocation tab blocks.</p>
<p>Once an arm is dropped the “Upon arm drop:” option in the Setup section of the allocation tab will determine how randomization proceeds.</p>
</section>
<section id="arm-dropping-criteria" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="arm-dropping-criteria"><span class="header-section-number">10.3.2</span> Arm Dropping Criteria</h3>
<p>The user may select any combination of Bayesian “Per Dose” QOIs: Posterior Probabilities or Predictive Probabilities, or a Target Dose QOI. For each criteria selected (at least one must be selected), the user supplies a direction of comparison and probability threshold. If at any interim, any arm meets the specified arm dropping criteria, then that arm becomes a candidate for dropping. After all candidates are identified for dropping, the Setup rules determine which, if any, of the candidates will be dropped.</p>
</section>
<section id="setup" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="setup"><span class="header-section-number">10.3.3</span> Setup</h3>
<p>A variety of rules are specified in the Setup section of the Allocation tab.</p>
<section id="max-number-of-arms-that-can-be-dropped-during-the-study" class="level4" data-number="10.3.3.1">
<h4 data-number="10.3.3.1" class="anchored" data-anchor-id="max-number-of-arms-that-can-be-dropped-during-the-study"><span class="header-section-number">10.3.3.1</span> Max number of arms that can be dropped during the study</h4>
<p>The maximum number of arms that can be dropped – this can be set to from 0 to the number of active arms, the Control and Active Comparator are never dropped. This figure is the ‘maximum number of arms that can be dropped over the duration of the trial’. At any interim any number between 0 and the ’maximum number of arms can be dropped as long as this limit is not exceeded on the overall number of arms that would have been dropped.</p>
<p>If the maximum number of arms that can be dropped is set to the number of study drug arms, then if all arms are dropped this is recorded as an “early termination for futility”.</p>
</section>
<section id="prune-from-lowesthighest-dose" class="level4" data-number="10.3.3.2">
<h4 data-number="10.3.3.2" class="anchored" data-anchor-id="prune-from-lowesthighest-dose"><span class="header-section-number">10.3.3.2</span> Prune from lowest/highest dose</h4>
<p>Arm dropping can be restricted to ‘pruning from the lowest dose’ and/or ‘pruning from the highest dose’. If ‘prune from the lowest dose’ is selected, then until the lowest dose meets the arm dropping criteria the second lowest dose cannot be dropped and so on. At an interim when the lowest dose <strong>does</strong> meet the arm dropping criteria, and the second dose does too, then the second dose can be dropped as well (and third and fourth …), it does not have to wait until the next interim. Pruning from the highest dose does the same thing, except that no dose can be dropped unless every larger dose will also be dropped.</p>
<p>If no pruning is selected or pruning from both ends is selected, then the user must select to prioritize the higher or lower dose to cover the instance when more doses are candidates for dropping than are allowed to drop by the maximum threshold. If “Prioritize dropping the lowest dose” is selected then when forced to choose between two or more doses to drop, the one with the lowest effective dose strength will be dropped.</p>
</section>
<section id="upon-arm-drop" class="level4" data-number="10.3.3.3">
<h4 data-number="10.3.3.3" class="anchored" data-anchor-id="upon-arm-drop"><span class="header-section-number">10.3.3.3</span> Upon arm drop</h4>
<p>Finally, specify what is to be done with the unused subjects that would have been allocated to an arm that has now been dropped. There are three options:</p>
<dl>
<dt>Maintain study size, maintain combined block size of treatments</dt>
<dd>
Subjects that would have been allocated to arms that have been dropped are now randomized between all the remaining active treatment arms (excluding control and active comparator) using their original allocation ratios. For example, if the allocation ratio was 2:1:1:1 between Control and D1, D2 and D3, then after dropping D1 the block size remains size 5 (2 to Control and 1 to each of D2 and D3) with the <span class="math inline">\(5^{th}\)</span> slot being allocated 1:1 between the remaining two study arms D2 &amp; D3. Thus, the overall proportion of subjects on Control (and Active Comparator) is maintained.
</dd>
<dt>Maintain study size, reduce combined block size of treatments</dt>
<dd>
Subjects that would have been allocated to any arms that have been dropped are randomized between all remaining arms (including control) using a reduced total block size. Thus, if the allocation ratio was 2:1:1 between Control and D1 and D2, then after dropping D1 the block size drops to total size three: 2 to Control and 1 to D2.
</dd>
<dt>Decrease the study size, reduce combined block size of treatments</dt>
<dd>
Subjects that would have been allocated to any arms that have been dropped are no longer recruited, and the total sample size of the study is reduced; the remaining subjects are recruited using a reduced block. If interims are specified by number of subjects recruited, these interim sizes are reduced proportionally. As an example of this, if an arm that gets 20% of the randomization is dropped when there are 100 subjects enrolled, then if the next interim is scheduled at 200 subjects enrolled, it will actually be performed at 180 subjects enrolled.
</dd>
</dl>
</section>
</section>
</section>
<section id="adaptive-allocation" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="adaptive-allocation"><span class="header-section-number">10.4</span> Adaptive Allocation</h2>
<p>In adaptive allocation, the relative probabilities of assigning each of the doses to a subject may change throughout the trial. The adaptive allocation method that FACTS supports is one in which the allocation ratio is modified at each interim to increase the allocation to doses that have the preferred characteristics.</p>
<p>An adaptive allocation design has two phases: the “burn-in” before any adaptation takes place and the “adaptive phase”. The burn-in lasts until the first interim occurs, which is defined on the <a href="../../../../documentation/v71/userguides/core/design/interims.html">Interims</a> tab. The adaptive phase lasts until the early stopping criteria are met or the maximum sample size is reached.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image43.png" style="width:5.68039in;height:4.04189in"></p>
<p>The table on the left hand side of the Adaptive Allocation tab allows for the specification of the allocation ratio during the burn-in period in the “Pre First Interim Allocation Ratio” column. The randomization during the burn-in period works exactly like Fixed Allocation with the provided randomization block.</p>
<p>When the first interim analysis is reached the allocation strategy changes from fixed to adaptive, and the “Pre First Interim Allocation Ratio” column is ignored. When randomizing adaptively the total block size is specified below the table in the “Post first interim block size:” entry. The “Fix Alloc.” column check boxes should be checked for any dose that should not be adaptively randomized to, but should get <a href="##" title="This is commonly done for the control arm and the active comparator in a trial that is randomizing adaptively.">a fixed proportion of the randomization block</a>. When an arm is checked for having a fixed allocation its block contribution within the total block size must be specified. The sum of the fixed allocations must be smaller than the “Post first interim block size.”</p>
<p>The slots that are in the block, but are not allocated to a fixed treatment are probabilistically assigned to one of the non-fixed treatments.</p>
<p>If the Control arm is not given a fixed allocation, it is allocated to with an adaptive probability that is equal to the treatment arm with the highest weight.</p>
<section id="adaptive-allocation-targets" class="level4" data-number="10.4.0.1">
<h4 data-number="10.4.0.1" class="anchored" data-anchor-id="adaptive-allocation-targets"><span class="header-section-number">10.4.0.1</span> Adaptive Allocation Targets</h4>
<p>Adaptive allocation probabilities can be driven by any combination of posterior probabilities, predictive probabilities, conditional powers, and target probability QOIs. The allocation ratio of each arm is a proportional to a function of the QOIs - simply, arms with higher QOIs have higher allocation probabilities.</p>
<p>The way that the allocation probabilities are calculated is as follows.</p>
<p>Suppose that <span class="math inline">\(M\)</span> QOIs are specified in the “Adaptive Allocation Targets” table. Call them <span class="math inline">\(W^{(1)}, \ldots, W^{(M)}\)</span>, and to index the <span class="math inline">\(m^{th}\)</span> QOI’s value for dose <span class="math inline">\(d\)</span> we use the notation <span class="math inline">\(W_d^{(m)}\)</span>. Then, the first step in calculating the allocation weights is to convert the QOIs <span class="math inline">\(W\)</span> to the allocation targets <span class="math inline">\(V\)</span>.</p>
<p>Any adaptive allocation QOI <span class="math inline">\(W_d^{(m)}\)</span> that has “Weight For:” of Probability has an allocation target of <span class="math display">\[V_d^{(m)} = \left(W_d^{(m)}\right)^\gamma,\]</span> and if it has “Weight For:” of Information it has an allocation target of <span class="math display">\[V_d^{(m)} = \left[ \sqrt{\frac{W_d^{(m)} \text{Var} \left( \theta_{d} \right)}{n_{d} + 1}} \right]^{\gamma}\]</span> where <a href="##" title="Note that it's not the 'Relative Weight' provided when the Adaptive Allocation Target is specified."><span class="math inline">\(\gamma\)</span> is the value provided in “Raise allocation to power (<span class="math inline">\(\gamma\)</span>)” in FACTS</a>, <span class="math inline">\(n_d\)</span> is the number of subjects on enrolled on dose <span class="math inline">\(d\)</span>, and <span class="math inline">\(\text{Var}(\theta_d)\)</span> is the variance of the dose-response model mean estimate for arm <span class="math inline">\(d\)</span>.</p>
<p>Then, when each dose has an allocation target <span class="math inline">\(V_d\)</span> for each of the <span class="math inline">\(M\)</span> QOIs, the allocation weights are combined in a linear combination to get the allocation weight. With <span class="math inline">\(M\)</span> allocation targets and Relative Weights <span class="math inline">\(\omega_m\)</span> provided when the allocation QOIs were specified: <span class="math display">\[\Omega_d = \sum_{m=1}^M (\omega_m V_{d}^{(m)})\]</span></p>
<p>Once each dose has an allocation weight <span class="math inline">\(\Omega_d\)</span>, the set of <span class="math inline">\(\Omega\)</span>’s is renormalized so that they add to they add to the proportion of slots in the block that will be allocated to adaptively. These renormalized values are the adaptive randomization probabilities. If, after renormalization, any of the doses have a randomization probability less than the value entered in “Allocation probability set to zero for values less than:”, then the dose with the lowest randomization probability is set to 0 and the other randomization probabilities are renormalized again to sum to the proportion of slots in the block that will be allocated to adaptively. This process iterates until all doses have randomization probabilities above the threshold or only one non-fixed dose is being randomized to.</p>
</section>
<section id="tips-tricks-and-intuition" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="tips-tricks-and-intuition"><span class="header-section-number">10.4.1</span> Tips, Tricks, and Intuition</h3>
<section id="weighting-for-probability-vs-information" class="level4" data-number="10.4.1.1">
<h4 data-number="10.4.1.1" class="anchored" data-anchor-id="weighting-for-probability-vs-information"><span class="header-section-number">10.4.1.1</span> Weighting for Probability vs Information</h4>
<p>When weighting for probability, the allocation target is derived simply from the value of the QOI. Weighting for probability is ‘more aggressive’ in adapting in pursuit of the target. The risk with a probability-based weighting is never allocating again to an arm where the initial data is so poor that its initial probability of being the target is so low it is never allocated to again. So, it is appropriate when the available sample size is small (and risks must be taken), the number of study arms is small (so it is unlikely an arm will not be allocated to again), or the allocation during the burn-in is large and evenly distributed (so that having unrepresentative data is very unlikely).</p>
<p>When weighting for information, the allocation target uses the value of the QOI, but is adjusted by the current variance of the dose response estimate and the number of subjects already allocated to the dose – an estimate of the additional information that would result from adding one more subject to that arm. Weighing for information will tend to spread the allocation around the most likely target, reducing the risk of never learning that dose is better than its initial data. If a dose response model is being used, allocation to doses around the target dose will contribute to the accuracy of the estimate of response on the target dose, but compared to the probability weighting will tend to result in fewer subjects allocated to the actual target dose.</p>
<p>Whichever weighing rule is selected the adaptation can be further ‘sharpened’ or ‘softened’ by adjusting the power to which the allocation probability is raised. Setting the power to 0.5 will significantly soften the allocation, setting it to 2 will significantly sharpen it.</p>
</section>
<section id="fixed-allocation-target" class="level4" data-number="10.4.1.2">
<h4 data-number="10.4.1.2" class="anchored" data-anchor-id="fixed-allocation-target"><span class="header-section-number">10.4.1.2</span> Fixed Allocation Target</h4>
<p>Any Bayesian “Per Dose” QOI, or “Target Dose” QOI can be used to determine the adaptive allocation weights. In addition there is the option to use a static weighting – this is of course not adaptive! What it does do is allow an adaptive allocation to be combined with a “guaranteed minimum allocation” (see example discussion below). If a Static target is included, a small table is displayed the specification of the ratio of the division of the static weight between the study arms that are being adaptively allocated to.</p>
</section>
<section id="non-fixed-control-adaptive-allocation" class="level4" data-number="10.4.1.3">
<h4 data-number="10.4.1.3" class="anchored" data-anchor-id="non-fixed-control-adaptive-allocation"><span class="header-section-number">10.4.1.3</span> Non-fixed Control Adaptive Allocation</h4>
<p>If the control allocation ratio is not fixed when performing adaptive allocation, then the control arm gets a randomization ratio that targets matching the number of control subjects to the active arm with the most subjects.</p>
<p>To derive the control allocation rate, let <span class="math inline">\(V_d\)</span> for <span class="math inline">\(d=1, 2, \ldots, D\)</span> be the allocation probabilities for each of the <span class="math inline">\(D\)</span> non-control dose arms (these may be obtained by calculating based on the probability or information criteria as described above or the fixed allocation proportion with respect to the block size), and let <span class="math inline">\(n_d\)</span> for <span class="math inline">\(d=1, 2, \ldots, D\)</span> be the number of subjects allocated to those arms.</p>
<p>Then, the allocation target for the control arm <span class="math inline">\(V_0\)</span> is:</p>
<p><span class="math display">\[V_{0} = \min\left\{\sum_{d = 1}^{D}{V_{d}\frac{(n_{d} + 1)}{(n_{0} + 1)}}, \;\; \text{max} \{V_{1},V_{2},\ldots,\\V_{D}\} \right\}\]</span></p>
<p>Following fixing this control rate, the allocation probabilities for the non-fixed doses are renormalized to add up to the total non-fixed probability.</p>
</section>
<section id="zero-out-allocation-probabilities" class="level4" data-number="10.4.1.4">
<h4 data-number="10.4.1.4" class="anchored" data-anchor-id="zero-out-allocation-probabilities"><span class="header-section-number">10.4.1.4</span> Zero Out Allocation Probabilities</h4>
<p>If, at the end of the adaptive allocation probability calculation, any adaptively allocated arms have a randomization probability smaller than the value provided for “Allocation probability set to zero for values less than:”, then the allocation probabilities are adjusted.</p>
<p>To adjust the probabilities, first the arm with the smallest randomization probability is given a fixed allocation rate of 0. Then, the remaining adaptively allocated arms have their allocation probabilities re-normalized to sum to the probability remaining after all fixed doses have been allocated. Then, if any doses remain below the zero-out threshold, then this process is repeated. Continue the repetition as necessary. If none of the allocation probabilities are below the threshold, then the allocation probabilities are set.</p>
<p>If all non-fixed doses drop due to being below the threshold, then the probability is reallocated to the fixed doses. This can only happen if the fixed doses take up a large enough proportion of the slots in the block.</p>
</section>
</section>
<section id="adaptive-allocation-calculation-examples" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="adaptive-allocation-calculation-examples"><span class="header-section-number">10.4.2</span> Adaptive Allocation Calculation Examples</h3>
<section id="simple-response-adaptive-randomization-example" class="level4" data-number="10.4.2.1">
<h4 data-number="10.4.2.1" class="anchored" data-anchor-id="simple-response-adaptive-randomization-example"><span class="header-section-number">10.4.2.1</span> Simple Response Adaptive Randomization Example</h4>
<p>Suppose you have a control and 3 active doses. The control arm is fixed to randomize <span class="math inline">\(3/10\)</span> slots in every block and a fixed 20% probability must be placed on the first active dose (dose A). So, the control arm gets 30% of the total allocation probability and dose A gets 20% of the total allocation. Suppose the target QOIs <span class="math inline">\(V_d\)</span>&nbsp;for the three active doses are 0.20, 0.20, and 0.60 and that we’re using probability weighting with weight 1 for all of them. The second two doses are the only doses with unknown randomization probabilities, so they split the amount of non-fixed allocation probability proportionally based on their <span class="math inline">\(V_d\)</span>.</p>
<p>The allocation probability of the second active dose is <span class="math display">\[\left( 1 - (0.3 + 0.2) \right)*\left( \frac{0.2}{0.2 + 0.6} \right)\]</span> and the allocation probability of the third active dose is <span class="math display">\[\left( 1 - (0.3 + 0.2) \right)*\left( \frac{0.6}{0.2 + 0.6} \right)\]</span></p>
<p>Thus, the final allocation probabilities for the control and the three active doses are: (0.3, 0.2, 0.125, 0.375).</p>
<p>If any of the adaptively allocated probabilities are less than a user specified minimum (“Allocation probability set to zero for values less than….” in the GUI) then these probabilities would be set to zero and the resulting probability is reallocated among the non-fixed probability doses. If all non-fixed doses drop at this point, then the probability is reallocated to the fixed doses.</p>
</section>
<section id="using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" class="level4" data-number="10.4.2.2">
<h4 data-number="10.4.2.2" class="anchored" data-anchor-id="using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms"><span class="header-section-number">10.4.2.2</span> Using Static Weighting Example: Ensuring a minimum allocation to all arms</h4>
<p>This example uses the static allocation QOI to allow adaptive randomization, but with a guaranteed minimum allocation of 10% to each of 5 study arms. Let us say that we want the adaptive allocation to be evenly divided between targeting an EDq and MED target.</p>
<p>As there are 5 study arms, allocating 10% each amounts to 50% of the total. Thus, we could specify weights of 1 to the MED target, 1 to the EDq target, and 2 to the Static target, so the Static target gets 50% of the total weighting.</p>
<p>However, this ignores the possible allocation to a Control arm. What we have achieved above either allocates 10% to each study arm if there is no Control arm, or if there is a Control arm, allocates 10% of the subjects <em>allocated to the study arms</em>, not 10% of the overall.</p>
<p>Let us say that in addition to the 5 study arms you have a Control that we want to have 20% allocation and we want each study arm to have at least 10% of the overall allocation. The simplest way to specify this is to set a “Post first interim block size” of 10 and that 2 slots are allocated to Control. This leave 8 slots to be allocated across the treatment arms. We don’t want to allocate 1 out of 10 slots in the block to each using fixed allocation, because that 10% is all they would get. We need to allow them to be allocated to adaptively and use the Static target to ensure they get a minimum of 10%. We can achieve this by giving the static allocation a weight of 5 and divide a weight of 3 between the MED and EDq targets, so they get a weight of 1.5 each. Then, set all of the “Static Weights” to be 1 (any non-zero value would work) for each active arm.</p>
<p>By doing this, the static allocation targets make up <span class="math inline">\(5\text{ arms }*\text{ weight of }5 = 25\)</span> parts of the weighted average and the MED and EDq combine to make up <span class="math inline">\(5\text{ arms }*\text{ weight of }3 = 15\)</span> parts. So, if an arm has an MED of 0 and EDq of 0 it is still guaranteed to get at least <span class="math inline">\(\frac{5}{(25 + 15)}*(1 - 0.2) = 0.1\)</span> of the total randomization.</p>
</section>
<section id="using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" class="level4" data-number="10.4.2.3">
<h4 data-number="10.4.2.3" class="anchored" data-anchor-id="using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose"><span class="header-section-number">10.4.2.3</span> Using Static Weighting Example: Ensuring a minimum allocation to top dose</h4>
<p>Imagine an early Phase II Proof-of-Concept study that wants to compare 3 doses of the study drug (low, medium and high) to Control, and adaptively allocates to the dose with the maximum response. The study team also wish to ensure a minimum allocation to the top dose as they have a strong prior that it will have the maximum effect. They want to minimize the risk that the adaptive allocation avoids the top dose because of randomly poor results on that dose early on in the trial.</p>
<p>The optimal allocation to control in a multi armed study is approximately <span class="math inline">\(\sqrt{N}:1:1:\ldots\)</span> where N is the number of study arms and in <span class="math inline">\(\sqrt{3}:1:1:1\)</span> the proportion on control would be 37%. Here we’ve rounded down to 30% rather than up to 40% to reflect a typical clinical teams desire to get more data on their study drug than Control.</p>
<p>After the first interim, we specify allocation to be in blocks of 10 with the Control allocated to 3 slots in each block, the “Relative Weight:” on the Static target is 2 and the “Relative Weight:” on the Pr(Max) target is 5. So 50% of the allocation is adaptive targeting the dose with the Maximum response and 20% is fixed and allocated to the top dose by specifying that the static weighting “Ratio” is split 0:0:1 in the “Static Weights” table.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image44.png" style="width:3.97826in;height:2.53209in"></p>
</section>
</section>
</section>
<section id="deterministic-allocation" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="deterministic-allocation"><span class="header-section-number">10.5</span> Deterministic Allocation</h2>
<p>The deterministic allocation option allows for the treatment assignments of subjects accrued into the simulated trials to be assigned without randomness based on an uploaded file. The file providing the assignments should be a comma separated .dat file with 2 columns, but no column labels.</p>
<p>The first column should be an increasing, unique column of numbers from 1 to at least the maximum number of subjects that can be enrolled in the study. The second column should be the set of treatment assignments in order from 1 to the number of patient IDs. The treatment assignments are used in row order – they do not use the subject ID order. So, the first subject accrued in the study is given the assignment indicated by the first row, second column value, the second subject accrued in the study is given the assignment indicated by the second row, second column value, and so on.</p>
<p>The treatment assignments column in the .dat file should always have a minimum value of 1 and a maximum of the number of total arms in the study. If there is a control arm in the study, then treatment assignment 1 corresponds to a control arm randomization. If there is no control arm in the study, then treatment assignment 1 in the .dat file corresponds to a subject randomized to the lowest active dose.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image46.png" style="width:5.0296in;height:3.70171in"></p>
</section>
<section id="cohort-recruitment-fixed-allocation" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="cohort-recruitment-fixed-allocation"><span class="header-section-number">10.6</span> Cohort recruitment – fixed allocation</h2>
<p>If allocation is to be fixed the “Early Stopping Only” option should be selected. Then on this tab the fixed allocation ratios and block size are specified – for the first cohort and then for all subsequent cohorts. In each case the user specifies the number of each arm to allocate in each cohort and the sum must equal the size of the cohort.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image47.png" style="width:5.52636in;height:3.93229in"></p>
</section>
<section id="cohort-recruitment-adaptive-allocation" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="cohort-recruitment-adaptive-allocation"><span class="header-section-number">10.7</span> Cohort recruitment – adaptive allocation</h2>
<p>If allocation is to be adaptive the “Adaptive Allocation” option should be selected and then under “Subsequent Cohort Allocation” the “Allocate cohort by sampling from allocation vector” should be selected. Then on this tab</p>
<ul>
<li><p>The fixed allocation ratios and block size are specified for the first cohort. The user specifies the number of each arm to allocate and the sum must equal the size of the cohort.</p></li>
<li><p>The user then specifies</p>
<ul>
<li><p>The fixed allocation to control</p></li>
<li><p>The QOIs to be used to calculate the allocation ratios for the remaining subjects in the cohort as for adaptive allocation (see Adaptive Allocation above).</p></li>
</ul></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image48.png" style="width:5.61615in;height:3.99618in"></p>
</section>
<section id="cohort-recruitment-allocate-to-best-dose" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="cohort-recruitment-allocate-to-best-dose"><span class="header-section-number">10.8</span> Cohort recruitment – allocate to best dose</h2>
<p>If allocation is to be adaptive, but at each cohort just Control and the “best dose” are to be allocated to, the “Adaptive Allocation” option should be selected and then under “Subsequent Cohort Allocation” the “Allocate cohort to single treatment (plus control)” should be selected. Then on this tab</p>
<ul>
<li><p>The fixed allocation ratios and block size are specified for the first cohort. The user specifies the number of each arm to allocate and the sum must equal the size of the cohort.</p></li>
<li><p>The user then specifies</p>
<ul>
<li><p>The fixed allocation to control</p></li>
<li><p>The QOIs to be used to calculate the allocation weighting to calculate for the non-Control arms, (see Adaptive Allocation above) and all the subjects not allocated to control will be allocated to this arm.</p></li>
</ul></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image49.png" style="width:5.5182in;height:3.92648in"></p>
</section>
</section>
<section id="interims" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Interims</h1>
<p>Interim analyses allow for decision making throughout the lifecycle of an adaptive trial in FACTS. Interim analyses can adjust allocation probabilities, drop arms, or allow for early success/futility of the trial. Interims can either be specified with calendar frequency – occurring every specified number of weeks or specified to occur after a specified amount of information has been collected.</p>
<section id="interim-analysis-triggers" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="interim-analysis-triggers"><span class="header-section-number">11.1</span> Interim Analysis Triggers</h2>
<section id="continuous-and-dichotomous-endpoint" class="level3" data-number="11.1.1">
<h3 data-number="11.1.1" class="anchored" data-anchor-id="continuous-and-dichotomous-endpoint"><span class="header-section-number">11.1.1</span> Continuous and Dichotomous Endpoint</h3>
<p>Information can be defined in terms of:</p>
<ul>
<li><p>number of subjects that have been recruited</p></li>
<li><p>the number of subjects who have actually completed a specified visit</p></li>
<li><p>the number of subjects who have had the opportunity to complete a specified visit (includes drop-outs)</p></li>
</ul>
<p>When specifying an interim analysis schedule, it can be done either based on time or based on one of the information categories above.</p>
<p>If specifying interims based on time the first interim analysis timing must be based on information, and each subsequent interim is triggered after the provided amount of time has elapsed. If accrual completes before the first interim threshold is reached, and the first interim was defined in terms of the number of subjects enrolled, then the interims by time start at full accrual. If the first interim is defined in any other terms (by events, subjects complete or subjects with opportunity to complete) then interims only start when this is reached (which might be never).</p>
<p>If specifying interims based solely on information, the table on the “Interims” tab determines when the analyses will be triggered. Each interim is defined individually by the number of patients/observations that have satisfied some criteria. If information is If information is defined as Subjects Enrolled, then interim are triggered immediately upon enrollment of the subject satisfying the criteria. If information is defined as completers or opportunity to complete, then interims are triggered immediately upon the visit being reached that satisfies the specified criteria. Successive interims must be in terms of the same or more observations at the same or later visit, and either Visit or Subject must increase. Different types of information cannot be mixed to trigger interim analyses except in using time to trigger interims after the first based on information.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image50.png" style="width:2.94314in;height:2.8326in" alt="Graphical user interface Description automatically generated"> <img src="coreUGattachments/CoreUserGuide/media/image51.png" style="width:2.99611in;height:2.86372in" alt="Graphical user interface Description automatically generated"></p>
<p>If interims are governed by time, there is the option as to whether interims should continue after full accrual, or discontinue.</p>
</section>
<section id="time-to-event-endpoint" class="level3" data-number="11.1.2">
<h3 data-number="11.1.2" class="anchored" data-anchor-id="time-to-event-endpoint"><span class="header-section-number">11.1.2</span> Time-to-Event Endpoint</h3>
<p>Information can be defined in terms of:</p>
<ul>
<li><p>number of subjects that have been recruited</p></li>
<li><p>the number of subjects who have observed their predictor endpoint</p></li>
<li><p>the number of subjects who have had the opportunity to observe their predictor endpoint (includes drop-outs)</p></li>
<li><p>specified numbers of events observed</p></li>
<li><p>specified number of predictor events observed</p></li>
</ul>
<p>Outside of the new types of information, the time-to-event triggers work in exactly the same way that continuous and dichotomous triggers do.</p>
</section>
</section>
<section id="subject-follow-up-options" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="subject-follow-up-options"><span class="header-section-number">11.2</span> Subject Follow-up Options</h2>
<p>Regardless of endpoint, the Interims tab contains options that control the behaviour should a trial stop at an interim analysis. The options allows the user to specify whether or not to complete the follow-up of subjects who have been accrued, but have not had time to observe their final endpoint.</p>
<p>The default options available for Subject Follow-Up are:</p>
<ul>
<li><p>Continue follow-up if study stopped for early success</p></li>
<li><p>Continue follow-up if study stopped for early futility</p></li>
</ul>
<p>If the check box corresponding to an interim decision is checked, then at the time of an interim analysis decision - accrual will be stopped, all subjects currently enrolled will be followed-up until they have had the opportunity to observe their final endpoint, and then the final analysis will be performed.</p>
<p>If the check box corresponding to an interim decision is not checked, then at the time of an interim analysis decision - accrual is stopped, the data is locked, and no follow-up on randomized patients is collected. The interim dataset is the final dataset. <a href="##" title="This can result in success to futility flip-flops or futility to success flip-flops, even if there is no additional follow-up, since the final analysis criteria can be specified to be less strict than the interim analysis threshold. If you do not follow up after a success, then a success to futility flip-flop can be considered simply an early success.">The final analysis is then performed using the same data and model as was used for the interim analysis.</a></p>
<p><img src="coreUGattachments/CoreUserGuide/media/image52.png" style="width:2.96325in;height:0.70635in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>If the allocation method is selected as, “Arm Dropping,” then an additional check box is provided in the Subject Follow-up Options box asking whether the user would like to “Continue follow-up if arm dropped.” If the box is checked, then subjects randomized to an arm that is dropped before they have the opportunity to complete their follow-up will have to opportunity to observe their final endpoint for subsequent analyses. If the box is not checked then incomplete subjects on an arm that is dropped will never have future endpoint values observed.</p>
</section>
</section>
<section id="successfutility-criteria" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Success/Futility Criteria</h1>
<p>The Success/Futility Criteria tab is where users specify the decision rules for determining study success or failure. The Final Analysis criteria always exist, and should, in general, be specified for every simulated trial. If simulating an adaptive trial, then interim analysis decision rules are also specified here.</p>
<p>There are <span class="math inline">\(7\)</span> possible decisions that can be made in a FACTS Core design, each with a numeric identifier that FACTS uses in the .csv output to denote decisions:</p>
<ol type="1">
<li><dl>
<dt>Early Success</dt>
<dd>
Early success is achieved if and only if the trial meets the success condition at an interim analysis, and does not meet the futility criteria at the final analysis. The final analysis criteria must not be met whether or not subjects were selected to follow-up after an early success decision.
</dd>
</dl></li>
<li><dl>
<dt>Late Success</dt>
<dd>
Late success is achieved if and only if the trial enrolls to the maximum sample size, collects full follow-up, and then meets the final analysis success criteria.
</dd>
</dl></li>
<li><dl>
<dt>Late Futility</dt>
<dd>
Late success is achieved if and only if the trial enrolls to the maximum sample size, collects full follow-up, and then meets the final analysis futility criteria. Late futility is not automatically the complement of late success; the futility rule must be specified as the complement of the success rule to make it true.
</dd>
</dl></li>
<li><dl>
<dt>Early Futility</dt>
<dd>
Early futility is achieved if and only if the trial meets the futility condition at an interim analysis, and does not meet the success criteria at the final analysis. The final analysis criteria must not be met whether or not subjects were selected to follow-up after an early success decision.
</dd>
</dl></li>
<li><dl>
<dt>Success to futility flip-flop</dt>
<dd>
Success to futility flip-flop is achieved if and only if the trial meets the success condition at an interim analysis, but meets the futility condition at the final analysis. Success to futility flip-flops can be achieved whether or not subjects are followed up after the early success decision.
</dd>
</dl></li>
<li><dl>
<dt>Futility to success flip-flop</dt>
<dd>
Futility to success flip-flop is achieved if and only if the trial meets the futility condition at an interim analysis, but meets the success condition at the final analysis. Futility to success flip-flops can be achieved whether or not subjects are followed up after the early futility decision.
</dd>
</dl></li>
<li><dl>
<dt>Inconclusive</dt>
<dd>
Inconclusive is achieved if and only if the trial enrolls to the maximum sample size, collects full follow-up, and then does not meet the final success or final futility criteria.
</dd>
</dl></li>
</ol>
<p>Every simulated trial will result in exactly one of these decisions. Non-adaptive trials will result in either Late Success, Late Futility, or Inconclusive. An adaptive trial that does not stop at an interim analysis will result in Late Success, Late Futility, or Inconclusive. An adaptive trial that stops enrolling for early success at an interim analysis will end up as an Early Success or a Success to Futility flip-flop. An adaptive trial that stops enrolling for early futility will result in Early Futility or Futility to Success flip-flop.</p>
<section id="final-evaluation" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="final-evaluation"><span class="header-section-number">12.1</span> Final Evaluation</h2>
<p>On the Final Evaluation tab, the user can specify rules for judging the study for final futility or final success at its end.</p>
<p>The left column of the Final Evaluation tab contains the specification of the trial final futility rule, and the right column contains the specification of the final success rule.</p>
<p>To add a decision rule, click the “Add…” button within the appropriate column, select a decision quantity QOI, a comparison inequality sign, and a threshold. Final success and final futility criteria can each have multiple components to them, and the selection at the bottom of the column called “Combine criteria using:” dictates if success or futility should be declared if every single criteria is met (AND) or if any criteria is met (OR).</p>
<p>The success and futility rules need not be complementary - there can be trials that do not meet either criteria at the final analysis. These trials would be considered inconclusive. It is allowable, although generally not recommended, to specify overlapping success and futility rules. If a trial were to satisfy both the success and futility criteria at the final analysis it would be considered a final futility.</p>
<p>The Final Evaluation Criteria are always applied at the time of the final analysis, even if the study stops early for success or futility, and whether or not “Continue follow-up if study stopped for success” or “Continue follow-up if study stopped for futility” are selected. As a result, setting final analysis criteria that are easier to satisfy than interim analysis criteria may result in the labelling of trials that meet the interim analysis criteria but do not satisfy the final analysis criteria as flip-flops.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image54.png" style="width:5.48603in;height:4.10627in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
<section id="interim-analysis-criteria" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="interim-analysis-criteria"><span class="header-section-number">12.2</span> Interim Analysis Criteria</h2>
<p>On the success/futility criteria of a design with “Enable adaptive features” checked on the Study &gt; Study Info page, the user can specify rules for judging the study for futility or success at an interim and at the final evaluation. If the trial has no interims there will be just a tab for the Final Evaluation criteria. If the trial has interim analyses, then there can be tabs that define different early success/futility criteria at the different interims.</p>
<p>At the top of the main tab is a control to allow tabs to be created for different interims. In a newly created adaptive design, FACTS will create a tab for interim 1.</p>
<p>If early success/futility criteria are specified for an interim, then they will be taken to apply to all subsequent interims until the next one for which criteria are supplied, then those criteria will apply until the next interim for which criteria are applied and so on. There will be no stopping for success or futility until the first interim for which early stopping criteria have been defined.</p>
<p>It is possible to specify overlapping early success and early futility criteria at an interim, but it is not possible to stop for both success and futility at the same time. The FACTS design engines will stop the trial but the user should not rely on one or other outcome taking precedence. It is not considered good practice to have success and futility rules that could both be true, so FACTS does not <a href="##" title="As of FACTS 7.1 early futility will be the result if both early success and early futility criteria are met.">guarantee a “tie break” rule</a>.</p>
<p>In the output files there are columns labeled “Success <qoi>” and “Futile <qoi>” indicating whether any decision criteria became true, and “Success Combined” and “Futile Combined” indicating if all the criteria for a success or futility determination have been met. If both sets of criteria are met simultaneously, FACTS will only flag one of “Success Combined” and “Futile Combined” as being met, corresponding to how the outcome of the trial has been flagged.</qoi></qoi></p>
<p><img src="coreUGattachments/CoreUserGuide/media/image53.png" style="width:5.52058in;height:4.13213in" alt="A screenshot of a social media post Description automatically generated"></p>
<p>Having created a tab to define the early success/futility criteria at an interim, the user has options to delete the tab or to copy criteria that have already been entered on another tab before editing them.</p>
<p>The user specifies:</p>
<ul>
<li><p>Whether early stopping for futility or success is to be allowed by selecting the “Futility criteria” or “Success criteria”</p></li>
<li><p>The stopping rules are specified, by selecting the QOI to be tested, the direction of the comparison and the threshold value for the criteria to be met, as in the Final Evaluation tab above.</p></li>
<li><p>The user can specify whether, if multiple criteria have been specified, they all need to be meet (Criteria combined using “AND”) or only any one of them needs to be met (Criteria combined using “OR”). These are specified independently for stopping for success and for futility.</p></li>
<li><p>If stopping is allowed, the user specifies what the minimum amount of information (using the information type specified on the Interims tab). This can be specified both in overall terms and information on specific doses. If multiple minimum-information criteria are specified they must all be met for the QOI criteria to be evaluated.</p></li>
</ul>


</section>
</section>

</main> <!-- /main -->
<!-- footer.html -->

<footer>

  <p>© 2024 <a href="https://www.berryconsultants.com">Berry Consultants</a></p>

  <!-- <p>Made with <span style="color: #11A473;">❤</span> and <a href="https://quarto.org">Quarto</a></p> -->

</footer>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>