<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>FACTS Core User Guide</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">

<!-- Roboto Serif -->
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:wght@400;700&amp;display=swap" rel="stylesheet">

<!-- Roboto Sans -->
<link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&amp;display=swap" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../../media/FACTS_logo.jpg" alt="" class="navbar-logo">
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../introduction/index.html"> 
<span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../../documentation/index.html" aria-current="page"> 
<span class="menu-text">Documentation</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../concepts/index.html"> 
<span class="menu-text">Concepts</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../notes/index.html"> 
<span class="menu-text">Field Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../releaseNotes/index.html"> 
<span class="menu-text">Release Notes</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../get.html"> 
<span class="menu-text">Get FACTS</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../contact.html"> 
<span class="menu-text">Contact</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Version 7.1</li><li class="breadcrumb-item"><a href="../../../documentation/v71/userguides/core.html">User Guides</a></li><li class="breadcrumb-item"><a href="../../../documentation/v71/userguides/core.html">FACTS Core User Guide</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Documentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/glossary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Glossary</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Version 7.1</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">User Guides</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth2 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/userguides/core.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">FACTS Core User Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/userguides/crm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FACTS Dose Escalation CRM</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/userguides/installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">FACTS Installation Guide</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false">
 <span class="menu-text">Examples</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth2 ">  
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false">
 <span class="menu-text">CRM</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/examples/CRM/example1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/examples/CRM/example2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 2</span></a>
  </div>
</li>
      </ul>
  </li>
          <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false">
 <span class="menu-text">Staged</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth3 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/examples/Staged/example1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 1</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../documentation/v71/examples/Staged/example2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Example 2</span></a>
  </div>
</li>
      </ul>
  </li>
      </ul>
  </li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#table-of-contents" id="toc-table-of-contents" class="nav-link active" data-scroll-target="#table-of-contents"><span class="header-section-number">1</span> Table of Contents</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">2</span> Introduction</a>
  <ul>
  <li><a href="#purpose-of-this-document" id="toc-purpose-of-this-document" class="nav-link" data-scroll-target="#purpose-of-this-document"><span class="header-section-number">2.1</span> Purpose of this document</a></li>
  <li><a href="#scope-of-this-document" id="toc-scope-of-this-document" class="nav-link" data-scroll-target="#scope-of-this-document"><span class="header-section-number">2.2</span> Scope of this document</a></li>
  <li><a href="#context-of-this-issue" id="toc-context-of-this-issue" class="nav-link" data-scroll-target="#context-of-this-issue"><span class="header-section-number">2.3</span> Context of this Issue</a></li>
  <li><a href="#citing-facts" id="toc-citing-facts" class="nav-link" data-scroll-target="#citing-facts"><span class="header-section-number">2.4</span> Citing FACTS</a></li>
  <li><a href="#definition-of-terms" id="toc-definition-of-terms" class="nav-link" data-scroll-target="#definition-of-terms"><span class="header-section-number">2.5</span> Definition of Terms</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">2.6</span> References:</a></li>
  </ul></li>
  <li><a href="#facts-core-overview" id="toc-facts-core-overview" class="nav-link" data-scroll-target="#facts-core-overview"><span class="header-section-number">3</span> FACTS Core Overview</a>
  <ul>
  <li><a href="#facts-7.1-changes-to-facts-core" id="toc-facts-7.1-changes-to-facts-core" class="nav-link" data-scroll-target="#facts-7.1-changes-to-facts-core"><span class="header-section-number">3.1</span> FACTS 7.1 Changes to FACTS Core</a></li>
  <li><a href="#facts-7.0-changes-to-facts-core" id="toc-facts-7.0-changes-to-facts-core" class="nav-link" data-scroll-target="#facts-7.0-changes-to-facts-core"><span class="header-section-number">3.2</span> FACTS 7.0 Changes to FACTS Core</a></li>
  <li><a href="#facts-6.5-changes-to-facts-core-design-options" id="toc-facts-6.5-changes-to-facts-core-design-options" class="nav-link" data-scroll-target="#facts-6.5-changes-to-facts-core-design-options"><span class="header-section-number">3.3</span> FACTS 6.5 Changes to FACTS Core Design options</a></li>
  <li><a href="#facts-6.4-changes-to-facts-core-design-options" id="toc-facts-6.4-changes-to-facts-core-design-options" class="nav-link" data-scroll-target="#facts-6.4-changes-to-facts-core-design-options"><span class="header-section-number">3.4</span> FACTS 6.4 Changes to FACTS Core Design options</a></li>
  <li><a href="#facts-6.3-changes-to-facts-core-design-options" id="toc-facts-6.3-changes-to-facts-core-design-options" class="nav-link" data-scroll-target="#facts-6.3-changes-to-facts-core-design-options"><span class="header-section-number">3.5</span> FACTS 6.3 Changes to FACTS Core Design options</a></li>
  <li><a href="#facts-6.2-changes-to-facts-core-design-options" id="toc-facts-6.2-changes-to-facts-core-design-options" class="nav-link" data-scroll-target="#facts-6.2-changes-to-facts-core-design-options"><span class="header-section-number">3.6</span> FACTS 6.2 Changes to FACTS Core Design options</a></li>
  <li><a href="#facts-6.1-changes-to-facts-core-design-options" id="toc-facts-6.1-changes-to-facts-core-design-options" class="nav-link" data-scroll-target="#facts-6.1-changes-to-facts-core-design-options"><span class="header-section-number">3.7</span> FACTS 6.1 Changes to FACTS Core Design options</a></li>
  </ul></li>
  <li><a href="#simulating-virtual-subjects" id="toc-simulating-virtual-subjects" class="nav-link" data-scroll-target="#simulating-virtual-subjects"><span class="header-section-number">4</span> Simulating Virtual Subjects</a>
  <ul>
  <li><a href="#subject-responses" id="toc-subject-responses" class="nav-link" data-scroll-target="#subject-responses"><span class="header-section-number">4.1</span> Subject Responses</a></li>
  <li><a href="#accrual" id="toc-accrual" class="nav-link" data-scroll-target="#accrual"><span class="header-section-number">4.2</span> Accrual</a>
  <ul class="collapse">
  <li><a href="#deterministic-accrual" id="toc-deterministic-accrual" class="nav-link" data-scroll-target="#deterministic-accrual"><span class="header-section-number">4.2.1</span> Deterministic Accrual</a></li>
  </ul></li>
  <li><a href="#drop-out-rates" id="toc-drop-out-rates" class="nav-link" data-scroll-target="#drop-out-rates"><span class="header-section-number">4.3</span> Drop-out Rates</a></li>
  </ul></li>
  <li><a href="#quantities-of-interest-qoi" id="toc-quantities-of-interest-qoi" class="nav-link" data-scroll-target="#quantities-of-interest-qoi"><span class="header-section-number">5</span> Quantities of Interest (QOI)</a>
  <ul>
  <li><a href="#posterior-probabilities" id="toc-posterior-probabilities" class="nav-link" data-scroll-target="#posterior-probabilities"><span class="header-section-number">5.1</span> Posterior Probabilities</a>
  <ul class="collapse">
  <li><a href="#notes-on-setting-deltas" id="toc-notes-on-setting-deltas" class="nav-link" data-scroll-target="#notes-on-setting-deltas"><span class="header-section-number">5.1.1</span> Notes on setting Delta’s</a></li>
  <li><a href="#p-value-deltas" id="toc-p-value-deltas" class="nav-link" data-scroll-target="#p-value-deltas"><span class="header-section-number">5.1.2</span> P-value Delta’s</a></li>
  </ul></li>
  <li><a href="#predictive-probabilities" id="toc-predictive-probabilities" class="nav-link" data-scroll-target="#predictive-probabilities"><span class="header-section-number">5.2</span> Predictive Probabilities</a>
  <ul class="collapse">
  <li><a href="#bayesian-predictive-probabilities" id="toc-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#bayesian-predictive-probabilities"><span class="header-section-number">5.2.1</span> Bayesian predictive probabilities</a>
  <ul class="collapse">
  <li><a href="#current-trial-bayesian-predictive-probabilities" id="toc-current-trial-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#current-trial-bayesian-predictive-probabilities"><span class="header-section-number">5.2.1.1</span> Current Trial Bayesian Predictive Probabilities</a></li>
  <li><a href="#current-trial-bayesian-predictive-probabilities-time-to-event" id="toc-current-trial-bayesian-predictive-probabilities-time-to-event" class="nav-link" data-scroll-target="#current-trial-bayesian-predictive-probabilities-time-to-event"><span class="header-section-number">5.2.1.2</span> Current Trial Bayesian Predictive Probabilities – Time-to-Event</a></li>
  <li><a href="#future-trial-bayesian-predictive-probabilities" id="toc-future-trial-bayesian-predictive-probabilities" class="nav-link" data-scroll-target="#future-trial-bayesian-predictive-probabilities"><span class="header-section-number">5.2.1.3</span> Future Trial Bayesian Predictive Probabilities</a></li>
  </ul></li>
  <li><a href="#conditional-power" id="toc-conditional-power" class="nav-link" data-scroll-target="#conditional-power"><span class="header-section-number">5.2.2</span> Conditional Power</a>
  <ul class="collapse">
  <li><a href="#current-trial-conditional-power" id="toc-current-trial-conditional-power" class="nav-link" data-scroll-target="#current-trial-conditional-power"><span class="header-section-number">5.2.2.1</span> Current Trial Conditional Power</a></li>
  <li><a href="#future-trial-conditional-power" id="toc-future-trial-conditional-power" class="nav-link" data-scroll-target="#future-trial-conditional-power"><span class="header-section-number">5.2.2.2</span> Future Trial Conditional Power</a></li>
  <li><a href="#technical-aspects-of-conditional-power-calculations" id="toc-technical-aspects-of-conditional-power-calculations" class="nav-link" data-scroll-target="#technical-aspects-of-conditional-power-calculations"><span class="header-section-number">5.2.2.3</span> Technical Aspects of Conditional Power Calculations</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#p-values" id="toc-p-values" class="nav-link" data-scroll-target="#p-values"><span class="header-section-number">5.3</span> P-values</a>
  <ul class="collapse">
  <li><a href="#p-values-when-there-is-no-control-arm" id="toc-p-values-when-there-is-no-control-arm" class="nav-link" data-scroll-target="#p-values-when-there-is-no-control-arm"><span class="header-section-number">5.3.1</span> P-values when there is no control arm</a></li>
  <li><a href="#fisher-exact-test" id="toc-fisher-exact-test" class="nav-link" data-scroll-target="#fisher-exact-test"><span class="header-section-number">5.3.2</span> Fisher-Exact Test</a></li>
  </ul></li>
  <li><a href="#target-doses" id="toc-target-doses" class="nav-link" data-scroll-target="#target-doses"><span class="header-section-number">5.4</span> Target Doses</a></li>
  <li><a href="#decision-quantities" id="toc-decision-quantities" class="nav-link" data-scroll-target="#decision-quantities"><span class="header-section-number">5.5</span> Decision Quantities</a></li>
  <li><a href="#standard-evaluation-variables" id="toc-standard-evaluation-variables" class="nav-link" data-scroll-target="#standard-evaluation-variables"><span class="header-section-number">5.6</span> Standard Evaluation Variables</a>
  <ul class="collapse">
  <li><a href="#the-direction-of-comparison-for-default-qois" id="toc-the-direction-of-comparison-for-default-qois" class="nav-link" data-scroll-target="#the-direction-of-comparison-for-default-qois"><span class="header-section-number">5.6.1</span> The direction of comparison for default QOIs</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#design-overview" id="toc-design-overview" class="nav-link" data-scroll-target="#design-overview"><span class="header-section-number">6</span> Design Overview</a>
  <ul>
  <li><a href="#evaluation-of-bayesian-posterior-estimates" id="toc-evaluation-of-bayesian-posterior-estimates" class="nav-link" data-scroll-target="#evaluation-of-bayesian-posterior-estimates"><span class="header-section-number">6.1</span> Evaluation of Bayesian Posterior Estimates</a></li>
  </ul></li>
  <li><a href="#dose-response" id="toc-dose-response" class="nav-link" data-scroll-target="#dose-response"><span class="header-section-number">7</span> Dose Response</a>
  <ul>
  <li><a href="#continuous-dichotomous-and-log-odds" id="toc-continuous-dichotomous-and-log-odds" class="nav-link" data-scroll-target="#continuous-dichotomous-and-log-odds"><span class="header-section-number">7.1</span> Continuous, Dichotomous and Log-Odds</a></li>
  <li><a href="#descriptions-of-dose-response-models" id="toc-descriptions-of-dose-response-models" class="nav-link" data-scroll-target="#descriptions-of-dose-response-models"><span class="header-section-number">7.2</span> Descriptions of Dose Response Models</a>
  <ul class="collapse">
  <li><a href="#independent-dose-model" id="toc-independent-dose-model" class="nav-link" data-scroll-target="#independent-dose-model"><span class="header-section-number">7.2.1</span> Independent Dose Model</a></li>
  <li><a href="#independent-beta-binomial-model-dichotomous-only" id="toc-independent-beta-binomial-model-dichotomous-only" class="nav-link" data-scroll-target="#independent-beta-binomial-model-dichotomous-only"><span class="header-section-number">7.2.2</span> Independent Beta-Binomial Model (Dichotomous Only)</a></li>
  <li><a href="#simple-ndlm" id="toc-simple-ndlm" class="nav-link" data-scroll-target="#simple-ndlm"><span class="header-section-number">7.2.3</span> Simple NDLM</a></li>
  <li><a href="#monotonic-ndlm" id="toc-monotonic-ndlm" class="nav-link" data-scroll-target="#monotonic-ndlm"><span class="header-section-number">7.2.4</span> Monotonic NDLM</a></li>
  <li><a href="#second-order-ndlm" id="toc-second-order-ndlm" class="nav-link" data-scroll-target="#second-order-ndlm"><span class="header-section-number">7.2.5</span> Second Order NDLM</a></li>
  <li><a href="#parameter-logistic" id="toc-parameter-logistic" class="nav-link" data-scroll-target="#parameter-logistic"><span class="header-section-number">7.2.6</span> 3-Parameter Logistic</a></li>
  <li><a href="#hierarchical-logistic" id="toc-hierarchical-logistic" class="nav-link" data-scroll-target="#hierarchical-logistic"><span class="header-section-number">7.2.7</span> Hierarchical Logistic</a></li>
  <li><a href="#sigmoid-model" id="toc-sigmoid-model" class="nav-link" data-scroll-target="#sigmoid-model"><span class="header-section-number">7.2.8</span> Sigmoid Model</a></li>
  <li><a href="#u-shaped-model" id="toc-u-shaped-model" class="nav-link" data-scroll-target="#u-shaped-model"><span class="header-section-number">7.2.9</span> U-Shaped Model</a></li>
  <li><a href="#plateau-model" id="toc-plateau-model" class="nav-link" data-scroll-target="#plateau-model"><span class="header-section-number">7.2.10</span> Plateau Model</a></li>
  <li><a href="#parameter-exp-logistic-dichotomous-only" id="toc-parameter-exp-logistic-dichotomous-only" class="nav-link" data-scroll-target="#parameter-exp-logistic-dichotomous-only"><span class="header-section-number">7.2.11</span> 3 Parameter Exp Logistic (Dichotomous Only)</a></li>
  <li><a href="#hierarchical-model" id="toc-hierarchical-model" class="nav-link" data-scroll-target="#hierarchical-model"><span class="header-section-number">7.2.12</span> Hierarchical Model</a></li>
  <li><a href="#linear-model" id="toc-linear-model" class="nav-link" data-scroll-target="#linear-model"><span class="header-section-number">7.2.13</span> Linear Model</a></li>
  <li><a href="#hierarchical-linear-model" id="toc-hierarchical-linear-model" class="nav-link" data-scroll-target="#hierarchical-linear-model"><span class="header-section-number">7.2.14</span> Hierarchical Linear Model</a></li>
  </ul></li>
  <li><a href="#d-treatment-dose-response-models" id="toc-d-treatment-dose-response-models" class="nav-link" data-scroll-target="#d-treatment-dose-response-models"><span class="header-section-number">7.3</span> 2D Treatment Dose Response Models</a>
  <ul class="collapse">
  <li><a href="#d-continuous-factorial-model" id="toc-d-continuous-factorial-model" class="nav-link" data-scroll-target="#d-continuous-factorial-model"><span class="header-section-number">7.3.1</span> 2D Continuous Factorial Model</a></li>
  <li><a href="#d-discrete-factorial-model" id="toc-d-discrete-factorial-model" class="nav-link" data-scroll-target="#d-discrete-factorial-model"><span class="header-section-number">7.3.2</span> 2D Discrete Factorial Model</a></li>
  <li><a href="#d-ndlm" id="toc-d-ndlm" class="nav-link" data-scroll-target="#d-ndlm"><span class="header-section-number">7.3.3</span> 2D NDLM</a>
  <ul class="collapse">
  <li><a href="#the-base-model-with-control-included" id="toc-the-base-model-with-control-included" class="nav-link" data-scroll-target="#the-base-model-with-control-included"><span class="header-section-number">7.3.3.1</span> The Base Model, with Control Included</a></li>
  <li><a href="#fix-smoothing-ratio-for-row-factor-and-column-factor" id="toc-fix-smoothing-ratio-for-row-factor-and-column-factor" class="nav-link" data-scroll-target="#fix-smoothing-ratio-for-row-factor-and-column-factor"><span class="header-section-number">7.3.3.2</span> Fix smoothing ratio for row factor and column factor</a></li>
  <li><a href="#control-not-in-model-no-zero-level-doses" id="toc-control-not-in-model-no-zero-level-doses" class="nav-link" data-scroll-target="#control-not-in-model-no-zero-level-doses"><span class="header-section-number">7.3.3.3</span> Control not in model, no zero-level doses</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#baseline-adjusted-model-continuous-only" id="toc-baseline-adjusted-model-continuous-only" class="nav-link" data-scroll-target="#baseline-adjusted-model-continuous-only"><span class="header-section-number">7.4</span> Baseline Adjusted Model (Continuous Only)</a></li>
  <li><a href="#control-and-comparator-priors" id="toc-control-and-comparator-priors" class="nav-link" data-scroll-target="#control-and-comparator-priors"><span class="header-section-number">7.5</span> Control and Comparator Priors</a></li>
  <li><a href="#inverse-gamma-priors" id="toc-inverse-gamma-priors" class="nav-link" data-scroll-target="#inverse-gamma-priors"><span class="header-section-number">7.6</span> Inverse-gamma priors</a></li>
  <li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data"><span class="header-section-number">7.7</span> Handling Missing Data</a>
  <ul class="collapse">
  <li><a href="#time-to-event-missingness" id="toc-time-to-event-missingness" class="nav-link" data-scroll-target="#time-to-event-missingness"><span class="header-section-number">7.7.1</span> Time-to-Event Missingness</a></li>
  </ul></li>
  <li><a href="#bayesian-baseline-adjusted-model" id="toc-bayesian-baseline-adjusted-model" class="nav-link" data-scroll-target="#bayesian-baseline-adjusted-model"><span class="header-section-number">7.8</span> Bayesian Baseline Adjusted Model</a></li>
  </ul></li>
  <li><a href="#augmented-priors-historical-prior" id="toc-augmented-priors-historical-prior" class="nav-link" data-scroll-target="#augmented-priors-historical-prior"><span class="header-section-number">8</span> Augmented Priors (Historical Prior)</a>
  <ul>
  <li><a href="#continuous-endpoints" id="toc-continuous-endpoints" class="nav-link" data-scroll-target="#continuous-endpoints"><span class="header-section-number">8.1</span> Continuous Endpoints</a></li>
  <li><a href="#dichotomous-endpoints" id="toc-dichotomous-endpoints" class="nav-link" data-scroll-target="#dichotomous-endpoints"><span class="header-section-number">8.2</span> Dichotomous Endpoints</a></li>
  <li><a href="#time-to-event-endpoints" id="toc-time-to-event-endpoints" class="nav-link" data-scroll-target="#time-to-event-endpoints"><span class="header-section-number">8.3</span> Time-to-Event Endpoints</a></li>
  <li><a href="#setting-priors-for-hierarchical-model-hyper-parameters" id="toc-setting-priors-for-hierarchical-model-hyper-parameters" class="nav-link" data-scroll-target="#setting-priors-for-hierarchical-model-hyper-parameters"><span class="header-section-number">8.4</span> Setting Priors for Hierarchical Model Hyper Parameters</a></li>
  <li><a href="#bac-example" id="toc-bac-example" class="nav-link" data-scroll-target="#bac-example"><span class="header-section-number">8.5</span> BAC Example:</a></li>
  </ul></li>
  <li><a href="#frequentist-analysis" id="toc-frequentist-analysis" class="nav-link" data-scroll-target="#frequentist-analysis"><span class="header-section-number">9</span> Frequentist Analysis</a>
  <ul>
  <li><a href="#continuous-endpoints-1" id="toc-continuous-endpoints-1" class="nav-link" data-scroll-target="#continuous-endpoints-1"><span class="header-section-number">9.1</span> Continuous Endpoints</a></li>
  <li><a href="#dichotomous-endpoints-1" id="toc-dichotomous-endpoints-1" class="nav-link" data-scroll-target="#dichotomous-endpoints-1"><span class="header-section-number">9.2</span> Dichotomous Endpoints</a></li>
  <li><a href="#time-to-event-frequentist-analysis" id="toc-time-to-event-frequentist-analysis" class="nav-link" data-scroll-target="#time-to-event-frequentist-analysis"><span class="header-section-number">9.3</span> Time-to-Event Frequentist Analysis</a></li>
  </ul></li>
  <li><a href="#longitudinal-modelling" id="toc-longitudinal-modelling" class="nav-link" data-scroll-target="#longitudinal-modelling"><span class="header-section-number">10</span> Longitudinal Modelling</a>
  <ul>
  <li><a href="#imputation" id="toc-imputation" class="nav-link" data-scroll-target="#imputation"><span class="header-section-number">10.1</span> Imputation</a></li>
  <li><a href="#how-many-longitudinal-models" id="toc-how-many-longitudinal-models" class="nav-link" data-scroll-target="#how-many-longitudinal-models"><span class="header-section-number">10.2</span> How many longitudinal models?</a></li>
  <li><a href="#longitudinal-models-for-a-continuous-endpoint" id="toc-longitudinal-models-for-a-continuous-endpoint" class="nav-link" data-scroll-target="#longitudinal-models-for-a-continuous-endpoint"><span class="header-section-number">10.3</span> Longitudinal Models for a Continuous Endpoint</a>
  <ul class="collapse">
  <li><a href="#locf-last-observation-carried-forward" id="toc-locf-last-observation-carried-forward" class="nav-link" data-scroll-target="#locf-last-observation-carried-forward"><span class="header-section-number">10.3.1</span> LOCF (Last Observation Carried Forward)</a></li>
  <li><a href="#linear-regression" id="toc-linear-regression" class="nav-link" data-scroll-target="#linear-regression"><span class="header-section-number">10.3.2</span> Linear Regression</a></li>
  <li><a href="#time-course-hierarchical" id="toc-time-course-hierarchical" class="nav-link" data-scroll-target="#time-course-hierarchical"><span class="header-section-number">10.3.3</span> Time Course Hierarchical</a></li>
  <li><a href="#kernel-density" id="toc-kernel-density" class="nav-link" data-scroll-target="#kernel-density"><span class="header-section-number">10.3.4</span> Kernel Density</a></li>
  <li><a href="#itp" id="toc-itp" class="nav-link" data-scroll-target="#itp"><span class="header-section-number">10.3.5</span> ITP</a></li>
  </ul></li>
  <li><a href="#longitudinal-models-for-a-dichotomous-endpoint" id="toc-longitudinal-models-for-a-dichotomous-endpoint" class="nav-link" data-scroll-target="#longitudinal-models-for-a-dichotomous-endpoint"><span class="header-section-number">10.4</span> Longitudinal Models for a Dichotomous Endpoint</a>
  <ul class="collapse">
  <li><a href="#locf-last-observation-carried-forward-1" id="toc-locf-last-observation-carried-forward-1" class="nav-link" data-scroll-target="#locf-last-observation-carried-forward-1"><span class="header-section-number">10.4.1</span> LOCF (Last Observation Carried Forward)</a></li>
  <li><a href="#beta-binomial" id="toc-beta-binomial" class="nav-link" data-scroll-target="#beta-binomial"><span class="header-section-number">10.4.2</span> Beta Binomial</a></li>
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><span class="header-section-number">10.4.3</span> Logistic regression</a></li>
  <li><a href="#restricted-markov-model-absorbing-markov-chain" id="toc-restricted-markov-model-absorbing-markov-chain" class="nav-link" data-scroll-target="#restricted-markov-model-absorbing-markov-chain"><span class="header-section-number">10.4.4</span> Restricted Markov Model (Absorbing Markov Chain)</a></li>
  <li><a href="#dichotomous-endpoint-dichotomized-continuous-longitudinal-model" id="toc-dichotomous-endpoint-dichotomized-continuous-longitudinal-model" class="nav-link" data-scroll-target="#dichotomous-endpoint-dichotomized-continuous-longitudinal-model"><span class="header-section-number">10.4.5</span> Dichotomous Endpoint: Dichotomized Continuous Longitudinal Model</a></li>
  </ul></li>
  <li><a href="#time-to-event-predictor-models" id="toc-time-to-event-predictor-models" class="nav-link" data-scroll-target="#time-to-event-predictor-models"><span class="header-section-number">10.5</span> Time-to-Event Predictor Models</a>
  <ul class="collapse">
  <li><a href="#continuous-predictor" id="toc-continuous-predictor" class="nav-link" data-scroll-target="#continuous-predictor"><span class="header-section-number">10.5.0.1</span> Continuous Predictor</a></li>
  <li><a href="#dichotomous-predictor" id="toc-dichotomous-predictor" class="nav-link" data-scroll-target="#dichotomous-predictor"><span class="header-section-number">10.5.0.2</span> Dichotomous Predictor</a></li>
  <li><a href="#time-to-event-predictor" id="toc-time-to-event-predictor" class="nav-link" data-scroll-target="#time-to-event-predictor"><span class="header-section-number">10.5.0.3</span> Time to Event Predictor</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#allocation" id="toc-allocation" class="nav-link" data-scroll-target="#allocation"><span class="header-section-number">11</span> Allocation</a>
  <ul>
  <li><a href="#non-adaptive-designs" id="toc-non-adaptive-designs" class="nav-link" data-scroll-target="#non-adaptive-designs"><span class="header-section-number">11.1</span> Non-adaptive designs</a></li>
  <li><a href="#fixed-allocation" id="toc-fixed-allocation" class="nav-link" data-scroll-target="#fixed-allocation"><span class="header-section-number">11.2</span> Fixed Allocation</a></li>
  <li><a href="#arm-dropping" id="toc-arm-dropping" class="nav-link" data-scroll-target="#arm-dropping"><span class="header-section-number">11.3</span> Arm Dropping</a></li>
  <li><a href="#adaptive-allocation" id="toc-adaptive-allocation" class="nav-link" data-scroll-target="#adaptive-allocation"><span class="header-section-number">11.4</span> Adaptive Allocation</a>
  <ul class="collapse">
  <li><a href="#weighting-and-calculation-of-adaptive-allocation-probabilities" id="toc-weighting-and-calculation-of-adaptive-allocation-probabilities" class="nav-link" data-scroll-target="#weighting-and-calculation-of-adaptive-allocation-probabilities"><span class="header-section-number">11.4.1</span> Weighting and Calculation of Adaptive Allocation Probabilities</a>
  <ul class="collapse">
  <li><a href="#non-fixed-control-adaptive-allocation" id="toc-non-fixed-control-adaptive-allocation" class="nav-link" data-scroll-target="#non-fixed-control-adaptive-allocation"><span class="header-section-number">11.4.1.1</span> Non-fixed Control Adaptive Allocation</a></li>
  <li><a href="#zero-out-allocation-probabilities" id="toc-zero-out-allocation-probabilities" class="nav-link" data-scroll-target="#zero-out-allocation-probabilities"><span class="header-section-number">11.4.1.2</span> Zero Out Allocation Probabilities</a></li>
  </ul></li>
  <li><a href="#adaptive-allocation-calculation-examples" id="toc-adaptive-allocation-calculation-examples" class="nav-link" data-scroll-target="#adaptive-allocation-calculation-examples"><span class="header-section-number">11.4.2</span> Adaptive Allocation Calculation Examples</a>
  <ul class="collapse">
  <li><a href="#simple-response-adaptive-randomization-example" id="toc-simple-response-adaptive-randomization-example" class="nav-link" data-scroll-target="#simple-response-adaptive-randomization-example"><span class="header-section-number">11.4.2.1</span> Simple Response Adaptive Randomization Example</a></li>
  <li><a href="#using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" id="toc-using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" class="nav-link" data-scroll-target="#using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms"><span class="header-section-number">11.4.2.2</span> Using Static Weighting Example: Ensuring a minimum allocation to all arms</a></li>
  <li><a href="#using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" id="toc-using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" class="nav-link" data-scroll-target="#using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose"><span class="header-section-number">11.4.2.3</span> Using Static Weighting Example: Ensuring a minimum allocation to top dose</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#deterministic-allocation" id="toc-deterministic-allocation" class="nav-link" data-scroll-target="#deterministic-allocation"><span class="header-section-number">11.5</span> Deterministic Allocation</a></li>
  <li><a href="#cohort-recruitment-fixed-allocation" id="toc-cohort-recruitment-fixed-allocation" class="nav-link" data-scroll-target="#cohort-recruitment-fixed-allocation"><span class="header-section-number">11.6</span> Cohort recruitment – fixed allocation</a></li>
  <li><a href="#cohort-recruitment-adaptive-allocation" id="toc-cohort-recruitment-adaptive-allocation" class="nav-link" data-scroll-target="#cohort-recruitment-adaptive-allocation"><span class="header-section-number">11.7</span> Cohort recruitment – adaptive allocation</a></li>
  <li><a href="#cohort-recruitment-allocate-to-best-dose" id="toc-cohort-recruitment-allocate-to-best-dose" class="nav-link" data-scroll-target="#cohort-recruitment-allocate-to-best-dose"><span class="header-section-number">11.8</span> Cohort recruitment – allocate to best dose</a></li>
  </ul></li>
  <li><a href="#interims" id="toc-interims" class="nav-link" data-scroll-target="#interims"><span class="header-section-number">12</span> Interims</a>
  <ul>
  <li><a href="#continuous-and-dichotomous-endpoints" id="toc-continuous-and-dichotomous-endpoints" class="nav-link" data-scroll-target="#continuous-and-dichotomous-endpoints"><span class="header-section-number">12.1</span> Continuous and Dichotomous Endpoints</a></li>
  <li><a href="#time-to-event-endpoint" id="toc-time-to-event-endpoint" class="nav-link" data-scroll-target="#time-to-event-endpoint"><span class="header-section-number">12.2</span> Time-to-Event Endpoint</a></li>
  <li><a href="#follow-up" id="toc-follow-up" class="nav-link" data-scroll-target="#follow-up"><span class="header-section-number">12.3</span> Follow-up</a></li>
  </ul></li>
  <li><a href="#successfutility-criteria" id="toc-successfutility-criteria" class="nav-link" data-scroll-target="#successfutility-criteria"><span class="header-section-number">13</span> Success/Futility Criteria</a>
  <ul>
  <li><a href="#interim-analysis-criteria" id="toc-interim-analysis-criteria" class="nav-link" data-scroll-target="#interim-analysis-criteria"><span class="header-section-number">13.1</span> Interim Analysis Criteria</a></li>
  <li><a href="#final-evaluation-criteria" id="toc-final-evaluation-criteria" class="nav-link" data-scroll-target="#final-evaluation-criteria"><span class="header-section-number">13.2</span> Final Evaluation Criteria</a></li>
  </ul></li>
  <li><a href="#trial-states" id="toc-trial-states" class="nav-link" data-scroll-target="#trial-states"><span class="header-section-number">14</span> Trial States</a>
  <ul>
  <li><a href="#state-descriptions" id="toc-state-descriptions" class="nav-link" data-scroll-target="#state-descriptions"><span class="header-section-number">14.1</span> State descriptions</a></li>
  <li><a href="#analysis-trigger-events" id="toc-analysis-trigger-events" class="nav-link" data-scroll-target="#analysis-trigger-events"><span class="header-section-number">14.2</span> Analysis trigger events</a></li>
  <li><a href="#trial-state-transitions" id="toc-trial-state-transitions" class="nav-link" data-scroll-target="#trial-state-transitions"><span class="header-section-number">14.3</span> Trial State Transitions</a></li>
  </ul></li>
  <li><a href="#reporting-of-results" id="toc-reporting-of-results" class="nav-link" data-scroll-target="#reporting-of-results"><span class="header-section-number">15</span> Reporting of Results</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">Version 7.1</li><li class="breadcrumb-item"><a href="../../../documentation/v71/userguides/core.html">User Guides</a></li><li class="breadcrumb-item"><a href="../../../documentation/v71/userguides/core.html">FACTS Core User Guide</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">FACTS Core User Guide</h1>
<p class="subtitle lead">All Endpoints: Quantities of Interest and Design options.</p>
</div>



<div class="quarto-title-meta column-body">

    
  
    
  </div>
  


</header>


<p><img src="coreUGattachments/CoreUserGuide/media/image1.png" style="width:6.93268in;height:1.84409in" alt="facts_splash.png"></p>
<section id="table-of-contents" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Table of Contents</h1>
<p><a href="#introduction">1 Introduction [6](#introduction)</a></p>
<p><a href="#purpose-of-this-document">1.1 Purpose of this document [6](#purpose-of-this-document)</a></p>
<p><a href="#scope-of-this-document">1.2 Scope of this document [6](#scope-of-this-document)</a></p>
<p><a href="#context-of-this-issue">1.3 Context of this Issue [6](#context-of-this-issue)</a></p>
<p><a href="#citing-facts">1.4 Citing FACTS [6](#citing-facts)</a></p>
<p><a href="#definition-of-terms">1.5 Definition of Terms [7](#definition-of-terms)</a></p>
<p><a href="#references">1.6 References: [9](#references)</a></p>
<p><a href="#facts-core-overview">2 FACTS Core Overview [9](#facts-core-overview)</a></p>
<p><a href="#facts-7.1-changes-to-facts-core">2.1 FACTS 7.0 Changes to FACTS Core [10](#facts-7.1-changes-to-facts-core)</a></p>
<p><a href="#facts-6.5-changes-to-facts-core-design-options">2.2 FACTS 6.5 Changes to FACTS Core Design options [10](#facts-6.5-changes-to-facts-core-design-options)</a></p>
<p><a href="#facts-6.4-changes-to-facts-core-design-options">2.3 FACTS 6.4 Changes to FACTS Core Design options [10](#facts-6.4-changes-to-facts-core-design-options)</a></p>
<p><a href="#facts-6.3-changes-to-facts-core-design-options">2.4 FACTS 6.3 Changes to FACTS Core Design options [10](#facts-6.3-changes-to-facts-core-design-options)</a></p>
<p><a href="#facts-6.2-changes-to-facts-core-design-options">2.5 FACTS 6.2 Changes to FACTS Core Design options [11](#facts-6.2-changes-to-facts-core-design-options)</a></p>
<p><a href="#facts-6.1-changes-to-facts-core-design-options">2.6 FACTS 6.1 Changes to FACTS Core Design options [11](#facts-6.1-changes-to-facts-core-design-options)</a></p>
<p><a href="#simulating-virtual-subjects">3 Simulating Virtual Subjects [11](#simulating-virtual-subjects)</a></p>
<p><a href="#subject-responses">3.1 Subject Responses [11](#subject-responses)</a></p>
<p><a href="#accrual">3.2 Accrual [11](#accrual)</a></p>
<p><a href="#deterministic-accrual">3.2.1 Deterministic Accrual [13](#deterministic-accrual)</a></p>
<p><a href="#drop-out-rates">3.3 Drop-out Rates [14](#drop-out-rates)</a></p>
<p><a href="#quantities-of-interest-qoi">4 Quantities of Interest (QOI) [15](#quantities-of-interest-qoi)</a></p>
<p><a href="#posterior-probabilities">4.1 Posterior Probabilities [17](#posterior-probabilities)</a></p>
<p><a href="#notes-on-setting-deltas">4.1.1 Notes on setting Delta’s [17](#notes-on-setting-deltas)</a></p>
<p><a href="#p-value-deltas">4.1.2 P-value Delta’s [18](#p-value-deltas)</a></p>
<p><a href="#predictive-probabilities">4.2 Predictive Probabilities [19](#predictive-probabilities)</a></p>
<p><a href="#bayesian-predictive-probabilities">4.2.1 Bayesian predictive probabilites [19](#bayesian-predictive-probabilities)</a></p>
<p><a href="#conditional-power">4.2.2 Conditional Power [22](#conditional-power)</a></p>
<p><a href="#p-values">4.3 P-values [23](#p-values)</a></p>
<p><a href="#p-values-when-there-is-no-control-arm">4.3.1 P-values when there is no control arm [25](#p-values-when-there-is-no-control-arm)</a></p>
<p><a href="#fisher-exact-test">4.3.2 Fisher-Exact Test [25](#fisher-exact-test)</a></p>
<p><a href="#target-doses">4.4 Target Doses [26](#target-doses)</a></p>
<p><a href="#decision-quantities">4.5 Decision Quantities [27](#decision-quantities)</a></p>
<p><a href="#standard-evaluation-variables">4.6 Standard Evaluation Variables [28](#standard-evaluation-variables)</a></p>
<p><a href="#the-direction-of-comparison-for-default-qois">4.6.1 The direction of comparison for default QOIs [29](#the-direction-of-comparison-for-default-qois)</a></p>
<p><a href="#design-overview">5 Design Overview [30](#design-overview)</a></p>
<p><a href="#evaluation-of-bayesian-posterior-estimates">5.1 Evaluation of Bayesian Posterior Estimates [30](#evaluation-of-bayesian-posterior-estimates)</a></p>
<p><a href="#dose-response">6 Dose Response [31](#dose-response)</a></p>
<p><a href="#continuous-dichotomous-and-log-odds">6.1 Continuous, Dichotomous and Log-Odds [31](#continuous-dichotomous-and-log-odds)</a></p>
<p><a href="#descriptions-of-dose-response-models">6.2 Descriptions of Dose Response Models [32](#descriptions-of-dose-response-models)</a></p>
<p><a href="#independent-dose-model">6.2.1 Independent Dose Model [32](#independent-dose-model)</a></p>
<p><a href="#independent-beta-binomial-model-dichotomous-only">6.2.2 Independent Beta-Binomial Model (Dichotomous Only) [33](#independent-beta-binomial-model-dichotomous-only)</a></p>
<p><a href="#simple-ndlm">6.2.3 Simple NDLM [33](#simple-ndlm)</a></p>
<p><a href="#monotonic-ndlm">6.2.4 Monotonic NDLM [34](#monotonic-ndlm)</a></p>
<p><a href="#second-order-ndlm">6.2.5 Second Order NDLM [35](#second-order-ndlm)</a></p>
<p><a href="#parameter-logistic">6.2.6 3-Parameter Logistic [36](#parameter-logistic)</a></p>
<p><a href="#hierarchical-logistic">6.2.7 Hierarchical Logistic [37](#hierarchical-logistic)</a></p>
<p><a href="#sigmoid-model">6.2.8 Sigmoid Model [39](#sigmoid-model)</a></p>
<p><a href="#u-shaped-model">6.2.9 U-Shaped Model [40](#u-shaped-model)</a></p>
<p><a href="#plateau-model">6.2.10 Plateau Model [42](#plateau-model)</a></p>
<p><a href="#parameter-exp-logistic-dichotomous-only">6.2.11 3 Parameter Exp Logistic (Dichotomous Only) [43](#parameter-exp-logistic-dichotomous-only)</a></p>
<p><a href="#hierarchical-model">6.2.12 Hierarchical Model [44](#hierarchical-model)</a></p>
<p><a href="#linear-model">6.2.13 Linear Model [45](#linear-model)</a></p>
<p><a href="#hierarchical-linear-model">6.2.14 Hierarchical Linear Model [45](#hierarchical-linear-model)</a></p>
<p><a href="#d-treatment-dose-response-models">6.3 2D Treatment Dose Response Models [46](#d-treatment-dose-response-models)</a></p>
<p><a href="#d-continuous-factorial-model">6.3.1 2D Continuous Factorial Model [46](#d-continuous-factorial-model)</a></p>
<p><a href="#d-discrete-factorial-model">6.3.2 2D Discrete Factorial Model [47](#d-discrete-factorial-model)</a></p>
<p><a href="#d-ndlm">6.3.3 2D NDLM [48](#d-ndlm)</a></p>
<p><a href="#baseline-adjusted-model-continuous-only">6.4 Baseline Adjusted Model (Continuous Only) [50](#baseline-adjusted-model-continuous-only)</a></p>
<p><a href="#control-and-comparator-priors">6.5 Control and Comparator Priors [51](#control-and-comparator-priors)</a></p>
<p><a href="#inverse-gamma-priors">6.6 Inverse-gamma priors [52](#inverse-gamma-priors)</a></p>
<p><a href="#handling-missing-data">6.7 Handling Missing Data [53](#handling-missing-data)</a></p>
<p><a href="#time-to-event-missingness">6.7.1 Time-to-Event Missingness [53](#time-to-event-missingness)</a></p>
<p><a href="#bayesian-baseline-adjusted-model">6.8 Bayesian Baseline Adjusted Model [53](#bayesian-baseline-adjusted-model)</a></p>
<p><a href="#augmented-priors-historical-prior">7 Augmented Priors (Historical Prior) [54](#augmented-priors-historical-prior)</a></p>
<p><a href="#continuous-endpoints">7.1 Continuous Endpoints [55](#continuous-endpoints)</a></p>
<p><a href="#dichotomous-endpoints">7.2 Dichotomous Endpoints [55](#dichotomous-endpoints)</a></p>
<p><a href="#time-to-event-endpoints">7.3 Time-to-Event Endpoints [55](#time-to-event-endpoints)</a></p>
<p><a href="#setting-priors-for-hierarchical-model-hyper-parameters">7.4 Setting Priors for Hierarchical Model Hyper Parameters [56](#setting-priors-for-hierarchical-model-hyper-parameters)</a></p>
<p><a href="#bac-example">7.5 BAC Example: [56](#bac-example)</a></p>
<p><a href="#frequentist-analysis">8 Frequentist Analysis [57](#frequentist-analysis)</a></p>
<p><a href="#continuous-endpoints-1">8.1 Continuous Endpoints [58](#continuous-endpoints-1)</a></p>
<p><a href="#dichotomous-endpoints-1">8.2 Dichotomous Endpoints [59](#dichotomous-endpoints-1)</a></p>
<p><a href="#time-to-event-frequentist-analysis">8.3 Time-to-Event Frequentist Analysis [60](#time-to-event-frequentist-analysis)</a></p>
<p><a href="#longitudinal-modelling">9 Longitudinal Modelling [60](#longitudinal-modelling)</a></p>
<p><a href="#imputation">9.1 Imputation [60](#imputation)</a></p>
<p><a href="#how-many-longitudinal-models">9.2 How many longitudinal models? [62](#how-many-longitudinal-models)</a></p>
<p><a href="#longitudinal-models-for-a-continuous-endpoint">9.3 Longitudinal Models for a Continuous Endpoint [63](#longitudinal-models-for-a-continuous-endpoint)</a></p>
<p><a href="#locf-last-observation-carried-forward">9.3.1 LOCF (Last Observation Carried Forward) [63](#locf-last-observation-carried-forward)</a></p>
<p><a href="#linear-regression">9.3.2 Linear Regression [63](#linear-regression)</a></p>
<p><a href="#time-course-hierarchical">9.3.3 Time Course Hierarchical [64](#time-course-hierarchical)</a></p>
<p><a href="#kernel-density">9.3.4 Kernel Density [65](#kernel-density)</a></p>
<p><a href="#itp">9.3.5 ITP [66](#itp)</a></p>
<p><a href="#longitudinal-models-for-a-dichotomous-endpoint">9.4 Longitudinal Models for a Dichotomous Endpoint [67](#longitudinal-models-for-a-dichotomous-endpoint)</a></p>
<p><a href="#locf-last-observation-carried-forward-1">9.4.1 LOCF (Last Observation Carried Forward) [67](#locf-last-observation-carried-forward-1)</a></p>
<p><a href="#beta-binomial">9.4.2 Beta Binomial [68](#beta-binomial)</a></p>
<p><a href="#logistic-regression">9.4.3 Logistic regression [68](#logistic-regression)</a></p>
<p><a href="#restricted-markov-model-absorbing-markov-chain">9.4.4 Restricted Markov Model (Absorbing Markov Chain) [69](#restricted-markov-model-absorbing-markov-chain)</a></p>
<p><a href="#dichotomous-endpoint-dichotomized-continuous-longitudinal-model">9.4.5 Dichotomous Endpoint: Dichotomized Continuous Longitudinal Model [69](#dichotomous-endpoint-dichotomized-continuous-longitudinal-model)</a></p>
<p><a href="#time-to-event-predictor-models">9.5 Time-to-Event Predictor Models [69](#time-to-event-predictor-models)</a></p>
<p><a href="#allocation">10 Allocation [70](#allocation)</a></p>
<p><a href="#non-adaptive-designs">10.1 Non-adaptive designs [71](#non-adaptive-designs)</a></p>
<p><a href="#fixed-allocation">10.2 Fixed Allocation [71](#fixed-allocation)</a></p>
<p><a href="#arm-dropping">10.3 Arm Dropping [72](#arm-dropping)</a></p>
<p><a href="#adaptive-allocation">10.4 Adaptive Allocation [74](#adaptive-allocation)</a></p>
<p><a href="#weighting-and-calculation-of-adaptive-allocation-probabilities">10.4.1 Weighting and Calculation of Adaptive Allocation Probabilities [76](#weighting-and-calculation-of-adaptive-allocation-probabilities)</a></p>
<p><a href="#adaptive-allocation-calculation-examples">10.4.2 Adaptive Allocation Calculation Examples [77](#adaptive-allocation-calculation-examples)</a></p>
<p><a href="#deterministic-allocation">10.5 Cohort recruitment – fixed allocation [79](#deterministic-allocation)</a></p>
<p><a href="#cohort-recruitment-adaptive-allocation">10.6 Cohort recruitment – adaptive allocation [80](#cohort-recruitment-adaptive-allocation)</a></p>
<p><a href="#cohort-recruitment-allocate-to-best-dose">10.7 Cohort recruitment – allocate to best dose [80](#cohort-recruitment-allocate-to-best-dose)</a></p>
<p><a href="#interims">11 Interims [82](#interims)</a></p>
<p><a href="#continuous-and-dichotomous-endpoints">11.1 Continuous and Dichotomous Endpoints [82](#continuous-and-dichotomous-endpoints)</a></p>
<p><a href="#time-to-event-endpoint">11.2 Time-to-Event Endpoint [83](#time-to-event-endpoint)</a></p>
<p><a href="#follow-up">11.3 Follow-up [83](#follow-up)</a></p>
<p><a href="#successfutility-criteria">12 Success/Futility Criteria [83](#successfutility-criteria)</a></p>
<p><a href="#interim-analysis-criteria">12.1 Interim Analysis Criteria [83](#interim-analysis-criteria)</a></p>
<p><a href="#final-evaluation-criteria">12.2 Final Evaluation Criteria [85](#final-evaluation-criteria)</a></p>
<p><a href="#trial-states">13 Trial States [86](#trial-states)</a></p>
<p><a href="#state-descriptions">13.1 State descriptions [86](#state-descriptions)</a></p>
<p><a href="#analysis-trigger-events">13.2 Analysis trigger events [87](#analysis-trigger-events)</a></p>
<p><a href="#trial-state-transitions">13.3 Trial State Transitions [87](#trial-state-transitions)</a></p>
<p><a href="#reporting-of-results">14 Reporting of Results [89](#reporting-of-results)</a></p>
</section>
<section id="introduction" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Introduction</h1>
<section id="purpose-of-this-document" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="purpose-of-this-document"><span class="header-section-number">2.1</span> Purpose of this document</h2>
<p>This document describes how to use the ‘Quantities of Interest’ and ‘Design’ options that are common across the FACTS Core design engines. It is intended for all end users of the system.</p>
</section>
<section id="scope-of-this-document" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="scope-of-this-document"><span class="header-section-number">2.2</span> Scope of this document</h2>
<p>This document covers the design options that are common across the four FACTS Core Design Engines: Continuous, Dichotomous, Time-to-Event and Multiple Endpoint. Design elements that are unique to a particular engine (primarily data simulation and simulation output) are covered in the endpoint specific Core Engine User Guide.</p>
<p>This document does not address the use of FACTS Enrichment Designs, Dose Escalation, or Platform Trials, which have separate User Guides.</p>
<p>The screenshots provided are specific to a particular installation and may not reflect the exact layout of the information seen by any particular user. They were taken from FACTS V7 &amp; V6[1] installed on Windows 10 or 11. If FACTS is installed on different versions of Windows, or with different Windows ‘themes’ there will be some differences in appearance introduced by Windows. The contents of each tab, however, will still be consistent with the screenshots in this document.</p>
</section>
<section id="context-of-this-issue" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="context-of-this-issue"><span class="header-section-number">2.3</span> Context of this Issue</h2>
<p>This is the version of the user guide for inclusion with the FACTS 7.1 release.</p>
</section>
<section id="citing-facts" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="citing-facts"><span class="header-section-number">2.4</span> Citing FACTS</h2>
<p>If writing in LaTex and using Bibtex, if you wish to cite FACTS (thank you!), can we suggest the following:</p>
<p><span class="citation" data-cites="techreport">(<a href="#ref-techreport" role="doc-biblioref"><strong>techreport?</strong></a>)</span>{FACTS71,</p>
<p>&nbsp;&nbsp;author = {{FACTS&nbsp;Development Team}},</p>
<p>&nbsp;&nbsp;title = {{FACTS}: Fixed and Adaptive Clinical Trial Simulator},</p>
<p>&nbsp;&nbsp;year&nbsp; = {2024},</p>
<p>&nbsp;&nbsp;month = {03},</p>
<p>&nbsp;&nbsp;number = {Version 7.1},</p>
<p>&nbsp;&nbsp;type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; = {Computer Software},</p>
<p>&nbsp;&nbsp;institution = {Berry Consultants LLC},</p>
<p>&nbsp;&nbsp;address = {Austin, TX},</p>
<p>&nbsp;&nbsp;note&nbsp;&nbsp; = {<a href="https://www.berryconsultants.com/software/facts/" class="uri">https://www.berryconsultants.com/software/facts/</a>}</p>
<p>}</p>
<p>This will result in a reference that, for example in the APA style, will look like the following:</p>
<p>FACTS&nbsp;Development Team (2024).&nbsp;FACTS: Fixed and adaptive clinical trial simulator. Computer Software Version 7.1, Berry Consultants LLC, Austin, TX.&nbsp;<a href="https://www.berryconsultants.com/software/facts/" class="uri">https://www.berryconsultants.com/software/facts/</a>.</p>
</section>
<section id="definition-of-terms" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="definition-of-terms"><span class="header-section-number">2.5</span> Definition of Terms</h2>
<p>The following acronyms and abbreviations are used in this document.</p>
<p>Active Comparator A treatment arm where subjects are treated with some existing therapy which the user either wishes to compare the novel treatment to (in addition to control), or wishes to use to check that the study has been properly designed to show a difference from control.</p>
<p>Baseline The subject’s baseline is their endpoint value before treatment on the trial is started. In FACTS the subject’s baseline is measured at their first visit, any prior visits (e.g.&nbsp;for screening to see if the patient is eligible for the trial) are not included in the simulation.</p>
<p>Cap A limit on the number of subjects recruited. In FACTS users can specify a cap on the overall number of subjects to be recruited in the trial (the ‘Overall Cap’) but through the use of early stopping rules the actual number recruited may be less, depending on the data observed.</p>
<p>Control Is the treatment arm with which the novel treatment(s) are principally being compared. Control may be placebo, or some existing standard of care, or therapy, against which the novel treatment has to be benchmarked in order to determine its likely usefulness.</p>
<p>Core FACTS Core: A mode of FACTS for designing trials where multiple treatments, (possibly different doses of a novel treatment) are tested against a control and optionally an active comparator.</p>
<p>CRM Continual Reassessment Method – a dose escalation design where the dose-toxicity is estimated using a simple Bayesian model, and the resulting estimates used to control the dose escalation and estimate the Maximum Tolerated Dose (MTD).</p>
<p>DE Dose Escalation: a mode of FACTS where subjects are treated in cohorts and dose escalation is determined by the number of toxicities observed.</p>
<p>ED Enrichment Designs: a mode of FACTS for designing trials where the same treatment is tested in different settings, for example different sub-populations or different but related indications.</p>
<p>Dose Response Model This is a model used in the statistical analysis of the final response as a function of the treatment dose. FACTS includes both parametric and non-parametric models including ‘no model’.</p>
<p>Endpoint An endpoint is a measure of the subject’s health that is being analyzed in order to learn about the effects of the treatments being studied in the trial.</p>
<p>FACTS Fixed and Adaptive Clinical Trial Simulator</p>
<p>Final Endpoint The final value, or state, of a subject’s endpoint.</p>
<p>Group The very neutral term ‘groups’ is used in ED, because the ED design could be used in a number of different settings. The groups could be for instance different patient sub-populations with the same disease, different disease sub-populations such as different sarcoma types, or even different but related diseases that the same treatment might be effective against (migraine, dental pain and post-operative pain for instance). The key characteristic is that there is a need to study each independently (with their own control) but also look across the different groups for some purpose – this might be for analysis where there is an expectation of commonality in response on control, or in the difference from control on the treatment arms; or operationally where there is limited budget, drug supply or time across the groups; or for the purposes of decision making – where the treatment has to be successful in more than one group to be worth considering for further development.</p>
<p>GUI Graphical User Interface, the part of the FACTS application that the user interacts with.</p>
<p>Historic Control A ‘historic control’ is where no control arm is included in the study, and the response on the arms where the novel treatment administered is compared to data from control arms from other already complete studies.</p>
<p>Imputation When the Bayesian statistical models are fitted to the simulated data within FACTS, if longitudinal modeling has been included, then multiple imputation is used for missing subject final endpoint values, whether missing due to the subject having dropped out or their final visit simply not occurred yet. The value is separately sampled at each iteration of the MCMC, from the posterior distribution of the longitudinal model, given the subject’s interim endpoint values.</p>
<p>Interim Visit A visit between the baseline visit and final visit, at which a subject’s endpoints are measured.</p>
<p>Intermediate Endpoint The value of a subject’s endpoint at a visit after their baseline visit, but before their final visit. Intermediate endpoint values can be used to estimate, using a longitudinal model, what the subject’s final endpoint will be (or would have been) thus providing additional information for analysis. Multiple imputation is used ensure that these estimated responses are included in the analysis with the correct weighting.</p>
<p>Longitudinal Model An analysis model that models the relationship between a subject’s interim endpoint values and their final endpoint value, that can be used to impute their final endpoint value when it is not available.</p>
<p>Method In the FACTS documentation we try to reserve the term ‘method’ for the algorithms used in the simulation (as opposed to the analysis) part of the program. In the analysis part we use the term ‘Model’, see below.</p>
<p>Model In the FACTS documentation we try to reserve the term ‘model’ for the statistical models used in the analysis of the trial data (in the ‘design’ section of the FACTS user interface). Where mathematical algorithms are used for other purposes in FACTS (for instance in the generation of the simulated data) we try to use the term ‘method’. We have found that initially it is very easy for users to be confused between these two parts of FACTS and we feel that using distinct terminology may help to reduce this.</p>
<p>Profile A profile is a specification of one aspect of a scenario. A scenario is made up of one profile of each of the required types for the type of trial being simulated. FACTS allows the user to specify multiple profiles of each type and then presents all the possible combinations of profiles as scenarios that can be used to drive simulations.</p>
<p>QOI</p>
<p>Quantity of Interest (QOI) A value to be calculated because it is of interest. The quantity may be of interest because it is to be used in an interim decision, to adapt allocation, for final evaluation, or to ensure it is value is written out in the FACTS results files for analysis outside of FACTS.</p>
<p>Response The change in a subject’s endpoint compared to their baseline state.</p>
<p>Scenario A scenario is the complete specification of the unknown external factors that determine the data observed on the trial and its timing. The exact factors depend on the type of trial being simulated but typically include:</p>
<blockquote class="blockquote">
<p>the distribution of the final change from base line, or probability of response or rate of events in the different treatment groups,</p>
<p>the properties of subjects’ early responses and the correlation with their final outcome,</p>
<p>the rate at which subjects are recruited into the trial,</p>
<p>the rate at which subjects drop out of the trial.</p>
</blockquote>
<p>SPEC The Design Engine Specification describes the system algorithms, and meaning of parameters.</p>
<p>Subject Someone recruited onto a clinical trial for the purposes of learning about the properties of a treatment. Depending on the type of trial they might be patients or they might be healthy volunteers.</p>
<p>Treatment Arm Subjects on entering the study are randomized to different ‘treatment arms’. Subjects randomized to the same arm receive the same treatment and the responses of the subjects in the arm analyzed to determine the expected response to that treatment, allowing the expected responses to the different treatments to be compared.</p>
<p>UG The User Guide, describes how to use the system.</p>
</section>
<section id="references" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="references"><span class="header-section-number">2.6</span> References:</h2>
<p>[Dunnett] Dunnett CW.&nbsp;A multiple comparison procedure for comparing several treatments with a control.&nbsp;Journal of the American Statistical Association&nbsp;1955;&nbsp;50: 1096–1121.</p>
</section>
</section>
<section id="facts-core-overview" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> FACTS Core Overview</h1>
<p>For an overview of the form entry and layout, see the User Guide for the Core Engine of the particular endpoint that you are using for your trial.</p>
<p>FACTS Core is for simulating trials where there are a number of related treatments being tested against a common control arm. Commonly, these different treatments will be different doses of the same drug and hence dose-response modelling is justifiable. If the treatments do not differ by dose but in some other way such as dosing frequency or treatment combination, then analysis can be by pairwise comparison with control, this is referred to as the ‘No model’ option.</p>
<p>FACTS provides numerous options for the statistical analysis, some of them straight forward, some of them quite novel, though all have been used in actual trials:</p>
<ul>
<li><p>The endpoint can be continuous, dichotomous or time to event.</p></li>
<li><p>As well as a control arm, the study arms can be compared with an active comparator.</p></li>
<li><p>With either a dichotomous or continuous endpoint, longitudinal models can used to impute the patient’s likely final outcome from early interim measures. This can be used when final endpoint data is missing due to subject drop-out or at interims for subjects who’ve not reached their final endpoint yet.</p></li>
<li><p>Estimation of the response on the control arm can be augmented using a hierarchical model to borrow from data from previous studies (This is known as Bayesian Augmented Control, BAC).</p></li>
<li><p>Interims can be specified at fixed intervals by time, the number of subjects recruited or the number of events observed.</p></li>
<li><p>At interims, options include:</p>
<ul>
<li><p>Choosing to stop the whole study for success or futility.</p></li>
<li><p>Dropping treatment arms</p></li>
<li><p>Adapting the randomization proportions to favor allocating to the doses that are most likely to be the desired target – which can be the study arm with the maximum response, the EDx, or minimum efficacious dose.</p></li>
</ul></li>
</ul>
<section id="facts-7.1-changes-to-facts-core" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="facts-7.1-changes-to-facts-core"><span class="header-section-number">3.1</span> FACTS 7.1 Changes to FACTS Core</h2>
<p>In FACTS 7.1 FACTS Core and FACTS Staged Design for all endpoints:</p>
<ol type="1">
<li>There is a new Quantity of Interest: a frequentist Conditional Power, that can be calculated for the current trial or a specified future trial.</li>
</ol>
<p>For Dichotomous endpoints only:</p>
<ol type="1">
<li><p>For p-value QOIs, users can now choose whether they should be derived using a normal approximation (this is the default option and was used in all previous versions of FACTS) or a Fisher’s exact test.</p></li>
<li><p>There is new Bayesian analysis model for dichotomous endpoints: “Beta-Binomial”, this is only available as an independent dose model, it cannot be combined with any dose response models.</p></li>
</ol>
</section>
<section id="facts-7.0-changes-to-facts-core" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="facts-7.0-changes-to-facts-core"><span class="header-section-number">3.2</span> FACTS 7.0 Changes to FACTS Core</h2>
<p>In FACTS 7.0 FACTS Core and FACTS Staged Design:</p>
<ol type="1">
<li><p>FACTS Core Continuous, Dichotomous and Multiple Endpoint no longer hav a requirement that there at least two arms in a trial and can simulate single arm trials without requiring ‘fake’ control or second arms. Both Bayesian posterior probability and p-value QOI’s can be evaluated comparing against an absolute response.</p></li>
<li><p>A change that breaks backwards compatibility: FACTS used to be inconsistent in the time units it used for the patient accrual date using days (rather than weeks, which is the time unit used everywhere else). FACTS now outputs the patient accrual date in weeks and expects it to be input in weeks (see the analysis tab and deterministic accrual option).</p></li>
</ol>
</section>
<section id="facts-6.5-changes-to-facts-core-design-options" class="level2" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="facts-6.5-changes-to-facts-core-design-options"><span class="header-section-number">3.3</span> FACTS 6.5 Changes to FACTS Core Design options</h2>
<p>FACTS 6.5 Core:</p>
<ul>
<li><p>In FACTS Core and Staged Continuous, Dichotomous and Multiple Endpoint there is a new option for p-value QOIs to be evaluated with a super-superiority or non-inferiority delta, and for current trial predictive probabilities the same delta is assumed for the prediction of success.</p></li>
<li><p>In FACTS Core and Staged Time-to-Event:</p>
<ul>
<li><p>With a Time-to-Event predictor, the timing of interims can be governed by the number of predictor events observed.</p></li>
<li><p>With a Time-to-Event predictor the file termination can be governed by the number of predictor events observed.</p></li>
<li><p>With any predictor it is possible to disable the use of the predictor model to predict event times for those patients who have not yet observed an event. The Bayesian analysis of the two endpoints is thus completely de-coupled.</p></li>
</ul></li>
</ul>
</section>
<section id="facts-6.4-changes-to-facts-core-design-options" class="level2" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="facts-6.4-changes-to-facts-core-design-options"><span class="header-section-number">3.4</span> FACTS 6.4 Changes to FACTS Core Design options</h2>
<p>FACTS 6.4 Core:</p>
<ul>
<li><p>introduces three new models: the Hierarchical, Linear, and Hierarchical Linear models. The Linear model subsumes the 2-parameter logistic model for dichotomous data.</p></li>
<li><p>Adds options to dichotomous and time-to-event endpoints to allow posterior probability QOIs to be evaluated on the comparison of log-odds or hazard rate (as an alternative to pre-existing comparison of rates or hazard ratio)</p></li>
</ul>
</section>
<section id="facts-6.3-changes-to-facts-core-design-options" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="facts-6.3-changes-to-facts-core-design-options"><span class="header-section-number">3.5</span> FACTS 6.3 Changes to FACTS Core Design options</h2>
<p>In FACTS 6.3 FACTS Core there are 3 new 2D dose response models – 2 factorial models and a 2D-NDLM response model.</p>
</section>
<section id="facts-6.2-changes-to-facts-core-design-options" class="level2" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="facts-6.2-changes-to-facts-core-design-options"><span class="header-section-number">3.6</span> FACTS 6.2 Changes to FACTS Core Design options</h2>
<p>There were no changes to the Core Design options in DACTS 6.2.</p>
</section>
<section id="facts-6.1-changes-to-facts-core-design-options" class="level2" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="facts-6.1-changes-to-facts-core-design-options"><span class="header-section-number">3.7</span> FACTS 6.1 Changes to FACTS Core Design options</h2>
<p>In FACTS 6.1 FACTS Core has the new feature of ‘design variants’ that allow the user to easily simulate and evaluate FACTS Core design at different sample sizes. This change doesn’t alter the design options – but it does make it much easier to explore the effect of the change of sample size on a design.</p>
<p>There are two additional changes concern frequentist calculations:</p>
<ol type="1">
<li><p>Better control over which frequentist analyses are computed and output. There is now no longer a need to ‘enable’ frequentist analysis; the user can just select which ones are required.</p></li>
<li><p>The ability to use p-values for early stopping decisions at interims – if there is too little final data to compute a p-value the values of ‘1’ is returned.</p></li>
</ol>
<p>And there is one change that effects TTE QOIs (Quantities of Interest), it is now possible to specify Target QOIs that use the predictor endpoint in a TTE design.</p>
</section>
</section>
<section id="simulating-virtual-subjects" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Simulating Virtual Subjects</h1>
<section id="subject-responses" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="subject-responses"><span class="header-section-number">4.1</span> Subject Responses</h2>
<p>The methods used to simulate subject responses vary by endpoint type. For each endpoint, the endpoint specific user guides provide information about simulating subject responses.</p>
<p>For simulating dichotomous responses see: FACTS Core Dichotomous User Guide</p>
<p>For simulating continuous responses see: FACTS Core Continuous User Guide</p>
<p>For simulating time to event responses see: FACTS Core Time-to-Event User Guide</p>
<p>For simulating multiple endpoint responses see the continuous or dichotomous user guide, depending on the type of endpoints used in the multiple endpoint study.</p>
</section>
<section id="accrual" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="accrual"><span class="header-section-number">4.2</span> Accrual</h2>
<p>The Accrual sub-tab provides an interface for specifying accrual profiles; these define the mean recruitment rate week by week during the trial. During the simulation, the simulator uses a Poisson process to simulate the random arrival of subjects with the specified mean accrual rate.</p>
<p>Accrual profiles are list on the left of the screen, as depicted below. These accrual profiles may be renamed by double-clicking on them, and typing a new profile name. After creating a profile, the user must create at least one recruitment region. Early in the trial design process, detailed simulation of the expected accrual pattern is typically not necessary and a single region with a simple mean accrual rate is sufficient.</p>
<p>To model more accurately the expected accrual rates over the trial, the user may specify multiple regions for each accrual profile and separately parameterize them. Regions are added via the table in the center of the screen (Figure 7‑1). Within this table, the user may modify:</p>
<ul>
<li><p>the peak, mean weekly recruitment rate,</p></li>
<li><p>the start date (in weeks from the start of the trial) for this recruitment region,</p></li>
<li><p>whether the region will have a ramp up phase and if so when the ramp up will be complete (in weeks from the start of the trial).</p></li>
<li><p>Whether the region will have a ramp down, and if so when the ramp down start and when the ramp down will complete (in weeks from the start of the trial).</p></li>
</ul>
<p>Ramp up/ramp down define simple linear increase/decreases in mean recruitment rate from the start to the end of the ramp. Note that simulation of accrual is probabilistic but ramp downs are defined in terms of time, so even if ramp downs are planned so that at the average accrual rate they will occur as the trial reaches cap, there is a risk in simulations when accrual has been slower than average, that ramp downs occur before the full sample size is reached. It is advisable to have at least one region that doesn’t ramp down to prevent simulations being unable to complete.</p>
<p>A graph of the recruitment rate of the highlighted region is shown as well. As the recruitment parameters are changed, the graph will update to show the time at which full accrual is reached. An accrual profile that does not reach full accrual is invalid and cannot be used to run simulations.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image2.png" style="width:5.44318in;height:4.13315in" alt="A screenshot of a social media post Description automatically generated"></p>
<p>In the screenshot above you can see the two step ramp up in accrual from two regions – each starting at different offsets into the trial.</p>
<p>Note that the accrual profile graph is only the mean expectation; actual accrual is simulated using exponential distributions for the intervals between subjects, derived from the mean accrual profile specified here. Thus some simulated trials will recruit more quickly than this and some more slowly.</p>
<p>There are commands to import and export region details from/to simple external XML files. When importing, the regions defined in the external file are <strong>added</strong> to the regions already defined, they don’t replace them.</p>
<p>This is an example of a very simple region file defining just one region:</p>
<p>&lt;?xml version=“1.0” encoding=“utf-8”?&gt;</p>
<p>&lt;regions&gt;</p>
<p>&lt;region&gt;</p>
<p>&lt;name&gt;Region 1&lt;/name&gt;</p>
<p>&lt;rate&gt;5&lt;/rate&gt;</p>
<p>&lt;start&gt;0&lt;/start&gt;</p>
<p>&lt;ramp-up /&gt;</p>
<p>&lt;ramp-down /&gt;</p>
<p>&lt;/region&gt;</p>
<p>&lt;/regions&gt;</p>
<section id="deterministic-accrual" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="deterministic-accrual"><span class="header-section-number">4.2.1</span> Deterministic Accrual</h3>
<p>If “Deterministic” accrual has been specified on the Study &gt; Study Info tab, then on the Accrual tab, rather that specifying an accrual profile from which subject recruitment times are simulated, the user loads a file of specific accrual dates for every subject.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image3.png" style="width:5.00179in;height:3.85875in"></p>
<p>The user specifies a “.dat” file to load that contains the subject accrual dates in weeks[2] from the start of the trial.</p>
<p>The required file format is a text file with comma separate values. One row per subject, with 3 fields on each row:</p>
<ol type="1">
<li><p>the subject ID, (an integer)</p></li>
<li><p>the ID of the region where the subject was recruited (an integer)</p></li>
<li><p>and the subjects randomization date (in weeks from the start of the trial – this is a ‘real’ number allowing fractions of a week to be specified)</p></li>
</ol>
<p>The file must contain sufficient entries to allow the maximum number of subjects specified on the Study &gt; Study Info tab to be recruited.</p>
<p>After successfully loading a file, the FACTS GUI shows a plot of the resulting weekly accrual rate</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image4.png" style="width:5.00179in;height:3.85875in"></p>
</section>
</section>
<section id="drop-out-rates" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="drop-out-rates"><span class="header-section-number">4.3</span> Drop-out Rates</h2>
<p>For the continuous and dichotomous engines, and the multiple endpoint engine, the default dropout scenario is that no subjects drop out of the study before observing their final endpoint data. If dropouts are expected, the user can specify either the “Dropouts per Dose,” or “Dropouts per Dose per Visit.”</p>
<p>If “Dropouts per Dose” is selected, then each subject has a probability of not having an observable final endpoint value equal to the dropout rate of the dose that subject is randomized to. If each subject has multiple visits and “Dropouts per Dose” is selected, then the conditional probability of dropping out before each visit given that the subject had not dropped out up to the visit before rates are all equal. In other words, if the total dropout rate is <em>π</em><sub><em>D</em></sub>, the probability of dropping out between visits <em>i</em> and <em>i</em> + 1 given that the subject had not dropped out at visit <em>i</em> is <span class="math inline">\(1 - \left( 1 - \pi\_{D} \right)^{\frac{1}{V}}\)</span> where <em>V</em> is the total number of visits.</p>
<p>If “Dropouts per Dose per Visit” is selected, then each subject has a user specified probability of dropping out before a visit <em>v</em> that is specified as the conditional probability of dropping out before visit <em>v</em> given that that they had not dropped out by visit <em>v</em> − 1. This leads to a total dropout rate <em>π</em><sub><em>D</em></sub> for a participant that is equal to:</p>
<p><span class="math display">\[\pi\_{D} = 1 - \prod\_{v = 0}^{V}{(1 - \pi\_{v})}\]</span></p>
</section>
</section>
<section id="quantities-of-interest-qoi" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Quantities of Interest (QOI)</h1>
<p>The quantities of interest tab allows the user to specify the Bayesian posterior probabilities and Frequentist p-values to be calculated and reported in the simulation results and available for use in early stopping decisions, trial adaptations and final evaluation.</p>
<p>There are 3 classes of QOI</p>
<ol type="1">
<li><p>A probability calculated independently <strong>for each dose</strong>, there are 3 types of comparison:</p>
<ol type="1">
<li><p>The posterior probability that the estimate of the response of the subjects on that dose is better/worse than an absolute value or the estimate of response of the subjects on a reference dose, such as Control.</p></li>
<li><p>The predictive probability of success (achieving frequentist statistical significance) in the current trial or a future trial comparing the estimate of response on the dose against that on the Control arm.</p></li>
<li><p>P-values for each dose comparing the estimate of response on that dose against that on the Control arm.</p></li>
</ol></li>
<li><p>Probabilities calculated across the doses for which dose is most likely to satisfy a specified <strong>target dose</strong> criteria – that is the dose with the maximum effect, that it is the minimum dose that achieves some minimum success in the estimate of response of the subjects on that dose, that it is the EDq – the dose that achieves some proportion of the overall maximum dose response.</p></li>
<li><p>A <strong>decision quantity</strong> – which is the value of a comparison probability for a specific target dose. For instance the probability that the response on the MED is better than that of the Active Comparator.</p></li>
</ol>
<p>Decisions are made on decision quantities and adaptation can be based on posterior probabilities, predictive probabilities and target probabilities.</p>
<p>Note that to create a QOI for early stopping or final evaluation decisions will usually involve using 3 QOIs:</p>
<ol type="1">
<li><p>The probability to be tested e.g.&nbsp;the probability of being better than the Control by a clinically significant difference.</p></li>
<li><p>The target dose criteria for selecting the dose that is to be used in the test – e.g.&nbsp;the ED90.</p></li>
<li><p>The decision quantity that combines 1 &amp; 2 – e.g.&nbsp;the probability that the ED90 is better than Control by a clinically significant difference.</p></li>
</ol>
<p>There are a number of pre-defined, default QOIs which simplifies the specification of the most commonly used decision quantities, and the importation of past FACTS designs. These are:</p>
<p><strong>Default Posterior Probabilities</strong></p>
<ul>
<li><p>The probability of being better than the control arm: “<strong>Pr(θ_d &gt; θ_(Control))</strong>”, previously referred to as “Pr(θ<sub>d</sub> – θ<sub>0</sub>)”, “Pr(Pbo)” and “Prob. Beats Ctrl” in earlier versions of FACTS.</p></li>
<li><p>The probability of being better than the control arm by a clinically significant difference “<strong>Pr(θ_d - θ_(Control) &gt; <em>nn</em>)</strong>”, previously referred to as “Pr(θ<sub>d</sub> – θ<sub>0</sub>&gt;CSD)”, Pr(CSD) and “Prob. Beats CSD” in earlier versions of FACTS. The value for the “nn” is the CSD which is set in the “Standard Evaluation Variables” panel at the bottom of the QOI tab.</p></li>
</ul>
<p><strong>Default Predictive Probabilities</strong></p>
<ul>
<li>The probability of success in a future trial “<strong>Pr(Succ. Future Trial): N=<em>nnn</em>, <em>Sup/Noninf</em>, α=<em>n.nnn</em>; δ=<em>n</em></strong>”, previously referred to as Pr(S Phase III) and “Prob. Stat Sig” in earlier versions of FACTS”. The parameters for the future trial can be set by clicking on the QOI’s row in the table.</li>
</ul>
<p><strong>Default Target Doses</strong></p>
<ul>
<li><p>The probability for each dose that it is the dose with the maximum response, “<strong>Pr(Max)</strong>”, previously referred to as d<sub>max</sub> and Ppn Max in earlier versions of FACTS. When used to select a dose in a decision quantity the label “… <strong>d= Greatest Pr(MAX)</strong>” is used.</p></li>
<li><p>The probability for each dose that it is the minimum dose that is better than Control by the specified CSD, “<strong>Pr(MED relative to Control: Delta = <em>nn</em>)</strong>”, previously referred to as “Ppn (MED)” in earlier versions of FACTS. The CSD used for comparison is specified in the Evaluation Variables panel at the bottom of the QOI tab. When used to select a dose in a decision quantity the label “<strong>d= Greatest Pr(MED relative to <em>ControlActive Comparator</em>: Delta = <em>nn</em>)</strong>” is used.</p></li>
<li><p>The minimum dose that gives a certain proportion of the maximum estimated response “pr(<strong>EDq relative to Control: Quantile=n.n)</strong>”, previously referred to as “d<sub>EDx</sub>” and “Ppn(EDx)” in earlier versions of FACTS. The Effective Dose quantile to use can be modified by the clicking on QOI’s row in the table. When used to select a dose in a decision quantity “… <strong>d=Greatest PR(EDq relative to Control: Quantile=n.n)</strong>” is used.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image5.png" style="width:6.14271in;height:4.66432in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>In each panel for each type of quantity, existing quantities can be deleted by clicking on the <img src="coreUGattachments/CoreUserGuide/media/image6.png" style="width:0.32292in;height:0.23958in"> at the end of the corresponding row. Each quantity’s definition can be displayed and edited (only edited for the default QOIs) by clicking on the row displaying the quantity’s definition. A new quantity can be defined by clicking on the bottom row of the corresponding panel labelled “Add…”.</p>
<section id="posterior-probabilities" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="posterior-probabilities"><span class="header-section-number">5.1</span> Posterior Probabilities</h2>
<p>These are Bayesian quantities to be calculated at each interim and at the final analysis.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image7.png" style="width:3.59231in;height:2.61812in"></p>
<p>A Posterior Probability is specified as:</p>
<ul>
<li><p>Compare:</p>
<ul>
<li><p>Continuous: Means</p></li>
<li><p>Dichotomous: Rates or Log-odds</p></li>
<li><p>Time-to-Event: Hazard Ratio or Hazard Rates.</p></li>
</ul></li>
</ul>
<!-- -->
<ul>
<li><p>Condition: “&gt;” or “&lt;” a comparison value.</p></li>
<li><p>Relative to an absolute value or relative to the response on a <em>specific</em> dose.</p></li>
<li><p>The comparison can include a delta, which is the absolute value to be compared against if the comparison is absolute, or a value that the difference relative to the comparison arm is compared to.</p></li>
<li><p>The QOI will be given a “name” derived from these details and a short or Alternative name that will be used in the output files to allow easier access from other software, e.g.&nbsp;from within R.</p></li>
<li><p>If the endpoint is TTE and the design includes a predictor endpoint, then the definition of the QOI includes the specification of which endpoint it applies to.</p></li>
</ul>
<section id="notes-on-setting-deltas" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="notes-on-setting-deltas"><span class="header-section-number">5.1.1</span> Notes on setting Delta’s</h3>
<p>In the three endpoints delta’s are defined as:</p>
<ul>
<li><p>Continuous A CSD (Clinically Significant Difference) in the estimates of the mean response.</p></li>
<li><p>Dichotomous A CSD in the estimate of the response rates</p></li>
<li><p>Time-to-Event A CSHRD (Clinically Significant Hazard Ratio Difference) in the estimate of the Hazard Ratio</p></li>
</ul>
<p>A “standard” hypothesis test for demonstrating superiority to control uses a delta of 0. Testing for superiority with a non-zero delta is different, and the implications need to be carefully understood[3]. Where the term CSD is used in this document, it should be taken to refer to CSHRD as well unless it is specifically stated otherwise.</p>
<p>When setting a target treatment difference from control for the study to beat, it is also common to require a degree of confidence that the target has been beaten. To achieve posterior probabilities of &gt; 50% that the target has been beaten, the estimated mean difference will have to be <strong>greater</strong> than the target difference.</p>
<p>Thus, when setting a delta, we are setting up two hurdles the study drug must beat, first the delta and then on top of that an additional margin to give a &gt; 50% confidence that the margin has been beaten. Thus, it is necessary to avoid setting the target delta too large. A common rookie error is to set the delta to the ‘expected difference’ (the value that might have been used in a conventional sample size calculation). In scenarios where the simulated response is equal to the ‘expected difference’ and hence the CSD this will give probabilities of being better than control by the delta of 50% on average, regardless of the sample size.</p>
<p>It is inadvisable to require a posterior probability of 50% or better than the response is better than the Control by the delta as this turns the test into one that simply depends on whether the point estimate of the response is better.</p>
<p>It is inadvisable to require posterior probability of less than 50% for success, as such criteria have the undesirable characteristic that they can be met in circumstances where it can be seen that if further data was gathered consistent with what has already been seen, it would lead the threshold no longer being met! The posterior distribution would shrink so that there was no longer sufficient of the tail above the CSD.</p>
<p>It is better therefore to use a delta that is less than the expected difference that it is hoped to achieve, somewhat like having a non-inferiority margin around the target. So, when the design is simulated with a response at the expected difference the target will be clearly exceeded. A useful default value to use for a delta is half the ‘expected difference’. This usually yields “comprehensible” probability thresholds for both success and futility.</p>
<p>Using a delta has benefits however – simply being better than control but for very small difference can be established simply by having large sample sizes. Being better than control by a delta establishes some confidence that there is some patient benefit. Use of a delta is also useful if otherwise success thresholds “well out in the tail” (e.g.&nbsp;&gt; 0.99) are required such as the equivalent of an early look in a conservative Group Sequential design. Though the use of a delta does mean that there is a less direct equivalence to a p-value.</p>
</section>
<section id="p-value-deltas" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="p-value-deltas"><span class="header-section-number">5.1.2</span> P-value Delta’s</h3>
<p>Separately from the CSD/CSHRD delta, with a continuous or dichotomous endpoint (but not time-to-event), a frequentist super-superiority/non-inferiority delta can be specified.</p>
<p>These use the same selection of super-superiority/non-inferiority as the CSD</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image8.png" style="width:4.06126in;height:1.06908in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>Currently, unlike the CSD delta that is only applied to the default posterior probability QOI and MED target QOI, the p-value delta is applied to <strong>all</strong> the p-value QOIs and it cannot be overridden.</p>
<p>The value of the p-value delta is constrained to be 0 or positive. The ‘direction’ of the delta depends then on the direction of the endpoint (whether “higher/lower is better” or “a response is a positive/negative outcome”.</p>
<table class="table">
<caption>
<p>
Figure 8‑1: Accrual
</p>
</caption>
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>
</th>
<th>
Higher is better / Response is positive
</th>
<th>
Lower is better / Response is negative
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
Super-Superiority
</td>
<td>
Trt – Control &gt; delta
</td>
<td>
Trt – Control &lt; -delta
</td>
</tr>
<tr class="even">
<td>
Non-inferiority
</td>
<td>
Trt – Control &gt; -delta
</td>
<td>
Trt – Control &lt; delta
</td>
</tr>
</tbody>
</table>
<p>Figure 8‑1: Accrual</p>
<p><strong>Sign of delta and direction of test</strong></p>
<p>If no control arm is included p-values, with a continuous or dichotomous endpoint, the treatment response is compared to a fixed value:</p>
<ul>
<li><p>Continuous – compared to a response of 0.</p></li>
<li><p>Dichotomous – compared to a rate of 0.5.</p></li>
</ul>
<p>Now with p-value deltas the p-value QOIs (and current trial predictive probability QOIs) can be compared to any fixed value – by specifying a delta that combined with the default value (of 0 or 0..5) gives the absolute value that you want to compare to.</p>
</section>
</section>
<section id="predictive-probabilities" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="predictive-probabilities"><span class="header-section-number">5.2</span> Predictive Probabilities</h2>
<p>There are two types of predictive probabilities –</p>
<ol type="1">
<li><p>Bayesian predictive probabilities, which are Bayesian predictions of frequentist outcomes and take into account the uncertainty around a set of parameters,</p></li>
<li><p>and conditional power, which aims to calculate the frequentist probability of success assuming a set of parameters to be true.</p></li>
</ol>
<p>The primary difference between the Bayesian predictive probabilities and the conditional power calculations is that the Bayesian predictive probabilities are calculated taking the variability around the estimated treatment effect into account, while the conditional power calculations assume that the observed test statistic of past data is the exact effect that future data will be generated from.</p>
<p>For both Bayesian predictive probabilities and conditional power, we differentiate two types, predicting the outcome in the current trial and predicting the outcome in a future trial.</p>
<section id="bayesian-predictive-probabilities" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="bayesian-predictive-probabilities"><span class="header-section-number">5.2.1</span> Bayesian predictive probabilities</h3>
<section id="current-trial-bayesian-predictive-probabilities" class="level4" data-number="5.2.1.1">
<h4 data-number="5.2.1.1" class="anchored" data-anchor-id="current-trial-bayesian-predictive-probabilities"><span class="header-section-number">5.2.1.1</span> Current Trial Bayesian Predictive Probabilities</h4>
<p>In the current trial, the outcome can be predicted under one of two assumptions:</p>
<ol type="1">
<li><p>That no new subjects are recruited, but all those who have been recruited are followed up until they are complete.</p></li>
<li><p>That the trial continues recruiting using the current allocation ratios until the trial maximum sample size is reached, and all subjects recruited are followed up until complete.</p></li>
</ol>
<p>Predictive probabilities currently can only predict outcomes based on p-values. Note that since p-values are only calculated as comparisons against a control arm, predictive probabilities of success in the current trial are only available if the current trial includes a control arm.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image9.png" style="width:2.64056in;height:2.61544in"></p>
<p>The user specifies how missingness is handled in the final analysis, the p-value test type – unadjusted, Bonferroni or Dunnett’s and the (one sided) alpha level for the significance test. The QOI assumes that the specified default p-value delta is used in the final test.</p>
<p>The predictive probability of the current trial at the maximum sample size is only available:</p>
<ul>
<li>If the allocation is either fixed, or fixed with arm dropping, but not adaptive allocation.</li>
</ul>
<p>The predictive probability is calculated by simulating the remaining subjects, assuming their allocated at the current probabilities of allocation and simulating their final response based on the rate of response or (Normal) distribution of responses observed so far for each arm.</p>
<ul>
<li><p>Ignoring the possibility of the trial stopping or dropping an arm at a future interim</p></li>
<li><p>Ignoring the possibility of future subject drop-outs.</p></li>
</ul>
<p>There is one simulation of the remaining data per MCMC loop, potentially significantly increasing the time to perform the overall simulation of the trial.</p>
<p>If there is no data available on the arms involved in the Bayesian predictive probability calculation, FACTS will still perform the simulation of future subject outcomes based on posterior distribution. The posterior distribution for the arms with no available data will be the same as the user specified prior distribution.</p>
</section>
<section id="current-trial-bayesian-predictive-probabilities-time-to-event" class="level4" data-number="5.2.1.2">
<h4 data-number="5.2.1.2" class="anchored" data-anchor-id="current-trial-bayesian-predictive-probabilities-time-to-event"><span class="header-section-number">5.2.1.2</span> Current Trial Bayesian Predictive Probabilities – Time-to-Event</h4>
<p>Unlike the Continuous and Dichotomous endpoints, to predict the probability of success at full enrolment with a Time-to-Event endpoint, it is also necessary to simulate the accrual rate (and hence how many events might be observed).</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image10.png" style="width:2.94043in;height:2.92636in"></p>
<p>For TTE, for a Predictive Probability of Success at Full Enrolment, there are new parameters to determine how accrual is modelled. There are 3 models for accrual</p>
<ul>
<li><p>Fixed Rate, the parameters for this are:</p>
<ul>
<li>The fixed (mean) accrual rate per week to simulate.</li>
</ul></li>
<li><p>Estimated from the Last ‘W’ Weeks accrual data, using a Poisson distribution, with a Gamma prior. The parameters for this are</p>
<ul>
<li><p>The number of past weeks W to use the accrual data from.</p></li>
<li><p>The prior mean for the model of the accrual rate</p></li>
<li><p>The weight of the prior</p></li>
</ul></li>
<li><p>Estimated from all the accrual data from the start of the trial, using a Poisson distribution, with a Gamma prior, the parameters for this are:</p>
<ul>
<li><p>The prior mean for the model of the accrual rate</p></li>
<li><p>The weight of the prior</p></li>
</ul></li>
</ul>
</section>
<section id="future-trial-bayesian-predictive-probabilities" class="level4" data-number="5.2.1.3">
<h4 data-number="5.2.1.3" class="anchored" data-anchor-id="future-trial-bayesian-predictive-probabilities"><span class="header-section-number">5.2.1.3</span> Future Trial Bayesian Predictive Probabilities</h4>
<p>For predictive probabilities for a future trial, a predictive probability of success in a subsequent phase 3 trial is estimated during the current trial. The probability of success in phase 3 is calculated for each study arm, based on the specification of the phase 3 trial given here of:</p>
<ul>
<li><p>whether the aim is to show superiority or non-inferiority,</p></li>
<li><p>the sample size per arm,</p></li>
<li><p>the required one-sided alpha,</p></li>
<li><p>and the super-superiority margin or non-inferiority margin (if any).</p></li>
</ul>
<p>Given these criteria, FACTS calculates the predicted probability of success of the subsequent trial for that endpoint assuming the estimate of the response on that endpoint, integrated over the uncertainty in those estimates. The conventional expected power of the specified future trial is calculated for the treatment effect in each MCMC sample and then averaged. This predicted probability of success can then be used in the stopping criteria and final evaluation criteria for the current trial.</p>
<p>This QOI is an extension of the “probability of success in phase 3” in earlier versions of FACTS – the difference now is that multiple different possible future trials can be specified in different QOIs and used for different decisions.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image11.png" style="width:3.21594in;height:3.21594in"></p>
<p>This predictive probability has the following parameters that must be specified:</p>
<ul>
<li><p>Whether the future trial will be for Superiority or Non-inferiority.</p></li>
<li><p>The size of the future trial in terms of the number of subjects on each arm.</p></li>
<li><p>The (one sided) alpha level that will be used to determine the significance of the trial.</p></li>
<li><p>The Super-superiority margin (if any) or the non-inferiority margin. The default p-value delta is <strong>not</strong> used for this QOI it is specified as part of the QOI and can be different from the default.</p></li>
</ul>
<p>As with all QOIs the QIO will be given an alternative shorter name that can be used when accessing the output files from other software such as R.</p>
<p>If there is no data available on the arms involved in the Bayesian predictive probability calculation, FACTS will still calculate the predictive probability of the future trial being a success based on the estimated posterior distribution. The posterior distribution for the arms with no available data will be the same as the user specified prior distribution.</p>
</section>
</section>
<section id="conditional-power" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="conditional-power"><span class="header-section-number">5.2.2</span> Conditional Power</h3>
<p>Conditional power is currently available for Continuous and Dichotomous endpoints in Core and Staged Designs.</p>
<p>When creating a Conditional Power QOI, the first specification that must be made is whether the conditional power should be calculated for the current trial or for a hypothetical future trial. The two selections are fundamentally different.</p>
<p>The Current Trial conditional power takes the information collected in the trial so far, and assumes that for the remainder of the current trial the data collected has an effect equal to the point estimate of the already collected data. The previously collected trial data is then combined with hypothetical future data and weighted based on the amount of information that has been and will be observed by the end of the trial. The result is the probability that the current trial will reject the null hypothesis at a provided alpha level under the assumption that the future patients are generated from a population having a treatment effect exactly equal to the past data’s test statistic.</p>
<p>The Future Trial conditional power also uses the information accrued in the trial so far to calculate the assumed treatment effect moving forward, but assumes that a new study would be started that does not use the data from the current trial in its analysis. The new study is assumed to be a 1:1 randomized study if there is a control arm, and a single arm study if no control, with a sample size per arm, objective, and alpha level specified at the time of QOI creation.</p>
<p>If a conditional power is ever calculated for an arm with no final response data or against a control arm with no final response data, the conditional power will be called missing (-9999 in FACTS).</p>
<section id="current-trial-conditional-power" class="level4" data-number="5.2.2.1">
<h4 data-number="5.2.2.1" class="anchored" data-anchor-id="current-trial-conditional-power"><span class="header-section-number">5.2.2.1</span> Current Trial Conditional Power</h4>
<p>When creating a current trial conditional power, the missingness strategy, multiplicity adjustment, final sample size, and alpha level for the significance test must be specified.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image12.png" style="width:2.61858in;height:2.61544in"></p>
<section id="handle-missingness-using" class="level5">
<h5 class="anchored" data-anchor-id="handle-missingness-using">Handle missingness using:</h5>
<p>Missingness handling for a continuous endpoint can be specified as:</p>
<ul>
<li><p>Ignore: subjects that are known dropouts are not included in the current or final sample size, and are not used to estimate the treatment effect.</p></li>
<li><p>Last Observation Carried Forward (LOCF): subjects that are known dropouts have their last observed endpoint value assumed to be their final endpoint. Subjects with no early observed data are ignored. Subjects that have data to carry forward are considered complete, and are used to estimate the current treatment effect.</p></li>
<li><p>Baseline Observation Carried Forward (BOCF): subjects that are known dropouts have their baseline value assumed to be their final endpoint. They are included in the current information as complete subjects and are used to estimate the current treatment effect. BOCF is only available for the continuous endpoint and when simulating baseline for subjects.</p></li>
<li><p>Failure: subjects that are known dropouts are assumed to have a negative outcome at their final visit. If responses are good, the subject is a non-response, and if responses are bad, the subject is a responder. Failure is only available for dichotomous endpoints.</p></li>
</ul>
</section>
<section id="test-type" class="level5">
<h5 class="anchored" data-anchor-id="test-type">Test Type</h5>
<p>The test type can either be Unadjusted or Bonferroni. An unadjusted test will always use the specified alpha level in the significance test. The Bonferroni adjustment will divide the specified alpha value by the number of non-control arms enrolling in the study in the enrolment period leading up to the current analysis time.</p>
</section>
<section id="sample-size" class="level5">
<h5 class="anchored" data-anchor-id="sample-size">Sample Size:</h5>
<p>The current trial conditional power can be calculated at two different future time points.</p>
<ol type="1">
<li><p><strong>Current Enrollment</strong>: That no new subjects are recruited, but all those who have been recruited are followed up until they are complete.</p></li>
<li><p><strong>Trial Maximum</strong>: That the trial would continue recruiting subjects using the current allocation ratios until the trial maximum sample size is reached, and all subjects recruited are followed up until they have the opportunity to complete.</p></li>
</ol>
</section>
<section id="one-sided-alpha" class="level5">
<h5 class="anchored" data-anchor-id="one-sided-alpha">One-sided Alpha</h5>
<p>The threshold that the current trial would have to be less than in order to be considered a success. The success/futility values specified in the design tab are not used in the conditional power calculation. This value may be adjusted by the “Test type:” input.</p>
</section>
<section id="super-superiority-non-inferiority-margin-for-p-value" class="level5">
<h5 class="anchored" data-anchor-id="super-superiority-non-inferiority-margin-for-p-value">Super-Superiority (Non-inferiority) margin for p-value:</h5>
<p>This value cannot be changed on the QOI pop-up. It’s instead modified at the bottom of the QOI page. The objective of the current trial cannot be different for each individual current trial conditional power QOIs.</p>
</section>
<section id="additional-notes" class="level5">
<h5 class="anchored" data-anchor-id="additional-notes">Additional Notes</h5>
<p>Currently, conditional power will always assume that there is no correction applied to combine the different p-values from the analysis timepoints, i.e.&nbsp;no combination test is used.</p>
<p>The conditional power of the current trial at the maximum sample size is only available if the allocation is either fixed, or fixed with arm dropping, but not adaptive allocation or deterministic allocation.</p>
<p>Conditional power for the current trial is calculated</p>
<ul>
<li>Ignoring the possibility of the trial stopping or dropping an arm at a future interim</li>
</ul>
<!-- -->
<ul>
<li>Ignoring the possibility of future subject drop-outs.</li>
</ul>
</section>
</section>
<section id="future-trial-conditional-power" class="level4" data-number="5.2.2.2">
<h4 data-number="5.2.2.2" class="anchored" data-anchor-id="future-trial-conditional-power"><span class="header-section-number">5.2.2.2</span> Future Trial Conditional Power</h4>
<p>Conditional power of a future trial is reduced to a power calculation for a future trial, given the current frequentist estimates of treatment effect and standard deviation and a set of assumptions for the future trial, such as sample sizes, hypothesis to be tested, and significance levels to be used.</p>
<p>The test type of the future trial can be set to Superiority or Non-inferiority. If the superiority or non-inferiority margin is set to 0, then both types of tests simplify to traditional tests of superiority with no margin. If a non-zero margin is set, then the future trial must meet the success criteria indicated by the test type and the margin. The margin cannot be negative, but a super superiority test with a margin of -0.5 is equivalent to a non-inferiority test with a margin of 0.5.</p>
<p>The subjects per arm dictates how many subjects would be enrolled on each arm in the future study. If there is a control arm in the current trial, then the future trial is assumed to be randomized 1:1 between the active arm and the control. If there is no control arm in the current study, then the future trial is a single arm trial testing against the performance goal specified in the Freq. Comparison Response box in the QOI creation pop-up.</p>
<p>The One-sided Alpha is the significance level of the final analysis test of the future trial. The future trial is assumed to have 1 active arm, so there are no adjustments to the alpha level available.</p>
<p>The superiority margin or non-inferiority margin indicate the amount that the active arm must be better/not worse than the control arm by. If there is no control arm then this is the Freq Comparison response, which is the value that the active arms must be significantly better than in order to be declared a success. The frequentist margin for p-value QOIs on the QOI tab is not used for Future conditional power calculations – the future trial can have a different objective than the current trial.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image13.png" style="width:3.20399in;height:3.21594in"></p>
</section>
<section id="technical-aspects-of-conditional-power-calculations" class="level4" data-number="5.2.2.3">
<h4 data-number="5.2.2.3" class="anchored" data-anchor-id="technical-aspects-of-conditional-power-calculations"><span class="header-section-number">5.2.2.3</span> Technical Aspects of Conditional Power Calculations</h4>
<p>The conditional power calculations in FACTS are all calculated similarly to Jennison and Turnbull (2000)[4].</p>
<p>For continuous endpoint conditional power calculations, the conditional power of the future trial is calculated using a pooled standard deviation from all arms. For dichotomous conditional power calculations, each arm has its own standard deviation based on the MLE estimate of its proportion. These decision result in the conditional power tests matching how simple p-values are calculated for continuous and dichotomous endpoints.</p>
<p>The following sections will provide formulae to calculate the conditional power in the case where there is a control arm. Simplifications for when the arm is being compared to a fixed value rather than a control arm are simple: information fractions are only a function of the active arm standard deviation and the test statistic does not have a second sample mean subtracted from the active arm.</p>
<p>The value of <em>δ</em>, which can be a non-inferiority margin or a super superiority margin, is always positive coming out of FACTS. To make the math more concise we can define a couple of coefficients for the <em>δ</em> term that allow it to be used without re-writing formulas for different hypothesis test setups. If high values of the endpoint are good, then <em>s</em><sub>1</sub> = 1, and if low values of the endpoint are good, then <em>s</em><sub>1</sub> = −1. If the specified <em>δ</em> is a non-inferiority margin, then <em>s</em><sub>2</sub> = 1, and if it’s a super superiority margin then <em>s</em><sub>2</sub> = −1.</p>
<section id="continuous-conditional-power-for-the-current-trial" class="level5">
<h5 class="anchored" data-anchor-id="continuous-conditional-power-for-the-current-trial">Continuous Conditional Power for the Current Trial</h5>
<p>Let t be the interim index that the conditional power is being computed at, and T be the time of the analysis that the conditional power is being computed for. Then <em>Z</em><sub><em>k</em></sub> is the test statistic of the data collected up to the current interim analysis in the study, <em>I</em><sub><em>k</em></sub> is the information level at the time of the interim analysis, and <em>I</em><sub><em>K</em></sub> is the information level at the end of the study that the conditional power is being calculated for.</p>
<p>Let arm 1 be the control and arm 2 be the active arm, &nbsp;<span class="math inline">\(\overline{x\_{it}}\)</span> be the sample mean of arm <em>i</em> at time t,&nbsp;<span class="math inline">\(\widehat{\sigma\_{i}^{2}}\)</span> be the sample variance of arm <em>i</em> at time <em>t</em>, <em>n</em><sub>*i**t<em></em></sub><em> be the number of subjects with complete known final data on arm </em>i* at interim analysis t, and <em>n</em><sub>*i**T<em></em></sub><em> be the number of subjects with complete known final data on arm </em>i* at the time that conditional power is being calculated for. The pooled variance estimate is <span class="math inline">\(\widehat{\sigma^{2}} = \sum\_{d = 1}^{D}\widehat{\frac{\sigma\_{d}^{2}}{n\_{dt}}}\)</span> where D is the total number of arms in the study.</p>
<p>Then,</p>
<p><span class="math display">\[I\_{t} = \left( \frac{\widehat{\sigma^{2}}}{n\_{1t}} + \widehat{\frac{\sigma^{2}}{n\_{2t}}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[I\_{T} = \left( \frac{\widehat{\sigma^{2}}}{n\_{1T}} + \widehat{\frac{\sigma^{2}}{n\_{2T}}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[Z\_{t} = \left( {\overline{x}}\_{2t} - {\overline{x}}\_{1t} + s\_{1}s\_{2}\delta \right)\sqrt{I\_{t}}\]</span></p>
<p>where <em>δ</em> is the non-inferiority or super superiority margin.</p>
<p>Then for a one-sided alpha level of <em>α</em>, let <em>z</em><sub>1 − <em>α</em></sub> be the critical value corresponding to <em>α</em>.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{Z\_{t}\sqrt{I\_{t}} - z\_{1 - \alpha}\sqrt{I\_{T}} + ({\overline{x}}\_{2t} - {\overline{x}}\_{1t} + s\_{2}\delta)\left( I\_{T} - I\_{t} \right)}{\sqrt{I\_{T} - I\_{t}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{{- Z}\_{t}\sqrt{I\_{t}} - z\_{1 - \alpha}\sqrt{I\_{T}} - ({\overline{x}}\_{2t} - {\overline{x}}\_{1t} - s\_{2}\delta)\left( I\_{T} - I\_{t} \right)}{\sqrt{I\_{T} - I\_{t}}} \right)\]</span></p>
</section>
<section id="calculation-of-continuous-conditional-power-for-a-future-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-continuous-conditional-power-for-a-future-trial">Calculation of Continuous Conditional Power for a Future Trial</h5>
<p>Most of the future trial conditional power calculation is the same as the above current trial conditional power. There are some simplifications.</p>
<p><span class="math inline">\({\overline{x}}\_{it}\)</span> and <span class="math inline">\(\widehat{\sigma\_{i}^{2}}\)</span> are the same as in the current conditional power calculation. <em>I</em><sub><em>t</em></sub>, the weight of the current trial Z-score, is set to 0. <em>I</em><sub><em>K</em></sub> is now the information at the end of the future trial, and is calculated as:</p>
<p><span class="math display">\[I\_{T} = \left( \frac{\widehat{\sigma^{2}}}{n\_{T}} + \widehat{\frac{\sigma^{2}}{n\_{T}}} \right)^{- 1}\]</span></p>
<p>where <em>n</em><sub><em>T</em></sub> is the sample size per arm in the future trial and again <em>σ̂</em><sup>2</sup> is the pooled variance.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{- z\_{1 - \alpha}\sqrt{I\_{T}} + ({\overline{x}}\_{2t} - {\overline{x}}\_{1t} + s\_{2}\delta)\left( I\_{T} \right)}{\sqrt{I\_{T}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of a <strong>future</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{- z\_{1 - \alpha}\sqrt{I\_{T}} - ({\overline{x}}\_{2t} - {\overline{x}}\_{1t} - s\_{2}\delta)\left( I\_{T} \right)}{\sqrt{I\_{T}}} \right)\]</span></p>
</section>
<section id="calculation-of-dichotomous-conditional-power-for-the-current-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-dichotomous-conditional-power-for-the-current-trial">Calculation of Dichotomous Conditional Power for the Current Trial</h5>
<p>The dichotomous conditional power calculations are similar in spirit to the continuous conditional power calculations. One substantial difference is in how the dichotomous conditional power tests handle a non-inferiority or super superiority margin, <em>δ</em>. The method of calculating an appropriate test statistic for a frequentist hypothesis test is not obvious when the null scenario has a non-zero <em>δ</em>.</p>
<p>When there is no margin, the estimate for each treatment is simply based on the observed response proportion&nbsp;<span class="math inline">\(\widehat{p\_{i}}\)</span> for arm <em>i</em>, and the test statistic for a comparison of the control arm, <em>c</em>, with dose <em>d</em> is the usual Wald test</p>
<p><span class="math display">\[Z\_{d} = \frac{\widehat{p\_{d}} - \widehat{p\_{c}}}{\sqrt{\frac{\widehat{p\_{d}}(1 - \widehat{p\_{d}})}{n\_{d}} + \frac{\widehat{p\_{c}}(1 - \widehat{p\_{c}})}{n\_{c}}}}\]</span></p>
<p>When there is a margin, FACTS uses the Farrington-Manning Likelihood Score test statistic to estimate quantities <span class="math inline">\(\widetilde{p\_{d}}\)</span> and <span class="math inline">\(\widetilde{p\_{c}}\)</span> based on the MLEs of the arm proportions governed by the constraint that <span class="math inline">\(\widetilde{p\_{d}} - \widetilde{p\_{c}} = - s\_{1}s\_{2}\delta\)</span>. These constrained MLE estimates are used in the standard error of the test statistic. The FM test statistic is then,</p>
<p><span class="math display">\[Z\_{FM,d} = \frac{\widehat{p\_{d}} - \widehat{p\_{c}} + s\_{1}s\_{2}\delta}{\sqrt{\frac{\widetilde{p\_{d}}(1 - \widetilde{p\_{d}})}{n\_{d}} + \frac{\widetilde{p\_{c}}(1 - \widetilde{p\_{c}})}{n\_{c}}}}\]</span></p>
<p>See the PASS documentation[5] or SAS documentation[6] for a complete description of the calculations that go into the FM test. In the SAS documentation, note that the FM test is the same as the Miettinen-Nurminen<strong><em>&nbsp;</em></strong>test without including the <span class="math inline">\(\frac{n}{n - 1}\)</span> variance correction. The FM test was used rather than the MN test because as <em>δ</em> → 0, the FM test converges to the simple Wald test.</p>
<p>Once the test statistic has been resolved, the dichotomous conditional power for the current trial is calculated as follows. For calculating the conditional power for arm 2 compared to the control arm, called arm 1 without loss of generality, let <em>I</em><sub><em>t</em></sub> be the current information amount and <em>I</em><sub><em>T</em></sub> be the amount of information that the conditional power is being calculated for. Then,</p>
<p><span class="math display">\[I\_{t} = \left( \frac{\widetilde{p\_{1}}\left( 1 - \widetilde{p\_{1}} \right)}{n\_{1t}} + \frac{\widetilde{p\_{2}}\left( 1 - \widetilde{p\_{2}} \right)}{n\_{2t}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[I\_{T} = \left( \frac{\widetilde{p\_{1}}\left( 1 - \widetilde{p\_{1}} \right)}{n\_{1T}} + \frac{\widetilde{p\_{2}}\left( 1 - \widetilde{p\_{2}} \right)}{n\_{2T}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[Z\_{t} = \left( \widehat{p\_{2}} - \widehat{p\_{1}} + s\_{1}s\_{2}\delta \right)\*\sqrt{I\_{t}}\]</span></p>
<p>where <em>δ</em> is the super superiority or non-inferiority margin, and <em>n</em><sub>1<em>t</em></sub> and <em>n</em><sub>2<em>t</em></sub> are current number of completers on the control and active arm, and <em>n</em><sub>1<em>T</em></sub> and <em>n</em><sub>2<em>T</em></sub> are the number of completers that will be on the control and active arm at time that the conditional power is being calculated for. Additionally, if there is no non-inferiority or super superiority margin <em>δ</em>, then all <span class="math inline">\(\widetilde{p\_{\*}}\)</span> values are equal to their corresponding <span class="math inline">\(\widehat{p\_{\*}}\)</span> values.</p>
<p>For a one-sided alpha level of <em>α</em>, let <em>z</em><sub>1 − <em>α</em></sub> be the critical value corresponding to <em>α</em>.</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{Z\_{t}\sqrt{I\_{t}} - z\_{1 - \alpha}\sqrt{I\_{T}} + (\widehat{p\_{2}} - \widehat{p\_{1}} + s\_{2}\delta)\left( I\_{T} - I\_{t} \right)}{\sqrt{I\_{T} - I\_{t}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{{- Z}\_{t}\sqrt{I\_{t}} - z\_{1 - \alpha}\sqrt{I\_{T}} - (\widehat{p\_{2}} - \widehat{p\_{1}} - s\_{2}\delta)\left( I\_{T} - I\_{t} \right)}{\sqrt{I\_{T} - I\_{t}}} \right)\]</span></p>
</section>
<section id="calculation-of-dichotomous-conditional-power-for-a-future-trial" class="level5">
<h5 class="anchored" data-anchor-id="calculation-of-dichotomous-conditional-power-for-a-future-trial">Calculation of Dichotomous Conditional Power for a Future Trial</h5>
<p>Most of the calculation quantities for the future trial conditional power are the same as the current trial conditional power. The only difference is that for the future trial conditional power we discard the influence of the current trial test statistic on the final analysis, so <em>I</em><sub><em>t</em></sub> = 0. Then the conditional power calculations become:</p>
<p>If <strong>high values of the endpoint are good,</strong> the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{- z\_{1 - \alpha}\sqrt{I\_{T}} + (\widehat{p\_{2}} - \widehat{p\_{1}} + s\_{2}\delta)\left( I\_{T} \right)}{\sqrt{I\_{T}}} \right)\]</span></p>
<p>If <strong>low values of the endpoint are good</strong>, the conditional power of the <strong>current</strong> trial is:</p>
<p><span class="math display">\[CP\_{T} = \Phi\left( \frac{- z\_{1 - \alpha}\sqrt{I\_{T}} - (\widehat{p\_{2}} - \widehat{p\_{1}} - s\_{2}\delta)\left( I\_{T} \right)}{\sqrt{I\_{T}}} \right)\]</span></p>
</section>
</section>
</section>
</section>
<section id="p-values" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="p-values"><span class="header-section-number">5.3</span> P-values</h2>
<p>A p-value QOI simply allows the user to specify which test type to be used (unadjusted, Bonferroni, Dunnett’s or Trend Test), and how missing data is to be handled (ignored, LOCF or BOCF – if baseline is being simulated). If a control arm is present, P-values are comparisons against the control arm, if there is no control arm present, p-value QOIs are comparisons against a fixed response or fixed rate that is specified at the bottom of the QOI tab (it cannot be set differently for separate QOIs).</p>
<p>Note that for dichotomous endpoints p-value are calculated using the Test of Proportions, this test statistic asymptotically approaches a normal distribution and at least 5 success and 5 failures should be observed for this to be reasonable.</p>
<p>The p-values are calculated including the default frequentist delta that has been specified at the bottom of the screen. They cannot be modified as part of QOI, the value of the delta and nature of the test is the same for all the p-value QOIs.</p>
<p>In a TTE design with a predictor the p-values are only calculated for the final event endpoint, not the predictor.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image14.png" style="width:3.08054in;height:1.89707in" alt="Graphical user interface, application Description automatically generated"></p>
<section id="p-values-when-there-is-no-control-arm" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="p-values-when-there-is-no-control-arm"><span class="header-section-number">5.3.1</span> P-values when there is no control arm</h3>
<p>If there is no control arm (not currently an option in Time-to-Event), the p-value delta is instead interpreted as the objective response or response rate to compare to. The option to set the trial type is also disabled (“Superiority” is selected and the “non-inferiority option is greyed out). For a non-inferiority trial comparing to an objective response or response rate simply use the objective rate minus the non-inferiority delta (if a higher response is better) or the objective rate plus the non-inferiority delta (if a lower response is better).</p>
<p>It is currently only possible to have one objective rate to compare against.</p>
<p>The same objective rate will be used for the target p-value test in the predictive probabilities.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image15.png" style="width:5.07319in;height:3.85221in" alt="Graphical user interface, text, application Description automatically generated"></p>
</section>
<section id="fisher-exact-test" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="fisher-exact-test"><span class="header-section-number">5.3.2</span> Fisher-Exact Test</h3>
<p>On the bottom of the QOI tab, we can specify what statistical test to use when calculating p-values. Options are “Normal approximation” (default) and “Fisher exact test”. “Normal approximation” uses a t-test and should yield similar results to a Chi-Square test without continuity correction, while “Fisher exact test” uses an exact Fisher’s exact test for 2x2 tables.</p>
<p>If “Fisher exact test” is chosen as the test type, all p-value QOIs will use a Fisher’s exact test, except for future trial predictive probabilities, which will still use a t-test.</p>
<p>If “Fisher exact test” is chosen as the test type, only “Bonferroni” and “Unadjusted” are available as multiplicity corrections and any QOIs previously created using different multiplicity corrections will be deleted.</p>
<p>“Fisher exact test” is not available for non-inferiority comparisons.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image16.png" style="width:6.925in;height:5.07292in" alt="A screenshot of a computer Description automatically generated"></p>
</section>
</section>
<section id="target-doses" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="target-doses"><span class="header-section-number">5.4</span> Target Doses</h2>
<p>The target dose QOIs are Bayesian posterior probabilities based on MCMC sampling of how often each dose meets the specified target criteria. There are 3 types of target specifiable</p>
<ul>
<li><p>Max – the dose with the maximum response, this has no parameters to specify, so is available as a pre-defined default QOI.</p></li>
<li><p>MED – a Minimum Effective Dose, the lowest dose that has a response better than an absolute or relative target.</p></li>
<li><p>ED – an effective dose, the dose that achieves a specified proportion (quantile) of the maximum improvement in response relative to an absolute value or the performance of a specific treatment arm.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image17.png" style="width:3.00783in;height:2.07488in"></p>
<p>A Target dose posterior probability is specified as:</p>
<ul>
<li><p>MED or EDq.</p></li>
<li><p>Relative to an absolute value or relative to the response on a Control or the Active Comparator.</p></li>
<li><p>The delta the MED must be better than, or the quantile of the effective dose.</p></li>
<li><p>If the endpoint is TTE and the design includes a predictor, then the definition of the QOI includes selecting which endpoint the QOI refers to.</p></li>
</ul>
<p>The QOI will be given a name derived from these details, and alternative simpler name that can be used when accessing the output files from other software such as R.</p>
</section>
<section id="decision-quantities" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="decision-quantities"><span class="header-section-number">5.5</span> Decision Quantities</h2>
<p>The QOI’s so far have defined values to be calculated across all the doses. For a Success / Futility decision to be taken, as well as the quantity to be tested, it is necessary to specify the treatment arm whose value is to be used. This selection can be by specifying a specific arm, but normally it is specified by using a “Probability of being Target” selection criteria. A simple and common example is “The probability of the response being better than that of the Control of the Treatment arm with the maximum response”:</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image18.png" style="width:2.98863in;height:1.43143in"></p>
<p><img src="coreUGattachments/CoreUserGuide/media/image19.png" style="width:3.71051in;height:1.77718in"></p>
<p>A decision QOI consists of (1) a QOI that has been calculated for each dose, and (2) at Target Dose QOI. The dose with the highest probability of being the target dose is selected and the value of the “per dose” QOI for that dose is the value used in the decision.</p>
<p>For example, evaluating a decision QOI that is the combination of</p>
<ol type="1">
<li><p>The probability of being better than Control by 2 points (Pr(θ<sub>d</sub> – θ<sub>0</sub> &gt; 2))</p></li>
<li><p>with the target dose EDq relative to control; Quantile 0.9</p></li>
</ol>
<p>is the probability that the response of the ED90 is better than control by 2 points.</p>
<p>Instead of a Target Dose QOI, it is also possible to specify a specific dose, or to use the terms “Max probability over all doses” and “Min probability over all doses” which mean that the dose with the minimum or maximum value of the per dose QOI is used. This enables:</p>
<ul>
<li><p>Decisions QOIs testing specific doses, for example by defining a Posterior probability QOI that compares all doses against the lowest dose, and then a Decision QOI using that posterior probability with the highest dose selected as the target dose it is possible to based decisions on the posterior probability that the highest dose is better than the lowest dose.</p></li>
<li><p>A Decision QOI using “Max …” allows a decision to be based on whether a probability or p-value is greater than a threshold at any dose, or less than a threshold at all doses.</p></li>
<li><p>A Decision QOI using “Min …” allows a decision to be based on whether a probability or p-value is less than a threshold for any dose or greater than a threshold at all doses.</p></li>
</ul>
<p>There is one special case: if the QOI chosen is the Trend Test p-value, then because this is not actually a per-dose value, only one “Target dose” can be selected: “Overall Significance”.</p>
</section>
<section id="standard-evaluation-variables" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="standard-evaluation-variables"><span class="header-section-number">5.6</span> Standard Evaluation Variables</h2>
<p>These 2 parameters are used across some of the default QOIs and hence specified outside the normal QOI dialog boxes.</p>
<ul>
<li><p>The CSD value</p></li>
<li><p>and whether absolute or relative to the Control arm</p></li>
</ul>
<p>these are used in both the default “Pr(CSD)” and the “MED relative to Control” QOIs. <img src="coreUGattachments/CoreUserGuide/media/image20.png" style="width:6.925in;height:0.49375in"></p>
<p>Note that the CSD value here is designed to be usually entered as a positive value, as in earlier versions of FACTS. Its sign is automatically adjusted if “lower score means subject improvement” or if the trial is a non-inferiority trial.</p>
<p>These adjustments are <strong>not</strong> made for other user entered QOI, the directions of comparison both for the definition of the probability to be calculated and the comparison of the resulting probability with a threshold are under the user’s control as are whether delta’s are –ve or +ve. This allows the user to define QOI’s in whatever fashion is natural to them and the team.</p>
<p>When there is no custom and practice as to how an endpoint and associated probability are expressed and used, it is recommended that the usual practice should be to create probabilities that are large when they are ‘good’ and low when they are ‘bad’. So tests for success are usually “&gt; threshold” and for futility are “&lt; threshold”. Using this convention whenever it is does not feel unnatural will reduce confusion and the opportunity for mistakes.</p>
<section id="the-direction-of-comparison-for-default-qois" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="the-direction-of-comparison-for-default-qois"><span class="header-section-number">5.6.1</span> The direction of comparison for default QOIs</h3>
<p>Note that as a result of being able to specify whether a higher or lower response represents improvement, and whether the aim is superiority or non-inferiority, the CSD or the NIM will almost always be a positive value. FACTS will automatically determine which direction is appropriate (e.g.&nbsp;if <strong><em>lower</em></strong> values are subject improvement, the engine will realize a CSD will need to be <strong><em>subtracted</em></strong> from the control score before comparing with the estimate of response on a treatment arm).</p>
</section>
</section>
</section>
<section id="design-overview" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Design Overview</h1>
<p>The FACTS core engine allows for the design and simulation of fixed and adaptive clinical trials, especially focused on, but not limited to, Bayesian designs with multiple active arms. Trials designed in the core engines are comprised of a number of elements:</p>
<ol type="1">
<li><p>The dose response model: the user must specify how the data will be analyzed, though there is a simple ‘no model’ option that estimates the mean treatment effect of each arm independently. A fixed trial uses the dose response model for the final Bayesian analysis of the data; an adaptive trial uses the same model both for the final analysis and at the interim updates.</p></li>
<li><p>The longitudinal (predictor) model: whether the trial is adaptive or fixed, the user may select to whether to use a longitudinal model (similarly, a predictor model in time to event). In a fixed trial the longitudinal model is used to impute final values for subjects that have dropped out, in an adaptive trial it is also used at the interim updates to impute final values for subjects who have been recruited but do not yet have final values. In a fixed trial with no subject dropouts using a longitudinal model would have no effect on the outcome, analysis or conduct of the trial.</p></li>
<li><p>Allocation rules: in a fixed trial the user just specifies the proportion of subjects to be recruited to each arm, and the same can be done in an adaptive trial (i.e.&nbsp;an adaptive trial does not have to adapt the allocation), but an adaptive trial has a range of options that the user can use to adapt how subjects are allocated to the different treatment arms as the trial progresses.</p></li>
<li><p>Early stopping rules: in an adaptive trial the user can select the criteria and specify the thresholds at which trial should be stopped at any interim where the conditions are satisfied. Early stopping is optional and even in an adaptive design the user can opt to always recruit the maximum permitted number of subjects. In a fixed trial there are no interims and hence no opportunity to stop early.</p></li>
<li><p>Final evaluation criteria: the same Bayesian evaluation criteria are available whether the trial is fixed or adaptive. The user selects which criteria to use and what thresholds will constitute success or failure. These allow the user to leave a range of outcomes as ‘inconclusive’, where they cannot not say, before the study starts, whether the compound’s development would be continued or not.</p></li>
<li><p>Frequentist analysis: frequentist p-values can be calculated comparing each dose to the control arm. P-values can be used as decision making quantities at interim updates or final analyses.</p></li>
</ol>
<section id="evaluation-of-bayesian-posterior-estimates" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="evaluation-of-bayesian-posterior-estimates"><span class="header-section-number">6.1</span> Evaluation of Bayesian Posterior Estimates</h2>
<p>The Bayesian model fitted to the data at each update contains a dose response model and usually a longitudinal model. In the absence of a longitudinal model, the posterior is calculated as:</p>
<p><span class="math display">\[p(\omega|Y) \propto \prod\_{i = 1}^{n}{p(y\_{i}|\phi)p(\phi)}\]</span></p>
<p>where <em>ϕ</em> is the set of parameters of the selected response model, <em>p</em>(<em>ϕ</em>) is the prior for those parameters, <em>y</em><sub><em>i</em></sub> is the final response for each subject and n is the number of subjects.</p>
<p>With a longitudinal model, this becomes:</p>
<p><span class="math display">\[p(\omega|Y) \propto \prod\_{i = 1}^{n}{p(y\_{i}|\phi)p(\phi)\prod\_{i = 1}^{n}{\prod\_{j = 1}^{L}{p(y\_{ij}|\psi)p(\psi)}}}\]</span></p>
<p>where <em>ψ</em> is the set of parameters of the selected longitudinal model, <em>p</em>(<em>ψ</em>) is the prior for those parameters, <em>y</em><sub>*i**j*</sub> is the response for each subject at each visit and L is the number of visits.</p>
<p>The posterior is evaluated using MCMC with individual parameters updated by Metropolis Hastings (or Gibbs sampling where possible), using only the <em>y</em><sub><em>i</em></sub> and <em>y</em><sub>*i**j*</sub> data available at the time of the update.</p>
</section>
</section>
<section id="dose-response" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Dose Response</h1>
<p>Dose response models in FACTS may be more accurately called final endpoint models. They create and model a relationship across the doses specified in the Treatment Arms tab. Often, but not always, the dose strength, called “Effective Dose Strength” in the Study &gt; Treatment Arms tab of FACTS, is used in the dose response models to determine the order of doses, and which doses are more related to others.</p>
<p>The dose response models can be simple, and model the doses largely independently, as is done with the Independent Dose Model or the Independent Beta Binomial Model (dichotomous only). They can have logistic style models with interpretable parameters, like the 3-parameter logistic or the <em>E</em><sub>max</sub> model (called Sigmoidal in FACTS). The dose response model can also be a model that creates a smooth, spline like, model over the doses using a normal dynamic linear model (NDLM), a monotonic NDLM, or a 2nd order NDLM.</p>
<p>For all endpoints, we model the response at each dose, d, in terms of <em>θ</em><sub><em>d</em></sub> on a continuous scale allowing a consistent and rich range of dose response models to be used for all endpoint types. Transformations (see below) of the dichotomous and time-to-event responses are used to achieve this.</p>
<section id="continuous-dichotomous-and-log-odds" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="continuous-dichotomous-and-log-odds"><span class="header-section-number">7.1</span> Continuous, Dichotomous and Log-Odds</h2>
<p>With the exception of two dose response models specific to a dichotomous endpoint, the same dose response modeling facilities are available for all endpoints.</p>
<p>Let there be D total doses including the control arm if it exists. For any endpoint, the estimate of dose response model is called <em>θ</em><sub><em>d</em></sub> for a dose <em>d</em> ∈ {1, …, <em>D</em>}.</p>
<ul>
<li><p>In the continuous case the individual response/change from baseline (if it exists) <em>Y</em><sub><em>i</em></sub> of the <em>i</em><sup>*t**h<em></em></sup><em> subject allocated to dose </em>d<em><sub></sub></em>i<em> is modeled: </em>Y<em><sub></sub></em>i<em>&nbsp;∼&nbsp;</em>N<em>(</em>θ<em><sub></sub></em>d<em><sub></sub></em>i<em>, </em>σ<em><sup>2</sup>). The variance </em>σ*<sup>2</sup> has an inverse-gamma prior.</p></li>
<li><p>In the dichotomous case the final endpoint of the <em>i</em><sup>*t<strong>h<em></em></strong></sup><strong><em> subject who has been allocated to dose </em>d<em><sub></sub></em>i<em> is modeled: </em>Y<em><sub></sub></em>i<em>&nbsp;∼&nbsp;</em>B</strong>e<strong>r</strong>n<strong>o</strong>u<strong>l</strong>l**i<em>(</em>P<em><sub></sub></em>d<em><sub></sub></em>i<em>) where </em>P<em><sub></sub></em>d<em><sub></sub></em>i<em> is the probability of response for a subject on dose </em>d<em><sub></sub></em>i<em>. The probability </em>P<em><sub></sub></em>d<em> is modelled on the logit scale, so <span class="math inline">\(P\_{d} = \frac{e^{\theta\_{d}}}{1 + e^{\theta\_{d}}}\)</span>, and thus </em>θ<em><sub></sub></em>d* is the log-odds ratio: <span class="math inline">\(\theta\_{d} = ln\left( \frac{P\_{d}}{1 - P\_{d}} \right)\)</span>,</p></li>
<li><p>In the time-to-event case the time to a subject’s response, <em>Y</em><sub><em>i</em></sub> is modeled as piece-wise exponentially distributed with hazard rates, <em>λ</em><sub><em>s</em></sub> for pieces <em>s</em> ∈ {1, …<em>S</em>}. So, <em>Y</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>P<strong>W</strong>E<strong>x</strong>p</em>({<em>λ</em><sub>1</sub>, …, <em>λ</em><sub><em>S</em></sub>}) for a subject on the control arm, and <em>Y</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>P<strong>W</strong>E<strong>x</strong>p</em>({<em>λ</em><sub>1</sub><em>e</em><sup><em>θ</em><sub><em>d</em></sub></sup>, …, <em>λ</em><sub><em>S</em></sub><em>e</em><sup><em>θ</em><sub><em>d</em></sub></sup>}) for non-control doses. Then, <em>θ</em><sub><em>d</em></sub> is the log-hazard ratio <span class="math inline">\(\left( \ln\left( \frac{\lambda\_{s}e^{\theta\_{d}}}{\lambda\_{s}} \right) = \ln\left( e^{\theta\_{d}} \right) = \theta\_{d} \right)\)</span> averaged over the observation time segments. This formulation implies a proportional treatment effect across the pieces of the piece-wise exponential.</p></li>
</ul>
<p>Each dose response model is parameterized in terms of <em>θ</em><sub><em>d</em></sub>, but each endpoint models this parameter on a different scale. The dichotomous dose response models are on the log-odds scale, and the time-to-event endpoint models are on the log hazard ratio. When specifying a prior distribution for a continuous endpoint dose response model the expected data mean and variance determine which priors should be considered non-informative. When estimating a probability in the dichotomous case, using a prior with standard deviation above, say, 10 leads to a diffuse distribution on the log-odds scale, but results in a prior distribution on the probability scale that is heavily peaked at 0 and 1. This can lead to undesirable model results and decisions being made in small sample size situations, and numerical instability in extreme cases. Similarly on the time-to-event scale, the prior put on the log-hazard ratio <em>θ</em><sub><em>d</em></sub> is exponentiated before being multiplied by the hazard rate, so diffuse priors on the log-hazard can have unexpected modelled results. Again, time-to-event <em>θ</em><sub><em>d</em></sub> priors that have standard deviations less than about 10 are generally acceptably diffuse for most situations while avoiding edge case curiosities.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image21.png" style="width:2.07519in;height:2.68327in"></p>
</section>
<section id="descriptions-of-dose-response-models" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="descriptions-of-dose-response-models"><span class="header-section-number">7.2</span> Descriptions of Dose Response Models</h2>
<p>The Dose Response section of the Design tab allows the user to specify how to analyze the relationship between dose/treatment arm and the final response and hence estimate the values <em>θ</em><sub><em>d</em></sub>. The interpretation of <em>θ</em><sub><em>d</em></sub> depends on the nature of the endpoint:</p>
<ul>
<li><p>Where the response is continuous, <em>θ</em><sub><em>d</em></sub> is the estimate of the mean response/change from baseline on treatment arm <em>d</em>, and the common inter-subject variance of the response <em>σ</em><sup>2</sup>, is also estimated.</p></li>
<li><p>Where the response is dichotomous, <em>θ</em><sub><em>d</em></sub> is the estimate of the log-odds of the probability of observing a response on the treatment arm <em>d</em>.</p></li>
<li><p>Where the response is time-to-event, <em>θ</em><sub><em>d</em></sub> is the estimate of the log hazard ratio compared to the control arm on the treatment arm <em>d</em>.</p></li>
</ul>
<p>Except where the endpoint is time to event, the response on the control arm, θ<sub>0</sub>, is estimated and can be included in the dose response model or modeled separately. When the endpoint is time-to-event, the response rate on the control arm, λ is estimated and <em>θ</em><sub><em>d</em></sub> for <em>d</em> ∈ {1,&nbsp;2,&nbsp;…,&nbsp;<em>D</em>} is the log hazard of the response rate of each treatment arm compared to the control arm, so <em>θ</em><sub>0</sub> ≡ 0.</p>
<p>Some, but not all, of the dose response models use the effective dose strength, <em>ν</em><sub><em>d</em></sub>, to model the dose response <em>θ</em><sub><em>d</em></sub>. The effective dose strength is specified on the Study &gt; Treatment Arms tab. It is always fixed at 0 for the control arm (<em>ν</em><sub>0</sub> = 0).</p>
<section id="independent-dose-model" class="level3" data-number="7.2.1">
<h3 data-number="7.2.1" class="anchored" data-anchor-id="independent-dose-model"><span class="header-section-number">7.2.1</span> Independent Dose Model</h3>
<p>The “Independent Dose Model” providing a simple pair-wise comparison between the study drug arms and the control arm and/or the active comparator arm. The doses are modelled as independent and normally distributed with a prior of:</p>
<p><em>θ</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>d</em></sub>, <em>ν</em><sub><em>d</em></sub><sup>2</sup>)</p>
<p>Where <em>μ</em><sub><em>d</em></sub> and <em>v</em><sub><em>d</em></sub><sup>2</sup> are specified in FACTS and can be the same or vary across arms.</p>
<p>This model is useful:</p>
<ul>
<li><p>When there is only one or two experimental arms</p></li>
<li><p>When the study drug arms don’t differ by dose but in other ways, so there is no ordered sequence of treatments – e.g.&nbsp;each arm is the study drug in combination with a different additional drug.</p></li>
<li><p>For simulating simple trial designs</p></li>
<li><p>For simulating a ‘conventional’ or ‘strawman’ design to compare more complex designs against</p></li>
</ul>
<p>Otherwise for trials with multiple related arms that differ by dose, it is usually more efficient to use a dose-response model.</p>
</section>
<section id="independent-beta-binomial-model-dichotomous-only" class="level3" data-number="7.2.2">
<h3 data-number="7.2.2" class="anchored" data-anchor-id="independent-beta-binomial-model-dichotomous-only"><span class="header-section-number">7.2.2</span> Independent Beta-Binomial Model (Dichotomous Only)</h3>
<p>This is a “no model” option similar to the above, but only available for the Dichotomous endpoint. Unlike any other dose response model, this model uses the beta distribution to model the probability of response directly rather than fitting a model to the log-odds of the probability.</p>
<p>The final endpoint response <em>Y</em><sub><em>i</em></sub> is modeled as:</p>
<p><em>Y</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>B<strong>e</strong>r<strong>n</strong>o<strong>u</strong>l<strong>l</strong>i</em>(<em>P</em><sub><em>d</em></sub>)</p>
<p>where <em>P</em><sub><em>d</em></sub> is the probability that a patient is a response at the final endpoint for subjects randomized to dose d.&nbsp;With posterior</p>
<p><em>P</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>B<strong>e</strong>t<strong>a<em>(</em>α<em><sub></sub></em>d<em> + </em>r</strong>e<strong>s</strong>p<strong>o</strong>n<strong>d</strong>e<strong>r</strong>s</em><sub><em>d</em></sub>,&nbsp;&nbsp;&nbsp;<em>β</em><sub><em>d</em></sub> + <em>n<strong>o</strong>n</em>_*r<strong>e</strong>s<strong>p</strong>o<strong>n</strong>d<strong>e</strong>r**s<em><sub></sub></em>d*)</p>
<p>Where α<sub>d</sub>, β<sub>d</sub> are the priors for the arm d, <em>r<strong>e</strong>s<strong>p</strong>o<strong>n</strong>d<strong>e</strong>r<strong>s<em><sub></sub></em>d<em> is the number of responders on arm d and </em>n</strong>o<strong>n<em>_</em>r</strong>e<strong>s</strong>p<strong>o</strong>n<strong>d</strong>e<strong>r</strong>s</em><sub><em>d</em></sub> is the number of non-responders on arm d.</p>
<p>This model has the advantages of an easier to understand prior, and better estimation of <em>P</em><sub><em>d</em></sub> when the number of responders and non-responders is small (either is &lt; 5) compared to the log-odds model. As it’s an independent model it is well suited to analyzing single arm, two arm or three arm trials, or trials where the experimental arms are unrelated, and so there is no basis on which to borrow information between them. With trials with multiple arms of the same treatment at different doses it is usually more advantageous to fit a dose response model.</p>
</section>
<section id="simple-ndlm" class="level3" data-number="7.2.3">
<h3 data-number="7.2.3" class="anchored" data-anchor-id="simple-ndlm"><span class="header-section-number">7.2.3</span> Simple NDLM</h3>
<p>The Normal Dynamic Linear Model (NDLM) estimates the final endpoint as a smoothed curve across doses included in the model. Doses are tied directly to their nearest neighbor, and the prior expectation for a dose is that it is equal to its neighboring doses, tending to a constant dose response across doses in the absence of data. The model is defined as follows:</p>
<p>Let doses <em>d</em> = <em>d</em>′, …, <em>D</em> be doses in the dose response model and <em>θ</em><sub><em>d</em></sub> be the estimated dose response for dose <em>d</em>. The initial dose <em>d</em><sup>′</sup> = 1 if there is no control or control is included in the dose response model, and <em>d</em><sup>′</sup> = 2 if the control arm is modelled separately.</p>
<p>The dose response of the first dose, <em>d</em>′, has a prior of:</p>
<p><em>θ</em><sub><em>d</em><sup>′</sup></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>d</em><sup>′</sup></sub>, <em>τ</em><sub><em>d</em><sup>′</sup></sub><sup>2</sup>)</p>
<p>where <em>μ</em><sub><em>d</em>′</sub> and <em>τ</em><sub><em>d</em>′</sub><sup>2</sup> are specified directly in FACTS. Subsequent dose response estimates <em>θ</em><sub><em>d</em><sup>′</sup> + 1</sub>, …,&nbsp;<em>θ</em><sub><em>D</em></sub> have priors centered at the previous dose response with variances based on the distance between the dose <em>d</em> strength and the dose <em>d</em> − 1 strength. Specifically,</p>
<p><em>θ</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>θ</em><sub><em>d</em> − 1</sub>, <em>τ</em><sub><em>d</em> − 1</sub><sup>2</sup>) for <em>d</em> = <em>d</em><sup>′</sup> + 1, …, <em>D</em></p>
<p>where for dose strengths <em>v</em><sub><em>d</em></sub> and <em>v</em><sub><em>d</em> − 1</sub>, <em>t</em><sub><em>d</em> − 1</sub><sup>2</sup> is defined as</p>
<p><em>τ</em><sub><em>d</em> − 1</sub><sup>2</sup> = <em>τ</em><sup>2</sup>(<em>v</em><sub><em>d</em></sub> − <em>v</em><sub><em>d</em> − 1</sub>)</p>
<p>The prior distribution for the “drift” parameter, which controls the amount of smoothing is:</p>
<p><span class="math display">\[\tau^{2}\sim IG\left( \frac{\tau\_{n}}{2},\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p>where <em>τ</em><sub><em>μ</em></sub> and <em>τ</em><sub><em>n</em></sub> are specified in the Dose Response tab in FACTS under Model Parameters.</p>
<p>In the continuous case the residual error around the estimated dose response is</p>
<p><span class="math display">\[\sigma^{2}\sim IG\left( \frac{\sigma\_{n}}{2},\frac{\sigma\_{\mu}^{2}\sigma\_{n}}{2} \right)\]</span></p>
<p>where <em>σ</em><sub><em>μ</em></sub>&nbsp;and&nbsp;<em>σ</em><sub><em>n</em></sub> are specified on the Dose Response tab in FACTS under Error Parameters.</p>
<p>The Simple NDLM is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Simple NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.</p>
<p>In a ‘null’ scenario where the response on all the doses is the same as control, the simple NDLM reduces type-1 error. The estimate of <em>τ</em><sup>2</sup> tends towards zero and the estimate of the dose response tends to a flat line. The smoothing of the estimates of the response reduces the random fluctuations in the estimates from dose to dose and is a very effective counter to the problem of type-1 error inflation due to the multiplicity of doses being tested. A small prior for the mean value of <em>τ</em> will accentuate this effect. The price to be paid for this benefit is a tendency to underestimate large changes in response or where there is a peak in the response. This over-smoothing can reduce power. A prior for the mean of <em>τ</em> centered at large values will minimize over-smoothing, and a very large prior would simply remove any smoothing effect at all. A standard prior for the mean of <em>τ</em> would be the expected average change in response from dose to dose, scaled to take into account the differences in the specified effective dose strengths.</p>
<p>Usually, the choice of prior for <em>τ</em><sup>2</sup> is tuned based on simulation results, trading off reducing type-1 error in the null case against loss of power and reduced estimate of maximum response in the effective scenario with the largest jump in response or steepest peak.</p>
<p><strong>Aside</strong>: When using the NDLM model or any of its alternatives (2<sup>nd</sup> order or Monotonic NDLM), and including doses in a design that receive no subject allocation (ie. Allocation ratio set to 0), some important characteristics of the model should be considered in the interpretation of results. First, the NDLM model “borrows” information from neighbouring doses, and therefore including unallocated intermediate doses will increase uncertainty in the fitted response. Information must “pass through” these intermediate doses, and uncertainty should be expected to increase as the number of intermediate unallocated doses between two allocated doses increases. Secondly, the NDLM model estimates the response at unallocated doses, but without subject data at these doses the uncertainty in the estimate can be considerably larger than doses with subject data. This high degree of uncertainty can lead to a vestigial probability that an unallocated dose is the target dose (Pr(ED<sub>x</sub>), Pr(MED), Pr(Max)) even though the mean response estimate and probabilities at neighbouring doses with subject data would not suggest this to be the case.</p>
</section>
<section id="monotonic-ndlm" class="level3" data-number="7.2.4">
<h3 data-number="7.2.4" class="anchored" data-anchor-id="monotonic-ndlm"><span class="header-section-number">7.2.4</span> Monotonic NDLM</h3>
<p>The Monotonic NDLM endpoint model is similar to the NDLM in the sense that it smooths dose response estimates using neighboring doses, but is constrained to be either monotonically increasing or monotonically decreasing across doses. The direction of monotonicity depends on the value specified in the “Monotonic:” selection in the Model Parameters section of the Monotonic NDLM Dose Response page.</p>
<p>The use of this model is generally limited to endpoints where a strong presumption of increasing/decreasing response with dose is reasonable – such as a biomarker or a toxicity endpoint.</p>
<p>Let doses <em>d</em> = <em>d</em>′, …, <em>D</em> be doses in the dose response model and <em>θ</em><sub><em>d</em></sub> be the estimated dose response for dose <em>d</em>. The initial dose <em>d</em><sup>′</sup> = 1 if there is no control or control is included in the dose response model, and <em>d</em><sup>′</sup> = 2 if the control arm is modelled separately. The following model is the monotonically positive NDLM:</p>
<p><em>θ</em><sub><em>d</em>′</sub> ∼ <em>N</em>(<em>μ</em><sub><em>d</em>′</sub>, <em>τ</em><sub><em>d</em>′</sub><sup>2</sup>)</p>
<p>and</p>
<p><em>θ</em><sub><em>d</em></sub> ∼ <em>N</em><sup>+</sup>(<em>θ</em><sub><em>d</em> − 1</sub>, <em>τ</em><sub><em>d</em> − 1</sub><sup>2</sup>) for <em>d</em> = <em>d</em><sup>′</sup>, …, <em>D</em>,</p>
<p>Where <em>τ</em><sub><em>d</em> − 1</sub><sup>2</sup> is defined as in the NDLM, and <em>X</em>&nbsp;∼&nbsp;<em>N</em><sup>+</sup>(<em>μ</em>, <em>σ</em><sup>2</sup>) refers to a positive truncated normal distribution with density function:</p>
<p><span class="math inline">\(f\_{X}(x) = \frac{1 - \Phi\left( - \frac{\mu}{\sigma} \right)}{\sqrt{2\pi}\sigma}\exp\left\\ - \frac{1}{2\sigma^{2}}(x - \mu)^{2} \right\\\)</span> for x &gt; 0.</p>
<p>The result of this dose-response model is that the curve is monotonically increasing, in that <em>θ</em><sub><em>d</em></sub> &gt; <em>θ</em><sub><em>d</em> − 1</sub>.</p>
<p>The monotonically decreasing NDLM is similar except:</p>
<p><em>θ</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>N</em><sup>−</sup>(<em>θ</em><sub><em>d</em> − 1</sub>, <em>τ</em><sub><em>d</em> − 1</sub><sup>2</sup>) for <em>d</em> = <em>d</em><sup>′</sup>, …, <em>D</em>,</p>
<p>Where <em>X</em>&nbsp;∼&nbsp;<em>N</em><sup>−</sup>(<em>μ</em>, <em>σ</em><sup>2</sup>) refers to a negative truncated normal distribution:</p>
<p><span class="math inline">\(f\_{X}(x) = \frac{\Phi\left( - \frac{\mu}{\sigma} \right)}{\sqrt{2\pi}\sigma}\exp\left\\ - \frac{1}{2\sigma^{2}}(x - \mu)^{2} \right\\\)</span> for x &lt; 0.</p>
<p>The result of this dose-response model is that the curve is monotonically decreasing, in that <em>θ</em><sub><em>d</em></sub> &lt; <em>θ</em><sub><em>d</em> − 1</sub>.</p>
</section>
<section id="second-order-ndlm" class="level3" data-number="7.2.5">
<h3 data-number="7.2.5" class="anchored" data-anchor-id="second-order-ndlm"><span class="header-section-number">7.2.5</span> Second Order NDLM</h3>
<p>The second order NDLM described in this section is the version utilized in FACTSTM version 4.0 and later. The model labelled “Second Order NDLM” versions before 4.0 is now maintained as the model labelled “Legacy 2nd Order NDLM.” The second order NDLM serves as a “smoother” similar to the NDLM, however it tends to smooth toward a linear fit with a slope (the NDLM itself tends to shrink each dose’s fit toward its neighbours, while the second order NDLM prefers any trend in the neighbours).</p>
<p>Let doses <em>d</em> = <em>d</em>′, …, <em>D</em> be doses in the dose response model and <em>θ</em><sub><em>d</em></sub> be the estimated dose response for dose <em>d</em>. The initial dose <em>d</em><sup>′</sup> = 1 if there is no control arm or control is included in the dose response model, and <em>d</em><sup>′</sup> = 2 if the control arm is modelled separately. The initial dose <em>d</em>′ is modelled:</p>
<p><em>θ</em><sub><em>d</em>′</sub> ∼ <em>N</em>(<em>μ</em><sub>0</sub>, <em>τ</em><sub>0</sub><sup>2</sup>)</p>
<p>Where <em>μ</em><sub>0</sub> and <em>τ</em><sub>0</sub><sup>2</sup> are specified directly in FACTS.</p>
<p>In the case of TTE, the initial dose <em>d</em>′ is the control arm, and has a <em>θ</em><sub><em>d</em>′</sub> = 0 by definition, so no prior distribution is needed.</p>
<p>The prior distribution for the dose response for the dose directly after the initial dose is specified on the difference between the <em>d</em>′ and <em>d</em><sup>′</sup> + 1 level doses:</p>
<p><em>θ</em><sub><em>d</em><sup>′</sup> + 1</sub> − <em>θ</em><sub><em>d</em><sup>′</sup></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>1</sub>, <em>τ</em><sub>1</sub><sup>2</sup>)</p>
<p>Successive doses are then modelled based on differences in slope between the dose and the two doses below them. Let:</p>
<p><span class="math display">\[\theta\_{d} = \theta\_{d - 1} + \Delta\_{d}\zeta\_{d} + \frac{\Delta\_{d}}{\Delta\_{d - 1}}\left( \theta\_{d - 1} - \theta\_{d - 2} \right)\]</span></p>
<p>for doses <em>d</em> = <em>d</em><sup>′</sup> + 2,&nbsp;…, <em>D</em>, where <em>Δ</em><sub><em>d</em></sub> = <em>ν</em><sub><em>d</em></sub> − <em>ν</em><sub><em>d</em> − 1</sub> and <em>Δ</em><sub><em>d</em> − 1</sub> = <em>ν</em><sub><em>d</em> − 1</sub> − <em>ν</em><sub><em>d</em> − 2</sub>. The priors for the dose response smoothing terms <em>ζ</em><sub><em>d</em></sub> are:</p>
<p><em>ζ</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>N</em>(0, <em>τ</em><sub>2</sub><sup>2</sup>)</p>
<p>The smoothing is determined by the parameter <em>τ</em><sub>2</sub>. Small values of <em>τ</em><sub>2</sub> lead to more smoothing, while large values of <em>τ</em><sub>2</sub> lead to little information sharing between doses (above dose 1). Note that “small” and “large” is dependent on the scale of the doses. The prior on the smoothing parameter is:</p>
<p><span class="math display">\[\tau\_{2}^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p>where <em>τ</em><sub><em>μ</em></sub> is a central value for <em>τ</em><sub>2</sub>, and <em>τ</em><sub><em>n</em></sub> is the prior weight.</p>
<p>Note that that in this formulation, <em>τ</em><sub>2</sub><sup>2</sup> can be thought of as the deviation from linearity. The linear scaling of deviations thus leads to a conditional variance that scales as the square of the dose difference:</p>
<p><em>V<strong>a</strong>r</em>[<em>θ</em><sub><em>d</em></sub>|<em>θ</em><sub><em>d</em> − 1</sub>, <em>θ</em><sub><em>d</em> − 2</sub>]=&nbsp;<em>τ</em><sub>2</sub><sup>2</sup>•(<em>ν</em><sub><em>d</em></sub> − <em>ν</em><sub><em>d</em> − 1</sub>)<sup>2</sup></p>
<p>The Second Order NDLM, like the Simple NDLM, is generally a good model to use when the shape of the likely dose response is unknown, but we would like to borrow information between a dose and its neighboring doses. No monotonicity or pre-determined shape is enforced by the Second Order NDLM. The variance in dose response from dose to dose is updated based on the observed data, but as the number of doses in a trial is typically small, a moderately informative prior is often used.</p>
<p>In a ‘null’ scenario where the response on all the doses is the same as control, like the simple NDLM, the second order NDLM reduces type-1 error. As the estimate of <em>τ</em><sup>2</sup> tends to zero and the estimate of the dose response tends to a line (with non-zero slope if appropriate).</p>
<p>The second order NDLM has more power than the Simple NDLM when the dose response is smooth, but will tend to underestimate by more than the Simple NDLM if there are marked peaks or steps in the response. Because it borrows from two doses, it is better at estimating a response for a dose where there is no data than the simple NDLM can, and can be used with burn-in’s where not all doses have been allocated to, but doesn’t cope well if there are consecutive doses where there is no data.</p>
<p>However, unlike the simple NDLMs where the variance structure is preserved if doses are added to or dropped from the design, this is not true for the 2<sup>nd</sup> order NLDM. Thus, if using the 2<sup>nd</sup> order NDLM, and the doses that are available to the model are changed, then the parameters for the prior for <em>τ</em><sub>2</sub><sup>2</sup> may need to be re-visited.</p>
<p>The simple NDLM is likely to be preferred where there are fewer doses (4-5), and the second order NDLM is often preferred when there are 7 or more (it will depend on the expected smoothness of the response – the smoother it is the more useful the second order NDLM will be).</p>
<p>As with the simple NDLM, the choice of prior for <em>τ</em><sup>2</sup> can be tuned based on simulation results: balancing having a smaller prior that limits type-1 error in the null case, against having a larger prior that yields more power and better estimate of maximum response in the effective scenarios with the large jumps in response or pronounced peaks.</p>
</section>
<section id="parameter-logistic" class="level3" data-number="7.2.6">
<h3 data-number="7.2.6" class="anchored" data-anchor-id="parameter-logistic"><span class="header-section-number">7.2.6</span> 3-Parameter Logistic</h3>
<p>The 3-parameter logistic dose response model estimates efficacy as a smooth curve using an intuitive parameterization. The dose response for a dose d with effective dose strength <em>v</em><sub><em>d</em></sub> is:</p>
<p><span class="math display">\[\theta\_{d} = a\_{1} + \frac{a\_{2}v\_{d}}{v\_{d} + a\_{3}}\]</span></p>
<p>Where the <em>a</em> parameters have the following description:</p>
<p><em>a</em><sub>1</sub>&nbsp;is the estimated dose response for a dose of strength 0</p>
<blockquote class="blockquote">
<p><em>a</em><sub>2</sub> is the estimated change in dose response for a dose with strength ∞ when compared to a dose of strength 0.</p>
<p><em>a</em><sub>3</sub> is the estimated ED50, the dose that has 50% of the dose response maximum (<em>a</em><sub>2</sub>)</p>
</blockquote>
<p>The shape of the 3-parameter logistic curve can vary wildly based on the parameter values, but always starts at <em>a</em><sub>1</sub> at dose strength 0 and monotonically increases to <em>a</em><sub>1</sub> + <em>a</em><sub>2</sub> as the effective dose strength goes to infinity.</p>
<p>The following independent prior distributions are assumed:</p>
<p><em>a</em><sub>1</sub> ∼ <em>N</em>(<em>Λ</em><sub>1</sub>,&nbsp;<em>λ</em><sub>1</sub><sup>2</sup>)</p>
<p><em>a</em><sub>2</sub> ∼ <em>N</em>(<em>Λ</em><sub>2</sub>,&nbsp;<em>λ</em><sub>2</sub><sup>2</sup>)</p>
<p><em>a</em><sub>3</sub> ∼ <em>N</em><sup>+</sup>(<em>Λ</em><sub>3</sub>,&nbsp;<em>λ</em><sub>3</sub><sup>2</sup>)</p>
<p>In the continuous case, the prior distribution for the error term in the 3-Parameter Logistic is Inverse Gamma:</p>
<p><span class="math display">\[\sigma^{2}\sim IG\left( \frac{\sigma\_{n}}{2},\frac{\sigma\_{\mu}^{2}\sigma\_{n}}{2} \right)\]</span></p>
<p>An advantage of the 3-Parameter Logistic model is that it is has a small number of parameters that have defined, intuitive interpretations. Since there are few parameters it’s generally easy to estimate the parameters even on small amounts of data. Because of the limited flexibility of the logistic curve, the 3-parameter logistic model should only be used when there is evidence that it is appropriate. See the Hierarchical Logistic and Sigmoid (<em>E</em><sub>max</sub>) models for dose response models with a similar pattern, but slightly more flexibility in shape.</p>
</section>
<section id="hierarchical-logistic" class="level3" data-number="7.2.7">
<h3 data-number="7.2.7" class="anchored" data-anchor-id="hierarchical-logistic"><span class="header-section-number">7.2.7</span> Hierarchical Logistic</h3>
<p>The hierarchical logistic model is an extension of the 3-parameter logistic with the form:</p>
<p><span class="math display">\[\theta\_{d} = a\_{1} + \frac{a\_{2}v\_{d}}{v\_{d} + a\_{3}} + \zeta\_{d}\]</span></p>
<p>where <em>ζ</em><sub><em>d</em></sub> is a random intercept term that modifies <em>a</em><sub>1</sub> differently for each dose under the constraint that all <em>ζ</em><sub><em>d</em></sub> must sum to 0.</p>
<p>The additional term <em>ζ</em><sub><em>d</em></sub> is a per dose ‘off-curve’ effect. It allows for a secondary non-parametric dose effect over and above the logistic model. It has been used in circumstances in which there is actually some falling away of effect at the highest dose. This is an example mean fit from 100 simulations. The model fit and error bars are in green, and the true dose responses are shown by the black line.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image22.png" style="width:2.97677in;height:2.6604in"></p>
<p><em>ζ</em><sub><em>d</em></sub> is modelled as:</p>
<p><em>ζ</em><sub><em>d</em></sub> ∼ <em>N</em>(0, <em>a</em><sub>4</sub><sup>2</sup>)</p>
<p>conditioned that</p>
<p><span class="math display">\[\sum\_{d}^{}\zeta\_{d} = 0\]</span></p>
<p>And <em>a</em><sub>4</sub><sup>2</sup> has an inverse gamma prior:</p>
<p><span class="math display">\[a\_{4}^{2}\sim IG\left( \frac{\Lambda\_{n}}{2},\frac{\Lambda\_{\mu}^{2}\Lambda\_{n}}{2} \right)\]</span></p>
<p>The following independent prior distributions are assumed:</p>
<p><em>a</em><sub>1</sub> ∼ <em>N</em>(<em>Λ</em><sub>1</sub>,&nbsp;<em>λ</em><sub>1</sub><sup>2</sup>)</p>
<p><em>a</em><sub>2</sub> ∼ <em>N</em>(<em>Λ</em><sub>2</sub>,&nbsp;<em>λ</em><sub>2</sub><sup>2</sup>)</p>
<p><em>a</em><sub>3</sub> ∼ <em>N</em><sup>+</sup>(<em>Λ</em><sub>3</sub>,&nbsp;<em>λ</em><sub>3</sub><sup>2</sup>)</p>
<p>A typical recommended value for the center of the prior distribution of <em>α</em><sub>4</sub> is the largest expected likely deviation in true response from the underlying logistic with a weight of 1. The effect of this prior is then checked through simulation of a range of plausible dose response profiles, with a range of designs to check the sensitivity of the final estimate of response to this prior.</p>
<p>In this model, compared to the ‘plain’ 3-parameter logistic above, it is important that the true ED50 lies within the expected dose range, and that the prior for the ED50, <em>a</em><sub>3</sub>, has the majority of its probability mass in the available dose range, for example if the range of the effective dose strengths is from 0 to <em>ν</em><sub><em>D</em></sub>, then a typical ‘weakly informative’ prior for <em>a</em><sub>3</sub> would be:</p>
<p><span class="math display">\[a\_{3}\\\sim\\N^{+}\left( \frac{\nu\_{D}}{2},\left( \frac{\nu\_{D}}{2} \right)^{2} \right)\]</span></p>
<p>Using a weaker prior, such as: <em>N</em><sup>+</sup>(<em>ν</em><sub><em>D</em></sub>, (<em>ν</em><sub><em>D</em></sub>)<sup>2</sup>), leads to a more linear fit, for instance with just this change to the prior for <em>a</em><sub>3</sub> the average of the estimated of the mean response change from the graph above, to:</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image23.png" style="width:2.9739in;height:3.15818in"></p>
</section>
<section id="sigmoid-model" class="level3" data-number="7.2.8">
<h3 data-number="7.2.8" class="anchored" data-anchor-id="sigmoid-model"><span class="header-section-number">7.2.8</span> Sigmoid Model</h3>
<p>A sigmoid model (<em>E</em><sub>max</sub> model) provides a coherent parameterization of the dose response trend similar to the 3-parameter logistic, but with one extra shape parameter, <em>a</em><sub>4</sub>.</p>
<p>The model formula is:</p>
<p><span class="math display">\[\theta\_{d} = a\_{1} + \frac{(a\_{2} - a\_{1})v\_{d}^{a\_{4}}}{{a\_{3}}^{a\_{4}} + v\_{d}^{a\_{4}}}\]</span></p>
<p>The interpretation of the four parameters is:</p>
<p><em>a</em><sub>1</sub>&nbsp;is the estimated dose response for a dose of strength 0</p>
<blockquote class="blockquote">
<p><em>a</em><sub>2</sub> is the estimated dose response for a dose of strength ∞ (slight difference from Logistic models)</p>
<p><em>a</em><sub>3</sub> is the estimated ED50, the dose that has 50% of the dose response maximum attainable effect (<em>a</em><sub>2</sub> − <em>a</em><sub>1</sub>)</p>
<p><em>a</em><sub>4</sub> controls the slope of the dose response model at the ED50. A larger value of <em>a</em><sub>4</sub> corresponds to a steeper slope. A value of <em>a</em><sub>4</sub> = 1 makes the Sigmoid model equivalent to a Three Parameter Logistic model with <em>a</em><sub>2</sub> equal to <em>a</em><sub>1</sub> + <em>a</em><sub>2</sub> from the Sigmoid model. A value of <em>a</em><sub>4</sub> approaching 0 corresponds to a dose response model that is nearly flat at <span class="math inline">\(\frac{a\_{1} + a\_{2}}{2}\)</span>. By differentiation, it can be seen that the slope where the effective dose <em>ν</em><sub><em>d</em></sub> = <em>a</em><sub>3</sub> is <span class="math inline">\((a\_{2} - a\_{1})\frac{a\_{4}}{4a\_{3}}\)</span>.</p>
</blockquote>
<p>The following independent prior distributions are assumed:</p>
<p><em>a</em><sub>1</sub> ∼ <em>N</em>(<em>Λ</em><sub>1</sub>,&nbsp;<em>λ</em><sub>1</sub><sup>2</sup>)</p>
<p><em>a</em><sub>2</sub> ∼ <em>N</em>(<em>Λ</em><sub>2</sub>,&nbsp;<em>λ</em><sub>2</sub><sup>2</sup>)</p>
<p><em>a</em><sub>3</sub> ∼ <em>N</em><sup>+</sup>(<em>Λ</em><sub>3</sub>,&nbsp;<em>λ</em><sub>3</sub><sup>2</sup>)</p>
<p><em>a</em><sub>4</sub> ∼ <em>N</em><sup>+</sup>(<em>Λ</em><sub>4</sub>,&nbsp;<em>λ</em><sub>4</sub><sup>2</sup>)</p>
<p>The advantage of the model is that it is considerably more flexible than the logistic, but still more efficient to estimate than an NDLM. This model (if applicable) is ideal if the target is an Effective Dose (ED) such as an ED90. Estimating an ED requires estimating the response on control, the maximum response, and the gradient which is requires a lot of data to do well if using no model or a smoothing model such as one of the NDLMs. With the 4-parameter sigmoid model (or 3-parameter logistic – but that has a more limited applicability due to being significantly less flexible in shape), it’s usually not an issue to estimate the EDx well.</p>
<p>The caveats to using this model are:</p>
<ul>
<li><p>Whilst being much more flexible than the logistic, it still has model assumptions, in particular monotonicity, that must be met for this to be a reasonable model to be used.</p></li>
<li><p>The curve is only well estimated if the true ED50 lies within the doses tested.</p></li>
<li><p>Like the hierarchical logistic model above, the prior for <em>a</em><sub>3</sub>&nbsp;should be weakly informative, with the majority of its probability mass in the available dose range. So similarly, if the range of the effective dose strengths is from 0 to <em>ν</em><sub><em>D</em></sub> then a typical ‘weakly informative’ prior for <em>α</em><sub>3</sub> would be:</p></li>
</ul>
<blockquote class="blockquote">
<p><span class="math display">\[a\_{3}\\\sim\\N^{+}\left( \frac{\nu\_{D}}{2},\left( \frac{\nu\_{D}}{2} \right)^{2} \right)\]</span></p>
</blockquote>
<p><img src="coreUGattachments/CoreUserGuide/media/image24.png" style="width:3.384in;height:2.12987in"></p>
</section>
<section id="u-shaped-model" class="level3" data-number="7.2.9">
<h3 data-number="7.2.9" class="anchored" data-anchor-id="u-shaped-model"><span class="header-section-number">7.2.9</span> U-Shaped Model</h3>
<p>The U-shaped model when the allows for an initial increase (decrease) in the dose response with dose, followed by a levelling out of the mean, then a decrease (increase). Whether the U-Shaped model increases then decreases or decreases then increases is specified by the user on the Dose Response tab. An example curve for this model is given in the figure below.</p>
<p>The dose-response curve can be characterized in four different regions of doses. For the first region, which contains the lowest doses, 0 &lt; <em>ν</em><sub><em>d</em></sub> &lt; <em>p</em><sub>min</sub>, the dose-response curve is increasing (decreasing):</p>
<p><span class="math display">\[\theta\_{d} = \theta\_{0} + S \bullet \delta \bullet \left( \frac{\nu\_{d}}{p\_{\min}} \right)^{\alpha}\]</span></p>
<p>The next region is the plateau, where the dose-response curve is constant. For <em>p</em><sub>min</sub> &lt; <em>ν</em><sub><em>d</em></sub> &lt; <em>p</em><sub>min</sub> + <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>:</p>
<p><em>θ</em><sub><em>d</em></sub> = <em>θ</em><sub>0</sub> + <em>S</em> • <em>δ</em></p>
<p>For the third region, the dose-response curve is decreasing (increasing). For <em>p</em><sub>min</sub> + <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> &lt; <em>ν</em><sub><em>d</em></sub> &lt; <em>p</em><sub>min</sub> + <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> + <em>w</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>,</p>
<p><span class="math display">\[\theta\_{d} = \theta\_{0} + S \bullet \delta \bullet \left( 1 - \frac{\nu\_{d} - \left( p\_{\min} + p\_{width} \right)}{w\_{width}} \right)^{\beta}\]</span></p>
<p>For the final region, the dose-response curve is again constant, at the same level as the zero-dose. For <em>ν</em><sub><em>d</em></sub> &gt; <em>p</em><sub>min</sub> + <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> + <em>w</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>,</p>
<p><em>θ</em><sub><em>d</em></sub> = <em>θ</em><sub>0</sub></p>
<p>The parameters of the model are described below:</p>
<ol type="1">
<li><p><em>S</em> is 1 or -1, as determined by the Model is increasing/decreasing radio buttons. S=1 if Model is Increasing is selected, indicating that the model starts increasing at low doses.</p></li>
<li><p><em>θ</em><sub>0</sub> represents the zero-strength dose response:</p></li>
</ol>
<blockquote class="blockquote">
<p><em>θ</em><sub>0</sub> ∼ <em>N</em>(<em>μ</em><sub>0</sub>, <em>σ</em><sub>0</sub><sup>2</sup>)</p>
</blockquote>
<ol type="1">
<li><em>δ</em> represents the maximal change in response from the zero-strength dose. It is restricted to be positive:</li>
</ol>
<blockquote class="blockquote">
<p><em>δ</em> ∼ <em>N</em><sup>+</sup>(<em>μ</em><sub><em>δ</em></sub>, <em>σ</em><sub><em>δ</em></sub><sup>2</sup>)</p>
</blockquote>
<ol type="1">
<li><em>p</em><sub>min</sub> represents the lowest dose at which the maximal change in response from the zero-strength is achieved. It is restricted to be positive:</li>
</ol>
<blockquote class="blockquote">
<p><em>p</em><sub>min</sub> ∼ <em>N</em><sup>+</sup>(<em>μ</em><sub>min</sub>, <em>σ</em><sub>min</sub><sup>2</sup>)</p>
</blockquote>
<ol type="1">
<li><em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> represents the width of the plateau – the region where all doses achieve maximal change in response from the zero-strength dose. It is restricted to be positive:</li>
</ol>
<blockquote class="blockquote">
<p><em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> ∼ <em>N</em><sup>+</sup>(<em>μ</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>, <em>σ</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub><sup>2</sup>)</p>
</blockquote>
<ol type="1">
<li><em>w</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> represents the width of the region for doses beyond the plateau, where response is returning to the zero-strength dose level. It is restricted to be positive:</li>
</ol>
<blockquote class="blockquote">
<p><em>w</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> ∼ <em>N</em><sup>+</sup>(<em>μ</em><sub><em>w</em></sub>, <em>σ</em><sub><em>w</em></sub><sup>2</sup>)</p>
</blockquote>
<ol type="1">
<li><em>α</em> determines the rate of change of the dose response curve for doses below the plateau. Values less than 1 indicate a rapid initial change from baseline, with slower change as the plateau is reached. Values greater than 1 indicate a slow initial change from baseline, with more rapid change as the plateau is reached. To help avoid identifiability issues, <em>α</em> is restricted to be between 10<sup>-1</sup> and 10<sup>1</sup>.</li>
</ol>
<blockquote class="blockquote">
<p><em>α</em> ∼ *L**N<em><sup>*</sup>(</em>μ<em><sub></sub></em>α<em>, </em>σ<em><sub></sub></em>α*<sup>2</sup>)</p>
</blockquote>
<p>where *L**N*<sup>*</sup> represents the lognormal distribution, with the truncation constraints at 10<sup>-1</sup> and 10<sup>1</sup>.</p>
<ol type="1">
<li><em>β</em> determines the rate of change of the dose response curve for doses beyond the plateau. Values less than 1 indicate a slow initial change from the plateau level, with more rapid change subsequently. Values greater than 1 indicate a rapid initial change from the plateau level, with slower change subsequently. To help avoid identifiability issues, <em>β</em> is restricted to be between 10<sup>-1</sup> and 10<sup>1</sup>:</li>
</ol>
<blockquote class="blockquote">
<p><em>β</em> ∼ *L**N<em><sup>*</sup>(</em>μ<em><sub></sub></em>β<em>, </em>σ<em><sub></sub></em>β*<sup>2</sup>)</p>
</blockquote>
<p>The U-shaped model has seven free parameters, and thus it is inadvisable to use such a model for dose-finding trial designs that contain only a few dose levels. When a small number of doses are available, it may help to constrain the values of <em>α</em> and <em>β</em> by utilizing small standard deviations in the priors.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image25.emf" style="width:4.63571in;height:4.63571in"></p>
</section>
<section id="plateau-model" class="level3" data-number="7.2.10">
<h3 data-number="7.2.10" class="anchored" data-anchor-id="plateau-model"><span class="header-section-number">7.2.10</span> Plateau Model</h3>
<p>The plateau model is a special case of the U-shaped model, in which <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub> = ∞. That is, there is no return to baseline for high doses. This model thus eliminates three parameters, since <em>p</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>, <em>w</em><sub><em>w<strong>i</strong>d<strong>t</strong>h</em></sub>, and <em>β</em> are not used. See the figure below to see an example dose response model for the plateau model that mimics the beginning of the U-Shaped model above.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image26.emf" style="width:4.70513in;height:4.70714in"></p>
</section>
<section id="parameter-exp-logistic-dichotomous-only" class="level3" data-number="7.2.11">
<h3 data-number="7.2.11" class="anchored" data-anchor-id="parameter-exp-logistic-dichotomous-only"><span class="header-section-number">7.2.11</span> 3 Parameter Exp Logistic (Dichotomous Only)</h3>
<p>The 3-parameter exponential logistic model has the following structure:</p>
<p><em>θ</em><sub><em>d</em></sub> = <em>a</em><sub>1</sub> + <em>a</em><sub>2</sub> * <em>ν</em><sub><em>d</em></sub><sup><em>a</em><sub>3</sub></sup></p>
<p>Where <em>ν</em><sub><em>d</em></sub> is the effective dose strength of dose <em>d</em>. This is a logistic model for the dichotomous endpoint because <em>θ</em><sub><em>d</em></sub> is the log odds ratio of the probability of the response, <em>P</em><sub><em>d</em></sub> at dose <em>d</em>.</p>
<p>The exponent parameter <em>α</em><sub>3</sub> allows the change in slope at the lower end of the curve to be asymmetric in comparison to the change in curve at the upper end of the curve.</p>
<p>The priors for the parameters are:</p>
<p><em>a</em><sub>1</sub> ∼ <em>N</em>(<em>Λ</em><sub>1</sub>,&nbsp;<em>λ</em><sub>1</sub><sup>2</sup>)</p>
<p><em>a</em><sub>2</sub> ∼ <em>N</em>(<em>Λ</em><sub>2</sub>,&nbsp;<em>λ</em><sub>2</sub><sup>2</sup>)</p>
<p><em>a</em><sub>3</sub> ∼ <em>N</em><sup>+</sup>(<em>Λ</em><sub>3</sub>,&nbsp;<em>λ</em><sub>3</sub><sup>2</sup>)</p>
<p>The interpretations of the parameters defining this model are:</p>
<p><em>a</em><sub>1</sub> is the dose response for a dose with strength 0</p>
<p><em>a</em><sub>2</sub> is the slope associated with the exponentiated dose strength</p>
<p><em>a</em><sub>3</sub> is a shape parameter modifying the effective dose strength through exponentiation.</p>
<p>The figure below shows an example of two different exp3-paramtere exponential logistic model fits. Notably, the fit showing in green has an <em>a</em><sub>3</sub> parameter greater than 1, which leads to faster increases of the sigmoid model as the effective dose strength increases.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image27.png" style="width:3.424in;height:2.28267in"></p>
</section>
<section id="hierarchical-model" class="level3" data-number="7.2.12">
<h3 data-number="7.2.12" class="anchored" data-anchor-id="hierarchical-model"><span class="header-section-number">7.2.12</span> Hierarchical Model</h3>
<p>Like the Independent Dose Model, the hierarchical model treats the arms as if they are an unordered set of treatments, but unlike the Independent Dose Model the Hierarchical Model shares information between doses included in the model. The hierarchical model is a way of encouraging the estimates of arm responses to be similar, and the degree of this encouragement can be controlled using parameters of the prior distribution. The hierarchical model assumes that the arm parameters are drawn from the same normal distribution:</p>
<p><em>θ</em><sub><em>d</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em>, <em>τ</em><sup>2</sup>)</p>
<p>Where <em>d</em> is the set of doses included in the model. The prior distributions for <em>μ</em> and <em>τ</em><sup>2</sup> are</p>
<p><em>μ</em>&nbsp;∼&nbsp;<em>N</em>(<em>Λ</em><sub><em>μ</em></sub>,&nbsp;<em>λ</em><sub><em>μ</em></sub><sup>2</sup>)</p>
<p>and</p>
<p><span class="math display">\[\tau^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p>where <em>τ</em><sub><em>μ</em></sub> is a central value for <em>τ</em>, and <em>τ</em><sub><em>n</em></sub> is the prior weight. <em>τ</em><sup>2</sup> governs the amount of information sharing between doses in the model. The estimates of the dose parameters can be encouraged to be close together by choosing a small value for <em>τ</em><sub><em>μ</em></sub> and a large value for <em>τ</em><sub><em>n</em></sub>.</p>
<p>The control arm can be included in the hierarchical model, if it is desired to encourage the experimental arms to be similar to the control arm, or excluded from it, if the experimental arms are encouraged to be similar to each other but not necessarily to the control arm. The exception is with time-to-event data, when the control arm must be excluded from the hierarchical model.</p>
</section>
<section id="linear-model" class="level3" data-number="7.2.13">
<h3 data-number="7.2.13" class="anchored" data-anchor-id="linear-model"><span class="header-section-number">7.2.13</span> Linear Model</h3>
<p>The linear model uses a strong assumption of exact linearity between the responses and the dose strengths. (For dichotomous models, the linearity is on the log-odds scale, and the linearity is on the log hazard ratio scale for TTE models.) The model is</p>
<p><em>θ</em><sub><em>d</em></sub> = <em>α</em> + *β**ν<em><sub></sub></em>d*</p>
<p>for all doses <em>d</em> in the model. Both <em>α</em> and <em>β</em> are given normal prior distributions:</p>
<p><em>α</em>&nbsp;∼&nbsp;<em>N</em>(<em>Λ</em><sub><em>α</em></sub>, <em>λ</em><sub><em>α</em></sub><sup>2</sup>)</p>
<p><em>β</em>&nbsp;∼&nbsp;<em>N</em>(<em>Λ</em><sub><em>β</em></sub>, <em>λ</em><sub><em>β</em></sub><sup>2</sup>)</p>
<p>The linear model is appropriate when there is strong scientific knowledge that the shape of the response curve should be linear as a function of dose strength. Note that if an arm has a dose strength between two other arms in the model, its response will always be estimated to be between the responses of those two arms. As a result, the linear model may not be appropriate in combination with certain decision quantities such as Pr(Max), because some doses are guaranteed to have probability zero of being the best arm. If the control arm is included in the linear model and it has the smallest dose value, then all experimental arms will always have exactly the same probability of being better than control.</p>
<p>We recommend creating scenarios where the true parameters deviate from linearity and simulating them to test the robustness of a design based on the linear model.</p>
<p>For dichotomous models, the linear model replaces the 2-parameter logistic model available in FACTS versions before 6.4. The two models are identical.</p>
</section>
<section id="hierarchical-linear-model" class="level3" data-number="7.2.14">
<h3 data-number="7.2.14" class="anchored" data-anchor-id="hierarchical-linear-model"><span class="header-section-number">7.2.14</span> Hierarchical Linear Model</h3>
<p>A more flexible version of the linear model is the hierarchical linear model. This model encourages the arm responses to have a linear-like shape, but also includes a term allowing parameters to deviate from linearity when appropriate. The arm parameters satisfy the relationship</p>
<p><em>θ</em><sub><em>d</em></sub> = <em>α</em> + *β**ν<em><sub></sub></em>d<em> + </em>ζ<em><sub></sub></em>d*</p>
<p>where the <em>α</em> and <em>β</em> parameters are as in the linear model, with prior distributions</p>
<p><em>α</em>&nbsp;∼&nbsp;<em>N</em>(<em>Λ</em><sub><em>α</em></sub>, <em>λ</em><sub><em>α</em></sub><sup>2</sup>)</p>
<p><em>β</em>&nbsp;∼&nbsp;<em>N</em>(<em>Λ</em><sub><em>β</em></sub>, <em>λ</em><sub><em>β</em></sub><sup>2</sup>),</p>
<p>and the <em>ζ</em><sub><em>d</em></sub> parameters are the deviations from linearity. These deviations are assumed to have a normal distribution constrained so that their average value is zero:</p>
<p><em>ζ</em><sub><em>d</em></sub> ∼ <em>N</em>(0, <em>τ</em><sup>2</sup>) with ∑<em>ζ</em><sub><em>d</em></sub> = 0.</p>
<p>The prior distribution for <em>τ</em><sup>2</sup> is</p>
<p><span class="math display">\[\tau^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p>If <em>τ</em><sup>2</sup> is small, which can be encouraged by choosing <em>τ</em><sub><em>μ</em></sub> to be small and <em>τ</em><sub><em>n</em></sub> to be large, then the dose parameter estimates will lie close to a line.</p>
<p>The hierarchical linear model is a good choice when, for example, one expects a linear relationship between the dose strengths and the response but one is not prepared to assume exact linearity. It can also be a good way of encouraging, but not requiring, monotonicity in the response.</p>
</section>
</section>
<section id="d-treatment-dose-response-models" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="d-treatment-dose-response-models"><span class="header-section-number">7.3</span> 2D Treatment Dose Response Models</h2>
<p>If on the Study &gt; Treatment Arms tab, the “Use 2D treatment arm model” option has been checked, the user may either use any of the 1D Dose Response options described above, or may use a dose response model specifically modelling the two dosing dimensions.</p>
<p>If using one of the 1D dose response models, the effective dose strength ν<sub>d</sub> is as specified by the user on the “Select doses to be used in the trial” tab. These calculated dose levels are forced to be distinct values, and this results in a 1D ordering of the combinations.</p>
<p>There are also three 2D Dose Response models that can be used:</p>
<ol type="1">
<li><p>2D Continuous Factorial Model</p></li>
<li><p>2D Discrete Factorial model</p></li>
<li><p>2D NDLM</p></li>
</ol>
<p>These are described in the next sections.</p>
<p>The 2D dose response models work with a slightly different notation to accommodate that treatments are defined as the combination of two factors. Rather than <em>θ</em><sub><em>i</em></sub> being the estimated mean of the dose response estimate for dose <em>i</em>, the estimated dose response for the treatment created from row factor level <em>r</em> and column factor level <em>c</em> is denoted <em>θ</em><sub><em>r<strong>c<em></em></strong></em></sub><em><strong><em>. </em>Y<em><sub></sub></em>r</strong>c</em> denotes the mean of the observed data in the cell.</p>
<p>In the continuous case, the likelihood for the data is,</p>
<p><em>Y</em><sub><em>r<strong>c<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>N<em>(</em>θ<em><sub></sub></em>r</strong>c</em>,&nbsp;<em>σ</em><sup>2</sup>)</p>
<p><span class="math display">\[\sigma^{2}\\\sim\\IG\left( \frac{\sigma\_{n}}{2},\frac{\sigma\_{\mu}^{2}\sigma\_{n}}{2} \right)\]</span></p>
<p>Where the form of <em>θ</em><sub>*r**c*</sub> varies based on dose response model selection.</p>
<p>Similarly, in the dichotomous case,</p>
<p><em>Y</em><sub><em>r<strong>c<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>B</strong>e<strong>r</strong>n<strong>o</strong>u<strong>l</strong>l<strong>i<em>(</em>P<em><sub></sub></em>r</strong>c</em>)</p>
<p><span class="math display">\[P\_{rc} = \\\frac{e^{\theta\_{rc}}}{1 + e^{\theta\_{rc}}}\]</span></p>
<section id="d-continuous-factorial-model" class="level3" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="d-continuous-factorial-model"><span class="header-section-number">7.3.1</span> 2D Continuous Factorial Model</h3>
<p>The 2D Continuous Factorial Model fits a regression on the dose response that uses the numeric dose strength as a continuous valued covariate. The dose response (with <em>η</em><sub><em>r</em></sub> and <em>ζ</em><sub><em>c</em></sub> denoting dose strength of the row level and column level, respectively) is modelled as:</p>
<p><em>θ</em><sub>*r**c<em></em></sub><em> = </em>α<em><sub>0</sub> + </em>α<em><sub>1</sub></em>ζ<em><sub></sub></em>c<em> + </em>α<em><sub>2</sub></em>η<em><sub></sub></em>r<em> + </em>α<em><sub>3</sub></em>ζ<em><sub></sub></em>c<em></em>η<em><sub></sub></em>r*</p>
<p>With priors</p>
<p><em>α</em><sub>0</sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>0</sub>,&nbsp;<em>σ</em><sub>0</sub><sup>2</sup>)</p>
<p><em>α</em><sub>1</sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>1</sub>,&nbsp;<em>σ</em><sub>1</sub><sup>2</sup>)</p>
<p><em>α</em><sub>2</sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>2</sub>,&nbsp;<em>σ</em><sub>2</sub><sup>2</sup>)</p>
<p><em>α</em><sub>3</sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>3</sub>,&nbsp;<em>σ</em><sub>3</sub><sup>2</sup>)</p>
<p>Thus <em>α</em><sub>0</sub> is the response at the control combination, <em>α</em><sub>1</sub> is the linear coefficient of the response to the column factor strengths <em>ζ</em><sub><em>c</em></sub>, and <em>α</em><sub>2</sub> is the linear coefficient of the response to the row factor strengths <em>η</em><sub><em>r</em></sub>.</p>
<p>The user has the option to simplify the model and exclude the interaction term <em>α</em><sub>3</sub>, which is the coefficient of the product of the two factor strengths.</p>
<p>Note that despite being called “continuous” this dose response model applies to all endpoints. It’s called continuous because the coefficients act on the dose strengths as continuous measures of strength.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image29.png" style="width:5.50007in;height:4.17635in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
<section id="d-discrete-factorial-model" class="level3" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="d-discrete-factorial-model"><span class="header-section-number">7.3.2</span> 2D Discrete Factorial Model</h3>
<p>The 2D Discrete Factorial Model fits a regression on the dose response that uses the dose strength as a factor covariate rather than a numeric dose strength. Each dose is an independent level within each row or column factor, so any dose is equidistant from all other doses</p>
<p><em>θ</em><sub>*r**c<em></em></sub><em> = </em>α<em> + </em>γ<em><sub></sub></em>r<em> + </em>β<em><sub></sub></em>c*</p>
<p>With priors</p>
<p><em>α</em>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>α</em></sub>,&nbsp;<em>σ</em><sub><em>α</em></sub><sup>2</sup>)</p>
<p><em>β</em><sub><em>c</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>β</em><sub><em>c</em></sub></sub>,&nbsp;<em>σ</em><sub><em>β</em><sub><em>c</em></sub></sub><sup>2</sup>)</p>
<p><em>γ</em><sub><em>r</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>γ</em><sub><em>r</em></sub></sub>,&nbsp;<em>σ</em><sub><em>γ</em><sub><em>r</em></sub></sub><sup>2</sup>)</p>
<p>The parameters associated with lowest level of each factor, <em>γ</em><sub>0</sub> and <em>β</em><sub>0</sub>, are constrained to be 0.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image30.png" style="width:5.51472in;height:4.35172in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
<section id="d-ndlm" class="level3" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="d-ndlm"><span class="header-section-number">7.3.3</span> 2D NDLM</h3>
<p>The 2-D NDLM Model takes the idea of smoothing across doses that was used in the standard NDLM model, but smooths across row factors and column factors separately.</p>
<section id="the-base-model-with-control-included" class="level4" data-number="7.3.3.1">
<h4 data-number="7.3.3.1" class="anchored" data-anchor-id="the-base-model-with-control-included"><span class="header-section-number">7.3.3.1</span> The Base Model, with Control Included</h4>
<p>The treatment effect for the combination of level <em>r</em> in the row factor and level <em>c</em> in the column factor is denoted as <em>θ</em><sub><em>r<strong>c<em></em></strong></em></sub><em><strong><em>, and </em>Y<em><sub></sub></em>r</strong>c</em> is the observed data in that cell. The borrowing parameters are denoted as <em>ϕ</em> for the row factor smoothing, and <em>τ</em> for the column factor smoothing. The dose strengths are denoted as <em>v</em><sub><em>r</em></sub> for the row factors, and <em>ω</em><sub><em>c</em></sub> for the column factors. Let Δ<em>ν</em><sub><em>r</em></sub> = <em>ν</em><sub><em>r</em></sub> − <em>ν</em><sub><em>r</em> − 1</sub> and Δ<em>ω</em><sub><em>c</em></sub> = <em>ω</em><sub><em>c</em></sub> − <em>ω</em><sub><em>c</em> − 1</sub> (for <em>r</em> &gt; 0 and <em>c</em> &gt; 0). For notational convenience at the grid edge, let <em>θ</em><sub>−1, <em>c</em></sub> = 0, <em>θ</em><sub><em>r</em>, −1</sub> = 0, Δ<em>ν</em><sub>0</sub> ≡ ∞, and Δ<em>ω</em><sub>0</sub> ≡ ∞.</p>
<p>The 2-D NDLM Model <em>with control included in the model</em> can then be specified as:</p>
<p><em>θ</em><sub>0, 0</sub>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub>0</sub>, <em>τ</em><sub>0</sub><sup>2</sup>)</p>
<p><em>θ</em><sub><em>r<strong>c<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>N<em>(</em>μ<em><sub></sub></em>r</strong>c</em>, <em>τ</em><sub>*r**c*</sub><sup>2</sup>)</p>
<p>where</p>
<p><span class="math display">\[\tau\_{rc}^{2} = \\\left( \frac{1}{\mathrm{\Delta}\nu\_{r}\phi^{2}} + \frac{1}{\mathrm{\Delta}\omega\_{c}\tau^{2}} \right)^{- 1}\]</span></p>
<p><span class="math display">\[\mu\_{rc} = \\\tau\_{rc}^{2}\left( \frac{\theta\_{r - 1,c}}{\mathrm{\Delta}\nu\_{r}\phi^{2}} + \frac{\theta\_{r,c - 1}}{\mathrm{\Delta}\omega\_{c}\tau^{2}} \right)\]</span></p>
<p>with priors</p>
<p><span class="math display">\[\tau^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p><span class="math display">\[\phi^{2}\\\sim\\IG\left( \frac{\phi\_{n}}{2},\frac{\phi\_{\mu}^{2}\phi\_{n}}{2} \right)\]</span></p>
<p>Note: that not all combinations of <em>r</em> and <em>c</em> will have data associated with them. However, FACTS will still evaluate the prior at all combinations. Thus, in the situation depicted below where the grayed-out point indicates a treatment combination with no allocation, <em>θ</em><sub>1, 2</sub> is not modeled conditionally only on <em>θ</em><sub>1, 1</sub>; <em>θ</em><sub>0, 1</sub> also informs on <em>θ</em><sub>1, 2</sub> via <em>θ</em><sub>0, 2</sub>.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image31.png" style="width:2.1in;height:2.1in" alt="Calendar Description automatically generated"></p>
</section>
<section id="fix-smoothing-ratio-for-row-factor-and-column-factor" class="level4" data-number="7.3.3.2">
<h4 data-number="7.3.3.2" class="anchored" data-anchor-id="fix-smoothing-ratio-for-row-factor-and-column-factor"><span class="header-section-number">7.3.3.2</span> Fix smoothing ratio for row factor and column factor</h4>
<p>Optionally, the user might want to specify the row factor borrowing as a function of the column factor borrowing:</p>
<p><em>ϕ</em> ≡ <em>k</em> • <em>τ</em></p>
<p>where <em>k</em> is a user-specified constant. This can be performed by selecting “Fixed smoothing ratio” in the <em>ϕ</em><sup>2</sup> prior specification area.</p>
</section>
<section id="control-not-in-model-no-zero-level-doses" class="level4" data-number="7.3.3.3">
<h4 data-number="7.3.3.3" class="anchored" data-anchor-id="control-not-in-model-no-zero-level-doses"><span class="header-section-number">7.3.3.3</span> Control not in model, no zero-level doses</h4>
<p>If neither treatment arm allows zero-level doses (e.g.&nbsp;like one would expect if the column factor represented doses and the row factor represented frequency), then a prior for the lowest dose would instead be needed as input from the GUI:</p>
<p><em>θ</em><sub>1, 1</sub> ∼ <em>N</em>(<em>μ</em><sub>1</sub>, <em>τ</em><sub>1</sub><sup>2</sup>)</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image32.png" style="width:5.47053in;height:4.31685in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
</section>
</section>
<section id="baseline-adjusted-model-continuous-only" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="baseline-adjusted-model-continuous-only"><span class="header-section-number">7.4</span> Baseline Adjusted Model (Continuous Only)</h2>
<p>If a baseline endpoint is simulated, the user has the option of adding a linear covariate effect to the dose response model. Thus, if the chosen dose response model states that for dose d,</p>
<p><em>E</em>[<em>Y</em><sub><em>d</em></sub>] = <em>g</em>(<em>d</em>)</p>
<p>Then the baseline adjusted model will fit a model of the form</p>
<p><em>E</em>[<em>Y</em><sub><em>d</em></sub>|<em>Z</em>] = <em>g</em>(<em>d</em>)+&nbsp;*β**Z*</p>
<p>where β is a parameter estimated alongside the dose response parameters, and <em>Z</em> is the standardized baseline value (take each baseline value, subtract the observed mean, and divide by the observed standard deviation, for a given dataset this creates a set of fixed known constants). The model uses a normal prior for β for which the user enters a mean and standard deviation.</p>
<p>Note that the VSR based simulation of baseline is more general than the model description (this is to allow baseline to be incorporated in a number of different ways). This means that the parameters entered in the VSR (for example the β parameter) need not match its estimated value. As a simple example, suppose we enter into the VSR response <em>Y</em>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>Y</em></sub>,&nbsp;<em>σ</em><sub><em>Y</em></sub>), baseline <em>X</em>&nbsp;∼&nbsp;<em>N</em>(<em>μ</em><sub><em>X</em></sub>,&nbsp;<em>σ</em><sub><em>X</em></sub>), and use the baseline adjustment so the actual simulated Y is <span class="math inline">\(Y^{'} = Y + \beta\_{VSR}\frac{X - c}{s}\)</span>.</p>
<p>The baseline adjusted value works for Z (standardized value of X). For a sufficiently large sample, this should be approximately <span class="math inline">\(Z = \\\frac{X - \mu\_{X}\\}{\sigma\_{X}}\)</span> and thus X is approximately *Z**σ<em><sub></sub></em>X<em> + </em>μ<em><sub></sub></em>X*. Thus, the actual simulated response is</p>
<p><span class="math display">\[Y^{'} = Y + \beta\_{VSR}\left( \frac{Z\sigma\_{X} + \mu\_{X} - c}{s} \right)\]</span></p>
<p>The model is fit under the assumption the Z values are fixed constants (identical to any simple linear regression). Thus, for a simple dose response (no model assumed, just fitting a separate mean for each dose</p>
<p><span class="math display">\[E\left\lbrack Y^{'} \right\rbrack = \mu\_{Y} + \beta\_{VSR}\left( \frac{Z\sigma\_{X} + \mu\_{X} - c}{s} \right) = \left\lbrack \mu\_{Y} + \beta\_{VSR}\left( \frac{\mu\_{X} - c}{s} \right) \right\rbrack + \left\lbrack \beta\_{VSR}\frac{\sigma\_{X}}{s} \right\rbrack Z\]</span></p>
<p>Thus, the fitted β from the model may not match the β used in the VSR, unless the values are also standardized in the VSR. Note the variances will always be inflated by using a baseline adjustment, so the estimated standard deviation of the responses from the model will tend to be greater than the standard deviation entered in the dose response tab of the VSR.</p>
</section>
<section id="control-and-comparator-priors" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="control-and-comparator-priors"><span class="header-section-number">7.5</span> Control and Comparator Priors</h2>
<p>The control arm may be modelled as part of the dose response model or separately. If it is modelled separately, it may have a simple user specified Normal prior or a “historical” prior. A historical prior in FACTS is a hierarchical prior that models the response on control as coming from a distribution that also contains some historical response rates.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image33.png" style="width:5.7284in;height:4.23754in"></p>
<p>The active comparator is always modelled separately, and as with a control arm modelled separately, it can be modelled with a user specified Normal prior or a “historical” prior.</p>
<p>When a user specified Normal prior is used the user specifies the mean and standard deviation of the prior normal distribution for <em>θ</em><sub>0</sub>. This is useful if the control response is not thought to be consistent with the model being used to model the study doses – for instance if using an NDLM and there might be a sharp step in response from control to the lowest dose.</p>
<p>If “historical” prior is selected for either the control arm or an Active Comparator arm, an “Augmented Priors” tab is created.</p>
</section>
<section id="inverse-gamma-priors" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="inverse-gamma-priors"><span class="header-section-number">7.6</span> Inverse-gamma priors</h2>
<p>FACTS uses inverse-gamma priors for parameters of variance – these are conjugate and allow efficient computation and avoid problems of convergence. Andrew Gelman’s 2006 paper[7] however notes a potential problem with this model, the problem is specifically</p>
<ul>
<li><p>When updating the estimate of the variance of a <strong>hierarchical</strong> model parameter there will be typically relative few actual data observations (e.g.&nbsp;relatively few historic studies for estimating the variance of the hyper parameter in a BAC (Bayesian Augmented Control) model for the response on a control arm, and relatively few observations of the change in response from one dose to the next when using an NDLM dose-response model).</p></li>
<li><p>The conventional ‘non-informative’ gamma-prior of IG(0.001, 0.001) has an effect when the observed variance is small, of over-shrinking the posterior estimate of variance.</p></li>
</ul>
<p>In FACTS this possibility arises in the dose response models in the context of priors for ‘tau’ <em>τ</em> parameter for the NDLM models and <em>α</em><sub>4</sub> parameter for the hierarchical logistic dose response model, where the number of observations is the number of doses or dose intervals. [It also arises in the context of Bayesian Augmented Control and the hierarchical modeling or responses in different groups in ED].</p>
<p>To avoid the problem reported by Gelman we recommend using a weakly informative prior. Using the settings that control how the inverse-gamma distribution is parameterized (Settings &gt; Options &gt; Gamma Distribution Parameters), use the ‘mean and weight’ options and use a weight of 1, with a ‘reasonable’ expectation for the upper limit difference in the values being modeled entered as the prior mean for the SD. Strictly the distribution is the prior of the variance, so the parameter being specified is more correctly the prior mean of the square root of the mean of the variance.</p>
<p>This ‘reasonable’ upper limit for the difference is a value that a clinical team will usually have an intuition about: for the largest change in mean response from one dose to another for instance, it is often[8] reasonable to assume that the upper limit for the expected change in response from one dose to the next is the ‘expected difference in effect size’ that might have been used to power the trial in a conventional setting.</p>
<p>In this setting we are typically less concerned with the final estimate of the parameters of the hierarchical model and more concerned with the estimates of the values in the model (the dose –response) and thus less concerned to have a non-informative prior for it. The purpose of the trial is usually to estimate the dose response, and the hierarchical models are a means to an end, not an end in themselves.</p>
</section>
<section id="handling-missing-data" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="handling-missing-data"><span class="header-section-number">7.7</span> Handling Missing Data</h2>
<p>FACTS allows a “preprocessing” step to occur in handling missing data due to dropouts. If a subject has incomplete data due to a dropout, the user may specify all dropouts have their unknown final endpoint treated as known with the following options</p>
<ol type="1">
<li><p>BOCF (continuous only, requires baseline be simulated) – All dropouts are assumed to have a final endpoint equal to their observed baseline value.</p></li>
<li><p>LOCF (continuous or dichotomous, requires longitudinal data be present) – All dropouts are assumed to have a final endpoint equal to their last observed visit value. If no post-baseline visits are available, but the subject has a baseline visit value, then the baseline values is carried forward to their final endpoint.</p></li>
<li><p>Missing is failure (dichotomous only) – All dropouts are assumed to be failures (which may be coded as 0 or 1 depending on whether a response is considered a success).</p></li>
</ol>
<p>Subjects who are imputed in this preprocessing step have final endpoint values known and used for the purposes of estimating the dose response curve. However, these preprocessed final endpoint values are not used in the updating on the longitudinal model, which is based only on observed visit data.</p>
<p>If the user does not specify one of the dropout imputation methods specified above, the dropout subjects and incomplete subjects (subjects who have not reached their final endpoint but are still continuing in the study) will have their final endpoints multiply imputed using Bayesian Multiple Imputation, described in the longitudinal modeling section.</p>
<p>Generally, patients with “no data” do not affect the posterior distribution, and thus are omitted from the analysis. However, one must take into account a subject can have no visit data but still have “data” based on these dropout imputation methods. For example, if one selects “missing as failure” and a patient drops out before any visit data is recorded, then the subject still supplies information through the dropout imputation (similarly for BOCF). However, if LOCF is selected and no visit data is available, there remains no information on the subject to be used for the LOCF dropout imputation, and thus these subjects are omitted from the analysis as well. Thus, all subjects are included which either 1) have some visit data available, or 2) are dropouts before visit 1 with sufficient information to impute their final endpoint with this preprocessing step.</p>
<section id="time-to-event-missingness" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="time-to-event-missingness"><span class="header-section-number">7.7.1</span> Time-to-Event Missingness</h3>
<p>For a time-to-event endpoint, as is the convention in this endpoint, subjects are observed up to the time they have an event (or the end of follow up), so no subject drops out after having had an event; subjects that do drop-out are included in the analysis as not having had an event up to the last observation of the subject.</p>
</section>
</section>
<section id="bayesian-baseline-adjusted-model" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="bayesian-baseline-adjusted-model"><span class="header-section-number">7.8</span> Bayesian Baseline Adjusted Model</h2>
<p>For a continuous endpoint, if Baseline has been included in the simulation, it is possible to include modeling a linear covariate effect to the dose response model. The model for response changes from:</p>
<p><em>Y</em>&nbsp;∼&nbsp;<em>N</em>(<em>θ</em><sub><em>d</em></sub>, <em>σ</em><sup>2</sup>)</p>
<p>to:</p>
<p><em>Y</em> ∼ <em>N</em>(<em>θ</em><sub><em>d</em></sub> + *β**Z<em>, </em>σ*<sup>2</sup>)</p>
<p>where β is the estimated parameter and Z is the standardized baseline value.</p>
<p><span class="math display">\[Z = \frac{\left( X - \overline{X} \right)}{s\_{x}}\]</span></p>
<p>Note that the estimate of β will only correspond to the β used on the VSR tab to simulate the baseline adjustment if the centering and scaling values are the mean and the standard deviation of the baseline values.</p>
</section>
</section>
<section id="augmented-priors-historical-prior" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Augmented Priors (Historical Prior)</h1>
<p>If a Bayesian Augmentation is used for either the Control or Active Comparator arm is used then the user specifies:</p>
<ul>
<li><p>The sufficient statistics to be included from each historic study, these are:</p>
<ul>
<li><p>Continuous: the mean response and the SD of the response of the control or active comparator arm and the number of subjects observed.</p></li>
<li><p>Dichotomous: the observed number of responders and the number of subjects observed in the study.</p></li>
<li><p>Time-to-Event: the number of events and the amount of exposure within each bin in the piecewise model.</p></li>
</ul></li>
</ul>
<p>The information from the historical studies can be ‘down-weighted’ by decreasing the effective information in the sample size. For continuous, this can be done by decreasing the sample size by a percentage. For dichotomous, both the number of responders and the number of subjects would be decreased by a percentage. For time-to-event, multiplying the number of events and the exposure by the same fraction will reduce the information in the study without changing the reported hazard rate.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image34.png" style="width:6.5in;height:4.62723in"></p>
<p>The hierarchical models for the control or active comparator rates are very similar across the endpoints. They are briefly described below.</p>
<section id="continuous-endpoints" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="continuous-endpoints"><span class="header-section-number">8.1</span> Continuous Endpoints</h2>
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><em>θ</em><sub>0<em>t</em></sub> ∼ <em>N</em>(<em>μ</em><sub>0</sub>, <em>τ</em><sub>0</sub><sup>2</sup>) for <em>t</em> = 0, 1, 2, …, <em>T</em></p>
<p>where <em>θ</em><sub>0<em>t</em></sub> is the mean for the control arm in trial <em>t</em> (<em>t</em> = 0 for the current trial; <em>t</em> = 1,&nbsp;2, …, <em>T</em> for previous trials). User needs to specify appropriate priors for the hyper-parameters:</p>
<p><em>μ</em><sub>0</sub>&nbsp;∼&nbsp;<em>N</em>(<em>m</em><sub>0</sub>,&nbsp;<em>σ</em><sub>0</sub><sup>2</sup>)</p>
<p><em>τ</em><sub>0</sub><sup>2</sup>&nbsp;∼&nbsp;*I**G<em>(</em>a<em><sub>0</sub>,&nbsp;</em>b*<sub>0</sub>)</p>
</section>
<section id="dichotomous-endpoints" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="dichotomous-endpoints"><span class="header-section-number">8.2</span> Dichotomous Endpoints</h2>
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><em>θ</em><sub>0<em>t</em></sub> ∼ <em>N</em>(<em>μ</em><sub>0</sub>, <em>τ</em><sub>0</sub><sup>2</sup>) for <em>t</em> = 0, 1, 2, …, <em>T</em></p>
<p>where <em>θ</em><sub>0<em>t</em></sub> is the log-odds for the control arm in trial <em>t</em> (<em>t</em> = 0 for the current trial; <em>t</em> = 1,&nbsp;2, …, <em>T</em> for previous trials). User needs to specify appropriate priors for the hyper-parameters:</p>
<p><em>μ</em><sub>0</sub>&nbsp;∼&nbsp;<em>N</em>(<em>m</em><sub>0</sub>,&nbsp;<em>σ</em><sub>0</sub><sup>2</sup>)</p>
<p><em>τ</em><sub>0</sub><sup>2</sup>&nbsp;∼&nbsp;*I**G<em>(</em>a<em><sub>0</sub>,&nbsp;</em>b*<sub>0</sub>)</p>
<p>The prior distributions for the hyper-parameters of the hierarchical model. The hyper-parameters are the mean and standard deviation of Normal distribution for the log hazard ratios of the event rates of the historical studies and the current study.</p>
</section>
<section id="time-to-event-endpoints" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="time-to-event-endpoints"><span class="header-section-number">8.3</span> Time-to-Event Endpoints</h2>
<p>The model used for incorporating data from previous trials is as follows:</p>
<p><em>λ</em><sub>*s**t<em></em></sub><em>=&nbsp;</em>λ<em><sub></sub></em>s<em>exp (</em>γ<em><sub></sub></em>t<em>) for </em>t<em> = 0, 1, 2, …, </em>T*</p>
<p>where <em>λ</em><sub>*s**t<em></em></sub><em> is the hazard rate for the control arm in segment </em>s* (<em>s</em> = 1,&nbsp;2,&nbsp;…,&nbsp;<em>S</em>) for previous trial <em>t</em> (<em>t</em> = 1,&nbsp;2,&nbsp;…,&nbsp;<em>T</em>) and <em>λ</em><sub><em>s</em>0</sub> is the hazard rate for the current control arm in segment <em>s</em>; <em>λ</em><sub><em>s</em></sub> is a base hazard for segment <em>s</em>; and <em>γ</em><sub><em>t</em></sub> is the log hazard ratio between that base rate and the <em>λ</em><sub>*s**t*</sub> values.</p>
<p>The following hierarchical model is used</p>
<p><em>γ</em><sub><em>t</em></sub> ∼ <em>N</em>(<em>μ</em><sub><em>γ</em></sub>, <em>τ</em><sub><em>γ</em></sub><sup>2</sup>) for <em>t</em> = 0, 1, 2, …, <em>T</em></p>
<p>Users specify priors for the hyper-parameters:</p>
<p><em>μ</em><sub><em>γ</em></sub> ∼ <em>N</em>(<em>m</em><sub><em>γ</em></sub>, <em>t</em><sub><em>γ</em></sub><sup>2</sup>)</p>
<p>and</p>
<p><em>τ</em><sup>2</sup> ∼ *I**G<em>(</em>a<em><sub></sub></em>γ<em>, </em>b<em><sub></sub></em>γ*)</p>
<p>The formulation above is not identifiable as changes in <em>λ</em><sub><em>s</em></sub> can be compensated for by changes in the <em>γ</em><sub><em>t</em></sub> values (thus, one can use different combination of <em>λ</em><sub><em>s</em></sub> and <em>γ</em><sub><em>t</em></sub> but acquire the same set of values <em>λ</em><sub>*s**t<em></em></sub><em> and thus the same likelihood. To avoid this difficulty, we use the above formulation but fix </em>γ<em><sub>0</sub> = 0. In addition to preserving the identifiability of the structure, this constraint allows </em>λ<em><sub></sub></em>s<em> to have the interpretation of being the hazard rate for the current control arm, and thus the prior on </em>λ<em><sub></sub></em>s<em> from the main dose response may be used as the prior for </em>λ<em><sub></sub></em>s*.</p>
</section>
<section id="setting-priors-for-hierarchical-model-hyper-parameters" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="setting-priors-for-hierarchical-model-hyper-parameters"><span class="header-section-number">8.4</span> Setting Priors for Hierarchical Model Hyper Parameters</h2>
<table>
<caption>
<p>
Figure 8‑2 Execution &gt; Accrual tab, with deterministic accrual
</p>
</caption>
<colgroup>
<col style="width: 100%">
</colgroup>
<thead>
<tr class="header">
<th>
<p>
Unless the intent is to add information that is not included in the historic studies, the hyper parameters can and should be set so that they are ‘weak’ priors, centered on the expected values.
</p>
<p>
In this case the following would be reasonable:
</p>
<ul>
<li>
<p>
Set the prior mean value for Mu as the mean of the mean responses on the control arm in the historic studies
</p>
</li>
<li>
<p>
Set the prior SD for Mu equal to the average SD of response divided by the square root of the number of studies.
</p>
</li>
<li>
<p>
Set the mean for tau to the same value as the prior SD for Mu.
</p>
</li>
<li>
<p>
Set the weight for tau to be &lt; 1.
</p>
</li>
</ul>
<p>
One can traverse the spectrum from ‘complete pooling of data’ to ‘completely separate analyses’ through the prior for tau. If the weight of the prior for tau is small (relative to the number of studies), then (unless set to a very extreme value) the mean of the prior for tau will have little impact and the degree of borrowing will depend on the observed data.
</p>
<p>
To give some prior preference towards pooling or separate analysis the <strong>weight</strong> for tau has to be large (relative to the number of historic studies) – to have a design that is like pooling all the historic studies the <strong>mean</strong> for tau needs to be small (say 10% or less of the value suggested above). For there to be no borrowing from the historic studies the value for tau needs to be large (say 10x or more the value suggested above).
</p>
<p>
The best way to understand the impact of the priors is try different values and run simulations.
</p>
</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<p>Figure 8‑2 Execution &gt; Accrual tab, with deterministic accrual</p>
</section>
<section id="bac-example" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="bac-example"><span class="header-section-number">8.5</span> BAC Example:</h2>
<p>It is easiest to study the impact of BAC in a simplified version of the trial being designed, for example use a 2 arm fixed design with ‘no model’, no adaptation, no longitudinal modeling, etc.</p>
<p>For instance in a continuous setting with an expected sample size of 50 on control, a mean response of 5 and an SD in the response of 2, looking at the effect of having 4 prior, similarly sized studies:</p>
<table class="table">
<caption>
<p>
Figure 8‑4 Deterministic accrual tab
</p>
</caption>
<colgroup>
<col style="width: 24%">
<col style="width: 22%">
<col style="width: 30%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th>
</th>
<th>
Number of subjects
</th>
<th>
Mean Response
</th>
<th>
SD of Response
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
Study 1
</td>
<td>
50
</td>
<td>
4.76
</td>
<td>
2
</td>
</tr>
<tr class="even">
<td>
Study 2
</td>
<td>
50
</td>
<td>
4.93
</td>
<td>
2
</td>
</tr>
<tr class="odd">
<td>
Study 3
</td>
<td>
50
</td>
<td>
5.07
</td>
<td>
2
</td>
</tr>
<tr class="even">
<td>
Study 4
</td>
<td>
50
</td>
<td>
5.24
</td>
<td>
2
</td>
</tr>
</tbody>
</table>
<p>Figure 8‑4 Deterministic accrual tab</p>
<p>For simplicity we have just varied the means of the studies – they are all consistent with a normally distributed estimate, with mean of 5 and a standard error of <span class="math inline">\(\frac{2}{\sqrt{50}}\)</span>.</p>
<p>By simulating a fixed trial with a sample size of 100 and fixed 1:1 allocation between control and a study arm we can easily observe the effects of a BAC on the control arm. Creating 6 VSR profiles with sigma = 2, and the same mean response for control and the study arm in each profile of: 4.53, 4.76, 5.07, 5.24 and 5.47 we can look at the bias of the final estimate and the shrinkage in the SD of the estimate that could be brought about by using BAC:</p>
<table class="table">
<caption>
<p>
Figure 3‑1 Quantities of Interest tab
</p>
</caption>
<colgroup>
<col style="width: 13%">
<col style="width: 13%">
<col style="width: 16%">
<col style="width: 15%">
<col style="width: 13%">
<col style="width: 10%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>
True Mean
</th>
<th>
Raw mean
</th>
<th>
Raw SD
</th>
<th>
Estimate inc BAC
</th>
<th>
SD inc BAC
</th>
<th>
Bias
</th>
<th>
Effective additional Subjects
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
4.53
</td>
<td>
4.55
</td>
<td>
0.28
</td>
<td>
4.64
</td>
<td>
0.255
</td>
<td>
2.1%
</td>
<td>
11.1
</td>
</tr>
<tr class="even">
<td>
4.76
</td>
<td>
4.78
</td>
<td>
0.28
</td>
<td>
4.83
</td>
<td>
0.250
</td>
<td>
1.0%
</td>
<td>
13.5
</td>
</tr>
<tr class="odd">
<td>
4.93
</td>
<td>
4.95
</td>
<td>
0.28
</td>
<td>
4.96
</td>
<td>
0.248
</td>
<td>
0.2%
</td>
<td>
14.3
</td>
</tr>
<tr class="even">
<td>
5.07
</td>
<td>
5.09
</td>
<td>
0.28
</td>
<td>
5.07
</td>
<td>
0.248
</td>
<td>
-0.4%
</td>
<td>
14.2
</td>
</tr>
<tr class="odd">
<td>
5.24
</td>
<td>
5.26
</td>
<td>
0.28
</td>
<td>
5.20
</td>
<td>
0.250
</td>
<td>
-1.1%
</td>
<td>
13.2
</td>
</tr>
<tr class="even">
<td>
5.46
</td>
<td>
5.49
</td>
<td>
0.28
</td>
<td>
5.38
</td>
<td>
0.255
</td>
<td>
-1.9%
</td>
<td>
10.7
</td>
</tr>
</tbody>
</table>
<p>Figure 3‑1 Quantities of Interest tab</p>
<p>Note it is important to use the column “SD Mean resp 1” from the simulations file to see the SD of the estimate and not use the SD of the estimates in the summary table.</p>
<p>The small shrinkage in the SD is more impressive when viewed in terms of how many additional subjects would have to be recruited to achieve the same shrinkage in the raw estimate. These are useful savings for small additional bias.</p>
<p>The “effective additional subjects” was calculated:</p>
<p><span class="math inline">\(\left( \frac{True\\sigma}{AVG(SD\\Mean\\resp)} \right)^{2} - \left( \frac{True\\sigma}{AVG(SE\\Mean\\Raw\\Response)} \right)^{2}\)</span>where in this example True Sigma was 2.</p>
</section>
</section>
<section id="frequentist-analysis" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Frequentist Analysis</h1>
<p>On the Frequentist Analysis tab the user can specify that some standard frequentist analyses be performed at trial analyses. Note that the frequentist analysis tab is completely separate from and independent of any p-value QOIs that have been defined.</p>
<p>Different analyses use different rules for how to treat missing data can be selected independently:</p>
<ul>
<li><p>Missing data replaced by last observation carried forward (LOCF)</p></li>
<li><p>Missing data replaced by baseline observation carried forward (BOCF). This is only available if the endpoint is continuous and Baseline is being simulated.</p></li>
<li><p>Missing data is ignored (a “per-protocol” analysis).</p></li>
<li><p>Missing data is treated as a failure. This is only available if the endpoint is dichotomous.</p></li>
</ul>
<p>If the trial has interims, then for the simulations for which frequentist weeks files are to be output (specified on the Simulation tab) the standard frequentist analyses will be performed. If the trial has p-values QOIs, those QOIs are calculated every interim in all simulations.</p>
<p>Having the frequentist analysis include Dunnett’s adjust p-values is a separate option (that applies to all the analysis type requested) because of the significant run-time overhead this can entail. Dunnett’s adjustment is available for the continuous and dichotomous frequentist analyses.</p>
<p>The frequentist analysis tabs for the continuous and dichotomous engines also have trend tests, and allow the user to specify contrast coefficients to conduct those tests.</p>
<p>Note that the reported frequentist estimates of the treatment effect take the specified direction of response on the Study tab (whether a response indicates subject improving or worsening) into account. They are adjusted so that a treatment that is estimated to be better than the control always has a positive treatment effect.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image35.png" style="width:4.51964in;height:3.24521in"></p>
<section id="continuous-endpoints-1" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="continuous-endpoints-1"><span class="header-section-number">9.1</span> Continuous Endpoints</h2>
<p>At the end of each simulated trial the following frequentist values will be calculated using LOCF for missing data:</p>
<ol type="1">
<li><p>Using unadjusted dose-placebo comparisons based on a two-sample t-test calculate the:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value[9],</p></li>
<li><p>confidence interval for the mean difference,</p></li>
<li><p>for each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were) .</p></li>
</ol></li>
<li><p>using Dunnett-adjusted[10] dose-placebo comparisons based on a two-sample t-test calculate the:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>confidence interval for the mean difference</p></li>
<li><p>for each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were) .</p></li>
</ol></li>
<li><p>Using the general trend test calculate the t-test statistic and p-value using user supplied contrast coefficients.</p></li>
</ol>
<p>(If neither placebo or active comparator are specified, difference from 0 is assessed for each dose arm and Dunnett-adjusted calculations are not carried out.)</p>
<p>P-values are calculated using a one-sided t-test testing <em>H</em><sub>0</sub>:&nbsp;μ<sub>T</sub> &lt; μ<sub>C</sub> against <em>H</em><sub>1</sub>:&nbsp;μ<sub>T</sub> ≥ μ<sub>C</sub>, with subscript T referring to the treatment arm and subscript C referring to the control arm (if high values are good; otherwise, the opposite hypotheses are being tested).</p>
<p>Last observation carried forward (LOCF), baseline observation carried forward (BOCF), and Per-protocol (Ignore) are available as ways to handle missingness in continuous frequentist calculations.</p>
</section>
<section id="dichotomous-endpoints-1" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="dichotomous-endpoints-1"><span class="header-section-number">9.2</span> Dichotomous Endpoints</h2>
<p>At the end of each simulated trial the following frequentist values will be calculated using LOCF for missing data:</p>
<ol type="1">
<li><p>Using the methodology described by Agresti[11], Mee[12] and Nurminem[13] for comparing the difference of proportions:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>95% confidence interval for the difference in proportions,</p></li>
<li><p>marginal probabilities of significance.</p></li>
</ol></li>
<li><p>using Dunnett-adjusted dose-placebo comparisons for comparing the difference of proportions:</p>
<ol type="1">
<li><p>test statistic,</p></li>
<li><p>p-value,</p></li>
<li><p>95% confidence interval for the difference in proportions,</p></li>
<li><p>marginal probabilities of significance.</p></li>
</ol></li>
<li><p>Using the general trend test calculate the t-test statistic and p-value using user supplied contrast coefficients.</p></li>
</ol>
<p>P-values are calculated by user choice either using a normal approximation (see previous section on p-value calculations for continuous endpoints) or a Fisher’s exact test, which is a conservative test to test the null hypothesis that the outcome is independent of the treatment assignment. For the normality approximation to have good asymptotic coverage, the expected number of successes and failures under the null hypothesis should be greater or equal to 5 for both groups. In cases where this is not guaranteed, Fisher’s exact test is recommended when strict type 1 error control is required.</p>
<p>If neither placebo or active comparator are specified, difference from 0 is assessed for each dose arm and Dunnett-adjusted calculations are not carried out.</p>
<p>Last observation carried forward (LOCF), Per-protocol (Ignore), and missing data considered failure are available as ways to handle missingness in dichotomous frequentist calculations.</p>
</section>
<section id="time-to-event-frequentist-analysis" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="time-to-event-frequentist-analysis"><span class="header-section-number">9.3</span> Time-to-Event Frequentist Analysis</h2>
<p>For each simulated trial, the following frequentist analyses will be performed:</p>
<ol type="1">
<li><p>Dose-placebo comparisons based on log-rank test and the Cox proportional hazards model. Summaries include:</p>
<ol type="1">
<li><p>The log-rank and Wilcoxon test statistics and the corresponding p-values,</p></li>
<li><p>Estimated hazard ratio and its confidence interval from Cox model,</p></li>
<li><p>For each dose its marginal probabilities of significance (the number of times it was significantly separated from placebo independent of whether any other doses were, based on the hazard ratio inference from the Cox model).</p></li>
</ol></li>
<li><p>Median survival times based on the Kaplan-Meier method.</p></li>
<li><p>For the predictor, descriptive statistics are computes – a 7 number summary for a continuous predictor, percentages for the dichotomous predictor, and median time, average hazard, and a cox model with predictor as covariate are computed for a time to event predictor.</p></li>
</ol>
<p>The following variations for adjusting the alpha level for multiple comparisons should be available using the user-specified 1-sided alpha: unadjusted, and Bonferonni adjusted.</p>
</section>
</section>
<section id="longitudinal-modelling" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Longitudinal Modelling</h1>
<p>The continuous and dichotomous endpoints provide the ability to use longitudinal models to utilize data from incomplete subject’s observed early endpoint values. These subjects may be those that have dropped out, or subjects at an interim that have not had the opportunity to complete their follow-up.</p>
<p>To perform any longitudinal modeling, ‘Use longitudinal modeling’ must be checked on the Study &gt; Study Info tab, and the subjects visit schedule must be defined. If enabled then subjects that are incomplete at an interim will be included in the dose response analysis using the model selected on the Design &gt; Longitudinal tab.</p>
<p>To include dropouts in the longitudinal analysis, on the Design &gt; Dose Response tab select “Bayesian multiple imputation from post baseline.”</p>
<section id="imputation" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="imputation"><span class="header-section-number">10.1</span> Imputation</h2>
<p>Unless a deterministic method is used such as LOCF or BOCF, longitudinal models inform the dose response estimates by using the longitudinal model to stochastically impute subjects’ final endpoint data when it’s not been directly observed.</p>
<p>First, data from subjects with intermediate and final observations is used to estimate the parameters of the longitudinal models.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image36.png" style="width:3.33848in;height:1.92in"></p>
<p>Subjects with missing final data have final data sampled from the posterior probability distribution of the longitudinal model given the subjects most recent intermediate visit (or in some models, all their available intermediate visit data). Subjects with no final or intermediate data have final data sampled from the posterior probability distribution of the dose response model given the dose arm the subject was allocated to.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image37.png" style="width:3.336in;height:1.91857in"></p>
<p>The dose response model is then re-estimated using all the data.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image38.png" style="width:3.352in;height:2.10985in"></p>
<p>This process is then repeated on successive iterations of the MCMC sampling loop. Thus the imputed values are imputed with both the uncertainty in the longitudinal model and the uncertainty in the estimates of the parameters of that model.</p>
<p>It is actually better not to update both the longitudinal model parameters and the dose response model parameters every MCMC step, but allow the model parameters to converge slightly before imputing the missing data again. This can be done on the MCMC settings control on the Simulation tab and setting the “Samples per Imputation” parameter. As a rough guide, if it at some early interims &gt; 5% of the data being analyzed will be imputed, a value in the range 2 to 10 is recommended to avoid underestimating the uncertainty. A higher number should be used the greater the proportion of imputed data.</p>
<p>A similar procedure is used when imputing event times based on a predictor endpoint in FACTS Core Time-to-Event.</p>
<p><strong>Note: FACTS is not fitting a joint Bayesian model of the longitudinal and dose response models. This would require a full MCMC fit of one model for every MCMC step of the other. Thus, if taking 2,500 samples, we would require a total of 2,500<sup>2</sup> samples. This would make running simulations with longitudinal model prohibitively expensive.</strong>[14] Rather in FACTS the LM is a “working mode” to improve our estimate of the dose response model.</p>
</section>
<section id="how-many-longitudinal-models" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="how-many-longitudinal-models"><span class="header-section-number">10.2</span> How many longitudinal models?</h2>
<p>When specifying a longitudinal model in FACTS, the user must clarify whether the longitudinal model is shared across all doses, or if different arms are to estimate different functions connecting early endpoints to the final endpoint.</p>
<p>The options that may be selected for the number of model instances are:</p>
<ul>
<li><p>“Single model for all arms” – just one set of longitudinal parameters is estimated using all the subject data regardless of their treatment.</p></li>
<li><p>“Model control separately” – two sets of longitudinal parameters are estimated, one using data from just those subjects on the control arm, and the other using all the subject data from all the other arms.</p></li>
<li><p>“Model comparator separately” (only available if there is an active comparator arm) - two sets of longitudinal parameters are estimated, one using data from just those subjects on the active comparator arm, and the other using all the subject data from all the other arms (control and active treatments).</p></li>
<li><p>“Model control and comparator separately” (only available if there is an active comparator arm) - three sets of longitudinal parameters are estimated, one using data from just those subjects on the active comparator arm, one using data from just those subjects on the control arm, and the third using all the subject data from all the other arms.</p></li>
<li><p>“Model all arms separately” – a set of longitudinal parameters is independently estimated separately for each arm, each set estimated just using the data available from the subjects on that arm.</p></li>
</ul>
<p>The fewer models used, the more data is pooled, the more precisely the model parameters can be estimated, and the more informative the intermediate data can be. Pooling data assumes that subjects in different groups have the same longitudinal profile, although they may still have different magnitude or probability of response (estimated by Dose Response Model).</p>
<p>If the response profile could be different on different treatment arms – for example, if subjects on control recover constantly over time, but those on an effective dose of the study drug recover very quickly early on, and more gradually later in their follow-up - a longitudinal model based on pooled data would tend to over-estimate the final endpoint of subjects on an effective dose of the study drug when only their early data was available. In a case like that, it would be better to use separate models. If the rapid early response was likely on all study drug treatment arms, then possibly use “model control separately.” If, however, the rapid response will only be seen on some study drug arms then use “model all arms separately”.</p>
<p>In addition to declaring how many longitudinal models should be estimated, when there is more than one model instance the user must declare if the prior distributions should be specified differently across each model instance or not. The options that may be selected for prior specification (for all LMs but linear regression) are:</p>
<ol type="1">
<li><p>Same priors across all model instances</p>
<ol type="1">
<li>Each instance of the model has identical prior distributions on its parameters. Estimation is still performed independently on each model instance.</li>
</ol></li>
<li><p>Specify priors per model instance</p>
<ol type="1">
<li>Each instance of the model has its own priors that may vary across instances.</li>
</ol></li>
</ol>
<p>The linear regression longitudinal model has a different parameter set estimated for each visit, so its prior specification rules are slightly different. See the linear regression section below for specifics about prior specification specific to this model.</p>
</section>
<section id="longitudinal-models-for-a-continuous-endpoint" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="longitudinal-models-for-a-continuous-endpoint"><span class="header-section-number">10.3</span> Longitudinal Models for a Continuous Endpoint</h2>
<section id="locf-last-observation-carried-forward" class="level3" data-number="10.3.1">
<h3 data-number="10.3.1" class="anchored" data-anchor-id="locf-last-observation-carried-forward"><span class="header-section-number">10.3.1</span> LOCF (Last Observation Carried Forward)</h3>
<p>The simplest possible longitudinal model. If {<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>} is the set of observed responses from early visits, and </em>y<em><sub></sub></em>i</strong>t</em><sub><em>m</em></sub> is the last observed value of <em>y</em><sub>*i**t<em></em></sub><em>, then the LOCF model for the final endpoint </em>Y<em><sub></sub></em>i* is</p>
<p><em>Y</em><sub><em>i</em></sub>|{<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>} = </em>y<em><sub></sub></em>i</strong>t</em><sub><em>m</em></sub></p>
<p>In the continuous engine <em>t</em><sub><em>m</em></sub> can be any earlier observed visit including the baseline value.</p>
</section>
<section id="linear-regression" class="level3" data-number="10.3.2">
<h3 data-number="10.3.2" class="anchored" data-anchor-id="linear-regression"><span class="header-section-number">10.3.2</span> Linear Regression</h3>
<p>The linear regression model fits a simple linear model from the data at each visit with the final visit</p>
<p><em>Y</em><sub><em>i</em></sub>|<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>α<em><sub></sub></em>t<em> + </em>β<em><sub></sub></em>t<em></em>y<em><sub></sub></em>i</strong>t</em> + <em>N</em>(0, <em>λ</em><sub><em>t</em></sub><sup>2</sup>)</p>
<p>The parameter <em>α</em><sub><em>t</em></sub> is the intercept of the model for visit t, and the parameter <em>β</em><sub><em>t</em></sub> is a multiplicative modifier (slope) of the response observed longitudinal at visit <em>t</em> to adjust the prediction of the final endpoint.</p>
<p>Imputation of the final endpoint value for a subject using the linear regression longitudinal model is based on only the latest observed visit’s endpoint value.</p>
<p>The default setting of “Same priors across all model instances and visits,” implies that each parameter <em>α</em>, <em>β</em>, and <em>λ</em> have the same prior for all <em>t</em>. Estimation of those parameters is still done independently for each model instance. The one prior across all model instance are formulated as:</p>
<p><em>α</em><sub><em>t</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>α</em><sub><em>μ</em></sub>, <em>α</em><sub><em>σ</em></sub><sup>2</sup>)</p>
<p><em>β</em><sub><em>t</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>β</em><sub><em>μ</em></sub>, <em>β</em><sub><em>σ</em></sub><sup>2</sup>)</p>
<p><span class="math display">\[\lambda\_{t}^{2}\\\sim\\IG\left( \frac{\lambda\_{n}}{2},\frac{\lambda\_{\mu}^{2}\lambda\_{n}}{2} \right)\]</span></p>
<p>The above prior formulation may not be desirable if specifying priors that are not extremely diffuse – especially on the <em>β</em> parameters. Instead, selecting “Specify priors per visit across all model instances,” will share the prior specification across all instances of the model, but allows for different priors to be put on the parameters associated with each visit. The user inputted prior parameters are now subscripted with <em>t</em> to denote the visit they correspond to. These priors apply to all model instances:</p>
<p><em>α</em><sub><em>t</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>α</em><sub><em>μ</em><sub><em>t</em></sub></sub>, <em>α</em><sub><em>σ</em><sub><em>t</em></sub></sub><sup>2</sup>)</p>
<p><em>β</em><sub><em>t</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>β</em><sub><em>μ</em><sub><em>t</em></sub></sub>, <em>β</em><sub><em>σ</em><sub><em>t</em></sub></sub><sup>2</sup>)</p>
<p><span class="math display">\[\lambda\_{t}^{2}\\\sim\\IG\left( \frac{\lambda\_{n\_{t}}}{2},\frac{\lambda\_{\mu\_{t}}^{2}\lambda\_{n\_{t}}}{2} \right)\]</span></p>
<p>It is also possible to specify priors “Per model instance and visit,” in which every visit has separate priors, and those differing priors vary across model instances. This is the most flexible prior specification method. The user inputted prior parameters are now subscripted by both <em>t</em> for visit and <em>i</em> for model instance.</p>
<p><em>α</em><sub><em>t<strong>i<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>N<em>(</em>α<em><sub></sub></em>μ<em><sub></sub></em>t</strong>i</em>, <em>α</em><sub><em>σ</em><sub>*t**i*</sub></sub><sup>2</sup>)</p>
<p><em>β</em><sub><em>t<strong>i<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>N<em>(</em>β<em><sub></sub></em>i<em>, </em>β<em><sub></sub></em>σ<em><sub></sub></em>t</strong>i</em><sup>2</sup>)</p>
<p><span class="math display">\[\lambda\_{ti}^{2}\\\sim\\IG\left( \frac{\lambda\_{n\_{ti}}}{2},\frac{\lambda\_{\mu\_{ti}}^{2}\lambda\_{n\_{ti}}}{2} \right)\]</span></p>
<p>A potential starting place for non-informative prior values would be</p>
<blockquote class="blockquote">
<p><em>α</em> mean of 0, SD &gt;= largest expected response</p>
<p><em>β</em> mean of either 0 or (final visit time / early visit time), SD &gt;= largest expected ratio of final visit to first visit</p>
<p><em>λ</em> mean of expected SD of the endpoint (‘sigma’), weight of 1. The variability of the prediction from the longitudinal model (based on an observed intermediate response) should be less than that based solely on the treatment allocation, thus this is a weakly pessimistic prior on the effectiveness of the longitudinal model that should be quickly overwhelmed by the data.</p>
</blockquote>
<p>This model is easy to understand and can be used even if there is only one visit, but doesn’t get more powerful if there are more visits. Its power will depend on the degree of correlation between the intermediate visit response and the final response.</p>
</section>
<section id="time-course-hierarchical" class="level3" data-number="10.3.3">
<h3 data-number="10.3.3" class="anchored" data-anchor-id="time-course-hierarchical"><span class="header-section-number">10.3.3</span> Time Course Hierarchical</h3>
<p>The Time Course Hierarchical models the relationship between subjects’ early responses and their final response. It incorporates a per-subject offset from the mean response and a scaling factor from each visit to the final endpoint, but with no model of the change from visit-to-visit.</p>
<p>The response at the <em>t</em><sup><em>t<strong>h<em></em></strong></em></sup><em><strong><em> visit for the </em>i<em><sup></sup></em>t</strong>h</em> subject, having been randomized to the <em>d</em><sup>*t**h*</sup> dose is modeled as:</p>
<p><em>y</em><sub>*i**t<em></em></sub><em>&nbsp;∼&nbsp;</em>e<em><sup></sup></em>α<em><sub></sub></em>t<em>(</em>θ<em><sub></sub></em>d<em> + </em>δ<em><sub></sub></em>i<em>) + </em>N<em>(0, </em>λ<em><sub></sub></em>t*<sup>2</sup>)</p>
<p>The imputed final response (visit <em>T</em>) for the <em>i</em><sup><em>t<strong>h<em></em></strong></em></sup><em><strong><em> subject, having been randomized to the </em>d<em><sup></sup></em>t</strong>h</em> dose is modeled as:</p>
<p><em>Y</em><sub>*i**T<em></em></sub><em>&nbsp;∼&nbsp;</em>θ<em><sub></sub></em>d<em> + </em>δ<em><sub></sub></em>i<em> + </em>N<em>(0, </em>λ<em><sub></sub></em>T*<sup>2</sup>)</p>
<p>(i.e.&nbsp;<em>α</em><sub><em>T</em></sub> is 0).</p>
<p>The model parameters can be interpreted as follows:</p>
<p><em>θ</em><sub><em>d</em></sub> is the estimated mean response at the final visit in dose <em>d</em> from the dose response model.</p>
<blockquote class="blockquote">
<p><em>δ</em><sub><em>i</em></sub> is the estimated patient level random effect around the mean final response (<em>θ</em><sub><em>d</em></sub>) for the dose <em>d</em> that patient <em>i</em> is randomized to.</p>
<p><em>α</em><sub><em>t</em></sub> is a scaling parameter that determines the proportion of the final response that is observable at visit <em>t</em>. A value of <em>α</em><sub><em>t</em></sub> = 0 indicates that the expected value of early visit <em>t</em> is equal to the estimated final visit mean <em>θ</em><sub><em>d</em></sub>. A value of <em>α</em><sub><em>t</em></sub> = −0.69315 indicates that the expected value of early visit <em>t</em> is 50% of the estimated final visit mean <em>θ</em><sub><em>d</em></sub>.</p>
<p><em>λ</em><sub><em>t</em></sub><sup>2</sup> is the variance of the endpoint around the estimated mean response at visit <em>t</em>.</p>
</blockquote>
<p>The prior for <em>α</em><sub><em>t</em></sub> is a normal distribution with a user specified the mean and standard deviation:</p>
<p><em>α</em><sub><em>t</em></sub>&nbsp;∼&nbsp;<em>N</em>(<em>α</em><sub><em>μ</em></sub>, <em>α</em><sub><em>σ</em></sub><sup>2</sup>),</p>
<p>The prior for the <em>δ</em><sub><em>i</em></sub> terms is a normal distribution with a mean of 0 and variance <em>τ</em><sup>2</sup>.</p>
<p><em>δ</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>N</em>(0,&nbsp;<em>τ</em><sup>2</sup>)</p>
<p><em>τ</em><sup>2</sup> is estimated as part of the longitudinal model, and has an inverse gamma prior distribution with prior central value <em>τ</em><sub><em>μ</em></sub> and weight (in terms of “equivalent number of observations”) <em>τ</em><sub><em>n</em></sub>:</p>
<p><span class="math display">\[\tau^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\\\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p>The prior for the <em>λ</em><sub><em>t</em></sub><sup>2</sup> terms is an inverse gamma distribution with prior central value <em>λ</em><sub><em>μ</em></sub> and weight (in terms of “equivalent number of observations”) <em>λ</em><sub><em>n</em></sub>:</p>
<p><span class="math display">\[\lambda\_{t}^{2}\\\sim\\IG\left( \frac{\lambda\_{n}}{2},\frac{\lambda\_{\mu}^{2}\lambda\_{n}}{2} \right)\]</span></p>
<p>A reasonable starting place for prior values would be</p>
<blockquote class="blockquote">
<p><em>α</em><sub><em>t</em></sub> mean of -2, SD of 2, … so the prior ~70% interval for <em>α</em><sub><em>t</em></sub> is between -4 and 0 (+/1 1 SD) and thus the prior 70% interval for <em>e</em><sup><em>α</em><sub><em>t</em></sub></sup> to be between 0.02 and 1.</p>
<p><em>τ</em> mean set to the expected SD of the endpoint (‘sigma’), with a weight of 1.</p>
<p><em>λ</em><sub><em>t</em></sub> mean set to the expected SD of the endpoint (‘sigma’), with weight of 1.</p>
<p>We would expect <em>τ</em><sup>2</sup> + <em>λ</em><sup>2</sup> ≈ <em>σ</em><sup>2</sup>, thus to specify a prior mean of <em>σ</em> for each with a weight of 1 is a weakly pessimistic prior that should be quickly overwhelmed by the data.</p>
</blockquote>
<p>This model is useful if there is thought to be a significant per-subject component to the response that should be manifest at the intermediate visits, and sufficient visits for the per-subject component to be estimated.</p>
</section>
<section id="kernel-density" class="level3" data-number="10.3.4">
<h3 data-number="10.3.4" class="anchored" data-anchor-id="kernel-density"><span class="header-section-number">10.3.4</span> Kernel Density</h3>
<p>The Kernel Density Model longitudinal model is a non-parametric re-sampling approach that is ideal for circumstances where the relationship between the interim time and the final endpoint is not known or not canonical.</p>
<p>The procedure is as follows. Assume an interim value for patient <em>i</em> at time <em>t</em>, <em>Y</em><sub>*i**t<em></em></sub><em>. Patient </em>i* does not have an observed final endpoint at time <em>T</em>, so one is to be imputed. Let (<em>X</em><sub>1<em>t</em></sub>, <em>X</em><sub>1<em>T</em></sub>),&nbsp;…,&nbsp;(<em>X</em><sub><em>n<strong>t<em></em></strong></em></sub><em><strong><em>,&nbsp;</em>X<em><sub></sub></em>n</strong>T</em>) be the set of values for the previous subjects for whom there exists an interim value <em>X</em><sub>*<em>t</em></sub> and final value <em>X</em><sub>*<em>T</em></sub>.</p>
<p>To impute a value of <em>Y</em><sub><em>i<strong>T<em></em></strong></em></sub><em><strong><em> given </em>Y<em><sub></sub></em>i</strong>t</em>, a pair (<em>X</em><sub><em>k<strong>t<em></em></strong></em></sub><em><strong><em>,&nbsp;</em>X<em><sub></sub></em>k</strong>T</em>) is selected with probability based on the pair’s time <em>t</em> visit response’s proximity to the observed <em>Y</em><sub>*i**t*</sub>:</p>
<p><span class="math display">\[\Pr\left( Selecting\\\left( X\_{kt},\\X\_{kT} \right) \right) = \frac{\exp\left( - \frac{1}{2h\_{X\_{t}}^{2}}\left( Y\_{it} - X\_{kt} \right)^{2} \right)}{\sum\_{k = 1}^{n}{\exp\left( - \frac{1}{2h\_{X\_{t}}^{2}}\left( Y\_{it} - X\_{kt} \right)^{2} \right)}}\]</span></p>
<p>Then, a value of <em>Y</em><sub><em>i<strong>T<em></em></strong></em></sub><em><strong><em> is imputed from the following distribution, which uses the selected pair’s final endpoint response </em>X<em><sub></sub></em>k</strong>T</em>:</p>
<p><em>Y</em><sub><em>i<strong>T<em></em></strong></em></sub><em><strong><em>&nbsp;∼&nbsp;</em>N<em>(</em>X<em><sub></sub></em>k</strong>T</em>,&nbsp;<em>h</em><sub><em>X</em><sub><em>T</em></sub></sub><sup>2</sup>)</p>
<p>The bandwidths <em>h</em><sub><em>X</em><sub><em>t</em></sub></sub> and <em>h</em><sub><em>X</em><sub><em>T</em></sub></sub> are selected based on the criterion given by Scott (1992). That is,</p>
<p><span class="math display">\[h\_{X\_{j}} = \sigma\_{X\_{j}}\\\left( 1 - \rho^{2} \right)^{\frac{5}{12}}\\\left( 1 + \\\frac{\rho^{2}}{2} \right)^{- \frac{1}{6}}{\\n}^{- \frac{1}{6}}\\\\\\\\\\\\for\\j = t\\and\\T\]</span></p>
<p>where <em>σ</em><sub><em>X</em><sub><em>j</em></sub></sub> is the standard deviation of the observed responses at time <em>j</em>, <em>n</em> is the number of pairs (<em>X</em><sub>*<em>t</em></sub>,&nbsp;<em>X</em><sub>*<em>T</em></sub>) that were chosen between, and <em>ρ</em> is the correlation coefficient between <em>X</em><sub><em>t</em></sub> and <em>X</em><sub><em>T</em></sub> in the pairs (<em>X</em><sub>1<em>t</em></sub>, <em>X</em><sub>1<em>T</em></sub>),&nbsp;…,&nbsp;(<em>X</em><sub><em>n<strong>t<em></em></strong></em></sub><em><strong><em>,&nbsp;</em>X<em><sub></sub></em>n</strong>T</em>).</p>
<p>The Kernel Density model does not take prior distributions as input. So long as each early visit has more subjects with an observed early response and final response than the value entered in “Kernel minimum number of subjects:” then this algorithm runs without regard for user input.</p>
<p>If any visit has fewer subjects with early data and final data than the value of “Kernel minimum number of subjects:”, then instead of calculating the values of <em>h</em><sub><em>X</em><sub><em>t</em></sub></sub> or <em>h</em><sub><em>X</em><sub><em>T</em></sub></sub> the input values of Kernel bandwidth and standard deviation of prior mean are used.</p>
<p>Possible starting values for these parameters are:</p>
<blockquote class="blockquote">
<p><em>h</em><sub><em>x</em></sub> and <em>h</em><sub><em>y</em></sub> the expected SD of the endpoint (‘sigma’)</p>
<p>The minimum number of subjects completed: 6</p>
</blockquote>
<p>The Kernel Density model is effective and flexible with no model assumptions, but its computational overhead is large. Simulations may take ~10 times longer to run, and having no prior model there has to be ‘in trial’ data before it can come into play.</p>
</section>
<section id="itp" class="level3" data-number="10.3.5">
<h3 data-number="10.3.5" class="anchored" data-anchor-id="itp"><span class="header-section-number">10.3.5</span> ITP</h3>
<p>The ITP (Integrated Two-component Prediction) model fits an observation for patient <em>i</em> on dose <em>d</em> at visit <em>t</em> as:</p>
<p><span class="math display">\[y\_{idt} = \left( \theta\_{d} + s\_{id} + \epsilon\_{idt} \right)\left( \frac{1 - \text{exp}\left( kx\_{idt} \right)}{1 - \text{exp}(kX)} \right)\]</span></p>
<p>where<em> </em> <em>ϵ</em><sub><em>i<strong>d</strong>t</em></sub> ∼ <em>N</em>(0, <em>λ</em><sup>2</sup>)</p>
<p><em>s</em><sub>*i**d<em></em></sub><em> ∼ </em>N<em>(0, </em>τ*<sup>2</sup>)</p>
<p>and <em>θ</em><sub><em>d</em></sub> is the mean estimate of the final endpoint for dose d using all complete and partial data and assuming an independent dose response model on the doses. <em>s</em><sub>*i**d<em></em></sub><em> is a subject specific random effect, </em>k* is a shape parameter, <em>x</em><sub><em>i<strong>d</strong>t</em></sub> is the time <em>y</em><sub><em>i<strong>d</strong>t</em></sub> is observed, X is the time to final endpoint, and each <em>ϵ</em><sub><em>i<strong>d</strong>t</em></sub> is a residual error.</p>
<p>The ITP model is similar to the Time Course Hierarchical above in that both models estimate subject specific component of the response. The biggest difference between the two is that the ITP models the response change over time as a parametric function based on the parameter <em>k</em>, rather than having a separately estimated <em>e</em><sup><em>α</em><sub><em>t</em></sub></sup> for each visit.</p>
<p>The shape parameter <em>k</em> determines the rate at which the final endpoint’s eventual effect is observed during a subject’s follow-up. A value of <em>k</em> = 0 indicates that the proportion of effect observed moves linearly with time. A value of <em>k</em> &lt; 0 means that the eventual final effect is observed earlier in follow-up and plateaus off as time moves towards the final endpoint. A value of <em>k</em> &gt; 0 indicates that less of the total final endpoint effect is observed early in follow up, but as time approaches the final endpoint time the proportion of the effect observed increases rapidly. Values of <em>k</em> less than 0 tend to be more common than values of <em>k</em> greater than 0. See the figure below for a visualization of the different response-over-time curves that can be estimated with the ITP model.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image39.png" style="width:3.26636in;height:2.104in"></p>
<p>The priors for the parameters in the ITP model are:</p>
<p><em>k</em> ∼ <em>N</em>(<em>μ</em><sub><em>k</em></sub>,&nbsp;<em>σ</em><sub><em>k</em></sub>)</p>
<p><em>θ</em><sub><em>d</em></sub> ∼ <em>N</em>(<em>μ</em><sub><em>θ</em><sub><em>d</em></sub></sub>,&nbsp;<em>σ</em><sub><em>θ</em><sub><em>d</em></sub></sub><sup>2</sup>)</p>
<p><span class="math display">\[\tau^{2}\\\sim\\IG\left( \frac{\tau\_{n}}{2},\\\frac{\tau\_{\mu}^{2}\tau\_{n}}{2} \right)\]</span></p>
<p><span class="math display">\[\lambda^{2}\\\sim\\IG\left( \frac{\lambda\_{n}}{2},\\\frac{\lambda\_{\mu}^{2}\lambda\_{n}}{2} \right)\]</span></p>
<p>A reasonable starting place for prior values would be:</p>
<blockquote class="blockquote">
<p><em>θ</em><sub><em>d</em></sub> mean of the expected mean improvement from baseline on the Control arm, with SD greater than or equal to the expected treatment effect size.</p>
<p><em>k</em> a mean of 0 and SD of 2, if subject improvement is expected to be rapid and then diminishing, the prior mean might be -0.5 or -1, if subject improvement is expected to be initially slow or non-existent then increasing, the prior mean might be 0.5 or 1.</p>
<p><em>τ</em> mean set to the expected SD of the endpoint (“sigma”), with a weight of 1.</p>
<p><em>λ</em> mean set to the expected SD of the endpoint (“sigma”), with a weight of 1.</p>
</blockquote>
<p>The ITP model implies that the variance of the observations shrinks towards 0 with the mean (so early visits have reduced expected responses and variances). The ITP model may result in biased estimates of <em>θ</em><sub><em>d</em></sub> and/or the variance terms <em>τ</em><sup>2</sup> and <em>λ</em><sup>2</sup> if the mean-variance relationship assumed by the ITP model is not present in the observed data. If the model assumptions are correct this can be a very effective longitudinal model.</p>
</section>
</section>
<section id="longitudinal-models-for-a-dichotomous-endpoint" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="longitudinal-models-for-a-dichotomous-endpoint"><span class="header-section-number">10.4</span> Longitudinal Models for a Dichotomous Endpoint</h2>
<section id="locf-last-observation-carried-forward-1" class="level3" data-number="10.4.1">
<h3 data-number="10.4.1" class="anchored" data-anchor-id="locf-last-observation-carried-forward-1"><span class="header-section-number">10.4.1</span> LOCF (Last Observation Carried Forward)</h3>
<p>The simplest possible longitudinal model. If {<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>} is the set of observed responses from early visits, and </em>y<em><sub></sub></em>i</strong>t</em><sub><em>m</em></sub> is the last observed value of <em>y</em><sub>*i**t<em></em></sub><em>, then the LOCF model for the final endpoint </em>Y<em><sub></sub></em>i* is</p>
<p><em>Y</em><sub><em>i</em></sub>|{<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>} = </em>y<em><sub></sub></em>i</strong>t</em><sub><em>m</em></sub></p>
</section>
<section id="beta-binomial" class="level3" data-number="10.4.2">
<h3 data-number="10.4.2" class="anchored" data-anchor-id="beta-binomial"><span class="header-section-number">10.4.2</span> Beta Binomial</h3>
<p>The Beta Binomial longitudinal model imputes a patient’s final endpoint given their most recent observed response.</p>
<p>The final endpoint response <em>Y</em><sub><em>i</em></sub> is modeled as:</p>
<p><em>Y</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>B<strong>e</strong>r<strong>n</strong>o<strong>u</strong>l<strong>l</strong>i</em>(<em>π</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub>)</p>
<p>where <em>π</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub> is the probability that a patient is a response at the final endpoint given its early observed endpoint at time <em>t</em>&nbsp;is <em>y</em><sub>*i**t*</sub>,</p>
<p><em>π</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub> = Pr (<em>Y</em><sub><em>i</em></sub> = 1&nbsp;|&nbsp;<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em>)&nbsp;∼&nbsp;</em>B</strong>e<strong>t</strong>a</em>(<em>α</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub>, <em>β</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub>)</p>
<p>We use the set cardinality operator |…| to obtain the posterior distributions of <em>α</em><sub><em>t</em>*</sub> and <em>β</em><sub><em>t</em>*</sub> as:</p>
<p><em>α</em><sub><em>t</em>0</sub> = <em>α</em><sub><em>μ</em>0</sub> + |<em>Y</em><sub><em>i</em></sub> = 1, <em>y</em><sub>*i**t*</sub> = 0|</p>
<p><em>β</em><sub><em>t</em>0</sub> = <em>β</em><sub><em>μ</em>0</sub> + |<em>Y</em><sub><em>i</em></sub> = 0, <em>y</em><sub>*i**t*</sub> = 0|</p>
<p><em>α</em><sub><em>t</em>1</sub> = <em>α</em><sub><em>μ</em>1</sub> + |<em>Y</em><sub><em>i</em></sub> = 1, <em>y</em><sub>*i**t*</sub> = 1|</p>
<p><em>β</em><sub><em>t</em>1</sub> = <em>β</em><sub><em>μ</em>1</sub> + |<em>Y</em><sub><em>i</em></sub> = 0, <em>y</em><sub>*i**t*</sub> = 1|</p>
<p>i.e.&nbsp;a prior value (<em>α</em><sub><em>μ</em>0</sub>,&nbsp;<em>α</em><sub><em>μ</em>1</sub>,&nbsp;<em>β</em><sub><em>μ</em>0</sub>,&nbsp;<em>β</em><sub><em>μ</em>1</sub>) plus the number of subjects for which the final response is known to be 1 for <em>α</em><sub><em>t<strong>x<em></em></strong></em></sub><em><strong><em> (or 0 for </em>β<em><sub></sub></em>t</strong>x</em>) and the response at time <em>t</em> is <em>x</em>.</p>
<p>The <em>α</em><sub><em>t<strong>x<em></em></strong></em></sub><em><strong><em> and </em>β<em><sub></sub></em>t</strong>x</em> parameters are independently estimated using only patients in their model instance, and may or not have identical priors <em>α</em><sub><em>μ</em>*</sub> and <em>β</em><sub><em>μ</em>*</sub> depending on the Model Priors selection in FACTS. A common non-informative prior for the <em>π</em><sub><em>t</em>0</sub> and <em>π</em><sub><em>t</em>1</sub> parameters is Beta(1,1).</p>
</section>
<section id="logistic-regression" class="level3" data-number="10.4.3">
<h3 data-number="10.4.3" class="anchored" data-anchor-id="logistic-regression"><span class="header-section-number">10.4.3</span> Logistic regression</h3>
<p>The Logistic regression longitudinal model works similarly to the Beta Binomial imputation model. The difference is in the method of modeling the probability of a transition from an interim visit to the final visit Pr (<em>Y</em><sub><em>i</em></sub> = 1|<em>y</em><sub>*i**t*</sub>). Like the Beta Binomial model, the logistic regression model imputes a patient’s final endpoint given their most recent observed response.</p>
<p>The final endpoint response <em>Y</em><sub><em>i</em></sub> is modeled as:</p>
<p><em>Y</em><sub><em>i</em></sub>&nbsp;∼&nbsp;<em>B<strong>e</strong>r<strong>n</strong>o<strong>u</strong>l<strong>l</strong>i</em>(<em>π</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub>)</p>
<p>where <em>π</em><sub><em>t<strong>y<em><sub></sub></em>i</strong>t</em></sub> is the probability of a response at the final endpoint time given that its early observed endpoint at time <em>t</em> is <em>y</em><sub>*i**t<em></em></sub><em>. Then, we define the parameter <span class="math inline">\(\theta\_{ty\_{it}} = logit\left( \pi\_{ty\_{it}} \right) = \log\left( \frac{\pi\_{ty\_{it}}}{1 - \pi\_{ty\_{it}}} \right)\)</span>. The priors on </em>θ<em><sub></sub></em>t<em>0 and </em>θ<em><sub></sub></em>t*1 are:</p>
<p><em>θ</em><sub><em>t</em>0</sub> ∼ <em>N</em>(<em>μ</em><sub>0</sub>,&nbsp;<em>σ</em><sub>0</sub><sup>2</sup>)</p>
<p><em>θ</em><sub><em>t</em>1</sub> ∼ <em>N</em>(<em>μ</em><sub>1</sub>,&nbsp;<em>σ</em><sub>1</sub><sup>2</sup>)</p>
<p>The model computes the posterior distribution of <em>θ</em><sub><em>t</em>0</sub> and <em>θ</em><sub><em>t</em>1</sub> using all patients in arms belonging to the model instance that have observed endpoint values at time <em>t</em> and the final endpoint time <em>T</em>.</p>
<p>The priors on <em>θ</em><sub><em>t</em>0</sub> and <em>θ</em><sub><em>t</em>1</sub> may be shared across model instances and/or visits depending on the selection made in the Model Priors section of the FACTS Logistic regression Longitudinal model page.</p>
<p>A possible starting place for non-informative priors in this model would be: <em>μ</em> = 0,&nbsp;&nbsp;<em>σ</em> = 2. A weakly informative set of priors that an early response makes a final response more likely could be <em>θ</em><sub><em>t</em>0</sub> ∼ <em>N</em>(−.75,&nbsp;1.25<sup>2</sup>) and <em>θ</em><sub><em>t</em>1</sub> ∼ <em>N</em>(0.75,&nbsp;1.25<sup>2</sup>).</p>
</section>
<section id="restricted-markov-model-absorbing-markov-chain" class="level3" data-number="10.4.4">
<h3 data-number="10.4.4" class="anchored" data-anchor-id="restricted-markov-model-absorbing-markov-chain"><span class="header-section-number">10.4.4</span> Restricted Markov Model (Absorbing Markov Chain)</h3>
<p>The Absorbing Markov Chain model assumes that at each visit a subject is in one of three states – responder (1), stable (S), or failure (0). The responder and failure states are absorbing, meaning that once a patient has entered one of those states they must remain in that state for the remainder of the visits. Patients in the stable state may move to a responder or a failure in subsequent visits.</p>
<p>Unlike most other longitudinal models in FACTS, the Restricted Markov Model estimates the probability of a result at a visit based on the visit right before it, rather than predicting directly to the final endpoint from the early visit.</p>
<p>Pr (<em>y</em><sub><em>i<strong>t<em></em></strong></em></sub><em><strong><em> = </em>n<em>&nbsp;|</em>y<em><sub></sub></em>i<em>, </em>t<em> − 1&nbsp; = </em>S<em>)&nbsp;∼&nbsp;</em>D</strong>i<strong>r</strong>i<strong>c</strong>h<strong>l</strong>e<strong>t<em>({</em>α<em><sub>0</sub></em>t<em>,&nbsp;</em>α<em><sub>1</sub></em>t<em>, </em>α<em><sub></sub></em>S</strong>t</em>})&nbsp;&nbsp;&nbsp;<em>f<strong>o</strong>r</em>&nbsp;<em>t</em> ≥ 2</p>
<p>Where n can be 0, 1, or S, denoting the probability of going to the Fail state, the Responder state, or the Stable state at visit <em>t</em> from the Stable state at visit <em>t</em> − 1. <em>t</em> must be greater than or equal to 2, because we do not impute the first visit – a subject missing visit 1 and all visits after does not contribute to the longitudinal model or dose response model.</p>
<p>The priors for the <em>α</em> parameters are specified in terms of the prior number of transitions from Stable at <em>t</em> − 1 to each different state at time <em>t</em>. For example, if the prior value for the parameter <em>γ</em><sub>13</sub> is 2, we are putting a priori information into the Dirichlet distribution suggesting that 2 patients transitioned from Stable at visit 2 to Responders at visit 3. Specified priors can either be common or different across model instances based on user specification.</p>
<p>The parameters defining the posterior distribution of the state probabilities are available in closed form as:</p>
<p><em>α</em><sub>0<em>t</em></sub> = <em>γ</em><sub>0<em>t</em></sub> + |<em>y</em><sub>*i**t<em></em></sub><em> = 0,&nbsp;</em>y<em><sub></sub></em>i<em>, </em>t<em> − 1 = </em>S*|</p>
<p><em>α</em><sub><em>S<strong>t<em></em></strong></em></sub><em><strong><em> = </em>γ<em><sub></sub></em>S</strong>t</em> + |<em>y</em><sub>*i**t<em></em></sub><em> = </em>S<em>,&nbsp;</em>y<em><sub></sub></em>i<em>, </em>t<em> − 1 = </em>S*|</p>
<p><em>α</em><sub>1<em>t</em></sub> = <em>γ</em><sub>1<em>t</em></sub> + |<em>y</em><sub>*i**t<em></em></sub><em> = 1,&nbsp;</em>y<em><sub></sub></em>i<em>, </em>t<em> − 1 = </em>S*|</p>
<p>To create a dichotomous endpoint, the user specifies in the Study &gt; Study Info &gt; Design Options section whether patients remaining in a stable state at the final visit should be dichotomized as responders or failures.</p>
</section>
<section id="dichotomous-endpoint-dichotomized-continuous-longitudinal-model" class="level3" data-number="10.4.5">
<h3 data-number="10.4.5" class="anchored" data-anchor-id="dichotomous-endpoint-dichotomized-continuous-longitudinal-model"><span class="header-section-number">10.4.5</span> Dichotomous Endpoint: Dichotomized Continuous Longitudinal Model</h3>
<p>The user may select (on the study tab) to assume that the dichotomous final endpoint is generated by observed continuous longitudinal data and then dichotomizing the final endpoint. The user specifies the dichotomization thresholds and whether a response occurs for values above or below the threshold. If the user selects this option, then the user may select any of the continuous longitudinal models specified in the Continuous Longitudinal Models section above. The engine will impute incomplete subjects according to the continuous model, resulting in a continuous imputed final endpoint. The imputed dichotomous final endpoint is then simply the dichotomized version of the continuous imputation.</p>
<p>All priors and methods are identical to the continuous longitudinal models mentioned above.</p>
</section>
</section>
<section id="time-to-event-predictor-models" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="time-to-event-predictor-models"><span class="header-section-number">10.5</span> Time-to-Event Predictor Models</h2>
<p>For all predictors (Z) for time to event endpoints, the engine estimates both a marginal distribution (normal mean and variance for continuous, probability of response for dichotomous, and a piecewise exponential hazard model for time to event predictors) and a working model relating the predictor to the final endpoint. The marginal distribution is used to impute predictors for subjects lacking an observed predictor value and may also be used for stopping (see section on stopping). The working model is used to impute final endpoints for subjects lacking a final endpoint. For subject missing both a predictor and final endpoint, the predictor is imputed first from its marginal distribution, and then the final endpoint is imputed conditionally on the predictor Z.</p>
<section id="continuous-predictor" class="level4" data-number="10.5.0.1">
<h4 data-number="10.5.0.1" class="anchored" data-anchor-id="continuous-predictor"><span class="header-section-number">10.5.0.1</span> Continuous Predictor</h4>
<p>Within each dose (including control and active comparator), the marginal distribution of Z is a normal distribution with mean <em>θ</em><sub><em>Z<strong>d<em></em></strong></em></sub><em><strong><em> and standard deviation </em>σ<em><sub></sub></em>Z<em>. The standard deviation is common across the doses, but the means </em>θ<em><sub></sub></em>Z</strong>d</em> are allowed to vary across the same range of dose response models as the final endpoint (NDLM, Logistic, etc.). The prior specification for these predictor dose response models is identical in structure to the final endpoint, although the user selects a separate set of parameter values. The dose response for the predictor does not need to match the dose response for the final endpoint.</p>
<p>The working model assumes the final event time T is related to the predictor Z by assuming <em>T</em>|<em>Z</em>&nbsp;∼&nbsp;<em>E<strong>x</strong>p</em>(<em>λ</em><sub><em>d</em></sub><em>e</em><sup>*β<strong>Z<em></em></strong></sup><strong><em>), where </em>λ<em><sub></sub></em>d<em> varies by dose and has separate priors </em>λ<em><sub></sub></em>d<em> ∼ </em>G</strong>a<strong>m</strong>m**a<em>(</em>α<em><sub></sub></em>d<em>, </em>β<em><sub></sub></em>d<em>) for each dose. The coefficient in the exponent β (no subscript) is constant across doses with prior </em>β<em>&nbsp;∼&nbsp;</em>N<em>(</em>m<em>, </em>s*).&nbsp;</p>
</section>
<section id="dichotomous-predictor" class="level4" data-number="10.5.0.2">
<h4 data-number="10.5.0.2" class="anchored" data-anchor-id="dichotomous-predictor"><span class="header-section-number">10.5.0.2</span> Dichotomous Predictor</h4>
<p>A dichotomous predictor is handled similarly to a continuous predictor, with a marginal distribution having a predictor dose response model. However, in this case the predictor dose response relates the log-odds rather than the probability of response itself. The working model for dichotomous is identical to the working model for a continuous predictor, with <em>T</em>|<em>Z</em>&nbsp;∼&nbsp;<em>E<strong>x</strong>p</em>(<em>λ</em><sub><em>d</em></sub><em>e</em><sup>*β<strong>Z<em></em></strong></sup><strong><em>). In this situation the working model is simpler to understand, as </em>T<em>|(</em>Z<em> = 0)&nbsp;∼&nbsp;</em>E</strong>x<strong>p<em>(</em>λ<em><sub></sub></em>d<em>) and </em>T<em>|(</em>Z<em> = 1)&nbsp;∼&nbsp;</em>E</strong>x**p<em>(</em>λ<em><sub></sub></em>d<em></em>β*)).</p>
</section>
<section id="time-to-event-predictor" class="level4" data-number="10.5.0.3">
<h4 data-number="10.5.0.3" class="anchored" data-anchor-id="time-to-event-predictor"><span class="header-section-number">10.5.0.3</span> Time to Event Predictor</h4>
<p>The time to event predictor is qualitatively different than the continuous or dichotomous predictors. Instead of the predictor adjusting the hazard, the time to event predictor is viewed as an offset. The final endpoint is viewed as a sum of a predictor time <em>Z</em><sub>1</sub> and a post-predictor time <em>Z</em><sub>2</sub>, where <em>Z</em><sub>1</sub> and <em>Z</em><sub>2</sub> are independent random variables and the final endpoint is thus <em>Z</em><sub>1</sub> + <em>Z</em><sub>2</sub>.</p>
<p>For the working model, <em>Z</em><sub>1</sub>&nbsp;∼&nbsp;*P<strong>E</strong>x<strong>p<em>(</em>λ<em><sub>1</sub></em>s<em> * </em>θ<em><sub>1</sub></em>d<em>) and </em>Z<em><sub>2</sub> ∼ </em>E</strong>x<strong>p<em>(</em>λ<em><sub>2</sub></em>d<em>), with priors </em>λ<em><sub>1</sub></em>s<em>&nbsp;∼&nbsp;</em>G</strong>a<strong>m</strong>m<strong>a<em>(</em>α<em><sub>1</sub></em>s<em>, </em>β<em><sub>1</sub></em>s<em>), </em>λ<em><sub>2</sub></em>d<em>&nbsp;∼&nbsp;</em>G</strong>a<strong>m</strong>m**a<em>(</em>α<em><sub>2</sub></em>d<em>, </em>β<em><sub>2</sub></em>d<em>) (with </em>Z<em><sub>1</sub>’s control hazard model potentially being piecewise exponential). For imputation, a subject missing both the biomarker and final endpoint times has both </em>Z<em><sub>1</sub> and </em>Z<em><sub>2</sub> imputed, with the final endpoint imputed as the sum. For a subject with a predictor time but no final endpoint, </em>Z*<sub>2</sub> is imputed and added to the observed predictor time to impute the final endpoint.</p>
</section>
</section>
</section>
<section id="allocation" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> Allocation</h1>
<p>The options on allocation tab depend on whether an adaptive or non-adaptive design has been selected on the ‘Study &gt; Study Info’ tab, and if adaptive whether subjects are recruited sequentially or in cohorts.</p>
<p>If the design is non-adaptive then the only allocation option is blocked with fixed allocation ratios.</p>
<p>If the design is adaptive with Continuous or Deterministic recruitment, then there are 4 allocation options.</p>
<ul>
<li>Fixed allocation – Subjects are randomized in blocks with fixed allocation ratios that do not change at interim analyses. This allocation strategy can still be useful in an adaptive design when paired with early stopping.</li>
</ul>
<!-- -->
<ul>
<li><p>Arm dropping – which uses fixed allocation combined with the ability to drop under-performing treatment arms at any interim.</p></li>
<li><p>Adaptive Allocation - dose response adaptive allocation. At every interim the randomization probabilities are modified based on the specified adaptive allocation targets.</p></li>
<li><p>Deterministic Allocation – subjects are assigned treatments in an order specified in an external file that is imported into FACTS. This can be used to create a flexible randomization scheme in non-standard simulation scenarios.</p></li>
</ul>
<p>If the design is adaptive with cohort recruitment then there are 3 allocation options, all of which can be combined with early stopping:</p>
<ul>
<li>Fixed allocation – subjects are block allocated to treatments. The block distribution can be specified differently for the first cohort and the subsequent cohorts.</li>
</ul>
<!-- -->
<ul>
<li><p>Adaptive Allocation - dose response adaptive allocation, in which at every interim the randomization probabilities are modified based on the provided adaptive allocation targets.</p></li>
<li><p>Adaptive Allocation – “best dose selection” after every interim the randomization for the next cohort is between the control and the dose that best meets the ‘target’ dose criteria.</p></li>
</ul>
<p>The details of specifying each type of adaptive design are described below, in each case specifying the “Interim Frequency” is the same, and this facility is described in subsection: 10</p>
<section id="non-adaptive-designs" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="non-adaptive-designs"><span class="header-section-number">11.1</span> Non-adaptive designs</h2>
<p>If the design is non-adaptive, then on this tab the user simply specifies the fixed allocation ratio to use between all the treatment arms for the duration of the study. The allocation is implemented using a blocking scheme – the block size is the sum of the allocation ratios entered and each arm is given the number of slots in the block corresponding to its allocation ratio. Consequently, the values entered must be integers.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image40.png" style="width:4.26584in;height:2.38513in"></p>
</section>
<section id="fixed-allocation" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="fixed-allocation"><span class="header-section-number">11.2</span> Fixed Allocation</h2>
<p>If allocation is to be fixed, then on this tab the fixed allocation ratios and block size are specified. For each arm in the study allocation ratios are entered as for fixed designs, and allocation uses a block size that is the sum of the ratios. Fixed allocation works identically to the non-adaptive design randomization. The difference is that this Fixed allocation can be performed concurrently with interim analyses being performed.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image41.png" style="width:4.17452in;height:2.8332in"></p>
</section>
<section id="arm-dropping" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="arm-dropping"><span class="header-section-number">11.3</span> Arm Dropping</h2>
<p>Adaptive arm dropping trials allow accruing data to inform the adaptive design that an arm, or a set of arms, can be dropped, meaning they no longer have subjects randomized to them. FACTS Core supports designs in which some number of arms that are clearly ineffective can be dropped. Designs where at an interim one or more arms are selected to be continued and all other arms are dropped can be simulated using FACTS Staged Designs.</p>
<p>For each arm in the study, allocation ratios are entered as for fixed designs. There are options for specifying the arm dropping rules, evaluated at each interim:</p>
<ul>
<li>The arm dropping criteria, the user may select any combination of Bayesian “Per Dose” QOIs: Posterior Probabilities or Predictive Probabilities, or a Target Dose QOI. For each criteria selected (at least one must be selected), the user supplies a direction of comparison and probability threshold. If at any interim, any arm meets the specified arm dropping criteria, then that arm becomes a candidate for dropping. After candidates are identified for dropping, the rest of the setup rules determine which, if any, of the candidates will be dropped.</li>
</ul>
<!-- -->
<ul>
<li><p>In the “Setup” area a number of rules for arm dropping are specified:</p>
<ul>
<li>The maximum number of arms that can be dropped – this can be set to from 0 to the number of active arms, the Control and Active Comparator are never dropped. This figure is the ‘maximum number of arms that can be dropped over the duration of the trial’. At any interim any number between 0 and the ’maximum number of arms can be dropped as long as this limit is not exceeded on the overall number of arms that would have been dropped.</li>
</ul></li>
</ul>
<blockquote class="blockquote">
<p>If the maximum number of arms that can be dropped is set to the number of study drug arms, then if all arms are dropped this is recorded as an “early termination for futility”.</p>
</blockquote>
<ul>
<li><p>Arm dropping can be restricted to ‘pruning from the lowest dose’ and/or ‘pruning from the highest dose’. If ‘prune from the lowest dose’ is selected, then until the lowest dose meets the arm dropping criteria the second lowest dose cannot be dropped and so on. At an interim when the lowest dose <strong>does</strong> meet the arm dropping criteria, and the second dose does too, then the second dose can be dropped as well (and third and fourth …), it does not have to wait until the next interim.</p></li>
<li><p>If no pruning is selected or pruning from both ends is selected, then the user must select to prioritize the higher or lower dose to cover the instance when more doses are candidates for dropping than allowed by the maximum threshold. If “Prioritize dropping the lowest dose” is selected then when forced to choose between two or more doses to drop, the one with the lowest effective dose strength will be dropped.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image42.png" style="width:6.925in;height:4.92978in"></p>
<p>Lastly the user specifies what is to be done with the unused subjects that would have been allocated to an arm that has been dropped. There are three options:</p>
<ul>
<li><p>Maintain study size, maintain combined block size of treatments: subjects that would have been allocated to arms that have been dropped are now randomized between all the remaining active treatment arms (excluding control and active comparator) using their original allocation ratios. For example, if the allocation ratio was 2:1:1:1 between Control and D1, D2 and D3, then after dropping D1 the block size remains size 5: 2 to Control and 1 to each of D2 and D3, with the 5<sup>th</sup> slot being allocated 1:1 between the remaining two study arms D2 &amp; D3. Thus, the overall proportion of subjects on Control (and Active Comparator) is maintained.</p></li>
<li><p>Maintain study size, reduce combined block size of treatments: subjects that would have been allocated to any arms that have been dropped are randomized between all remaining arms (including control) using a reduced total block size. Thus, if the allocation ratio was 2:1:1 between Control and D1 and D2, then after dropping D1 the block size drops to total size three: 2 to Control and 1 to D2.</p></li>
<li><p>Decrease the study size, reduce combined block size of treatments: subjects that would have been allocated to any arms that have been dropped are no longer recruited and the total sample size of the study is reduced; the remaining subjects are recruited using a reduced block. If interims are specified by number of subjects recruited, these interim sizes are reduced proportionally. As an example of this, if an arm that gets 20% of the randomization is dropped when there are 100 subjects enrolled, then if the next interim is scheduled at 200 subjects enrolled, it will actually be performed at 180 subjects enrolled.</p></li>
</ul>
</section>
<section id="adaptive-allocation" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="adaptive-allocation"><span class="header-section-number">11.4</span> Adaptive Allocation</h2>
<p>In adaptive allocation, the relative probabilities of assigning each of the doses to a subject may change throughout the trial. The adaptive allocation design that FACTS supports is one where the allocation ratio is modified at each interim to increase the allocation to doses that have the preferred characteristics.</p>
<p>An adaptive allocation design has two phases: the “burn-in” before any adaptation takes place and the “adaptive phase”. The burn-in lasts until the first interim occurs, and is defined on the Interims tab. The adaptive phase lasts until the early stopping criteria are met or the maximum sample size is reached.</p>
<p>The allocation of subjects in burn-in is specified by entering the allocation ratio to each arm for the burn-in period. Once the first interim is reached the allocation becomes adaptive.</p>
<ul>
<li><p>It is possible to specify that specific treatment arms are <strong>not</strong> to be allocated to adaptively by specifying a fixed allocation for that arm.</p></li>
<li><p>Adaptive and fixed allocation is combined within an overall blocking scheme, within which some slots are fixed and some are adaptive.</p></li>
</ul>
<!-- -->
<ul>
<li>The arms to allocate to with a fixed probability are selected by clicking the “Fix Alloc” check box for that arm.</li>
</ul>
<!-- -->
<ul>
<li><p>The overall block size is set by entering it in the ‘Block size’ field.</p></li>
<li><p>The number of ‘slots’ in the block to be given to the fixed arms are set by entering the number on the “Post Burn-in Alloc per Block” cell for the fixed arms.</p></li>
<li><p>The non-fixed arms will be allocated to adaptively and probabilistically in the slots not taken by the fixed allocation (so the Block size must exceed the number of fixed slots being used!)</p></li>
</ul>
<p>Commonly, the control arm and active comparator arms are allocated to in this way and the treatment arms are left to be allocated to adaptively. If the Control arm is not given a fixed allocation, it is allocated to with an adaptive probability that is an equal weight to the treatment arm with the highest weight.</p>
<p>There are options for specifying the adaptive allocation, evaluated at each interim:</p>
<ul>
<li><p>“Probability set to zero for values less than:” - specifies an allocation probability threshold, which if an arms probability of allocation falls below this value then it is set to 0 and the remaining allocation probabilities re-normalized.</p></li>
<li><p>In the “Adaptive Allocation Weights” the user selects which QOI to use to determine the adaptive allocation, and what relative weight to give them. The user also selects for each target whether the weight to use should be “probability” that the dose is the target or the “information” allocating to the dose would give about the target.</p></li>
</ul>
<blockquote class="blockquote">
<p>Any Bayesian “Per Dose” QOI, or “Target Dose” QOI can be used to determine the adaptive allocation weights. In addition there is the option to use a static weighting – this is of course not adaptive! What it does do is allow an adaptive allocation to be combined with a “guaranteed minimum allocation” (see example discussion below). If a Static target is included, a small table is displayed the specification of the ratio of the division of the static weight between the study arms that are being adaptively allocated to.</p>
</blockquote>
<ul>
<li><p>When weighting for probability, the weight is derived simply from the value of the QOI.</p></li>
<li><p>When weighting for information, the weight uses the value of the QOI but adjusted by the current variance of the estimate and the number of subjects already allocated to the dose – an estimate of the additional information that would result from adding one more subject to that arm.</p></li>
<li><p>Weighting for probability is ‘more aggressive’ in adapting in pursuit of the target. The risk with a probability-based weighting is never allocating again to an arm where the initial data is so poor that its initial probability of being the target is so low it is never allocated to again. So, it is appropriate when the available sample size is small (and risks must be taken), the number of study arms is small (so it is unlikely an arm will not be allocated to again), or the allocation during the burn-in is large and evenly distributed (so that having unrepresentative data is very unlikely).</p></li>
<li><p>Weighing for information will tend to spread the allocation around the most likely target, reducing the risk of never learning that dose is better than its initial data. If a dose response model is being used, allocation to doses around the target dose will contribute to the accuracy of the estimate of response on the target dose, but compared to the probability weighting will tend to result in fewer subjects allocated to the actual target dose.</p></li>
<li><p>Whichever weighing rule is selected the adaptation can be further ‘sharpened’ or ‘softened’ by adjusting the power to which the allocation probability is raised. Setting the power to 0.5 will significantly soften the allocation, setting it to 2 will significantly sharpen it.</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image43.png" style="width:5.68039in;height:4.04189in"></p>
<section id="weighting-and-calculation-of-adaptive-allocation-probabilities" class="level3" data-number="11.4.1">
<h3 data-number="11.4.1" class="anchored" data-anchor-id="weighting-and-calculation-of-adaptive-allocation-probabilities"><span class="header-section-number">11.4.1</span> Weighting and Calculation of Adaptive Allocation Probabilities</h3>
<p>For a QOI <em>P</em><sub><em>i</em>, <em>d</em></sub> that is specified as an Adaptive Allocation Target, if probability weighting is selected, the allocation target for dose <em>d</em> is:</p>
<p><em>V</em><sub><em>d</em>, <em>i</em></sub><sup>*</sup> = [<em>P</em><sub><em>d</em>, <em>i</em></sub>]<sup><em>γ</em></sup></p>
<p>where <em>γ</em> is the allocation probability power.</p>
<p>If information weighting is selected, then the allocation target for <em>P</em><sub><em>i</em>, <em>d</em></sub> is:</p>
<p><span class="math display">\[V\_{d,i}^{\*} = \left\lbrack \sqrt{\frac{P\_{d,i}Var\left( \theta\_{d} \right)}{n\_{d} + 1}} \right\rbrack^{\gamma}\]</span></p>
<p>where <em>γ</em> is the allocation probability power, <em>n</em><sub><em>d</em></sub> is the number of subjects on dose <em>d</em>, and <em>θ</em><sub><em>d</em></sub> is the dose-response model mean estimate for arm <em>d</em>.</p>
<p>If there are multiple allocation targets used for an adaptive randomization, then these allocation targets are combined to create a single allocation weight <em>W</em><sub><em>d</em></sub>. The allocation weight for a dose is the weighted average of the allocation targets for the dose.</p>
<p><span class="math display">\[W\_{d} = \sum\_{i = 1}^{I}{w\_{i}V\_{d,i}}\]</span></p>
<p>where <em>I</em> is the number of allocation targets, <em>w</em><sub><em>i</em></sub> is the weight of allocation target <em>i</em>, and <em>V</em><sub><em>d</em>, <em>i</em></sub> is the value of the allocation target for dose <em>d</em> on target <em>i</em>.</p>
<p>If there is only 1 allocation target, then the allocation weight <em>W</em><sub><em>d</em></sub> = <em>V</em><sub><em>d</em>, 1</sub>.</p>
<p>Finally, for the doses which are adaptively allocated (not fixed or within their burn-in period), these allocation weights are renormalized to sum to the probability remaining after all fixed doses have been allocated.</p>
<section id="non-fixed-control-adaptive-allocation" class="level4" data-number="11.4.1.1">
<h4 data-number="11.4.1.1" class="anchored" data-anchor-id="non-fixed-control-adaptive-allocation"><span class="header-section-number">11.4.1.1</span> Non-fixed Control Adaptive Allocation</h4>
<p>If the control allocation ratio is not fixed when performing adaptive allocation, then the control arm gets a randomization ratio that targets matching the number of control subjects to the active arm with the most subjects.</p>
<p>To derive the control allocation rate, let <em>V</em><sub><em>d</em></sub> for <em>d</em> = 1,&nbsp;2, …<em>D</em> be the allocation probabilities for each of the D non-control dose arms (these may be obtained by calculating based on the probability or information criteria as described above or the fixed allocation proportion with respect to the block size), and let <em>n</em><sub><em>d</em></sub> for <em>d</em> = 1,&nbsp;2, …<em>D</em> be the number of subjects allocated to those arms.</p>
<p>Then, the allocation to the control arm <em>V</em><sub>0</sub> is:</p>
<p><span class="math display">\[V\_{0} = \min\left\\ \sum\_{d = 1}^{D}{V\_{d}\frac{(n\_{d} + 1)}{(n\_{0} + 1)},\\\\max\\ V\_{1},V\_{2},\ldots,\\V\_{D}\\} \right\\\]</span></p>
<p>Following fixing this control rate, the allocation probabilities for the non-fixed doses are renormalized to add up to the total non-fixed probability.</p>
</section>
<section id="zero-out-allocation-probabilities" class="level4" data-number="11.4.1.2">
<h4 data-number="11.4.1.2" class="anchored" data-anchor-id="zero-out-allocation-probabilities"><span class="header-section-number">11.4.1.2</span> Zero Out Allocation Probabilities</h4>
<p>If, at the end of the adaptive allocation probability calculation, any adaptively allocated arms have a randomization probability smaller than the value provided for “Allocation probability set to zero for values less than:”, then the allocation probabilities are adjusted.</p>
<p>To adjust the probabilities, first the arm with the smallest randomization probability is given a fixed allocation rate of 0. Then, the remaining adaptively allocated arms have their allocation probabilities re-normalized to sum to the probability remaining after all fixed doses have been allocated. Then, if any doses remain below the zero-out threshold, then this process is repeated. Continue the repetition as necessary. If none of the allocation probabilities are below the threshold, then the allocation probabilities are set.</p>
</section>
</section>
<section id="adaptive-allocation-calculation-examples" class="level3" data-number="11.4.2">
<h3 data-number="11.4.2" class="anchored" data-anchor-id="adaptive-allocation-calculation-examples"><span class="header-section-number">11.4.2</span> Adaptive Allocation Calculation Examples</h3>
<section id="simple-response-adaptive-randomization-example" class="level4" data-number="11.4.2.1">
<h4 data-number="11.4.2.1" class="anchored" data-anchor-id="simple-response-adaptive-randomization-example"><span class="header-section-number">11.4.2.1</span> Simple Response Adaptive Randomization Example</h4>
<p>Suppose you have a control and 3 active doses. The control arm is guaranteed 2/6 slots in every block and a fixed 20% probability must be placed on the first active dose (dose A). So, the control arm gets 33.3% of the total allocation probability and dose A gets 20% of the total allocation. Suppose the target QOIs <em>V</em><sub><em>d</em></sub>&nbsp;for the three active doses are 0.20, 0.50, and 0.30 and that we’re using probability weighting with weight 1. The second two doses are the only doses with unknown randomization probabilities, so they split the amount of non-fixed allocation probability proportionally based on their <em>V</em><sub><em>d</em></sub>.</p>
<p>The allocation probability of the second active dose is <span class="math inline">\(\left( 1 - (0.333 + 0.2) \right)\*\left( \frac{0.5}{0.5 + 0.3} \right)\)</span> and the allocation probability of the third active dose is <span class="math inline">\(\left( 1 - (0.333 + 0.2) \right)\*\left( \frac{0.3}{0.5 + 0.3} \right)\)</span>.</p>
<p>Thus, the final allocation probabilities for the control and the three active doses are: (0.333, 0.2, 0.292, 0.175).</p>
<p>If any of the adaptively allocated probabilities are less than a user specified minimum (“Allocation probability set to zero for values less than….” in the GUI) then these probabilities would be set to zero and the resulting probability is reallocated among the non-fixed probability doses. If all non-fixed doses drop at this point, then the probability is reallocated to the fixed doses.</p>
</section>
<section id="using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms" class="level4" data-number="11.4.2.2">
<h4 data-number="11.4.2.2" class="anchored" data-anchor-id="using-static-weighting-example-ensuring-a-minimum-allocation-to-all-arms"><span class="header-section-number">11.4.2.2</span> Using Static Weighting Example: Ensuring a minimum allocation to all arms</h4>
<p>As an example of using the static weight to allow adaptive randomization along with a guaranteed minimum allocation of 10% to each of 5 study arms. Let us say that we want the adaptive allocation to be evenly divided between targeting an EDq and MED target.</p>
<p>As there are 5 study arms, allocating 10% each amounts to 50% of the total. Thus we could specify weights of 1 to the MED target, 1 to the EDq target, and 2 to the Static target, so the Static target gets 50% of the total weighting.</p>
<p>However, this ignores the possible allocation to a Control arm. What we have achieved above either allocates 10% to each study arm if there is no Control arm, or if there is a Control arm, allocates 10% of the subjects <em>allocated to the study arms</em>, not 10% of the overall.</p>
<p>Let us say that in addition to the 5 study arms you have a Control that we want to have 20% allocation and we want each study arm to have at least 10% of the overall allocation. The simplest way to specify this is to set a “Post first interim block size” of 10 and that 2 slots are allocated to Control.</p>
<p>This leave 8 slots to be allocated across the treatment arms, to ensure a 10% allocation for each of the 5 treatment arms - that takes up 5 more slots in the block – but we don’t want to allocate 1 in the block to each using fixed allocation – because then that’s all they would get. We need to allow them to be allocated to adaptively and use the Static target to ensure they get a minimum of 10%. We can achieve this by giving the static allocation a weight of 5 and divide a weight of 3 between the MED and EDq targets, so they get a weight of 1.5 each.</p>
</section>
<section id="using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose" class="level4" data-number="11.4.2.3">
<h4 data-number="11.4.2.3" class="anchored" data-anchor-id="using-static-weighting-example-ensuring-a-minimum-allocation-to-top-dose"><span class="header-section-number">11.4.2.3</span> Using Static Weighting Example: Ensuring a minimum allocation to top dose</h4>
<p>Imagine an early Phase II Proof-of-Concept study that wants to compare 3 doses of the study drug (low, medium and high) to Control, and adaptively allocate to the dose with the maximum response. The study team also wish to ensure a minimum allocation to the top dose as they have a strong prior that it will have the maximum effect. They want to minimize the risk that the adaptive allocation avoids the top dose because of randomly poor results on that dose early on in the trial.</p>
<p>Solution 1 uses a fixed allocation to Control of 30%. The optimal allocation to control in a multi armed study is approximately √N:1:1:… where N is the number of study arms [Dunnett] and in √3:1:1:1 the proportion on control would be 37%. Here we’ve rounded down to 30% rather than up to 40% to reflect a typical clinical teams desire to get more data on their study drug rather than Control.</p>
<p>After the first Interim, we specify allocation to be in blocks of 10 with the Control allocate 3 slots in each block, the weight on the Static target is 2 and the Weight on the Pr(Max) target is 5. So 50% of the allocation is adaptive targeting the dose with the Maximum response and 20% is fixed and allocated to the top dose by specifying that the static weighting is split 0:0:1.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image44.png" style="width:3.97826in;height:2.53209in"></p>
<p>Solution 2 uses adaptive allocation to Control. Adaptive allocation to Control allocates to control with the same weight as the adaptive allocated arm with the highest weight. Under this scheme the top dose will receive its minimum allocation when there is an arm with close to 100% Pr(Max). If that arm is the top dose, then allocation will be close to 50% to Control and 50% to the top dose, so the 20% minimum allocation requirement is met. If it is a different arm with close to 100% Pr(Max) then, if the allocation to top dose is <em>t</em> and the allocation to Pr(Max) 100 - <em>t</em>, the allocation ratio is (100 – <em>t</em>) : (100 – <em>t</em>) : <em>t,</em> (Control : Best Dose : Top Dose).</p>
<p>The total allocation is (200 – <em>t</em>) and we want to select <em>t</em> so that <em>t</em>/(200 – <em>t</em>) ≅ 0.2. So <em>t</em> = 33.3. With the static weight allocated 0:0:1.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image45.png" style="width:3.97349in;height:2.54141in"></p>
</section>
</section>
</section>
<section id="deterministic-allocation" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="deterministic-allocation"><span class="header-section-number">11.5</span> Deterministic Allocation</h2>
<p>The deterministic allocation option allows for the treatment assignments of subjects accrued into the simulated trials to be assigned without randomness based on an uploaded file. The file providing the assignments should be a comma separated .dat file with 2 columns, but no column labels.</p>
<p>The first column should be an increasing, unique column of numbers from 1 to at least the maximum number of subjects that can be enrolled in the study. The second column should be the set of treatment assignments in order from 1 to the number of patient IDs. The treatment assignments are used in row order – they do not use the subject ID order. So, the first subject accrued in the study is given the assignment indicated by the first row, second column value, the second subject accrued in the study is given the assignment indicated by the second row, second column value, and so on.</p>
<p>The treatment assignments column in the .dat file should always have a minimum value of 1 and a maximum of the number of total arms in the study. If there is a control arm in the study, then treatment assignment 1 corresponds to a control arm randomization. If there is no control arm in the study, then treatment assignment 1 in the .dat file corresponds to a subject randomized to the lowest active dose.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image46.png" style="width:5.0296in;height:3.70171in"></p>
</section>
<section id="cohort-recruitment-fixed-allocation" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="cohort-recruitment-fixed-allocation"><span class="header-section-number">11.6</span> Cohort recruitment – fixed allocation</h2>
<p>If allocation is to be fixed the “Early Stopping Only” option should be selected. Then on this tab the fixed allocation ratios and block size are specified – for the first cohort and then for all subsequent cohorts. In each case the user specifies the number of each arm to allocate in each cohort and the sum must equal the size of the cohort.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image47.png" style="width:5.52636in;height:3.93229in"></p>
</section>
<section id="cohort-recruitment-adaptive-allocation" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="cohort-recruitment-adaptive-allocation"><span class="header-section-number">11.7</span> Cohort recruitment – adaptive allocation</h2>
<p>If allocation is to be adaptive the “Adaptive Allocation” option should be selected and then under “Subsequent Cohort Allocation” the “Allocate cohort by sampling from allocation vector” should be selected. Then on this tab</p>
<ul>
<li><p>The fixed allocation ratios and block size are specified for the first cohort. The user specifies the number of each arm to allocate and the sum must equal the size of the cohort.</p></li>
<li><p>The user then specifies</p>
<ul>
<li><p>The fixed allocation to control</p></li>
<li><p>The QOIs to be used to calculate the allocation ratios for the remaining subjects in the cohort as for adaptive allocation (see Adaptive Allocation above).</p></li>
</ul></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image48.png" style="width:5.61615in;height:3.99618in"></p>
</section>
<section id="cohort-recruitment-allocate-to-best-dose" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="cohort-recruitment-allocate-to-best-dose"><span class="header-section-number">11.8</span> Cohort recruitment – allocate to best dose</h2>
<p>If allocation is to be adaptive, but at each cohort just Control and the “best dose” are to be allocated to, the “Adaptive Allocation” option should be selected and then under “Subsequent Cohort Allocation” the “Allocate cohort to single treatment (plus control)” should be selected. Then on this tab</p>
<ul>
<li><p>The fixed allocation ratios and block size are specified for the first cohort. The user specifies the number of each arm to allocate and the sum must equal the size of the cohort.</p></li>
<li><p>The user then specifies</p>
<ul>
<li><p>The fixed allocation to control</p></li>
<li><p>The QOIs to be used to calculate the allocation weighting to calculate for the non-Control arms, (see Adaptive Allocation above) and all the subjects not allocated to control will be allocated to this arm.</p></li>
</ul></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image49.png" style="width:5.5182in;height:3.92648in"></p>
</section>
</section>
<section id="interims" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Interims</h1>
<p>Interim analyses allow for decision making throughout the lifecycle of an adaptive trial in FACTS. Interim analyses can adjust allocation probabilities, drop arms, or allow for early success/futility of the trial. Interims can either be specified with calendar frequency – occurring every specified number of weeks or specified to occur after a specified amount of information has been collected.</p>
<section id="continuous-and-dichotomous-endpoints" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="continuous-and-dichotomous-endpoints"><span class="header-section-number">12.1</span> Continuous and Dichotomous Endpoints</h2>
<p>Information can be defined in terms of:</p>
<ul>
<li><p>number of subjects that have been recruited</p></li>
<li><p>the number of subjects who have actually completed a specified visit</p></li>
<li><p>the number of subjects who have had the opportunity to complete a specified visit (includes drop-outs)</p></li>
<li><p>interims can be by time with the first interim defined by information and time thereafter, or each information can be defined by the amount of information required to trigger the interim..</p></li>
</ul>
<p><img src="coreUGattachments/CoreUserGuide/media/image50.png" style="width:2.94314in;height:2.8326in" alt="Graphical user interface Description automatically generated"> <img src="coreUGattachments/CoreUserGuide/media/image51.png" style="width:2.99611in;height:2.86372in" alt="Graphical user interface Description automatically generated"></p>
<p>If defining interims by time, these are defined by frequency (number of weeks between interim) – fractions of weeks can be used for very frequent interims! The first interim is defined in terms of an information threshold, with the type of information selected above.</p>
<p>If the accrual completes before the first interim threshold is reached, and the first interim was defined in terms of the number of subjects enrolled, then the interims by time start at full accrual. If the first interim is defined in any other terms (by events, subjects complete or subjects with opportunity to complete) then interims only start when this is reached (which might be never).</p>
<p>If defiing interims by information, then each interim is defined individually, by number of patients/observations and iif information is interms of completers, then the week of the visit that is being used to define “complete”. Successive interims must be in terms of the same or more observations at the same or later visit and at least one needs to be “more” or “later”.</p>
<p>If interims are governed by time, completers or events there is the option as to whether interims should continue after full accrual, or discontinue.</p>
</section>
<section id="time-to-event-endpoint" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="time-to-event-endpoint"><span class="header-section-number">12.2</span> Time-to-Event Endpoint</h2>
<p>Information can be defined in terms of:</p>
<ul>
<li><p>number of subjects that have been recruited</p></li>
<li><p>the number of subjects who have observed their predictor endpoint</p></li>
<li><p>the number of subjects who have had the opportunity to observe their predictor endpoint (includes drop-outs)</p></li>
<li><p>specified numbers of events have observed (time to event trials only). With early stopping only, or arm dropping designs, the occurrence of the first interim is also specified, with an adaptive allocation design, the first interim is at the end of the burn-in.</p></li>
</ul>
</section>
<section id="follow-up" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="follow-up"><span class="header-section-number">12.3</span> Follow-up</h2>
<p>Regardless of endpoint, the Interims tab contains options that control the behaviour should a trial stop at an interim. The option allows the user to specify whether or not to complete the follow-up of subjects who have been accrued, but have not had time to observe their final endpoint.</p>
<p>The default options available for Subject Follow-Up are:</p>
<ul>
<li>Continue follow-up if study stopped for success</li>
</ul>
<!-- -->
<ul>
<li>Continue follow-up if study stopped for futility</li>
</ul>
<p>If the check box corresponding to an interim decision is checked, then at the time of an interim analysis decision accrual will be stopped, all subjects currently enrolled will be followed-up until they have had the opportunity to observe their final endpoint, and then the final analysis will be performed.</p>
<p>If the check box corresponding to an interim decision is not checked, then at the time of an interim analysis decision accrual is stopped, the data is locked, and no follow-up on randomized patients is collected. The interim dataset is the final dataset. The final analysis is then performed using the same data and model as was used for the interim analysis.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image52.png" style="width:2.96325in;height:0.70635in" alt="Graphical user interface, text, application Description automatically generated"></p>
<p>If the allocation method is selected as, “Arm Dropping” then an additional check box is provided in the Subject Follow-up Options box asking whether the user would like to “Continue follow-up if arm dropped.” If the box is checked, then subjects randomized to an arm that is dropped before they have the opportunity to complete their follow-up will have to opportunity to observe their final endpoint for subsequent analyses. If the box is not checked then incomplete subjects on an arm that is dropped will never have future endpoint values observed.</p>
</section>
</section>
<section id="successfutility-criteria" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> Success/Futility Criteria</h1>
<section id="interim-analysis-criteria" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="interim-analysis-criteria"><span class="header-section-number">13.1</span> Interim Analysis Criteria</h2>
<p>On the success/futility criteria page the user can specify rules for judging the study for futility or success at an interim and at the final evaluation. If the trial has no interims there will be just a tab for the Final Evaluation criteria. If the trial has interim analyses, then there can be tabs that define different early success/futility criteria at the different interims.</p>
<p>At the top of the main tab is a control to allow tabs to be created for different interims. In a newly created adaptive design, FACTS will create a tab for interim 1.</p>
<p>If early success/futility criteria are specified for an interim, then they will be taken to apply to all subsequent interims until the next one for which criteria are supplied, then those criteria will apply until the next interim for which criteria are applied and so on.</p>
<p>Note:</p>
<ol type="1">
<li><p>Early stopping for success/futility only occurs at interims.</p></li>
<li><p>There will be no stopping for success or futility until the first interim for which early stopping criteria have been defined.</p></li>
<li><p>It is left to the user to ensure that the early stopping criteria at any interim are mutually exclusive and it is not possible to stop for both success and futility at the same time. The FACTS design engines will stop the trial but the user should not rely on one or other outcome taking precedence. It is not considered good practice to have success and futility rules that could both be true, so FACTS does not guarantee a “tie break” rule.</p></li>
<li><p>In the output files there are columns labeled “Success &lt;QOI&gt;” and “Futile &lt;QOI&gt;” indicating whether any decision criteria became true, and “Success Combined” and “Futile Combined” indicating if all the criteria for a success or futility determination have been met. If both sets of criteria are met simultaneously, FACTS will only flag one of “Success Combined” and “Futile Combined” as being met, corresponding to how the outcome of the trial has been flagged.</p></li>
</ol>
<p><img src="coreUGattachments/CoreUserGuide/media/image53.png" style="width:5.52058in;height:4.13213in" alt="A screenshot of a social media post Description automatically generated"></p>
<p>Having created a tab to define the early success/futility criteria at an interim, the user has options to delete the tab or to copy criteria that have already been entered on another tab before editing them.</p>
<p>The user specifies:</p>
<ul>
<li><p>Whether early stopping for futility or success is to be allowed by selecting the “Futility criteria” or “Success criteria”</p></li>
<li><p>The stopping rules are specified, by selecting the QOI to be tested, the direction of the comparison and the threshold value for the criteria to be met.</p></li>
<li><p>The user can specify whether, if multiple criteria have been specified, they all need to be meet (Criteria combined using “AND”) or only any one of them needs to be met (Criteria combined using “OR”). These are specified independently for stopping for success and for futility.</p></li>
<li><p>If stopping is allowed, the user specifies what the minimum amount of information (using the information type specified on the Interims tab). This can be specified both in overall terms and information on specific doses. If multiple minimum-information criteria are specified they must all be met for the QOI criteria to be evaluated.</p></li>
</ul>
<blockquote class="blockquote">
<p>Note that stopping is only assessed at interims, not immediately when these criteria are met.</p>
</blockquote>
</section>
<section id="final-evaluation-criteria" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="final-evaluation-criteria"><span class="header-section-number">13.2</span> Final Evaluation Criteria</h2>
<p>On the Final Evaluation Criteria tab, the user can specify rules for judging the study for final futility or final success at its end. The tab layout is the same as an interim Success/Futility tab except there are no minimum information rules to be specified.</p>
<p>The Final Evaluation Criteria are always applied at the time of the final analysis, even if the study stops early for success or futility, and whether or not “Continue follow-up if study stopped for success” or “Continue follow-up if study stopped for futility” are selected. As a result, setting final analysis criteria that are easier to satisfy than interim analysis criteria may result in the labelling of trials that meet the interim analysis criteria but do not satisfy the final analysis criteria as flip-flops.</p>
<p><img src="coreUGattachments/CoreUserGuide/media/image54.png" style="width:5.48603in;height:4.10627in" alt="A screenshot of a social media post Description automatically generated"></p>
</section>
</section>
<section id="trial-states" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> Trial States</h1>
<section id="state-descriptions" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="state-descriptions"><span class="header-section-number">14.1</span> State descriptions</h2>
<p>For the purposes of interims, the different states or stages of a trial are:</p>
<ol type="1">
<li><p><strong>In Burn-in / before first analysis.</strong> In adaptive allocation designs, the burn-in denotes the initial group of subjects explicitly assigned to treatment arms before probabilistic allocation begins. FACTS prevents the burn-in requiring more subjects than the maximum number of subjects – but the numbers can be equal. Regardless of the interim schedule specified (e.g., frequency, number of subjects or number of events), a) no analyses are performed during this period of time, and b) the first analysis is performed at its conclusion. In arm dropping and early stopping designs the first analysis occurs at the explicitly specified initial interim. Interims are never performed in non-adaptive designs; rather, the first and only analysis occurs when the max subject’s final observation is taken. In all cases, it is possible to reach the maximum number of events prior to the first analysis, making the study complete.</p></li>
<li><p><strong>Mid Trial</strong>. Interims are performed and all rules assessed. If arms have been dropped, the per-arm posterior probabilities are still calculated for the dropped arms but the drop decision for the arms is absorbing and not re-assessed.</p></li>
<li><p><strong>Fully Accrued but not complete</strong>. All subjects have been recruited and being followed up. If interims are by subject or ‘interim analysis beyond full accrual’ is set to FALSE, then the only possible next event is ‘last subject final observation’.</p></li>
<li><p><strong>Stopped Early but still following up.</strong> The study stopping rules are not evaluated, but arm dropping rules are. Interims may still occur.</p></li>
<li><p><strong>Complete.</strong> All possible data collected for every enrolled subject.</p></li>
</ol>
</section>
<section id="analysis-trigger-events" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="analysis-trigger-events"><span class="header-section-number">14.2</span> Analysis trigger events</h2>
<p>The following are the events that trigger interims, stopping or changes of trial state:</p>
<ol type="1">
<li><p>Last event is observed (TTE trial with a max number of events – this is the only circumstance that can arise before the end of burn-in / first analysis that can stop the trial).</p></li>
<li><p>A “number of subjects interim” occurs (other than last subject of burn-in / first analysis)</p></li>
<li><p>A “cohort complete” interim occurs (when using cohort enrolment). A cohort complete event is slightly different from a “number of subjects interim” in that after a cohort is fully enrolled the interim does not occur until all the subjects are complete.</p></li>
<li><p>Study max subject size is reached.</p></li>
<li><p>Recruit last subject of burn-in / first analysis occurs.</p></li>
<li><p>A “time” or “number of events” interim occurs.</p></li>
<li><p>Last subject’s final observation is taken (in a TTE trial this might be that the last subject to have an event has their event, or last subject recruited reaches the end of the maximum follow-up and is censored).</p></li>
</ol>
</section>
<section id="trial-state-transitions" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="trial-state-transitions"><span class="header-section-number">14.3</span> Trial State Transitions</h2>
<p>Note: the term “study arms” is used to refer to the treatment arms that are not the control or active comparator arm. In an arm dropping design only the study arms can be dropped, and the trial stops if all study arms are dropped.</p>
<table class="table">
<caption>
<p>
Figure 3‑2 Add Posterior Probability QOI dialog
</p>
</caption>
<colgroup>
<col style="width: 16%">
<col style="width: 17%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 17%">
<col style="width: 15%">
</colgroup>
<thead>
<tr class="header">
<th>
</th>
<th colspan="5">
State transition table
</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>
<p>
Triggers
</p>
<p>
Processed in order …
</p>
</td>
<td>
<p>
<strong>1: In Burn-in / before first analysis</strong>
</p>
<p>
[This is the starting state for adaptive allocation designs]
</p>
</td>
<td>
<p>
<strong>2: Mid Trial</strong>
</p>
<p>
[This is the starting state for arm dropping, early stopping, and non-adaptive designs]
</p>
</td>
<td>
<strong>3: Fully Accrued but not complete</strong>
</td>
<td>
<p>
<strong>4: Stopped Early but following up</strong>
</p>
<p>
[This state can only be entered if “Continue follow-up if study stopped for success/futility is set]
</p>
</td>
<td>
<p>
<strong>5: Complete</strong>
</p>
<p>
[This is the final state]
</p>
</td>
</tr>
<tr class="even">
<td>
A: Last event is observed [can only occur in TTE trials]
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
N/A
</td>
</tr>
<tr class="odd">
<td>
B: A “number of subjects” interim occurs
</td>
<td>
N/A
</td>
<td>
<p>
An interim is output.
</p>
<p>
If arm dropping, check not yet dropped arms to see if any should be dropped and flag those that are.
</p>
<p>
If stopping conditions are met or all study arms dropped then if “Continue follow-up” for the appropriate decision is selected go to “4: Stopped Early” otherwise a “final evaluation” is output and
</p>
<p>
Go to “5: Complete”
</p>
<p>
If the interim size = Max subjects then go to “3: Fully Accrued”
</p>
<p>
Otherwise stay in “2: Mid Trial”
</p>
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
N/A
</td>
</tr>
<tr class="even">
<td>
C: A “cohort complete” interim occurs [for trials using cohort enrolment]
</td>
<td>
<p>
[Can only occur when the final observation of a burn-in cohort is observed]
</p>
<p>
An interim is output.
</p>
<p>
If stopping conditions are met a “final evaluation” is output and go to “5: Complete”.
</p>
<p>
Otherwise go to “2: Mid Trial”.
</p>
</td>
<td>
<p>
An interim is output.
</p>
<p>
If stopping conditions are met a “final evaluation” is output and go to “5: Complete”.
</p>
<p>
If the interim size = Max cohort or the max cohort size is reached then a “final evaluation” is output and go to “5: Complete”.
</p>
<p>
Otherwise stay in “2: Mid Trial”
</p>
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
N/A
</td>
</tr>
<tr class="odd">
<td>
D: Study max subject size is reached
</td>
<td>
<p>
[Can only occur if Burn-in / first interim size = Max subjects]
</p>
<p>
Go to “3: Fully Accrued”.
</p>
</td>
<td>
Go to “3: Fully Accrued”
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
N/A
</td>
</tr>
<tr class="even">
<td>
E: Recruit last subject of burn-in / first analysis
</td>
<td>
<p>
An interim is output.
</p>
<p>
If arm dropping, check not yet dropped arms to see if any should be dropped and flag those that are.
</p>
<p>
If stopping conditions are met or all study arms dropped then ff “Continue Follow-up if study stopped“ for the appropriate decision is set go to “4: Stopped Early but following up” otherwise a “final evaluation” is output and go to “5: Complete”
</p>
<p>
Otherwise go to “2: Mid Trial”
</p>
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
N/A
</td>
</tr>
<tr class="odd">
<td>
F: A “time” or “number of events” interim occurs
</td>
<td>
N/A
</td>
<td>
<p>
An interim is output.
</p>
<p>
If arm dropping, check not yet dropped arms to see if any should be dropped and flag those that are.
</p>
<p>
If stopping conditions are met or all study arms dropped then ff “Continue Follow-up if study stopped“ for the appropriate decision is set go to “4: Stopped Early but following up” otherwise a “final evaluation” is output and go to “5: Complete”
</p>
<p>
Otherwise stay in “2: Mid Trial”
</p>
</td>
<td>
<p>
If “Discontinue interim analysis after full enrollment” is set, then there is no output. Stay in “3: Fully Accrued”
</p>
<p>
Otherwise:
</p>
<p>
An interim is output.
</p>
<p>
If arm dropping, check not yet dropped arms to see if any should be dropped and flag those that are.
</p>
<p>
If stopping conditions are met or all study arms dropped then ff “Continue Follow-up if study stopped“ for the appropriate decision is set go to “4: Stopped Early but following up” otherwise a “final evaluation” is output and go to “5: Complete”
</p>
<p>
Otherwise stay in “3: Fully Accrued”
</p>
</td>
<td>
<p>
If “Discontinue interim analysis after full enrollment” is set then there is no output, stay in “4: Stopped Early”
</p>
<p>
Otherwise:
</p>
<p>
An interim only checking arm-dropping is output. Stopping conditions not checked.
</p>
<p>
If arm dropping, check not yet dropped arms to see if any should be dropped and flag those that are.
</p>
<p>
If all study arms are dropped then if “Continue follow-up if arm dropped” is set stay in “4: Stopped Early” otherwise a “final evaluation” is output and go to “5: Complete”
</p>
</td>
<td>
N/A
</td>
</tr>
<tr class="even">
<td>
G: Last subject’s final observation is taken
</td>
<td>
N/A
</td>
<td>
N/A
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
<p>
A “final evaluation” is output.
</p>
<p>
Go to “5: Complete”
</p>
</td>
<td>
N/A
</td>
</tr>
</tbody>
</table>
<p>Figure 3‑2 Add Posterior Probability QOI dialog</p>
</section>
</section>
<section id="reporting-of-results" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Reporting of Results</h1>
<p>For detailed descriptions of trial output see the user guide corresponding to the endpoint used in the FACTS file.</p>
<p>[1] Screenshots from earlier versions of FACTS 6 are retained only where they are unchanged in FACTS 7.1</p>
<p>[2] This value is in weeks from FACTS 7.0 onwards, previously it was in days.</p>
<p>[3] Simulating its use in FACTS is a good way to achieve that understanding!</p>
<p>[4] Jennison, C., &amp; Turnbull, B.W. (1999). Group Sequential Methods with Applications to Clinical Trials (1st ed.). Chapman and Hall/CRC. https://doi.org/10.1201/9780367805326</p>
<p>[5] NCSS, LLC. Assurance for Non-Inferiority Tests for the Difference Between Two Proportions. In <em>PASS Sample Size Software Documentation</em> (pp.&nbsp;289-1-289–31).Retrieved from <a href="https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/Assurance_for_Non-Inferiority_Tests_for_the_Difference_Between_Two_Proportions.pdf" class="uri">https://www.ncss.com/wp-content/themes/ncss/pdf/Procedures/PASS/Assurance_for_Non-Inferiority_Tests_for_the_Difference_Between_Two_Proportions.pdf</a>.</p>
<p>[6] SAS Institute Inc.&nbsp;2016. Base SAS® 9.4 Procedures Guide: Statistical Procedures, Sixth Edition. Cary, NC: SAS Institute Inc.</p>
<p>[7] “Prior distributions for variance parameters in hierarchical models”, Andrew Gelman, Bayesian Analysis 2006, 1, Number 3 pp 515-533</p>
<p>[8] If the trial has doses that are more closely spaced than usual, a smaller figure can be used.</p>
<p>[9] 1-sided p-value is reported in all the frequentist results. This is done in order to be consistent with comparisons with 1-sided α-values elsewhere.</p>
<p>[10] Dunnett CW. A multiple comparison procedure for comparing several treatments with a control. Journal of the American Statistical Association. 1955; 50: 1096-1121.</p>
<p>[11] Agresti, A. 2002.&nbsp; Categorical Data Analysis. Second Edition. Wiley.</p>
<p>[12] Mee, R. W. 1984. Confidence bounds for the difference between two probabilities. Biometrics. 40, 1175-1176.</p>
<p>[13] Nurminen, M. 1986. Confidence intervals for the ratio and difference of two binomial proportions. Biometrics. 42, 675-676.</p>
<p>[14] It is possible that the approach taken in FACTS is the same as, or very similar to, the MICE “Multiple Imputation by Chained Equations” approach. More research is required to see if this is indeed the case.</p>


</section>

</main> <!-- /main -->
<!-- footer.html -->
<footer>
  <p>© 2024 <a href="https://www.berryconsultants.com">Berry Consultants</a></p>
  <!-- <p>Made with <span style="color: #11A473;">❤</span> and <a href="https://quarto.org">Quarto</a></p> -->
</footer>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>