---
title: "Simulation"
subtitle: "Description of the simulation tab and the results generated by simulations."
format:
  html:
    toc: true
    toc-depth: 4
    toc-title: "Table of Contents"
    number-sections: false
    number-depth: 4
---

The Simulation tab allows the user to execute simulations for each of
the scenarios specified for the study. The user may choose the number of
simulations, whether to execute locally or on the Grid, and modify the
random number seeds.

![The Simulation tab with complete simulation output in the table.](../coreUGattachments/continuous/media/image36.png){#fig-simoutput}

In the Simulation tab the user can provide simulation configuration parameters
like the number of simulations to run, whether the simulations can be run
on the Grid, the parallelization strategy, the random
number seed used in the simulations, and the number of certain output files
that should be kept during the simulation execution.

# Simulation Options

## Number of simulations

This box allows the user to enter the number of simulations that they would like
FACTS to run for each scenario listed in the table at the bottom of the simulation
tab. There is no set number of simulations that is always appropriate.

10 simulations
: You might want to run 10 simulations if you just want to look at a few simulated
trials and assess how the decision rules work and if FACTS is simulating what
you expected based on what you input on the previous tabs. If all 10 simulations of a
'null' scenario are successful, or all 10 simulations of what was
intended to be an effective drug scenario are futile, it is likely
there has been a mistake or misunderstanding in the specification of
the scenarios or the final evaluation or early stopping criteria.

100 simulations
: You might want to run 100 simulations if you want to look at many individual
trials to make sure that what you want to happen is nearly always happening. You
can also start to get a very loose idea about operating characteristics like
power based on 100 sims. 100 simulations is also
usually sufficient to spot big problems with the data analysis such as
poor model fits or significant bias in the posterior estimates.

1,000 simulations
: You might want to run 1,000 simulations if you want estimates of operating
characteristics like power, sample size, and Type I error for internal use or
while iterating the design. This generally isn't considered enough simulations for
something like a regulatory submission. With 1,000 simulations the standard error
for a typical type I error calculation is on the order of $0.005$.

10,000 simulations
: You might want to run 10,000 simulations per scenario if you are finalizing a
design and are preparing a report. This is generally enough simulations for a
regulatory submission, especially in non-null simulation scenarios. The standard
error for a typical type I error calculation using 10,000 simulations is on the
order of $0.0015$.

\> 10,000
: You might want to run more than 10,000 simulations if you want to be very certain of
an operating characteristic's value - like Type I error. And plan to use the measurement
of the quantity for something important like a regulatory submission. The standard error of
a Type I error calculation with 100,000 simulations, e.g., is on the order of $0.0005$.

\> 100,000
: You probably don't want to run more than 100,000 simulations per scenario. Maybe
your finger slipped an hit an extra 0, or you thought there were 5 zeroes in that
number when there were actually 6. If the simulated trial is adaptive, this is
going to take a while.

Each time the FACTS application opens, the "Number of Simulations"
will be set to the number of simulations last run for this design. Not all
scenarios must be run with the same number of simulations. If
completed results are available, the *actual* number of simulations run
for each scenario is reported in the 'Num Sims' column of the results
table. The value displayed in the "Number of Simulations" control is the
number of simulations that *will be* run if the user clicks on the
'Simulate' button.

Note also that if a scenario uses an external VSR file or directory of
external files, the number of simulations will be rounded down to the
nearest complete multiple of the number of VSR lines or external files.
If the number of simulations requested is less than the number
of VSR lines or external files, then just the requested number of simulations are run.

## Start at Simulation

The "Start at simulation" option allows for the simulation of a particular trial seen in a previous set of simulations without having to simulate all of the previous trials in that previous set to get to it.

The initial [random seed](#random-seed) for FACTS simulations is set in the simulation tab.
The first thing that FACTS does is to draw the random number seeds to
use at the start of each simulation. Thus, it is possible to re-run
a specific simulation out of a large set without re-running all of
them. For example, say the 999^th^ simulation out of a set displayed some unusual behavior,
in order to understand why, one might want to see the individual interim
analyses for that simulation (the "weeks" file), the sampled subject
results for that simulation (the "Subjects" files) and possibly even the
MCMC samples from the analyses in that simulation. You can save the
.facts file with a slightly different name (to preserve the existing
simulation results), then run 1 simulation of the specific scenario,
specifying that the simulations start at simulation 999 and that at
least 1 weeks file, 1 subjects file and the MCMC samples file (see the
"MCMC settings" dialog) are output.

## Parallelization Packet Size

The parallelization packet size option allows simulation jobs to be
split into runs of no-more than the specified number of trials that are
run in parallel. If more simulations of a scenario are requested than can
be done in one packet, the simulations are broken into the requisite
number of packets, run, and combined and summarized when they
are all complete. The final results files will look just as though
all the simulations were run as one job or packet.

The packet size must be a perfect divisor of the number of simulations. This is
usually easy since common numbers of simulations are multiples of 100, but don't
try to use a prime number for Number of Simulations or you're stuck with only 2
packet size options.

By default (if the check box with Choose Parallel Packet Size is not checked)
the number of simulations per packet depends on the number of simulations per
scenario. If the number of simulations is less than 1000, then each scenario
is packaged as a single packed and simulated. If the number of simulations per
scenario is greater than or equal to 1000, the default packet size is 10 and
all simulations are decomposed into packets of size 10.

:::{.callout-tip}
### Packetization with VSRs using .mvsr files

If an external file is used to create explicit VSRs (a .mvsr file), then the
packet size should be a multiple of the number of rows in
that MVSR file. Each packet will get passed the entire .mvsr file to run. If
there are multiple .mvsr files with differing numbers of lines then only the
VSR scenarios that have a .mvsr file that has a number of rows that is a divisor
of the packet size will be run. The rest will error. The packet size can then be
modified to get each of the .mvsr specified VSR files to be run.

Care should be taken when packetizing a scenario that includes an
external data file to supply the virtual subject responses; in this
situation, a of copy of the external file is included *in each packet*
which can cause the packetisation process to run out of memory as the
packets are being created. In this case, use a smaller number of larger
packets, such as packets that are 1/10^th^ of the total number of
simulations.

:::

When running simulations, FACTS will create and run as many packets in parallel as there are
execution threads on the local machine. In general, the overhead of
packetization is quite low, so a packet size of 10 to 100 can help
speed up the overall simulation process. Threads used to simulate
scenarios that finish quickly can pick up packets for scenarios that
take longer. The progress bar updates as
simulation packets complete, so the smaller the
packet size, the more accurately FACTS can report the overall progress of
the simulation execution.

## Random Seed

Random number generation plays a huge role in FACTS's virtual patient
generation and statistical analyses. In order to exactly
reproduce a statistical set of results, it is necessary to start the
random number generation process from an identical "Random Seed". Using the
same random seed in the same version of FACTS guarantees that simulated
trials will always be reproducible. Changing the design parameters or the
version of FACTS may or may not remove this reproducibility depending on the change.

Even a small change in the random seed will produce very different simulation results.

In addition to setting the seed, the user can choose whether they want the
"Same seed for all scenarios" or "Different seed" for different scenarios. If
"Same seed for all scenarios" is selected, the subjects generated for each simulated
trial will match for the different scenarios. This induces a correlation among the
simulation output for different scenarios. This can be good if you're trying to compare
operating characteristics for different scenarios, but it can also be misleading. To
disable this option select the "Different Seed" option. If "Different seed" is selected,
then each scenario has its own seed that samples a different set of subjects than any
other scenario. This uncorrelates the simulation output across scenarios, which can
be advantageous if the absolute value of the operating characteristics are more valuable
to you than the comparison of operating characteristics across scenarios.

## MCMC Settings

To set advanced settings for simulation, the user may click the "MCMC
Settings" button, which will display a number of additional specifiable
parameters for simulation in a separate window.

![Advanced MCMC settings.](../coreUGattachments/continuous/media/image37.png){#fig-mcmcsettings}

The first two values specify two standard MCMC parameters --

-   The length of burn-in is the number of the initial iterations whose
    results are discarded, to allow the MCMC chain to reach its
    stationary distribution. Burn-in samples are output in MCMC files if
    the files are output.

-   The number of samples is the number of subsequent iterations whose
    results are recorded in order to give posterior estimates of the
    values of interest.

The third parameter controls the number of MCMC samples taken
after each imputation of missing data using the longitudinal
model. The default value is 1. This parameter only has an effect if
Bayesian imputation is being used to impute missing or partially observed
data. Increasing the value of this parameter allows the parameter estimates to converge
somewhat to a potentially new stationary distribution for each new set of
imputed data. If the imputed data is only a
small percentage of the overall data this is likely unnecessary. As a rough
guide, if it at some early interims \> 5% of the data being analyzed
will be imputed, a value in the range 2 to 10 is recommended to
avoid underestimating the uncertainty. A higher number should be
used the greater the proportion of imputed data.

The next parameter concerns the output of the MCMC samples to a
file. It is possible to have the design engine output the sampled values
from the MCMC in all of the interims of the first N simulated trials
of each scenario by specifying the "Number of MCMC files to output" to be
greater than 0. The resulting files, 'mcmcNNNN.csv', will be in
the results directory with all the other results files for that
scenario. These files include the burn-in samples from the MCMC chains.

The final parameter in MCMC Settings is the thinning parameter. This parameter
will only keep every $N^{th}$ sample taken during MCMC where $N$ is the thinning
parameter. Thinning MCMC samples can reduce the autocorrelation of consecutive
MCMC iterations, which increases the effective samples per retained sample, but
also results in needing many more MCMC iterations to reach the same number of
retained samples. Generally, we do not recommend thinning for standard simulation
runs.

::: {.callout-warning}

### Warning about thinning

Unlike other software that performs MCMC, when you choose to thin by a value,
FACTS does not increase the number of MCMC iterations it performs in order to
retain the value specified in "Number of Samples". So if you leave "Number of
Samples" at its default value, $2500$, and thin by $10$, you will be left with $250$
retained samples. You should adjust for this by increasing the "Number of Samples"
if you choose to thin.

:::

## Results Output

The results output section of the Simulation tab allows for the specification of how many output files should be generated for files that are individually created for each simulation. Summary files (summary.csv) that have 1 line per scenario are always created. Simulations files (simulations.csv) that
have 1 line per simulation are always created. Weeks files (weeksXXXXX.csv), patients files (patientsXXXXX.csv), and frequentist weeks files (weeks_freq_{missingness}_XXXXX.csv) are not created for every single simulation. Instead, the number of simulation specific output files can be set per type. This limits the amount of output files that FACTS will save.

See the endpoint specific descriptions of the output files for descriptions of what the previously mentioned output files report. See [here](./contanddichot.qmd) for core continuous or dichotomous output files, and see [here](./tte.qmd) for core time-to-event output files.

Some plots in FACTS that are created based on weeks files, and if very few weeks files are saved, the plots will not be as accurate or descriptive.

# Run Simulations

Click in the check box in each of the rows corresponding the to the
scenarios to be run. FACTS displays a row for each possible combination
of the 'profiles' that have been specified: - baseline response, dose
response, longitudinal response, accrual rate, and dropout rate. Or
simply click on "Select All".

Then click on the "Simulate" button.

During simulation, the user is prevented from modifying any parameters
on any other tab of the application. This safeguard ensures that the
simulation results reflect the parameters specified in the user
interface.

When simulations are started, FACTS saves all the study parameters, and
when the simulations are complete all the simulation results are saved
in results files in a "\_results" folder in the same directory as the
".facts" file. Within the "\_results" folder there will be a sub-folder
that holds the results for each scenario.

## FACTS Grid Simulation Settings

A user with access to a computational grid may choose to run
simulations on the grid instead of running them locally. This frees the
user's computer from the computationally intensive task of simulating so
that they can continue other work or even shutdown their PC or laptop.
In order to run simulations on the grid, it must first be configured.
This is normally done via a configuration file supplied with the FACTS
installation by the IT group responsible for the FACTS installation.

# Simulation Results

In the center of the simulation tab, the summary simulation results are
displayed. There are many columns of results, these are organized
into related groups of sub-windows, which can be displayed by clicking
on the "Show More Columns" button.

![Options available when clicking on the "Show More Columns..." button.](../coreUGattachments/continuous/media/image38.png){#fig-showmorecolumns}

These windows will show:

All all the columns

Highlights the columns shown on the main tab.

Allocation the columns that report of subject recruitment and allocation

Response the columns that report that estimate treatment response, the
SD of the estimate, the estimate of the SD of the response, the true
treatment response and the true SD of the response.

Probabilities the proportion of times for each dose that it met the
different target criteria (Max, EDx & MED) and the posterior
probabilities for each dose that its treatment response is better than
control, better than control by the CSD and better than the active
comparator.

Stopping Rules the proportion of times the different stopping criteria
were met

Model Parameters the columns that report the estimates of the values of
the model parameters.

Simulation Results | A window that displays the individual simulation
results for the currently selected scenario.

Frequentist results | If frequentist analysis is enabled, the summary
results can be viewed, these are grouped by how missing data has been
treated: Last Observation Carried Forward (LOCF), Baseline Observation
Carried Forward (BOCF -- if baseline has been simulated), Per-Protocol
(PP).

## Right Click Menu

Clicking the Right-hand mouse button on a row in the simulations tab
brings up a short cut menu:

![The menu that appears when you right click on the table within the simulation tab.](../coreUGattachments/continuous/media/image39.png){#fig-simrightclick}

These will respectively:

-   Open a new Windows directory browser window showing the contents of
    the simulation results for that scenario.

-   Open a window that displays the individual simulation results for
    that scenario. The results initially displayed are the 'highlights'
    columns, similarly to the summary results (see below) the results
    columns are collected into sub-groups, windows of these subgroups
    can be opened from the Right Click menu of the Simulation Results
    highlights window.

-   Open a window that displays the frequentist analysis summary
    results. This option is only available if one or more frequentist
    analyses have been selected on the Design \> Frequentist Analysis
    tab. (If more than one analysis has been requested -- using
    different treatments of missing data there will be separate options
    in the menu to display each summary).

-   Open R loading in the result files for that scenario as separate
    dataframes.

-   Opens the FACTS graph control displaying the graphs for that
    scenario.

-   Opens the FACTS graph control that displays the trellis plot of
    graphs of selected scenarios for selected design variants.

## Open in R

If aggregated results files have been created then the Open in R button
will start R and load the aggregated '.csv' files.

If there are no aggregated files then the results files of the currently
selected scenario are loaded. R can also be opened in this fashion by
right clicking on a row in the simulation results table.

When FACTS starts R it writes out an R auto run startup script that
loads the csv files into R as separate dataframes.

## Aggregation

Aggregation combines the csv output from multiple scenarios into fewer
csv files. The Aggregate... button displays a dialog which allows the
user to select what to aggregate.

![Window that appears when aggregating simulation results.](../coreUGattachments/continuous/media/image40.png){#fig-aggregate}

The default location for the aggregated files is the results directory
for the study, but this can be changed.

Aggregation may be performed with or without pivoting on group, or both.

-   Unpivoted files will have one row for each row in the original
    files.

-   In pivoted files each original row will be split into one row per
    dose.

    -   Where there is a group of columns for each dose, they will be
        turned into a single column with each value on a new row.

    -   Values in columns that are independent of dose will be repeated
        on each row.

The default is to aggregate all scenarios, but any combination may be
selected.

Pressing "Aggregate" generates the aggregated files.

Each type of csv file is aggregated into a separate csv file whose name
begins agg\_ or agg_pivot\_, so agg_summary.csv will contain the rows
from each of the summary.csv files, unpivoted. WeeksNNNNN.csv files are
aggregated into a single agg\_\[pivot\_\]weeks.csv file.
PatientsNNNNN.csv files are aggregated into a single agg_patients.csv
file, but they are never pivoted because each row already refers to a
single dose. Similarly the various frequentist results at the summary,
simulation and weeks level are aggregated (if they've been output).

RegionIndex.csv is not aggregated.

Each aggregated file begins with the following extra columns, followed
by the columns from the original csv file:

  -----------------------------------------------------------------------
  Column Name          Comments
  -------------------- --------------------------------------------------
  Scenario ID          Index of the scenario

  Recruitment Profile  A series of columns containing the names of the
                       various profiles used to construct the scenario.
                       Columns that are never used are omitted (e.g.
                       External Subjects Profile if there are no external
                       scenarios)

  Dropouts Profile

  Longitudinal Rates
  Profile

  Dose Response
  Profile

  External Subjects
  Profile

  Agg Timestamp        Date and time when aggregation was performed

  P(TS)                Proportion of trial success (early success + late
                       success)

  P(TF)                Proportion of trial futility (early futility +
                       late futility)

  Sim                  Simulation number. Only present in weeks and
                       patients files.

  Dose                 Only present if pivoted
  -----------------------------------------------------------------------

## Design Report

This button becomes enabled once there are simulation results, it uses
an R script and R libraries to generate a MS Word document describing
the design.

See the FACTS Design Report User Guide for details of what R packages
need installing, how FACTS needs configuring to use the correct R
instance, how the generate_report() function is run, and where the
resulting report can be found.

<!--
# Trial States

## State descriptions

For the purposes of interims, the different states or stages of a trial
are:

1.  **In Burn-in / before first analysis.** In adaptive allocation
    designs, the burn-in denotes the initial group of subjects
    explicitly assigned to treatment arms before probabilistic
    allocation begins. FACTS prevents the burn-in requiring more
    subjects than the maximum number of subjects – but the numbers can
    be equal. Regardless of the interim schedule specified (e.g.,
    frequency, number of subjects or number of events), a) no analyses
    are performed during this period of time, and b) the first analysis
    is performed at its conclusion. In arm dropping and early stopping
    designs the first analysis occurs at the explicitly specified
    initial interim. Interims are never performed in non-adaptive
    designs; rather, the first and only analysis occurs when the max
    subject’s final observation is taken. In all cases, it is possible
    to reach the maximum number of events prior to the first analysis,
    making the study complete.

2.  **Mid Trial**. Interims are performed and all rules assessed. If
    arms have been dropped, the per-arm posterior probabilities are
    still calculated for the dropped arms but the drop decision for the
    arms is absorbing and not re-assessed.

3.  **Fully Accrued but not complete**. All subjects have been recruited
    and being followed up. If interims are by subject or ‘interim
    analysis beyond full accrual’ is set to FALSE, then the only
    possible next event is ‘last subject final observation’.

4.  **Stopped Early but still following up.** The study stopping rules
    are not evaluated, but arm dropping rules are. Interims may still
    occur.

5.  **Complete.** All possible data collected for every enrolled
    subject.

## Analysis trigger events

The following are the events that trigger interims, stopping or changes
of trial state:

1.  Last event is observed (TTE trial with a max number of events – this
    is the only circumstance that can arise before the end of burn-in /
    first analysis that can stop the trial).

2.  A “number of subjects interim” occurs (other than last subject of
    burn-in / first analysis)

3.  A “cohort complete” interim occurs (when using cohort enrolment). A
    cohort complete event is slightly different from a “number of
    subjects interim” in that after a cohort is fully enrolled the
    interim does not occur until all the subjects are complete.

4.  Study max subject size is reached.

5.  Recruit last subject of burn-in / first analysis occurs.

6.  A “time” or “number of events” interim occurs.

7.  Last subject’s final observation is taken (in a TTE trial this might
    be that the last subject to have an event has their event, or last
    subject recruited reaches the end of the maximum follow-up and is
    censored).

## Trial State Transitions

Note: the term “study arms” is used to refer to the treatment arms that
are not the control or active comparator arm. In an arm dropping design
only the study arms can be dropped, and the trial stops if all study
arms are dropped.

<style>
 .table_wrapper{
    /* display: block; */
    overflow-x: auto;
    /* white-space: nowrap; */
    /* min-width: 1000px; */
    width: 100%;
}
</style>

<div class="table_wrapper" >
<table>
<caption><p>Figure 3‑2 Add Posterior Probability QOI
dialog</p></caption>
<thead>
<tr class="header">
<th></th>
<th colspan="5">State transition table</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p>Triggers</p>
<p><span style="white-space: nowrap;">Processed in order…</span></p></td>
<td><p><strong><span style="white-space: nowrap;">1: In Burn-in / before</span> first analysis</strong></p>
<p>[This is the starting state for adaptive allocation designs]</p></td>
<td><p><strong>2: Mid Trial</strong></p>
<p><span style="white-space: nowrap;">[This is the starting state</span> for arm dropping, early stopping, and
non-adaptive designs]</p></td>
<td><p><strong><span style="white-space: nowrap;">3: Fully Accrued but not</span> complete</strong></p></td>
<td><p><strong><span style="white-space: nowrap;">4: Stopped Early but following</span> up</strong></p>
<p>[This state can only be entered if “Continue follow-up if study
stopped for success/futility is set]</p></td>
<td><p><strong><span style="white-space: nowrap;">5: Complete</span></strong></p>
<p>[This is the final state]</p></td>
</tr>
<tr class="even">
<td>A: Last event is observed [can only occur in TTE trials]</td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td>N/A</td>
</tr>
<tr class="odd">
<td>B: A “number of subjects” interim occurs</td>
<td>N/A</td>
<td><p>An interim is output.</p>
<p>If arm dropping, check not yet dropped arms to see if any should be
dropped and flag those that are.</p>
<p>If stopping conditions are met or all study arms dropped then if
“Continue follow-up” for the appropriate decision is selected go to “4:
Stopped Early” otherwise a “final evaluation” is output and</p>
<p>Go to “5: Complete”</p>
<p>If the interim size = Max subjects then go to “3: Fully Accrued”</p>
<p>Otherwise stay in “2: Mid Trial”</p></td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr class="even">
<td>C: A “cohort complete” interim occurs [for trials using cohort
enrolment]</td>
<td><p>[Can only occur when the final observation of a burn-in cohort is
observed]</p>
<p>An interim is output.</p>
<p>If stopping conditions are met a “final evaluation” is output and go
to “5: Complete”.</p>
<p>Otherwise go to “2: Mid Trial”.</p></td>
<td><p>An interim is output.</p>
<p>If stopping conditions are met a “final evaluation” is output and go
to “5: Complete”.</p>
<p>If the interim size = Max cohort or the max cohort size is reached
then a “final evaluation” is output and go to “5: Complete”.</p>
<p>Otherwise stay in “2: Mid Trial”</p></td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr class="odd">
<td>D: Study max subject size is reached</td>
<td><p>[Can only occur if Burn-in / first interim size = Max
subjects]</p>
<p>Go to “3: Fully Accrued”.</p></td>
<td>Go to “3: Fully Accrued”</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr class="even">
<td>E: Recruit last subject of burn-in / first analysis</td>
<td><p>An interim is output.</p>
<p>If arm dropping, check not yet dropped arms to see if any should be
dropped and flag those that are.</p>
<p>If stopping conditions are met or all study arms dropped then ff
“Continue Follow-up if study stopped“ for the appropriate decision is
set go to “4: Stopped Early but following up” otherwise a “final
evaluation” is output and go to “5: Complete”</p>
<p>Otherwise go to “2: Mid Trial”</p></td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr class="odd">
<td>F: A “time” or “number of events” interim occurs</td>
<td>N/A</td>
<td><p>An interim is output.</p>
<p>If arm dropping, check not yet dropped arms to see if any should be
dropped and flag those that are.</p>
<p>If stopping conditions are met or all study arms dropped then ff
“Continue Follow-up if study stopped“ for the appropriate decision is
set go to “4: Stopped Early but following up” otherwise a “final
evaluation” is output and go to “5: Complete”</p>
<p>Otherwise stay in “2: Mid Trial”</p></td>
<td><p>If “Discontinue interim analysis after full enrollment” is set,
then there is no output. Stay in “3: Fully Accrued”</p>
<p>Otherwise:</p>
<p>An interim is output.</p>
<p>If arm dropping, check not yet dropped arms to see if any should be
dropped and flag those that are.</p>
<p>If stopping conditions are met or all study arms dropped then ff
“Continue Follow-up if study stopped“ for the appropriate decision is
set go to “4: Stopped Early but following up” otherwise a “final
evaluation” is output and go to “5: Complete”</p>
<p>Otherwise stay in “3: Fully Accrued”</p></td>
<td><p>If “Discontinue interim analysis after full enrollment” is set
then there is no output, stay in “4: Stopped Early”</p>
<p>Otherwise:</p>
<p>An interim only checking arm-dropping is output. Stopping conditions
not checked.</p>
<p>If arm dropping, check not yet dropped arms to see if any should be
dropped and flag those that are.</p>
<p>If all study arms are dropped then if “Continue follow-up if arm
dropped” is set stay in “4: Stopped Early” otherwise a “final
evaluation” is output and go to “5: Complete”</p></td>
<td>N/A</td>
</tr>
<tr class="even">
<td>G: Last subject’s final observation is taken</td>
<td>N/A</td>
<td>N/A</td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td><p>A “final evaluation” is output.</p>
<p>Go to “5: Complete”</p></td>
<td>N/A</td>
</tr>
</tbody>
</table>
</div> -->
